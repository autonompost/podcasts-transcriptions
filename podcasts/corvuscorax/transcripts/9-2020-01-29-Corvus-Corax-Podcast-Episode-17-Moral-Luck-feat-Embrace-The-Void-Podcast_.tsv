start	end	text
0	4600	In dieser Episode des Podcasts spreche ich mit Aaron Rabinovitz mit meinem schlechten
4600	9440	Englisch über das Phänomen des ganz stupide übersetzt moralischen Glücks.
9440	14400	Eine deutsche Zusammenfassung für alle, die entweder kein Englisch können oder sich mein
14400	17960	Englisch nicht antun wollen, würde es am Ende noch zusätzlich geben.
17960	22920	Wenn ihr diesen Podcast unterstützen wollt oder bei dem Gast vorbeischauen wollt, dann
22920	24480	schaut doch mal in die Beschreibung.
24480	26560	Mit diesen Worten viel Spaß.
30000	55640	Welcome back, everyone.
55640	61920	Today in the 17th Episode of the Podcast, we have a very special guest.
61920	68880	He's the person or entity behind one of my favorite podcasts.
68880	74760	And I think he can introduce himself a bit, if that's okay for you.
74760	75760	Sure.
75760	77040	My name is Aaron Rabinovitz.
77040	85080	I teach at Rutgers University and do Embrace the Void Podcast and the Philosophers in Space
85080	91840	Podcast and generally hang around social medias, trying to get people to argue about
91840	92840	philosophy.
92840	93840	Great.
93840	98920	So today's topic will be moral luck because a lot of the viewers wanted me to talk about
98920	104320	it and that's not really my specialty.
104320	109800	But as far as I'm aware, you have thought quite a bit about the topic.
109800	110800	Am I correct?
110800	111800	Yeah.
111800	112800	I'm certainly obsessed with the topic.
112800	116760	I don't know if I have anything particularly insightful or useful to say about it, but
116760	119600	I can certainly explain why I'm obsessed with it.
119600	120600	Great.
120600	130120	I think that would be even better than just saying something very important.
130120	131120	Fair enough.
131120	132120	Yeah.
132120	137040	No, no, because I think if you're able to motivate some viewers to think about the topic,
137040	145600	I think that will have a more positive outcome than if you just say something that would
145600	150240	finish the whole topic for the viewer.
150240	155320	So just before we really get into the topic, I have to do something that I always do.
155320	158240	I always have a different drink in the show.
158240	161760	It's a really boring drink as always.
161760	169280	Today I have the star drink, orange zero sugar, just so that everyone knows and can
169280	174320	be aware of me annoying them with the sounds of me drinking.
174320	177360	Do you have anything to drink on your end?
177360	183040	So over here it's 11 a.m., so I'm sticking with water at the moment, depending on what
183040	187640	particular podcast I'm recording and what the content is that that can scale up in various
187640	189760	ways towards whiskey.
190760	192240	Okay, great.
192240	195480	So I guess we could just start.
195480	204240	So the first question would be what moral luck is or what moral luck means.
204240	205760	What are we talking about?
205760	213400	Yeah, so moral luck refers to situations where a person is held morally responsible for
213400	216640	something that is beyond their control.
216640	225000	So in contexts where, you know, someone is seen as guilty of a crime and punished for
225000	231600	doing that crime, even though it seems like the fact that they did that crime was beyond
231600	238080	their control in some important way, would be the sort of classic examples of moral
238080	240280	luck.
240280	245760	And the view that I hold is that pretty much all moral judgments are cases of moral luck
245800	249000	because everything is entirely the result of luck.
249320	251160	Everything is just luck all the way down.
251880	258480	And so that raises real problems for someone like me, who also believes that moral judgments
258480	264240	are real and true and apply objectively and that we should care about them.
264440	269080	So how one reconciles those two things, that's that's really tricky dance.
269960	271040	But I think it's good.
271520	276640	Yeah, on that note, I just have a question on your definition of luck.
277080	280920	So what would you define as luck?
281560	286080	Yeah, and so this gets a little tricky to avoid kind of circularities here.
286080	292360	But I think luck refers to things that are beyond our control.
293320	298840	So the sort of textbook examples that we can think of are, you know, if you're playing a
298840	303280	video game or something that has a random number generator in it, right, it rolls a
303280	305440	number that you have no control over.
305640	311320	And that element of luck, you know, shapes the way that the game is played or how how
311320	312880	these kind of games work.
312880	319480	Right. So, you know, other examples of, you know, really cases of really good or really
319480	320640	bad luck. Right.
320640	326000	You happen to be born into a family where you inherit massive amounts of wealth versus
326000	328880	being born into an abusive household, for example.
329840	335160	Right. These are things that I think there's lots of things that we can reasonably say
335160	337440	are beyond people's control.
337840	343120	Those are the things that I think of as, you know, the features of the world that are luck
343600	349240	in relation to me and in relation to other entities.
350560	354920	And then the hard jump is and everything counts as luck.
354920	360160	Right. And like all of the things are things that are beyond your control in an important
360160	368160	sense. OK, so that that actually was one thing that that was quite problematic for me
368160	375760	when I first read about it, because to me it seems like a problem that I also have with
375760	381440	determinism or fatalism, because in a certain way, if you can apply this concept to
381440	385880	absolutely everything, it seems to me very trivial, like the meaning.
388240	392600	It in a certain sense destroys its own meaning.
393800	395640	Its own impact, because.
397360	399560	Right. It cannot not apply.
400480	404960	Well, so there's a tension right between universality and triviality.
404960	411400	Right. Like we have a similar sort of thing in ethics, I think, where, you know,
411600	416600	you want your moral judgments to be your moral premises to be universal.
416600	420600	You want them to apply to everyone in all situations, in all contexts.
420800	423480	And if they don't, that can seem problematic.
424360	429640	But then some folks will argue the flip side of that is you end up with moral principles
429640	432720	that are incredibly trivial in some kind of way.
432720	439080	And then the hard work becomes teasing out if there really is anything that this adds
439080	440160	to the conversation.
440160	445720	Now, here's why I don't think that this is trivial is because I think a lot actually
445720	450720	really does hang on whether or not everything is beyond our control or not.
450720	455280	If it's true that certain things are under our control and certain things aren't, that's
455280	460440	going to have really important implications for how we shape society, how we treat good
460440	461960	people and bad people.
462920	468120	So I don't think that we can say that this is trivial merely in virtue of the fact that
468400	474080	my position is to argue that everything qualifies as luck, because I think that is a
474080	478600	substantive claim that has substantial implications.
478600	479600	That makes sense?
479840	481800	Yeah, it absolutely makes sense.
481800	492560	But I'm wondering if it is really that important, if it would actually, let's say, let's
492560	493760	say you're absolutely correct.
493760	503920	But would it really change anything in the way of how we experience the world, how we
503920	507520	experience moral dilemmas and so on?
508440	509520	I absolutely think so.
510240	516080	I think that there really is a genuine tension, because so here's why the moral luck problem
516080	520960	and Nagle, I think, does a great job explaining this arises because of a natural feature of
520960	526360	morality, which is that we do think that people should only be held morally responsible
526360	528160	for things that are under their control.
528440	531520	That's a natural condition for moral judgments.
531760	537000	Right. If someone took over your body and went on a killing spree with your body, we
537000	540560	wouldn't think that you should be held morally responsible for that killing spree.
541400	547200	So. So I do think it's important and where we see the implications in the real world
547200	550320	would be in things like how we structure our judicial system.
550320	551800	This is the go to example.
551800	557640	Is that like if you think that human beings have a choice and what they did was wrong and
557640	562280	they did it knowing that it was wrong and that they deserve to be punished for that, you
562280	567040	can build a kind of deterrent, sorry, not deterrent, a kind of retributive model for
567040	571720	justice and say, you know, bad people should go to jail because they deserve to be punished.
573040	577280	If you buy my view, right, it becomes much harder to make any sense of the idea that
577280	582680	people deserve to suffer in any kind of way and that if you're going to have a prison
582680	588000	system, which I still think you need in some form, you're going to have to base it on
588280	594760	rehabilitative kinds of principles, restorative kinds of principles, deterrent kinds of
594760	598120	principles rather than a retributive kind of system.
598400	604720	And that'll have implications for how you build that model, how cruel it is, you know,
604760	610640	what what things you allow your prisoners to do during the times that they are in prison,
610640	616560	stuff like that. So I think it definitely has real applied ethics downstream implications.
617320	620680	And on the personal level, a lot hinges.
620680	626200	A lot of us build our sense of I think all of us, whether we try to resist it some, but
626200	631120	like it's a natural feeling to build your sense of self on your accomplishments and
631120	634520	failures, that like these are the things that define you.
634800	639280	And so I think one reason that people are very uncomfortable with this idea that everything
639280	643760	is luck is that they feel like their sense of self slips away.
643760	649280	And it does. And like part of the reality of recognizing moral luck is recognizing that
649280	655600	there is no free will in a robust sense and with it no robust sense of the separate
655600	659800	self that deserves, you know, a bunch of accolades for doing the right thing.
660040	662480	So I think, yeah, it has lots and lots of implications.
663040	667320	So it's great that you mentioned free will, because I was actually wondering if there
667320	674560	really was a difference on the on a systematic argumentative level between the debate
674560	677720	on free will and determinism and moral luck.
678960	681000	Do you think there is any significance?
681520	683480	I mean, I think they're all connected here, right?
683520	691400	I think what we're saying here is determinism is true and it's true for sentient beings
691400	693920	just as much as it's true for non sentient beings.
694320	701080	And as a result, moral luck is pervasive because luck is pervasive and we continue to
701080	702880	make moral judgments.
703120	710920	So this is a fundamental problem and it is a problem because human beings don't have
711160	715960	free will in the robust kind of sense that we want to think that they do, that you're
715960	721760	not you're just not the author of your actions in the way that would be necessary for it
721760	729080	to be true that you did something wrong in a way that was that was radically independent
729080	731960	and so should be punished in a retributive kind of way.
733800	740040	OK, because to me it was kind of confusing, because when you take a look at the
740040	744680	arguments, how determinism works and how moral luck works, they seem to me to work
744680	747520	on two different different levels.
747520	754080	Determinism is trying to argue from the position of the thing in itself.
754080	760480	If you would like to make this distinction and moral luck is more arguing from the first
760480	765960	person perspective, it seems to me, because luck seems to be a rather strange category
765960	767240	when it comes to determinism.
767720	772800	Mhm, well, so I think it's interesting that you bring that up, because the moral luck
772800	780360	paper that you read is in Nagel's book, Mortal Questions, and he sort of views the unifying
780360	786360	problem of that book, of which moral luck is one version of the problem, as an unresolvable
786360	790960	tension between the subjective way of seeing the world, the way of seeing the world from
790960	795560	our inside first person perspective and an objective account of the world.
795560	798240	The world is seen from the view from nowhere.
798240	804760	And basically the problem is, maybe debatably, from our subjective point of view, we can't
804760	806120	help but see ourselves as free.
806120	810840	Actually, I don't fully believe that, but I think Nagel probably did, or he says that
810840	814880	he does at the end of moral luck.
814880	823560	And so some folks are really concerned that there's no livable way to fully deny the
823560	829840	idea of free will, to deny the idea of the independent, subjectively experiencing self,
829840	832680	to reduce it down to the purely objective.
832680	837360	And I think there are ways in which they're correct about that with regard to phenomenal
837360	840760	consciousness, but not with regard to free will.
840760	847880	I think that the reality is, we are just parts of the large, radically interconnected
847880	850600	system of causal events.
850600	858200	Now, I want to also address your point in terms of unpacking a little bit more the features
858200	863200	of moral luck that Nagel puts forward, because you're right that some of them aren't put
863200	867080	in this necessarily strictly determinist way, though I think that they are just sort of
867080	870880	unpacking forms of determinism.
870880	874040	So he lays out four different kinds of luck.
874040	878920	He talks about luck of consequences, luck of how your actions turn out, right?
878920	886600	He talks about luck of circumstances, what situations that you are facing in your life.
886600	890560	He talks about luck of constitution, which I think is the most important one that he
890560	891560	talks about.
891560	896840	And that's the one that really undermines free will in a robust sense.
896840	901400	And then that's the luck of what makes you who you are, what the features that you happen
901400	902760	to have.
902760	908560	And then there's a fourth one, which often gets dropped out because it's probably exhaustively
908560	913920	accounted for by the other ones, which is essentially the luck of antecedent circumstances,
913920	919560	which is to say, you know, every events are the result of prior events.
919560	922680	And so that one is basically just determinism, right?
922680	927160	It's just saying, you know, we are part of the deterministic framework.
927160	934000	But the value of his argument is the unpacking of that in terms of the nature of constitutive
934080	941240	luck and how it erases any room for an independent, freely acting self.
943240	947600	OK, so you already answered the question of different types.
949600	950600	No problem.
951480	955520	I think it's good that there's a dynamic in this discussion.
957680	963680	Do you yourself think that there are any epistemic problems, any serious epistemic
963680	967120	problems with this position?
968080	972880	Well, yes and no, I guess is my answer to that question, right?
972880	979200	I think there are massive epistemic problems whenever you're talking about conscious
979200	984040	sentient beings and what they are experiencing or not experiencing.
984320	990440	I don't. So like, I've been wrestling myself with this question of do I have, you know,
990440	994480	like I can tell you, I believe that I am not a free agent, right?
994480	998200	I do not have free will, but I'm mouthing those words to you.
998200	1004120	Do I know that I actually believe that or is there some part of me that still clings
1004120	1006440	to the idea that I am actually free?
1006440	1010840	There are some people who will argue that, like, I am committed in every action to
1010840	1013600	still believing that I am free in some kind of way.
1013800	1018440	I don't necessarily think that's true from a logical argumentative side.
1018640	1023120	But there's also the psychological question of, you know, am I still clinging to this
1023120	1028400	habituated idea that I am a free, separate entity when I go around continuing to
1028400	1035040	enact behaviors that, you know, are things like praising and blaming other people?
1035040	1038840	Because I will still go around and say, you know, great job for doing that other thing,
1039080	1043600	right? I think that I can make a sense, reasonably explain why I'm doing that
1043600	1046320	without appealing to personal freedom.
1046920	1049680	But it is a habit that is associated with that.
1049680	1052040	And so, you know, we are creatures of habit.
1052440	1054000	That's part of the whole argument here.
1054240	1060120	So, like, it may just be part of my luck that I will continue to always believe that
1060120	1065160	I'm free, even when I have solid arguments, I think that I am not.
1065400	1067560	If that were true, that would be really unfortunate, right?
1067560	1071280	Because that's like saying you're stuck believing false things that you know are
1071280	1073440	false, which we hope is not the case.
1073480	1076560	But that could be the bad luck that a person has.
1077400	1083520	And I'm not even sure how I prove either to myself or to other people that I genuinely
1083800	1085360	have adopted this belief.
1085640	1089400	So, like, that's about as big an epistemic problem as that you can get, right?
1089400	1093320	You don't even know if you're holding a belief or whether you can prove it to yourself
1093760	1098200	or anyone. I think that, like, I have reasonably good reasons to think that I have
1098200	1101880	adopted the no control, no free will view.
1102240	1106760	I'm not convinced that I have any good way to convey that to anyone else in a convincing
1106880	1113000	fashion if they don't sort of also buy my no free will view and then sort
1113000	1116600	of infer that I'm really genuinely believing it.
1118320	1120360	So that's that's one major problem, right?
1120360	1125080	I guess, you know, other problems are, of course, I can't prove that none of you are
1125080	1127240	free and it's not just me that's the freak here.
1127560	1129960	Right. That's that's another major problem here.
1129960	1132000	But like, I think the argument is sound.
1132040	1137000	Like, I think there's there's no way to point to anything that anyone does that
1137000	1140920	isn't incredibly coded in luck and just luck all the way through.
1144480	1151080	Would you then agree that you have to presuppose certain positions concerning,
1151320	1156840	for example, the construction of reality?
1156920	1164600	How how reality at its base is built some ontological presuppositions for that?
1165600	1172200	I mean, so I guess it's possible just on the topic of sorry, sorry.
1174400	1179360	Just on the topic, for example, of of the philosophy of science, for example,
1179680	1185320	because for me it's just like most deterministic accounts nowadays.
1185320	1191680	It really sounds like an argument from the point of view of science or something
1191800	1195280	that is approaching science methodologically.
1197240	1202040	Well, I think it is. Yeah, I mean, I think it is an argument bolstered by
1202120	1206520	empirical evidence, but I also think that it's it's an argument that can be done
1207000	1213000	without appeals to science would be my I mean, like, I think you could give a
1213000	1218240	philosophical argument that isn't empirical in nature or fundamentally
1218240	1221120	empirical in nature. Maybe it's a synthetic a priori kind of thing.
1221120	1228000	But like, I think it's I think it is the case that we have an argument for this
1228240	1234520	that isn't just assuming certain things about the nature of reality any more
1234520	1236680	than like any other argument is right.
1236680	1240360	Like, I think you can have radical skeptical concerns about all our beliefs.
1240360	1245600	Like, if if the universe turns out to just not be a consistently behaving thing,
1245880	1247640	then like everything is out the window.
1247880	1252440	But like, I think we have good reason to think that the universe behaves
1252440	1257960	according to consistent patterns and that determinism is the view that like
1258360	1265960	those consistent patterns involve some sorts of stable relations between things
1266960	1272600	and that once you have that, the problems arise pretty much immediately.
1273360	1279040	So I don't I don't think that it's presupposing anything that is implausible.
1279040	1282760	I think it's presupposing things that are essential for the universe as we
1282760	1286880	experience it being the way that we experience it in a Kantian kind of sense.
1287840	1295520	OK. So to take a step back for everyone who's who's listening and who's trying
1295520	1301440	to get into the topic, where should one start to read, for example?
1303600	1305920	Yeah, so I would start with the Nagel paper.
1305920	1309640	I think Thomas Nagel's Moral Luck paper is and you can get it.
1309920	1311360	It's easy to find Google online.
1312800	1315880	It's short. It's a little it's a little hard language.
1315880	1319000	It's not the easiest philosophy language ever, but it's also not the hardest
1319000	1320840	philosophy language either.
1321000	1327120	And I think that some of his prose are quite eloquent in laying out the problem,
1327120	1331640	especially like the parts about two thirds of the way through, where he talks
1331640	1338560	about how when you really take into account constitutive luck and how everything
1338560	1343960	about you is the result of factors beyond your control and therefore every action
1343960	1347800	that you engage in is the result of factors beyond your control.
1347880	1353800	He talks about how this shrinks the space of the self to an extensionless point.
1354360	1360320	And I think that that's a really beautiful way of describing how the problem works.
1361080	1363480	So I think the Nagel paper is really good.
1364280	1369600	And then, you know, there's various kinds of analysis of this, but I don't I don't
1369600	1376480	think that anyone has really resolved the problem that he lays out in that
1376480	1377760	particular paper.
1377760	1382520	So I think you mentioned, right, you went and read the paper before that, which is
1382520	1387600	the Williams paper, which I think is good, but I don't think goes as far as the
1387600	1391000	Nagel paper. And then sorry.
1391760	1393200	Absolutely. I totally agree.
1393720	1400120	Yeah. And then there's like one or two individuals whose I'm blanking on the
1400120	1403240	names, but I can get you for the show notes if you want, who've written like
1403480	1407640	books about luck who take, I think, different views than me generally in terms
1407640	1413640	of trying to find, trying to find a way to claim that everything isn't the result
1413640	1416040	of luck rather than biting the bullet the way that I do.
1417520	1421680	I don't know of anyone who's out there who's really willing to go.
1422440	1424600	I don't know. I don't know of a lot of people out there who are going as all in
1424600	1427160	as I am on on this particular side of things.
1427160	1431920	I'm sure there are people out there who do take a similar view, though.
1433840	1437720	Okay, great. Yeah, would would be absolutely great if you can could send me
1437720	1439800	those names.
1441120	1446360	Okay, so I just have something left.
1446440	1454320	I found a definition of luck on the topic that I thought was fairly interesting,
1454320	1456000	and I wanted to hear your opinion on it.
1456040	1460800	Maybe you have already heard of it, maybe not from, I hope I pronounce this name
1460800	1462360	correctly, Nicholas Reschers.
1463040	1463440	Mhm.
1465200	1467120	And I summarize it like this.
1468000	1473000	Something is luck when it is the result of an unplanned event or that the result
1473000	1478600	itself is unexpected, plus the result has a significant evaluative status in
1478600	1480480	representing a good or bad result.
1481360	1482920	So in terms of a benefit or a loss.
1486120	1487760	Yes, there's a couple of features in there.
1487760	1491120	So let's go back to it one more time, just real slow.
1491280	1493320	And I just want to take a part.
1493320	1499000	Something is luck when it is the result of an unplanned event or that the result
1499000	1503240	itself is unexpected, plus the results.
1503240	1504920	Let's hold there for one second, right?
1504920	1508760	So so I don't know if he's going to say that we need all of these features, but
1508760	1513360	I'm not sure why either I'm not convinced that either of those features is
1513360	1516200	necessarily essential for luck.
1516440	1522720	So like, I think that an event that is planned can still be the result of luck
1522720	1529640	if the planning process is itself tainted by luck in a, in a sufficient kind of way,
1529640	1532480	or if the mechanism that is then enacted, right?
1532480	1537960	So if I plan to roll a die, right, the die result is still the result of luck, it
1537960	1538880	seems like to me.
1539040	1542000	Yeah, and your decision to roll the die also and so on and so on.
1542160	1542640	Right.
1542640	1547160	And predictability seems to also, I think, be a bit of a red herring here in the
1547160	1552920	sense that, you know, I think there can be incredibly predictable events that are
1552920	1558080	still the result of factors beyond anyone's control and so fall into the kind
1558080	1561600	of luck that I have in mind here, right?
1561600	1566720	I think your yours and my behavior can be predictable and still the result of luck.
1566720	1572840	So I'm not convinced that that one makes sense either as a necessary condition.
1572840	1573920	So all right, go ahead, go ahead.
1573920	1575200	Why don't you do the other half of it?
1575200	1580320	So yeah, plus the result has a significant evaluative status in
1580320	1582200	representing a good or bad result.
1583960	1586480	The result has a significant evaluative status.
1587680	1589240	I'm not sure exactly what he means there.
1589240	1593480	I guess I would need like an example to think about what, what he's trying to
1593480	1594680	get at with that particular.
1594680	1600960	If something happened, some event took place and either it can be understood as a
1600960	1604400	benefit or a loss, I think that that would summarize it.
1605000	1607520	OK, I mean, yeah, I think, oh, I see.
1607520	1612040	So he's so the criteria that he's putting in there is for it to count as luck.
1612040	1614600	It has to be like a good thing or a bad thing essentially.
1614640	1616880	Yeah, and you have to be able to evaluate it.
1616920	1619160	I think that that is also very important.
1619600	1622320	Yeah, I mean, I'm not sure that's necessarily true either, right?
1622320	1626320	So either it's the case that everything is a good thing or a bad thing, in which case
1626320	1628600	what he's saying is tautologically true, right?
1628600	1633920	It isn't adding anything to the definition or if there are neutral events out there in
1633920	1637920	the world, events that are neither good nor bad, I don't see why they would be any
1637920	1645040	less the result of determinism and therefore any less the result of luck than like it
1645040	1648840	seems like the sort of account of luck he's giving there is very similar to like an
1648840	1655000	anthropomorphic kind of like luck as it pertains to my specific desired outcomes
1655000	1660080	and goals, whereas I think my definition of luck is a much thinner, you know, anything
1660080	1664760	that is beyond one's control, where that's important because what is beyond one's
1664760	1669200	control then does have significant implications when we consider morality.
1671640	1677720	Yeah, OK, I think that those were very good points on this attempt of a definition.
1679080	1684280	Yeah, I mean, I think it's a hard thing to define and like there's tricky sort of weird
1684280	1689440	circularity things about that that I have to try to tease out in terms of what I say
1689440	1692880	when I say, you know, everything is the result of luck because everything is the result
1692880	1700160	of things beyond our control, where luck means, you know, sort of things beyond our control.
1700160	1704280	But I do think that it's that's the right way to unpack luck.
1704280	1707800	And I think Nagel makes a really good case for that as being sort of the right way to
1707800	1713240	understand this. When we are when we are keeping in the front of our mind, what is
1713240	1718760	at stake here in terms of judgments of morality and judgments about the nature of the self?
1722800	1729040	OK. I think we are almost done.
1730360	1732640	That went faster than I expected.
1732920	1735960	Oh, that's no problem. If I may, if we have a little bit extra time.
1736120	1737720	Sure, we have a lot of extra time.
1737720	1741800	Yeah. Well, there's a there's a way that I try to make this argument to try to make it
1741800	1748080	compelling for folks who have, you know, who might be sort of skeptical about this,
1748080	1752520	because usually the response I get is something along the lines of everybody agrees that a
1752520	1757800	lot of things are the result of luck, but there's still a little part of you inside of you
1757800	1760680	somewhere that is still making decisions.
1760680	1767680	And that thing is somehow separate from in the right kinds of ways these endless chains
1767680	1772120	of luck. And that's where free will still exists.
1772120	1773960	That's where control still exists.
1773960	1778720	Right. There's this little person inside at the control panel kind of view.
1778920	1785520	So I want to try to make a case against that for folks who may be sort of sitting in that
1785520	1787000	particular place at the moment.
1787040	1792080	And the way I like to do this is via sort of a Socratic dialogue where I like to ask a
1792080	1794680	person I'm talking to, to give an example.
1794680	1799320	I don't know how convinced you are by my arguments at this point, but if you can remember
1799320	1803840	a time when you weren't convinced by them, if you are, what you would point to as something
1803840	1809800	in your life that is an action that you would say is beyond it was under your control,
1809840	1812600	right, that you would say you were you freely chose to do.
1812600	1826160	OK, so first I want to say that when I presuppose a certain conception of a self, then I absolutely
1826160	1830160	agree with you.
1830160	1839320	The way that I understand the self does not have this homunculi that is able to control
1839320	1849520	anything, but it leaves the possibility for an event that, how do you say, it overcomes the
1851080	1856640	strict determinism of the real.
1858040	1868240	But I would have to have to prepare the explanation for that, because it's not that easy.
1869840	1875040	For me to do this in English just spontaneously.
1875040	1877360	Sure, I understand.
1877360	1883240	But if you take this position, then I would absolutely agree with you.
1883240	1889040	So, but for the sake of my argument, for people who don't agree, is there an action that you
1889040	1895840	would point to as being the sort of thing that you think should be counted as an argument
1895840	1899120	against my position or evidence against my position?
1899920	1911400	OK, I can try to come up with one, but I think that the hypothetical person in this dialogue
1911400	1917480	could take any action as an example.
1917480	1924880	So let's say I bought three apples instead of two because I wanted to.
1925560	1932120	Mhm, yeah, so you're right that I think almost any action can be put forward.
1932120	1935920	And they usually, I think, actually get chunked into two categories.
1935920	1938560	The one you gave would be kind of the trivial category, right?
1938560	1944400	People think that like trivial small actions are independent in some kind of way.
1944400	1948720	And then the other would be like big momentous actions that they think that they spend a lot
1948720	1954000	of time deliberating on, for example, would be the other kind where they think that they
1954080	1956080	have some sort of control over them.
1957160	1963080	And so the way I push back on these kind of examples is I ask them to apply a kind of
1963080	1968760	regress to this, a regress of reasons where I ask them to think, you know, why did you
1968760	1971080	pick the three apples instead of the two apples?
1972360	1977280	For example, I saw a tweet by Matonia, which motivated me to buy more apples.
1978600	1983760	Right. So one account could be, you know, I can point to the thing that got me
1983760	1986320	thinking about having one more apple or something like that, right?
1986320	1990920	In which case the argument runs, you know, it was luck that you happened to see that
1990920	1992600	tweet versus not see that tweet, right?
1992600	1994760	It wasn't under your control in some kind of way.
1995000	2000800	And so that the the motivating causal force in your behavior was this thing that was
2000800	2002520	clearly beyond your control.
2003960	2008640	So that that seems to reduce that down to an example of not freedom in the sense that
2008640	2013200	I'm talking about in my framework or right.
2013200	2017360	The other way this sometimes gets answered is, well, nothing caused it, right?
2017360	2020880	There was absolutely nothing where somebody will try to say there was there was no no
2020880	2024280	thing that that made me pick three instead of two.
2024280	2025920	It just happened. Right.
2027480	2032480	And there it seems like maybe we can call that free.
2032480	2036240	But I think I think the reality is that's still going to be a determined event.
2036400	2041160	You may not be able to point to what I wouldn't I wouldn't say that if nothing caused
2041160	2043120	that it would was really free.
2043520	2047560	Right. And we certainly wouldn't say it's an example of the kind of will that we have in
2047560	2048960	mind when we say free will.
2049200	2055520	Right. We we want our will to be driven by reasons and we don't want to claim that our
2055520	2060760	will is free merely because it can sometimes act, you know, with no reason whatsoever.
2062120	2065120	Right. We want to be able to say our will has reasons.
2065240	2072200	But we chose those reasons and they are us and that we can have, you know, ownership
2072200	2073400	of those reasons.
2073600	2078000	So I don't I don't think that kind of, you know, I rose I raised my left hand side of
2078000	2082640	my right hand is going to be the kind of case that people want to hang their their free
2082640	2083720	will arguments on.
2083880	2088560	And I also think that they are pretty clearly still reducible to, you know, causal effects.
2088560	2092040	Right. If I ask someone, you know, prove to me that you have free will and they raise
2092040	2096080	their arm and say, you know, I proved it by raising my hand, I would say you you raised
2096080	2100440	your hand because you wanted some way to prove that I, you know, prove to me that you had
2100440	2104360	free will. And you in your mind, you were convinced that that would be sufficient evidence.
2104560	2111120	And so you did that action caused by trying to want to prove to me that you have free
2111120	2112240	will in that kind of way.
2113080	2117160	So these regress problems, I think, arise for all of our actions.
2117160	2120000	Right. The big momentous choices.
2120240	2125440	You can still ask, you know, what was your reason for doing this big momentous thing?
2126440	2130720	And they can, you know, if they give the reason, you can then say, well, what about you?
2130720	2138440	What about your constitutive luck made you such that you made you such that you were
2138440	2142240	susceptible to that reason and not all the other competing reasons?
2142240	2146200	Right. Let's say that you you saved someone's life at some point.
2146240	2151640	Right. Like what what caused you to do that kind of thing would be that you had been
2151880	2155480	habituated to be the sort of person who would dive into the water and swim and save
2155480	2157480	someone's life in that particular situation.
2157720	2162640	You were lucky enough to have the physical capacity to do that physical event in that
2162640	2167520	moment. All of these things come together to make it the case that you save that
2167520	2169240	person's life. And it's a good thing.
2169240	2172120	Right. It's morally good that you saved that person's life.
2172360	2177640	But ultimately all of the things that contributed to that event were things that
2177640	2178840	were beyond your control.
2179720	2187800	Hmm. Yeah, I only have one question for the first answer, because to me it sounds like
2188400	2194680	the functionalist description of the self, where you have an output and it doesn't
2194680	2196080	really matter what happened inside.
2196080	2200600	But you have an you have an input that doesn't really matter what happens inside.
2200600	2201600	And then you have an output.
2201680	2205520	So it's this chain of reactions where the internal state.
2208160	2209160	Yeah, OK, sure.
2209320	2212040	No, I didn't know if you've heard that from talking about on the show before.
2212040	2214640	And that was why you were trying to poke at me with this.
2215040	2218880	And so, yeah, so here's what I'll say about that.
2218880	2225840	I it is similar to a functionalist account of the self and that they are both objective
2226040	2229040	accounts of the self rather than subjective.
2229040	2235040	But on my view, I don't think that this is incompatible with there being a phenomenal
2235040	2240840	self that exists and is part of these causal frameworks.
2240840	2244880	So usually when people think of a functionalist account of the self, they think of an
2244880	2250360	eliminativist account, functionalist account that says there is no, you know, robust
2250360	2252240	mental properties or something like that.
2252240	2254520	There is literally just the input output.
2255360	2257480	My view is sorry.
2258480	2265320	I just want to ask if you would then say that in your opinion, the phenomenal
2265320	2269840	consciousness has some form of causal power or if it just is part of the.
2270960	2273840	OK, yes, I reject epiphenomenalism.
2273840	2280520	I think I think that mental states or properties have some sort of causal impact.
2280840	2282440	And that's absolutely great.
2282440	2283880	We agree on that. Oh, yeah.
2283960	2285520	Yeah, no, I totally think that's the case.
2285520	2290320	My view is just the mental properties and states are just as much the result of luck
2290320	2292400	as the physical properties and states.
2292400	2295400	And so they are part of the causal chains.
2295400	2297040	So your beliefs, for example, right?
2297040	2301760	I think that your beliefs have and play an important role in how you act in your life.
2301760	2304680	And they are mental states that you possess.
2304680	2307960	But every belief you have is the result of luck.
2307960	2312120	Everything that you've come to believe is the result of the luck of your education,
2312120	2317920	the location that you were in, your dispositions with regard to like how much evidence
2317920	2322040	you personally feel you need in order to believe a thing or not believe a thing.
2323000	2325040	So, yeah, I think.
2325040	2329040	Yeah, I think the functionalist account is not a sufficient account
2329040	2333800	if it's meant to replace or leave out the phenomenal side of things.
2333960	2336520	But the phenomenal side of things are not indeterminate.
2336680	2340120	They are part of the deterministic framework.
2340120	2341120	OK.
2343240	2347880	I adopt lots of very weird positions and then try to match them together, I suppose, to put this.
2351720	2354040	I don't think that it's really a weird position.
2354040	2357240	I think, actually, that's what a lot of functionalists are lacking.
2359320	2360880	I mean, it comes with cost is what I mean.
2360880	2364280	There's always, you know, like sure, but which position position doesn't.
2364440	2367000	Right, of course, except for trivialism.
2367600	2369960	Right. We could always be very trivialist about this.
2370200	2376560	And like, you know, I mean, I mean, do you know the epistemological position of trivialism?
2377080	2379400	Oh, no. What is that?
2380080	2381680	It's absolutely great. I love it.
2381680	2384400	It's that every proposition is true.
2384400	2386560	Hmm. Interesting.
2387280	2390960	So you can't really disagree with it because they will agree with you that it's wrong,
2391320	2393600	but it's still true because it's not true.
2393600	2397240	Oh, this is the bit from Fiddler on the Roof where it's like, oh, you're right.
2397240	2398560	You're right. Oh, and you're right.
2398560	2400160	You're right, too. Yeah, I know that joke.
2401880	2403800	Yeah, but it's a real position.
2404040	2406440	Yeah, I mean, real. I mean, I'm a discordian.
2406440	2410240	I think everything is true in some sense and false in some sense and meaningless in some sense.
2412560	2417760	And thanks for reminding me to read the Discordia Procipia.
2418000	2419360	Oh, yes. Right.
2419360	2420960	And so here's what I mean.
2420960	2425040	One of the things I will say about like the kind of quietest,
2425520	2430640	you know, unresolvability side of all of this that like,
2431840	2437440	you know, I don't think there's a solution here because I don't think that
2438160	2443640	our sense of self is really reconcilable with the reality as we understand it.
2443640	2448000	So I think the best thing to do is to try to jettison our sense of self
2448000	2452080	and replace it with a more sophisticated framework
2452080	2455920	that keeps front and center in our mind all of these,
2457760	2461360	however you think is the result of luck, because I don't think it changes our behavior
2461360	2468560	in terms of things like humility and how we approach others when they've done things wrong.
2469800	2473520	But it's always going to be an uneasy tension
2473720	2478440	because it's always going to be tricky to figure out how to
2478880	2481720	reinforce people in acting in better ways.
2481720	2482880	Because I like another part of this.
2482880	2485600	I do absolutely think that we should still change people's behavior
2485600	2487520	and think that we can change people's behavior.
2488680	2491280	And so the question is, how do we do that in a way that
2492400	2496360	isn't too like horrifyingly dystopian, right?
2496360	2500680	We still have to kind of respect their autonomy in sophisticated ways, even though.
2500880	2504480	So, you know, one way to read what I'm saying
2504480	2507800	would be to say that I've rejected the idea that humans have autonomy.
2508000	2509360	But I don't think that's the case.
2509360	2514680	I think that you have autonomy in a sense, in the sense of being able to hear
2514680	2518720	arguments and adopt different beliefs as a result of those arguments.
2518880	2521880	Now, whether or not you adopt them is the result of luck.
2522160	2526280	But we should still respect individuals' freedom.
2526720	2528400	You know, we shouldn't try to brainwash you.
2528400	2532080	We should try to convince you, is basically what I'm saying, that there are more
2532080	2536600	or less coercive ways of approaching changing people's behavior.
2536840	2542640	And the reality of moral luck is not does not give us sort of carte blanche to go around
2543520	2547840	reprogramming people because we're all programmed to begin with, if that makes sense.
2548880	2550680	Yeah, absolutely, it does.
2552200	2555200	I think if it's true, it would be
2556200	2558480	really good for everyone to adopt you.
2560800	2561720	I think it's really healthy.
2561720	2566480	I like this is why this is why I'm not sure if I actually believe it or not.
2566480	2570360	But I really do think that the more I've internalized this view, the more I'm able
2570360	2574480	to cope with bad things, the more like,
2576600	2581040	you know, when certain people do certain things.
2581440	2583080	Yeah, the more I can forgive.
2583080	2586520	And it's hard. Again, there's that there's that unrelenting tension of like,
2586880	2590320	I don't want this to become a view that means that no one has ever held
2590320	2592520	responsible for anything in any way.
2592840	2595840	I just think that we have to hold them responsible in the right way.
2595840	2599280	And with awareness of the factors
2599280	2603320	that made them engage in that particular kind of behavior.
2605160	2609480	And also on the on the personal side, that someone should be happy
2609480	2612720	if they do something that is something that they wanted to achieve.
2613520	2616680	Yeah, I mean, they take pleasure, right?
2616680	2618680	Like crazy. You can't resist taking pleasure.
2618680	2621560	So like take some pleasure in the world.
2621560	2624680	And like, I don't think that luck undermines that at all, right?
2624680	2628480	Everything that I find pleasurable, I do as a result of luck, find it pleasurable.
2628640	2629960	But I still find it pleasurable.
2629960	2632120	Like, I still love having this conversation with you.
2632360	2635640	And like, you know, if we're stuck here, you might as well do the things
2635640	2637640	that are pleasurable up to a point, right?
2637640	2639840	There's moral obligations that get in the way
2639840	2641760	and you shouldn't always just do what's pleasurable.
2641760	2645360	So I think like none of this undermines the complexity
2645360	2650480	of moral judgments and like all of the competing factors
2650480	2653680	that go into making good moral decisions.
2654400	2656160	In fact, I think it just makes it harder.
2656160	2659040	It makes it more like you have to recognize that like you're going to spend
2659040	2662400	your whole life wrestling with moral tensions
2662680	2665920	and it's going to be a matter of luck how well you actually do.
2666280	2669240	And that that means that I think that you can like let yourself
2669240	2671400	off the hook a little bit more than some people do.
2671560	2674560	I think it's you know, I think a lot of ethics come down to correctives
2674560	2678120	that like if you if you are, you know, if you have the luck
2678120	2681920	of being the sort of person who lets yourself off the hook too much, do that less.
2682240	2685440	Right. And if you're the sort of person who, you know,
2685920	2688600	you know, beats yourself up for weeks on end, this is what this is.
2688600	2691160	Like why I became an ethicist is because I'm the sort of person who like
2691640	2694840	just, you know, kills myself over and over when I've done something
2694840	2698680	even minorly wrong to someone. I just like it makes me crazy.
2699680	2703320	And so like maybe I've adopted this as a corrective
2703320	2706480	for letting myself off the hook a little bit more.
2708000	2710480	They, you know, we always joke that like philosophers
2710480	2712360	are always always telling you more about themselves
2712360	2714200	than about the nature of the universe.
2714200	2718240	So maybe I'm just, you know, confessing to everyone
2718240	2721720	that I don't have free will and maybe all of you do so.
2722280	2726720	Yeah, but that wouldn't be really a problem, because in the end, as a solipsist, you.
2728240	2729200	Right, I'm the only one.
2729200	2733520	So the rest of you are just figments of my not free imagination.
2733520	2735920	It would actually be horrible if you would be a solipsist
2735920	2738600	who thinks that you are the only one who's determined.
2739560	2741040	I think you just described God.
2741040	2744320	I think that's pretty much how God works.
2744320	2746400	OK, great.
2746400	2749160	I do believe you all are real, though, if it makes you feel any better.
2750600	2755520	OK, when we when we are already talking about what's real and what not,
2756560	2761680	I hope you're aware that I have reappropriated your lightning round.
2762000	2764480	I am, and I approve of this.
2764480	2767080	All ideas are free for everyone.
2767080	2769400	And I modified it a bit.
2769920	2773360	I try I try to have less categories in the end, I had more.
2775880	2776600	It's hard, right?
2777600	2781760	Absolutely, especially because I have a big interest in psychoanalysis,
2781760	2784640	so I can't not ask certain things.
2784800	2788040	Every subset of the every subset of the psychological mind.
2788680	2791960	So how that works, at least from the Lacanian perspective.
2793440	2795520	And I don't know if you've caught this on the show, but I've
2796240	2798800	I've started adding a question at the beginning that I'm finding to be very useful.
2798800	2800400	I have, but I will not.
2800400	2802640	You're not going to ask that. Yeah.
2802640	2804680	OK, fair enough.
2804680	2806560	Do you think that it primes them?
2806560	2809880	I think it's useful, but I don't like doing useful things.
2811440	2813400	I mean, I think there are tradeoffs in doing it.
2813400	2816200	I think it changes their answers and maybe you want the answers to be different
2816200	2819680	or maybe you don't. So I think there's no there's no moral
2819680	2821640	fact of the matter about how to do the lightning round.
2821640	2823480	It's just luck.
2825200	2830040	OK, so I think every viewer is aware of how this works.
2831600	2834840	Just basically I will ask if something is real or not and.
2835960	2839760	You will answer whether or not you think it's real or not,
2839760	2842920	and you will not be able to explain what you mean by that.
2843960	2846600	And I promise that I've done prep work in this.
2846600	2849200	I'm shooting from the hip 100 percent.
2849200	2853040	Would have been hard, because some of them, I guess, you might
2853040	2855640	not really have thought about before.
2855640	2856640	Here's hoping.
2858160	2860480	Is this the first time you have to suffer through this?
2860480	2863400	It is. This is a novel experience for me.
2863400	2866360	Absolutely great. I feel really honored.
2866360	2869600	Yeah, the torture implement is on the other foot.
2871840	2874160	OK, so let's start.
2874160	2877520	The first question would be, is the real lightning round
2877520	2880520	real?
2880520	2882600	Is the real real?
2882600	2885320	Yes, real.
2885320	2888480	So what about the symbolic order?
2888480	2891160	The sorry, the symbolic symbolic order.
2894760	2897600	Yeah, I think symbolic orders are real.
2897600	2900000	And the imaginary.
2901840	2903440	Yes.
2903440	2906560	OK, now a classic one, the external world.
2907440	2909720	Yes, real colors.
2916280	2918280	Honestly, not real.
2918280	2922840	OK, phenomenal consciousness, real, the self.
2926240	2929160	Not real gender.
2930920	2933400	Not real race.
2934400	2937120	Not real species.
2940200	2943920	Said I really I personally struggle with this with this line here, I.
2946320	2948080	I'm going to go with not real, not real.
2948080	2951160	OK, morality, real.
2952360	2955720	More luck, real, pervasive.
2957640	2960600	Rights, real.
2960600	2964760	Borders, borders.
2967200	2969440	Not real.
2969440	2975160	OK, knowledge, real.
2976280	2979880	God, gods or similar entities.
2979880	2982320	Not real society.
2987440	2989560	Real.
2989560	2993400	And just to throw your silence.
2995560	2997240	Real, yeah.
2997240	3000160	OK, fictional characters.
3008240	3011840	Pardon me, really doesn't want to say real.
3011840	3015200	Do I genuinely believe that they are real, though?
3015200	3016960	Yeah, I do. I think I do.
3016960	3018920	Yeah, sure, they're real.
3018920	3021640	Great. Holes.
3021640	3023480	Holes are real.
3024760	3027000	Great. Chess.
3028880	3031000	Chess like the game chess.
3031000	3034440	Chair. Oh, chairs, excuse me, chairs.
3034760	3037200	Chairs are sitting.
3037200	3040440	Yeah, chairs are not real.
3041880	3043760	OK, desks.
3045480	3048080	Desks are also not real.
3048080	3049800	Sandwiches.
3050520	3053560	Sandwiches are not real, definitely not real.
3053560	3055640	OK, science.
3060240	3064400	As far as I can tell, not well, I don't know if I think society is real.
3065520	3067680	Yeah, I think science is real.
3067680	3069840	OK, beauty.
3078480	3080600	I'm just going to be wildly inconsistent and say that it's real,
3080600	3084160	even though I said colors aren't real earlier, I'm doing it.
3084160	3087200	OK, that does not have to be necessarily.
3087200	3089520	I know, I know that it doesn't necessarily be inconsistent,
3089520	3091120	but my justifications for it are.
3091120	3093640	Yeah, linear time.
3093640	3095760	Linear time.
3100320	3102040	That's a hard one.
3102040	3104520	Honest, I'll say not real.
3104520	3107240	OK, the unconscious.
3113000	3114600	Real.
3114600	3117200	OK, unicorns.
3117200	3119200	Unicorns.
3120720	3122440	Is a subset of fictional characters?
3122440	3124240	Sure, yeah, real.
3124240	3126240	Causality.
3126240	3128240	Causality.
3128320	3130320	Not real.
3130320	3132320	Causality.
3132320	3134320	Causality is real.
3134320	3136320	Nothingness.
3136320	3138320	Nothingness is real.
3138320	3140320	Yeah.
3140320	3142320	Great.
3142320	3144320	And the last one would be crows.
3144320	3146320	Crows.
3146320	3148320	Not real.
3148320	3150320	Oh, now I'm sad.
3150320	3153320	Oh, I still like you in a conventional sense.
3153320	3155320	I'm just talking like ultimately you're not real.
3158320	3160320	But it's OK, because ultimately I'm not real either.
3160320	3163320	So like it's not a slight against you, it's we're on the same boat.
3163320	3166320	But the problem is I'm now twice not real.
3166320	3170320	So myself not real and me being a crow.
3170320	3172320	That's very problematic.
3172320	3175320	But it makes you feel better, like I was just clearly wildly inconsistent
3175320	3180320	in my assessment, so like no one should take anything I say remotely seriously.
3180320	3187320	But would being two times not real not be like being real?
3187400	3188400	Oh, yeah.
3188400	3190400	Like two negatives canceling each other out?
3190400	3192400	Yeah, I'd buy that.
3192400	3194400	It's like horseshoe theory.
3194400	3196400	You circle all the way back around to being real.
3196400	3199400	I'm so not real that I'm real again.
3199400	3202400	Horseshoe theory of ontology.
3202400	3203400	Retro-real.
3203400	3204400	OK, great.
3204400	3206400	That's it.
3206400	3208400	Thank you for taking the time.
3208400	3209400	No problem.
3209400	3210400	Thank you for having me on.
3210400	3215400	I always love chatting about moral luck and how absurd reality is.
3215480	3216480	OK.
3222480	3225480	Man spricht generell über moralisches Glück,
3225480	3228480	wenn jemand, der handelt, als moralischer Akteur bewertet wird,
3228480	3231480	obwohl ein signifikanter Teil seines Handelns
3231480	3236480	von Faktoren außerhalb seines Einflusses beeinflusst oder bewirkt wird.
3236480	3238480	Dieser Umstand wirft die Frage auf,
3238480	3242480	inwiefern man jemanden für sein Handeln bewerten kann und sollte.
3242560	3246560	Je nachdem, wie ernst man das Thema moralisches Glück nimmt,
3246560	3249560	ist niemand mehr als gut oder schlecht zu bewerten,
3249560	3252560	da die Person nichts für das Handeln kann.
3252560	3255560	Diese gesamte Argumentationslinie erinnert an Diskussionen
3255560	3258560	über freien Willen und Determinismus.
3258560	3261560	Wie in dieser Diskussion ist auch hier die Position
3261560	3266560	eines harten moralischen Glücks schwer im eigenen Leben umzusetzen.
3266560	3271560	Thomas Nagel hat in seinem einflussreichen Artikel über moral luck
3271640	3274640	vier Arten von moralischem Glück herausgearbeitet.
3274640	3277640	Erstens, resultierendes Glück.
3277640	3279640	Über resultierendes Glück spricht man,
3279640	3282640	wenn alles außer dem Resultat der Handlung gleich ist,
3282640	3285640	also die Intention, die Vorbereitung und so weiter.
3285640	3288640	Und dieses Resultat Produkt von Glück ist.
3288640	3292640	Zum Beispiel, wenn zwei Personen betrunken nach Hause fahren
3292640	3295640	und einer von beiden bringt dadurch einen Menschen um.
3295640	3299640	Wir sollten verstehen, dass es sich dabei nur um resultierendes Glück handelt
3299720	3302720	und beide gleich bewerten.
3302720	3305720	Zweitens, das den Umständen verschuldete Glück.
3305720	3308720	Hierüber spricht man, wenn die äußeren Umstände
3308720	3311720	das moralische Handeln signifikant beeinflussen.
3311720	3314720	Ein Beispiel dafür sind die Menschen,
3314720	3317720	die in Deutschland mit den herrschenden Nazis kollaborierten,
3317720	3321720	es aber, während sie vorher ausgewandert, nicht getan hätten.
3321720	3324720	Wenn diese Unterscheidung im Verhalten auftauchen würde,
3324720	3327720	haben wir es mit dem, den Umständen verschuldeten Glück zu tun.
3327800	3330800	Drittens, konstitutives Glück.
3330800	3333800	Hierbei geht es darum, mit welchen Eigenschaften und Dispositionen
3333800	3336800	jemand ins Leben kommt und aufwächst.
3336800	3339800	Diese Art des moralischen Glücks ist insbesondere
3339800	3342800	im politischen Kontext äußerst relevant,
3342800	3345800	da man hierüber aus einem anderen Blickwinkel über Themen
3345800	3348800	wie Umverteilung, Privilegien usw. diskutieren kann.
3348800	3351800	Viertens, kausales Glück.
3351800	3354800	Dabei geht es darum, wie jemand durch vorherige Umstände
3354880	3357880	Determiniert wurde.
3357880	3360880	Für weitere Informationen, die tiefer gehen bezüglich dieses Themas
3360880	3363880	und neue Einsichten und Kritik vorstellen,
3363880	3366880	kann ich das Buch Moral Luck, editiert von Daniel Stedman, vorschlagen.
3366880	3369880	Es beinhaltet sowohl die klassischen Essays
3369880	3372880	als auch neuere zu diesem Thema.
3372880	3375880	Ich hoffe, die Episode hat euch gefallen.
3375880	3378880	Wenn ja, dann gebt doch eine Rückmeldung.
3378880	3381880	Ansonsten wünsche ich euch noch einen schönen Tag.
3381880	3384960	Tschüss.
