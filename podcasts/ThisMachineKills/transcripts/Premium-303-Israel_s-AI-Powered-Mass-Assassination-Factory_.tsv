start	end	text
0	9920	When a child is killed in Gaza, it's because somebody made a decision that this killing
9920	15320	was worth it to hit another target, and this is according to five sources that I've spoken
15320	17160	with in Israeli intelligence.
17160	22960	In all of the target fires that Israel is bombing right now, the amount of civilians
22960	27520	that are likely to be killed is written down.
27520	32160	After October 7th, there is a total disregard for Palestinian civilian life, even when hitting
32160	37240	targets that are either not distinctly military in nature.
37240	43360	And I think that to look at the civilian devastation that is happening right now in Gaza, you have
43360	47640	to understand that it's a consequence of a particular Israeli war policy.
47640	55840	It is a war policy that has a very loose interpretation of what a military target is, also attacking
55840	58520	people in civilian spaces.
58520	64440	It is a war policy that centers on deterrents and hitting these power targets that are intended
64440	73320	to place civilian pressure on Hamas, and it is a war policy that is increasingly being
73320	78840	helped by the use of big data, automation software, and AI.
78840	86040	My evidence suggests that many, many of the of the civilians who are being killed in Gaza
86040	93080	are being killed as a result of these policies that I do not think are justifiable policies.
93080	96000	International law experts would call them war crimes.
106880	107880	Hello comrades.
108240	111200	It's episode 303 of This Machine Kills.
111200	116320	I'm Jaythin, joined by Ed and producer Jeremy in the future.
116320	120880	It's your premium episode for this week, but I'm just going to say right up off the top
120880	128880	because we are going to get into a topic, into a very long investigative report that
128880	136040	is fucking stunning and shocking to me, stunning in its content, but also as Ed and I were
136200	141760	yelling about before recording, stunning in the fact that nobody else is fucking talking
141760	146800	about it and everyone needs to be talking about it.
146800	151880	While this is a premium episode, largely just because that's how the schedule of our recordings
151880	158080	worked out, we are going to pretty quickly unlock this one for the free feed because
158080	165560	this is something that deserves much wider discussion than it's receiving, especially
165560	173720	among people who like us are constantly crowing about the real material and imminent consequences
173720	182120	of AI and its use by people in power, whether that's corporations or governments, militaries,
182120	184120	whatever it might be.
184120	191760	And yet a lot of people ain't talking about this topic that we got for you all today.
191760	199000	And so we need to, yeah, we need to do our part to at least try to bring some more attention
199000	200000	to it.
200000	203680	So let's set the scene here, Ed.
203680	214780	So about a week ago as a recording for us, 972 Magazine in partnership with Local Call,
214780	225260	So 972 Magazine is a left-wing politics magazine, politics and news magazine based in Tel Aviv
225260	229860	and Local Call is a Hebrew language publication.
229860	237680	So 972 publishes a lot of investigative reporting from a left-wing perspective about Israel
237680	239520	and Palestine.
239520	242900	They're based in Tel Aviv, although they publish a lot of their stuff in English because they
243020	246700	want a big international audience to read it.
246700	248700	They want to draw attention to it.
248700	254020	And they've published in partnership with Local Call, which is a Hebrew language based
254020	268060	outlet in Israel, this just long and stunning report titled A Mass Assassination Factory
268260	272440	Inside Israel's Calculated Bombing of Gaza.
272440	277700	And then the deck here is permissive airstrikes on non-military targets and the use of an
277700	283280	artificial intelligence system have enabled the Israeli army to carry out its deadliest
283280	285660	war on Gaza.
285660	295420	So this is a really long piece on the systems, the technological systems and the military
295420	305220	strategies that are underlying Gaza's current and previous military campaigns, the genocide
305220	312780	that they're waging, the mass destruction that they are committing on Gaza, this AI
312780	318100	system that is really being revealed in this report that we're going to talk about and
318700	326860	strategy underlying that this is what is a really kind of massive foundational pillar
326860	333220	behind everything that we see happening in Gaza right now.
333220	337900	And of course, when there's an AI angle, TMK is going to be on the case.
337900	347180	But this is striking me as not just a little bit of AI sauce on something else.
347180	355500	This is really striking me as a case where Israel and the IDF is really, you know, and
355500	368980	proudly putting AI at the front and center of their strategies, their target making.
368980	374860	They've got this, we'll get into it, but there's like a target administrative system or whatever
374940	385180	it is that is really focused on creating in a really mass produced way targets for these
385180	392700	like one ton bombs that Israel is dropping on high rise buildings, on universities, on
392700	400420	hospitals, on mosque, on open air, you know, flea markets, on schools, wherever they can.
400460	407940	They are claiming at least that this AI system that we'll get into is what's spitting out
407940	414380	all of these targets, right, is giving them, as they claim, 100 targets a day, more targets
414380	420820	than they can keep up with with their bombing campaign, giving out of a total database of
420820	428380	something like 30 to 40,000 individual targets for Israel to airstrike.
428420	432060	There's obviously a lot here, but we'll get into the details.
432500	436580	There's a lot to discuss around the kind of the politics of this.
436580	443220	There's a lot to discuss around the technology of this as well and what what we should or
443220	448740	should not believe in terms of what IDF spokespeople or the IDF chief of staff is saying
448740	451580	and claiming versus what might be the actual fact.
451700	460180	But there is also a lot to be said about how, at the end of the day, there is a really clear,
460660	469980	you know, AI, whether it's an AI powered or an AI alibi, right, justified by AI, there
469980	473980	is a really clear kill chain happening here.
474060	477380	There's a really clear kill matrix happening here.
477540	485540	You know, as we get into this, I think astute listeners might recall some of the reporting
485820	492900	from 10 years ago, you know, in 2013 around the Obama administration's secret kill
492900	499100	matrix, right, or the disposition matrix, the kill list that they had created.
499500	502220	So crazy. They call it the dispossession matrix.
502220	506940	It's like it's some fucking spin off of the dispossessed from Ursula Le Guin, you know.
507500	508500	Oh, my God.
508940	514260	But, you know, this kill list that the Obama administration created to guide their drone
514260	521460	strikes, right, that and so astute listeners might find some really obvious connections
521460	527420	here from the from 10 years ago with the Obama administration's kill list or or I should
527540	532620	say it's the disposition matrix, but it did dispossess a lot of people of their lives.
532620	535300	That's for sure. And then upgrade.
535300	543020	And then what we're talking about now with this AI system that Israel has is very much
543020	552100	a in the direct lineage of the disposition matrix, but is one that, you know, is powered
552100	558380	by machine learning, is taking it to another level, is handing over a lot more decision
558380	564540	making to an automated system, whereas if the kill list, the disposition matrix was
564540	573020	a database, this AI system that Israel has is very much at least in the way that the
573020	579420	IDF is talking about it quite explicitly from both current and former soldiers who spoke
579420	582100	to 972 and intelligence officials.
582420	589980	They are talking about it as a automated system that that that that title mass assassination
589980	597300	factory is not a bit of a stylistic verve that the magazine came up with.
597460	605580	That is a direct quote from an IDF source who called it a mass assassination factory.
605700	611620	Right. And so I think let's get into what this system is, what the underlying strategy,
611620	614060	the military strategy is for this.
614260	616700	But it's it's it's stunning.
616700	622780	It's shocking. And it's even to people like me and Ed, who like our whole job is to not
622780	628820	only know about this stuff, but to like think about it in the most cynical and pessimistic
628820	630140	terms possible.
630300	639940	And so it is always a real a real blow when we read stuff that is beyond even our our
639940	642860	imagination of what's actually going on.
644460	647660	You know, this article and we were talking a little bit about this before this article
647660	655660	sickening on two accounts, right on the first account, right, is that this makes it this
655660	660060	kind of makes me think about all the death and destruction in a slightly more darker
660060	665740	way and that like, you know, these people are, you know, whether or not, you know, because
665740	671260	we still need reporting done on what the AI, what the actual artificial intelligence is.
671260	675140	But like you like you said off the top, it doesn't really matter whether what the
675140	680860	configuration is. Right. This is one of the risk of AI being promulgated like this, which
680860	686260	is that it sanitizes monstrous crimes because data is neutral.
686340	691540	Right. Because a collation via algorithm is neutral because automation is neutral.
691540	692860	These are not political things.
693300	697580	These are categories that are outside of human cognition.
697620	703980	And as thus we can refer to them, we can embody them, we can reinforce them because
703980	707260	they're not flawed, biased, so on and so forth.
707740	712220	So sickening because it probably also reveals an even like greater pathology about the
712220	717340	children that are being murdered, about the, you know, the young men and women that are
717340	723100	being murdered, about the civilians that are being murdered, right, that in one way or
723100	730220	another, not only is there already the racism, incumbent and Zionism, and especially this
730220	736900	genocide of Palestinians, but then there's also this insistence that might emerge even
736900	740900	from people who might not have that or might take pause with that, that, well, you know,
740900	746700	the mass murder is reciprocal and neutral, you know, because the data is just leading
746700	750980	us in that direction. And then on the second count, also sickening in a way that we'll
750980	758340	talk more about later in the episode, just like, you know, this, this is, this is the
758340	763860	fucking fire this time, you know, and what are people doing?
763860	769380	What are people in the AI ethics and the AI risk and the AI safety community saying
769380	774900	about this, about a system where whether or not AI is actually in a role of it, a military
774900	783220	is proudly saying, we named this thing the gospel. It's job, find people to kill. What
783220	791780	does it do? Help us kill as many people as possible. Seems like the worst possible scenario
791780	797940	and the perfect one for all of these industries and cottage factories and all these fuckers
797940	806660	to speak up and say anything. How many have a handful? If that, right, you can, you can
806660	812420	guess if you're sitting at home, you can probably guess who has said literally anything about
812420	818900	this and deals with those fields. And you'd be almost certainly right on those instances.
818980	825540	I guess who would say this? And you'd be wrong because a lot of those people have not said
825540	831300	anything. That is also true. That's another thing to say that there also are some notable
831300	838500	notable signs. Yes. Um, and so it's like, okay, well, what's going on here? You know,
838500	846820	because I find it hard to believe it's either they don't know about it or, you know, as
846820	850180	we have talked about, and as other people have talked about, you know, for example,
850180	855060	Khadija over at logic, my editor, you know, has talked about, there's just like a moral
855780	861460	failure in the core framework about how we think about AI ethics and safety and risk
861460	867300	that makes the framework almost useless, right? Like maybe from an outside in perspective,
867940	873460	we can all agree and understand that things should not be developed mindlessly and that
873460	880020	there are real consequences to taking data that's constructed in biased means and racist
880020	885460	means from a society that has its own politics and its own social relations and its own economics
885460	890420	and its own history and its own culture, that things will bleed through and, you know,
890420	897140	result in the creation of data sets or result in the deployment of weapons and surveillance in
897140	903140	ways that discriminate and hurt certain people. But the industries as they actually are,
903140	911220	AI safety, AI risk, AI ethics, they're corporate captured, you know, industries,
911220	916980	and what are, you know, what are, that are doing what? Soaking up all the academic talent
916980	924100	and critical thinkers and critics, hoarding all the resources and the access to the data and to
924100	930580	the computational infrastructure, right? And sucking the air out of any real critique
931540	934740	of how artificial intelligence is talked about, thought about, deployed,
934740	941940	and integrated into things that leaves us within a moment where these motherfuckers are building a
941940	948660	Death Star, you know, like a literal fucking Death Star aimed at civilians in a place that
948660	954420	they occupy and are doing a genocide in, everybody shuts the fuck up. You know, is this, it's useless.
954420	959140	It's useless. I don't, we don't even need, we don't even need, what more do we need to say about it
959220	962580	other than that? If in the moment where there's a literal genocide happening,
963460	970100	most of them are silent. It's so fucking frustrating. And it's even more frustrating
970100	976740	when you read the piece, right? Because the piece makes it very clear, whatever the system is,
977780	982820	it has massively expanded the capabilities, right? Where in previous operations,
982820	988100	they were happy to get maybe 100 targets a year. And now they're generating as many targets as
988100	993860	they did in a year inside of a day because what they're doing or what they claim to be doing with
993860	1002900	this AI system is that they will take, hey, this is, this is the address of a spokesperson for Hamas.
1002900	1008580	Hey, this is a militant that we know is in this group. Hey, this is like, you know, someone who
1008580	1012820	was spotted at some sort of demonstration or resistance. This is someone we arrested or picked
1012820	1019220	up and saying, okay, this is where they live. This is where they work. Are these places affiliated
1019220	1025860	with Hamas? Probably not. But because this person lives there or works there or has been there,
1026740	1033460	we can blow that shit to shit, blow it to shit. You know, there's just one really striking
1033940	1045140	paragraph. I think it's pretty demonstrative both of the danger in this AI system existing
1045140	1050980	and then also in the fact that we can say that and not get caught up on how much of it is AI or not
1050980	1058180	because at the end of the day, it's a digital system or piece of technology that's being used
1058180	1063140	by people who are already looking for a certain problem to be served in a certain way.
1063220	1070180	Solved in a certain way and they have the solution in the way that they deploy it. So we have,
1070180	1079780	at one point, this guy says, you know, first I'll step back and kind of explain one of the
1079780	1088340	insights of the report. In case you might not have known, you know, and as 972 and local call kind
1088340	1096660	of talk about, there are four categories and targets that are struck by Israeli aircraft.
1096660	1102660	The first are tactical targets, right? And so, you know, these are supposed to be standard military
1102660	1107380	targets. These are arm cells. These are places where weapons are being held. These are actual
1107380	1112260	weapons themselves, rocket launchers, anti-tank missile launchers, launch pits, mortar bombs,
1112260	1117380	military headquarters, observation posts, and so on. The second are hardened underground targets,
1117380	1125220	the tunnels that Hamas uses as well as the tunnels that span through Gaza and underneath
1125220	1131860	Gaza's neighborhoods that are part of the network that brings in goods since Israel's
1131860	1139780	maintaining a blockade. Then, you know, strikes of these targets are not as clear as the first one
1139780	1145940	because a lot of these tunnels are under civilians, right? They're homes. They're actual
1145940	1153380	infrastructure, the centers of their life, universities, hospitals. You know, you strike
1153380	1157700	that, you're going to kill a massive amount of people, right? Not that that's going to stop them.
1158340	1164820	The third are power targets, as they call them, and these are high rises, residential towers,
1165380	1172900	public buildings, right? These are things that where you hit them, you're hitting not just a place,
1172900	1178020	you know, not just a neighborhood, not just a place where people work, but like a center
1178020	1182740	of a section of the life, of the rhythm of a city, of a community, right? You're killing the
1182740	1186340	university, you're killing the banks, you're killing the government offices, you're killing
1186340	1192500	hospitals, you're killing office buildings and commercial areas. You're crippling the city,
1192500	1197460	essentially, right? And you're crippling the ability of people to do anything other than
1197460	1202020	cower in their homes, which you're going to bomb anyway, right? And the idea here,
1202020	1210500	as self-admitted by the Israeli intelligence sources, is that if we hit these power targets,
1210500	1219700	we place pressure on Hamas, that Palestinian society will reject Hamas. Sidebar, war crime.
1220260	1232740	You know, you can't bomb civilians collectively punishing them for something that groups,
1232740	1237060	in this case, Hamas is done, right? Not that that matters, but that will come back to be relevant
1237060	1242180	later. And then the final category are family homes or operatives homes, right? And so these
1242180	1251220	are homes where, these are targets where you suspect one person in that residence is in Hamas
1251220	1258180	or the Islamic Jihad, right? And you bomb it so that you might be able to get that one person,
1258180	1262100	even though as other, and as we'll talk about other reporting reveals, a lot of the times,
1263540	1269140	the houses that people say are, you know, that houses that the IDF says we're holding, one
1269140	1274740	militant or one operative of the Islamic Jihad actually didn't. And in fact, they just killed
1274740	1279380	huge amount of civilians, right? And so 972 writes that, you know,
1280420	1286900	the Israeli army had really been focusing on the third and fourth categories this time
1287620	1295700	in response to October 7th, in response to Hamas' operation on October 7th. And that,
1296660	1300820	they write, according to statements on October 11th by the IDF spokesperson,
1300820	1308660	during the first five days of fighting, half the targets bombed, 1,329 out of a total 2,687
1308660	1313700	were deemed power targets. And so here's the quote. One source said, we are asked to look
1313700	1320180	for high rise buildings with half a floor that can be attributed to Hamas. Sometimes it is a
1320180	1326580	militant group spokesperson office or a point where operatives meet. I understood that the
1326580	1331780	floor is an excuse that allows the army to cause a lot of destruction in Gaza. This is what they
1331780	1337620	told us. If they would tell the whole world that the Islamic Jihad offices on the 10th floor are
1337620	1343940	not important as a target, but that its existence is a justification to bring down the entire high
1343940	1349700	rise with the aim of pressuring civilian families who live in it in order to put pressure on terrorist
1349700	1355940	organizations, this would itself be seen as terrorism. So they do not say it. Yeah,
1355940	1363060	because that's terrorism. That is literally the textbook definition of terrorism. When we went
1363060	1372500	into the fucking Middle East and the phase of the invasions premised on the idea that we have
1372500	1378660	evidence. This is when we were still trying to figure out what the war aims were going to be.
1378660	1384740	We have evidence that Osama bin Laden was responsible for 9-11. Give him over to us
1384740	1389780	in senior leadership who's involved in planning it and we won't invade. Okay. Do you have evidence?
1389780	1395860	Yeah. Will you give us the evidence? No. Okay. Then we're not going to hand him over. It was
1395940	1404100	more or less the exchange in the early years. So we invaded. There are very clear guidelines
1404100	1408980	in international law on what you're supposed to do. You don't have to follow them when you
1408980	1413860	have the largest military in the world. An insistence to follow them is deemed as
1413860	1425860	unpatriotic, naive, simple-minded, apologism for terrorism when in reality it's to present
1425860	1434020	situations like this, where you have Israel bombing, flying anything that moves on anything
1434020	1442100	that moves so that they can do what? Clear out Gaza as part of what is the very transparent
1442100	1446660	genocide of Palestinians so that they can come in and eventually settle the northern and the
1446660	1454740	southern strips of Gaza. So what I was saying earlier about whether or not the role of AI here
1455620	1461220	as it gets fleshed out in future reporting, we see here the thing that we've talked about as an
1461220	1471060	actual risk of artificial intelligence. There's a problem. Israel wants justification for killing
1471060	1477780	as many civilians as possible for clearing out buildings in Gaza, for terrorizing Palestinian
1477780	1484420	society. Solution, argue that the reason you're doing the thing that you've been planning on
1484420	1491300	doing that you have actually been doing for the past few decades is because of a new technology
1491300	1500660	that allows you to collate disparate threads of intelligence and pinpoint with computational
1500660	1510820	sanitation or cleanliness exactly what parts of Palestinian society you need to press on to make
1510820	1517540	Hamas screen because that's really what it comes down to. Whether or not
1518900	1523620	AI, there's an actual real automated system here or it's a bunch of people who still have to review
1524420	1528900	the system and are still doing the final say on everything or it's a bunch of people just signing
1528900	1532900	off. Whatever it is, it's very clear what's happening here, which is one of the things
1532900	1538980	we should be concerned about as an AI risk, which is that people are going to use it to justify some
1539780	1545940	incredibly immoral thing that they're eager to do by saying that, well, the computer is just turning
1545940	1551860	out the numbers. I'm just in the Chinese box. I'm just following orders. I'm just translating
1551860	1558660	reality based on what this thing is finding out there. And that, again, it's just like it's
1558660	1564340	so insane. This is like one of the earliest parts of the article, right? This is one of the earliest
1564340	1572340	and such unambiguous war crime material, AI risk material things, silence, silence from that sector.
1574420	1582500	Yeah, the silence is deafening. Really, truly, the silence is deafening. And you're exactly
1582500	1590260	right here. When we get into, and we will very shortly, more into Habsora, which is the name
1590260	1598020	of this system. And as you said, that translates to English from Hebrew as the gospel, which,
1599700	1604500	talk about the direct link to the episode we just released as well.
1604500	1606180	Yeah, about making God.
1606980	1617460	About making God, using AI to make God, and using AI to justify the techno fascism through
1617460	1628100	religiosity. You name your mass assassination factory, the gospel, as if it is the voice of
1628180	1639620	God telling you where to drop tens of thousands of tons of bombs on all these
1639620	1646180	quote unquote power targets. It's so unambiguous here. It's so unambiguous. And like you said,
1646180	1654580	it doesn't matter if it's truly some AI automated system. Even though, I mean,
1654580	1659860	it is telling, and we'll get to this later as well, that IDF people are explicitly saying
1660420	1668020	that they don't have the ability to closely review all of the outputs from the system
1668020	1675220	because there are just so many, but their whole mandate is quantity. The more targets, the better.
1675220	1681460	And so they are explicitly, which is a total reversal of everybody else who is always talking
1681460	1689460	about how, no, no, no, we have careful human review of the outputs from automated systems.
1689460	1694500	And here the IDF is being like, we don't have time to do all that human review of this shit.
1694500	1695780	We got bombs to drop.
1696420	1700900	There was some guy who was just talking the other day on Twitter about how artificial
1700900	1706660	intelligence is like the printing press, and that it's an inherent good, and everybody is
1706660	1713620	made more intelligent by the proliferation of AI products, goods, and services.
1713620	1719380	And when you mentioned and talk about that quantity over quality element,
1720580	1726580	in some ways it is like the printing press. And in this specific scenario,
1727620	1735700	getting flooded with junk, with bullshit, with bad data. I don't even want to call it bad data
1735700	1741140	because that suggests there's good data that the IDF could use. But getting flooded with
1741140	1746100	information and then using that to just be like, well, we are going to kill them all anyway.
1746100	1755300	So now at least we have nicely tabulated formal categories and zones of attack and targets
1755860	1759940	versus having to ad hoc justify why we did a war crime again.
1759940	1767060	Yeah. And talk about the links to the Obama kill list as well.
1768660	1773940	The IDF is explicitly saying, they explicitly said, we are not being surgical.
1777380	1783140	They are just loving to say the loud part, the quiet part loud right now on all of this.
1783140	1788180	But that is also, I think, really telling here as well where the disposition matrix
1788180	1795620	and drone warfare was designed to be sanitized through its surgicalness. It was supposed to be
1796260	1802260	precise, surgical. We have a kill list of individual targets. We have drones that are
1802900	1810180	dropping smart missiles on people. It's all surgical. It's all precise. It's sanitized.
1810500	1818740	Here, what we have is an AI system, Haspera, which is cranking out more targets than IDF
1818740	1828340	intelligence can keep up with. Those targets are leading. They are the justification.
1830660	1839380	Ultimately, it doesn't really matter if the AI is leading you to the power targets or the AI is
1839380	1845620	the justification for bombing power targets you already want to bomb. At the end of the day,
1845620	1855220	it's the same output where the IDF is claiming that the AI is leading them through this network
1855220	1863300	analysis to these targets. And then all they do is if a target is spit out, then they bomb it.
1863700	1866900	Targets spit out, they bomb it. Targets spit out, they bomb it.
1869700	1877700	It does seem to be a really nice coincidence for the IDF that so many of the targets that are being
1877700	1888660	spit out by Hapsora are targets that their military strategy is focused on. As you said
1889380	1896740	from the 972 reporting power targets, so the high-rise buildings, the universities,
1896740	1904900	the hospitals, the infrastructure. It's not even shock and awe. It's shock and massacre
1904900	1909300	because also the fourth target that you mentioned is the family home.
1909300	1920260	So Hapsora is pointing them to power targets and family homes. It explains why if you are
1920260	1925540	paying attention to what's happening in Gaza, the reporting is constantly talking about,
1925540	1934100	well, Gaza has no more universities. Gaza has no more hospitals. Oh, here's yet another person
1934100	1943220	who has had more than 30 of their family members killed by Israel. The reporting here as well
1943220	1952420	around some of those numbers are mind-boggling. It really puts a material human cost on these
1952420	1961460	systems and strategies. For the IDF for Israel, the technological system and the military strategy
1961460	1968340	are intimately linked together. They are not able to be disentangled. They are serving each other.
1968340	1977540	It's not a unidirectional causal flow where the technology leads to the strategy or the strategy
1977540	1983220	leads. It's bidirectional. It's a relationship. They are mutually reinforcing each other.
1983780	1993620	We can see this in the material human cost that is being reported. We're recording this. It's
1994340	1998260	December 6. I'll just put a time date on it because this is all moving so fast.
2001300	2010260	This is two months after October 7, after everything started. The report that we're seeing
2010740	2021460	and that 972 reports on some of the death toll numbers even just from a month into the war,
2021460	2028420	the massacre, the genocide. There's numbers from November 11 talking about that even by that time,
2028420	2037220	even a month into it, there were over 300 people who had more than 10 family members killed.
2037620	2047700	Then there were hundreds of people who had seven to nine family members killed,
2047700	2057060	hundreds more that had five family members. The death tolls here are only able to be
2057060	2064020	comprehended, I think, as incomprehensible as they are by understanding it as an outcome of
2064980	2073780	the bombing power targets in family homes. It is a military strategy bolstered by, powered by,
2073780	2081780	justified by, sanitized by a technological system that is designed to not just cause
2082340	2090500	mass destruction but wipe out entire family lineages. This is ethnic cleansing.
2090580	2101620	This is Nakba. We have to understand that sanitizing nature of the technology is also
2101620	2110340	a cleansing. It's an ethnic cleansing that we see here. A cleansing by wiping away whole lineages
2110900	2116340	of families, of Palestinian families. You can even hear it when they talk about,
2117140	2122820	you know, for example, they talk about bombing entire neighborhoods. Like you said,
2122820	2126900	how they're not surgical. When pressed about it, they're just like, well, you know,
2127860	2132340	and they've always been, and IDF has always been consistent on this. Neighborhoods are
2134020	2140500	just tamas recruiting grounds. They're terror nests. They're operational headquarters.
2141060	2146100	Civilians are operational assets. Residents inside of these buildings are assets that might
2146100	2150740	be used by the terrorist buildings. Like no one's a person. Everyone's a potential terrorist
2151940	2159220	or a subhuman that's waiting to be purged. And now we have this technological implementation
2159220	2165300	that just so happens to agree with us, right? Exactly. Exactly. And, you know, I want to get
2165300	2173700	into the technology a bit more too. But before, you know, I'll do that right now. But before I do,
2173700	2179860	you know, I mentioned the kill, the Obama kill list. The way this technology works and the way
2179860	2188100	it's being used also really strikes me as being extremely similar to Palantir, right? The network
2188100	2196980	analysis that Palantir has created, which was as we should always remember and always mention,
2197780	2205300	you know, Palantir was created with funding from the, in QTEL, the CIA's venture capital
2206100	2212660	arm. And it was created originally, despite its widespread use now in public health,
2213380	2219540	in finance and policing and mineral extraction, you know, despite all of that,
2220020	2227860	it was originally created for the war on terror. It was created as a tool for the CIA. It was
2227860	2234340	created as a tool for the Pentagon. It was created to do this kind of network analysis,
2234340	2241380	as they call it, to find terror cells, right? And how do they do that? Well, the whole idea
2241380	2248740	is that they were going to create networks of associations with people, right? You create a
2248740	2256500	network of all of the people associated with somebody, all of the addresses associated with
2256500	2264820	them, the locations, the vehicles, everything that you possibly can, every object or relationship
2264820	2270420	that you can associate with somebody, you map that into this big, giant network. And the idea
2270420	2276180	is that through that, you are able to map these terror cells, right? You're able to see how,
2276900	2285300	oh, these people have a vehicle in common with each other. We've got data that at independent
2285300	2294500	times, these three people have used this same vehicle. Okay, maybe that's an Al-Qaeda vehicle.
2295460	2302500	That was the whole idea of Palantir, is to create this network analysis, specifically to map out
2302820	2309220	these terror cells, to map out their associations with addresses, with vehicles, with families,
2309220	2318580	with friends, with whoever, with whatever, with wherever, and then as a way to then create targets
2319460	2329860	to do an enhanced interrogation of, to assassinate, right? Whatever it is that you're doing,
2330500	2338500	all of the terrible things, that is also, it sounds to me like the way Hapsara works is very,
2338500	2346660	very similar to that kind of network analysis, right? I think it's also important to keep in
2346660	2355700	mind all of these technological lineages that we see here, that as absolutely fucking terrifying,
2355700	2364740	horrendous and shocking as this is, it is also not unprecedented. It is very much in a, which
2364740	2374420	means it's not unpredictable either, or unpredicted. It is in a long precedent and lineage of how these
2374500	2378900	technologies are designed, how they're created, and what they are used for.
2378900	2405700	So, let's talk a little bit about 972's reporting on Hapsara so that we can understand as well.
2406580	2412660	We talked about the military strategy here of focusing on power targets and family homes.
2412660	2417780	Let's talk about the technological system that is powering that and justifying that, right?
2418500	2422980	I'm actually just going to quote some from 972 because I think they really clearly
2423620	2427940	lay it out and I don't want to mince their careful wording here.
2428180	2434100	According to intelligence sources, Hapsara, which, as a side note, remember, this translates as
2434100	2441300	the gospel. So, always keep that in mind too. According to intelligence sources, Hapsara generates,
2441300	2448100	among other things, automatic recommendations for attacking private residences where people suspected
2448100	2455220	of being Hamas or Islamic Jihad operatives live. Israel then carries out large-scale assassination
2455700	2461700	operations through the heavy shelling of these residential homes.
2461700	2467860	Side note as well, this is not our common imagination of assassination.
2469780	2478660	We now think of assassination as Assassin's Creed or as Hitman or as Navy SEALs or James Bond.
2479460	2487860	As this thing that happens in secret and with surgical precision, no. For Israel, assassination
2487860	2495700	means heavy shelling of residential homes. It is literally shooting a passenger plane out of the
2495700	2502740	sky not because there's a Hamas operative on the plane, but because a Hamas operative once sat on
2502740	2515140	a seat in the plane. That is what's happening here. Hapsara, as one of the sources explained,
2515140	2521220	processes enormous amounts of data that, quote, tens of thousands of intelligence officers could
2521220	2528660	not process and recommends bombing sites in real time because most senior Hamas officials head into
2528660	2533940	underground tunnels with the start of any military operation, the sources say. The use
2533940	2540340	of a system like Hapsara makes it possible to locate and attack the homes of relatively junior
2540340	2546580	operatives. One former intelligence officer explained that the Hapsara system enables the
2546580	2554180	army to run a, quote, unquote, mass assassination factory in which the, quote, emphasis is on
2554180	2560420	quantity and not on quality. A human eye will go over the targets before each attack,
2560420	2565380	but it need not spend a lot of time on them, said the former intelligence officer.
2566020	2572580	Since Israel estimates that there are approximately 30,000 Hamas members in Gaza and they are all
2572580	2580180	marked for death, the number of potential targets is enormous. In 2019, the Israeli
2580180	2587700	army created a new center aimed at using AI to accelerate target generation. As the former IDF
2587700	2593380	chief of staff said in an in-depth interview with YNET earlier this year, quote, the target's
2593380	2599940	administrative division is a unit that includes hundreds of officers and soldiers and is based on
2599940	2607060	AI capabilities. The IDF chief of staff went on to say, quote, this is a machine that with the help
2607060	2614180	of AI processes a lot of data better and faster than any human and translates it into targets
2614180	2620660	for attack. The result was that in Operation Guardian of the Walls in 2021, from the moment
2620660	2626660	this machine was activated, it generated 100 new targets every day. You see, in the past,
2626660	2632260	there was times in Gaza when we would create 50 targets per year, and here the machine produced
2632260	2639460	100 targets in one day. We prepare the targets automatically and work according to a checklist,
2639460	2645780	one of the sources who worked in the new targets administrative division told 972 and Local Call.
2645780	2651700	Quote, it really is like a factory. We work quickly and there is no time to delve deep into
2651700	2657220	the target. The view is that we are judged according to how many targets we manage to generate.
2658100	2665220	So, I mean, that's Hapsara in a nutshell. That's the gospel in a nutshell. It is about
2665220	2673220	maximizing. Calling it a mass assassination factory is actually the most apt description you have
2673220	2681060	because it is truly about mass production. It is Fordism for genocide, right? It is about maximizing
2681060	2688980	the quantity of target generation and then responding to those targets in an automated way
2688980	2695380	of, you know, as I said before, target generated, bomb dropped, target generated, bomb dropped,
2695380	2702020	and you just, and the whole job is to keep up with the factory line, spitting out targets,
2702020	2710260	no review, no oversight for quality, no concerns about the morality or legality of it, right?
2710260	2716500	But instead, the AI provides justification. You know, the AI is giving you targets of
2716500	2722900	her mass operatives. It's not our fault that they use human shields, whether it be
2724180	2730500	their own families or hospitals or schools or mosque, you know, it's not our fault,
2730500	2736340	but we got to kill the Hamas operative, you know, and so if we have to, you know, hey,
2736340	2742020	we're not the one holding the human shield, right? But we are blowing it apart. I mean,
2744100	2749940	this is what's happening here, right? I think, you know, to go back as well to some of the real,
2749940	2757620	the deafening silence of the fact that people are, like, why are the people that we follow,
2757620	2764580	the people that are in our networks, the people we know, who are, like, always, who are so concerned
2764580	2771140	about the ethics and politics and impacts of AI, why is this not the thing everyone is screaming
2771140	2776020	their head off about right now? Or at least linking to the article, right? I've not even seen
2776020	2783860	people link to the article, you know, like, why? It doesn't make sense to me, especially when,
2783860	2792420	you know, if you consider how much attention it receives, how loudly people crow
2793380	2799940	when, and rightfully so, whenever there's a similar kind of automated system that is
2800980	2808420	targeting people for welfare fraud, right? And like, as we've seen, as we see in recent reporting
2808420	2814420	in France, as we talked about with the Dutch algorithm, as we've talked about with Australia,
2814420	2818420	as we talked about in the US, right? Like, as we've talked about in the UK, right? These systems
2818660	2824340	exist all over the place, right? These AI systems or automated systems that target people
2825540	2834020	with risk scores, label them as welfare frauds, and then deny them their welfare benefits,
2834020	2842340	trap them in these labyrinthine bureaucratic systems, deprive them of the resources and aid
2842340	2848820	that they not only need, but are due, right? That they deserve. Anytime that happens,
2849460	2856420	there is so much attention to it, right? There is so much writing about it, you know,
2856420	2862020	yelling about it, and rightfully so. It's truly awful. And yet, when we see a system that is
2862020	2867700	doing much the same, but not to deprive you of welfare benefits, but to deprive you of your life,
2867700	2874100	to deprive you of your entire family, to deprive you of your communities, to deprive you of your
2874100	2880420	land, to deprive you of everything that you have, and everything that you will ever have.
2881460	2888020	When we see a system doing that, people just are suddenly clamped up, you know? Are they too
2888020	2897220	shocked to talk? Why is it that it seems to be more morally reprehensible to deprive a Palestinian
2897220	2903780	of their welfare benefits than it is to deprive them of their life and their whole family? Why?
2903780	2913300	I don't understand. Have we reached the limits of politics where it is so horrendous that we
2913300	2919540	can't even speak of it? Have we reached the limits of morality and legality where actually,
2919540	2924980	this is justified, that the people deserve it, that, hey, I can see both sides of the issue,
2924980	2932660	and it's a land of contrast? None of that holds water for me. I don't understand.
2933940	2940580	I mean, it's cowardice, right? I mean, it's cowardice. Khadijah wrote a long time about
2940580	2948180	this in an article that I think got a lot of people to pay attention to. It was called
2948180	2952660	on the moral collapse of AI ethics, right? And it was talking about how a lot of people are
2952660	2962100	focusing on the firing of Timnit Gebru and the firing shows that Google is fucked, right? But
2962980	2969060	there are also other questions and debates and discussions we should have, like the fact that AI
2969060	2973540	ethics is a fundamentally limited thing, especially if we're talking about AI ethics in Google.
2974740	2980820	We've already lost the plot if we think that a firing at Google is the problem, because the
2980820	2992180	problem is even larger than the fact that Google has a specific engagement with the AI ethics
2992180	2998500	community, right? It scales up to the fact that even our ideas about what AI ethics looks like
2998500	3004900	are just nonsense, right? Because they don't begin with a fundamentally antagonistic relationship
3004900	3013140	or engagement towards how capitalism and specifically racial capitalism has created
3013140	3019940	and spurred along the development of deeply discriminatory and exploitative and extractive
3019940	3025220	technologies. We talk about it all the time. Most of the technology we have in this world
3025220	3031780	that people crow about is just an exotic way to surveil on another person or to kill another
3031780	3037300	person. That's most of the shit. That's most of the shit that everyone is excited about all the
3037300	3042580	fucking time, right? And so when we are over here talking about AI ethics, a lot of the time it's
3042580	3046420	like, well, how do we make a more humane way of killing other human beings? Or how do we make a
3046420	3052980	more humane way of surveilling other people, right? Fundamentally. And to lose sight of that is to have
3052980	3060660	lost the plot. And most people in that field or industry in one way or another have lost the plot,
3060660	3065700	which is not to say there are a lot of people I know and respect who are in these fields,
3065700	3071620	right? But the ones whose work I really love and look to and read and think about are also grappling
3071620	3076820	with the fact that there are fundamental limits here, right? And that the real problem is how do
3076820	3082260	we get out of it? What's the off ramp? How do you get out of this stupid fucking discussion?
3082260	3089060	Well, the question is, do we do a one-year moratorium on Apple's facial recognition software
3089060	3094260	inside of its ring surveillance cameras that it gives to police departments for free or a two-year
3094260	3102580	moratorium instead of why the fuck is a delivery company giving surveillance cameras to police
3102580	3111460	departments and giving them facial recognition software when it's misidentifying black and
3111460	3115700	brown people at a ridiculous rate? Why is that? What's going on there? Well,
3118660	3124660	good luck really having a great discussion with that. And even, as Skedija points out,
3126340	3130420	even the engagement that we do get with that in the form of surveillance capitalism
3130420	3138420	falls short. The idea of surveillance as a service is still fundamentally blunted once
3138420	3142660	she writes that the larger point is even our language is failing us because we're too often
3142660	3147220	fighting to save a democracy that modernity has foreclosed. We need a radical reframing away from
3147220	3153540	the lone researcher against Goliath to reckon with the failures of fairness, accountability,
3153540	3158820	transparency, and broader ethics frameworks that have allowed opportunists to build their brand,
3158820	3164100	taking up space required to address the core issues of big tax hegemonic violence as described
3164100	3173860	in Timnit's paper. I'll also quote at length because I think that I really encourage you to
3173860	3177940	check out the writings from a few years ago, but it's still poignant. I think about it,
3177940	3182500	think about it especially with this piece. She writes, if you were shocked by the firing
3182500	3186900	of Timnit, you haven't been paying attention. We need to fucking take responsibility for the
3186900	3191780	present because while you're immobilized, debating whether if you're the one who should mention the
3191780	3197380	corporate diversity, equity, and inclusion lexicon inherently decoupled from political
3197380	3205140	economic analysis is half the problem. The most opportunist and or mediocre are defining the
3205140	3210980	discourse on a global stage. We're ruminating about Jeff Deans' feelings instead of building
3210980	3218180	a cross-class labor movement that defines tech workers broadly, i.e. researchers, engineers,
3218180	3223300	Uber drivers, Amazon warehouse workers, content moderators, etc. We should cry out,
3223300	3228100	not because Timnit is a brilliant scientist who shaped her field, but because her firing
3228100	3233700	is a symptom of a broken society we've constructed. She isn't fucked, we're all fucked.
3234500	3237780	The academics and computer scientists claiming they will no longer volunteer their free labor
3237780	3242900	when it comes time to reviewing Google academic submissions should be commended. Whoever they
3242900	3247780	should ask themselves, what is it about the high-minded ideals of unimpeded academic freedom
3247780	3252900	that were so divorced from the praxis that research was enabling? Saying that phrenology
3252900	3259140	was conducted rigorously is insufficient. That issue isn't Google or language models or Jeff
3259140	3264260	Dean, rather it is a field that has sold itself to industries that are killing people. That is the
3264260	3273460	crux of the thing. That's where it comes down home to. Israel is a perfect either representation or
3273460	3284180	mirror in our own tech industry. I'll start with Israel first. As we had Anthony Lowenstein come
3284180	3288740	on to talk about the Palestine laboratory, one of the indispensable roles that Israel plays
3288740	3295460	in the world is that it battle tests surveillance tech and murder tech on Palestinians and then
3295460	3300340	exports it to autocratic regimes around the world to suppress minority populations.
3301300	3310580	As the climate begins to get worse on climate refugees, silence on that as well as a refusal
3310580	3319300	to acknowledge that axis of oppression that's going on is a lot of things, but we should also
3319300	3326420	understand fundamentally is moral cowardice. Part of that is also because the same fucking
3326500	3335860	thing happens here. The largest sources of legitimacy in the tech industries and in
3335860	3341060	various fields attached to the tech industry come from how close people are to the money
3341060	3350260	that's being generated from selling yourself to an industry that kills people. How much money
3350260	3355780	are you going to be making if you're helping train these drones or do the network analysis
3355780	3361300	that helps with this targeted assassination or help militarize this or that technology and
3361300	3368260	application in the field? What kind of innovations to surveillance as a service can you offer
3369140	3375220	both in terms of the advertising model and also in terms of also just surveillance as a product
3375220	3382100	that will allow you to tap into other aspects of people's daily lives? We can talk about the
3382100	3387140	surveillance products that Amazon rolls out without dipping into the limited surveillance
3387140	3392260	capitalism thing because we can talk about the fact that, again, the ring cameras.
3393300	3398260	What is a ring camera? A ring camera is not simply like a little surveillance camera
3398260	3404340	that is offered as a product divorced from reality that you get to buy. A ring camera is a pretty
3404340	3410340	smart move that ends up playing roles intentional and growing to fill unintentional ones with a
3410340	3415540	little nudging. When you have a ring camera, you're part of a process where this company gives them
3415540	3421460	to other people, departments for free, and gins them up in marketing as, look, you live in an
3421460	3429860	unsafe place. You should have surveillance so that you can protect your property, you can protect
3429860	3434980	your packages, you can protect your family, ignoring that, for example, a lot of the people
3434980	3439380	who get them are in places that are already relatively safe and also that a lot of people
3439380	3448260	who use them are using them to surveil packages that, if you lose them, Amazon refunds you
3448900	3453380	and you can get them, again, no questions asked. You could get the thing, take it into your home,
3453380	3458020	say you never got it, and they give it to you, no questions asked. But besides the point on that,
3458020	3463140	also, you're getting then ingratiated into this network where the idea is we should all be
3463140	3470740	encouraged in one way or another to sign on to these forms of surveillance as they help out
3470740	3481780	Amazon. Sometimes that means disciplining or surveilling delivery workers who are already
3481780	3488580	overworked and underpaid and over-exploited. But then Amazon has created a Byzantine legal
3488580	3492340	structure to keep hands distance at, so maybe it doesn't have as much control as it might want,
3492340	3499140	but has more control than it should. Well, the surveillance camera has now allowed people inside
3499140	3504740	of their homes with the Ring cameras to act as another boss that they have to deal with
3504740	3509620	while they're still being kept away from Amazon as not being an actual employee of Amazon.
3511140	3517540	The Ring camera ends up growing and expanding because Ring is going here and saying,
3517540	3521220	look, Amazon is going here and saying, we have a piece of technology.
3521220	3525220	And the thing that we're interested in doing is growing it out, one, as surveillance products so
3525220	3529380	that we can fill our other needs inside of the ecosystem, and two, because we're interested in
3529380	3534900	exploring whether we can plug it into other goods and services, whether we can garner insights from
3534900	3540100	there that will get us into maybe creating more network devices in your home, or maybe in figuring
3540100	3545380	out if we can try to push on to larger and larger groups of people, larger and larger, smaller and
3545380	3551540	more niche products. You see that the technology quickly grows and expands until it becomes
3551540	3557220	an all-consuming, it becomes plugged into part of this ever-consuming expansionary goal.
3558100	3563700	So we can note all that and then also talk about the racial elements that come with racial capitalism
3563700	3567940	and talk about how a lot of the times the surveillance technology is used to raise its
3567940	3572100	ends, it's biased against black and brown faces, and even if you correct the bias,
3572180	3576420	it's still going to be used by institutions, by the police departments, as an example,
3576420	3581300	by welfare agencies, as we've talked about in previous episodes, to discriminate against
3581300	3586340	people. Because in the real world, even outside of the corrected data, if you made it neutral
3586340	3593620	somehow, you still have a racist politics at the end of the day. The idea that you can just create
3593620	3599940	a piece of tech and debate about the rules that are inscribed on it inside of this narrow
3599940	3605300	application, ignoring the actual society in which it's being deployed in and the people who are
3605300	3609620	deploying it is stupid. And it's also cowardice and it's coming usually from people who are
3609620	3614340	compensated well enough to ignore that, as it is in the United States, as it is in Israel.
3615140	3619460	Because if you were in Israel and someone was like, oh, what's going on with all the things
3619460	3628900	that we're testing out on Palestinians? We would find it a little stupid if people were debating
3628900	3634980	about how high the apartheid border fences should be, or what kind of cameras should be put on them,
3634980	3643620	or whether the camera should have algorithmic facial recognition services or not, or what types
3643620	3651380	of labor regimes settlers should be subjecting Palestinians to, what type of schedules of work
3651380	3656260	they should be subjected to. All of this would be considered quibbling and over a fundamentally
3656260	3662980	immoral thing. And yet, or I would hope so, because some people don't actually even think
3662980	3667060	that there's anything wrong going on with the apartheid system. But nonetheless,
3667780	3671940	when we look here and then when some people look out there, they don't see anything wrong.
3671940	3678580	There's nothing wrong to them. And whenever you come across that as a case, it's usually because
3678580	3684020	of moral cowardice. It's because people who really think that when we say the word AI ethics, AI safety,
3684020	3689860	AI risk, in their heads, they're talking about the sci-fi shit. They're talking about God going
3689860	3694580	in a mech and killing everybody. They're talking about Skynet. They're not talking about here and
3694580	3700660	now where there's a fucking genocide going on, or where there's an apartheid going on, where there's
3700660	3710900	a welfare system going on. And it's a bit insane. It's a bit insane. It speaks to such a deep
3711620	3718580	moral collapse and rot that the nicest thing you can say about such an industry is that it's useless.
3720580	3729940	Because how do you have that much access to capital? You're soaked by that many corporations.
3731220	3738020	You're isolated and given enough access to academic resources and time and space to develop
3738020	3743860	them intellectually or synthesize them into some framework. And the best that we come up with
3743860	3752260	a lot of the times from these ethics, safety, and risks people is checking the boxes on diversity.
3756260	3761380	I don't know. It's just a fundamental failure. It's disgusting.
3762340	3769220	It is. And I think Khadijah is also dead on here as well, where she says in her essay,
3770340	3775460	if the room taken up with building individual brands lends itself to researching with those
3775460	3781300	most impacted, developing tactical initiatives like a social justice war room, we'd be in a
3781300	3786020	very different place. I think that's also a big part of it too. A lot of this is, unfortunately,
3786020	3794900	about building up your brand as the more ethical person in the room. It's not to say that people
3794900	3801780	don't care about this stuff. I'm not saying that. I don't think people are cynical and they don't
3801780	3809220	actually care beyond seeing it as an opportunity to build a brand. But we are reaching some limits
3809300	3815300	here where people have decided the trade off of speaking versus not speaking.
3819300	3829380	I can't take that trade off because it might irreparably damage my brand. It might damage
3829380	3834580	my ability to do more good in the future. We've got to think effectively about these altruistic
3834580	3841060	actions. What's the most good I can do as an activist in the future?
3843940	3852740	It's cowardice. It's a cowardice. I think it is also based in an ironic fetishism of the technology
3852740	3861700	itself. We might bang on about those people who fetishize the technology because they think it's
3861700	3868020	going to make God. It is God. It's going to end the world. It's going to bring utopia. They
3868020	3874660	fetishize the technology and say, tis, tis, tis. Don't fetishize the technology. At the end of the
3874660	3883540	day as well, they fetishize the technology. They're concerned about the ethics or morality
3883540	3890900	or politics or responsibility of AI. Hey, we've got to make it ethical. We've got to make the
3890900	3899700	technology responsible. Our whole analysis forever has always been a materialist one,
3899700	3908100	which is focused on not the technology itself but the systems that the technology emerges out of,
3908100	3915300	plugs into, plays a role in. We talk about the technology because we want to talk about
3915300	3920740	capital. We talk about the technology because we want to talk about fascism. We talk about
3920740	3924740	the technology because we want to talk about genocide. Those are the things we're actually
3924740	3932500	talking about. We're talking about the ways that the technology gets enrolled into perpetuating,
3932500	3939540	intensifying, justifying, covering up those other things that actually matter in the world.
3941460	3947860	I guess when the genocide is too out in your face, it's hard to talk about the AI.
3948740	3949220	Mm-hmm.
3950260	3963140	It's too much for me. This story, it hits so close to us as well because it is talking about
3963140	3967700	how these systems are being used. Ultimately, it doesn't matter, as we've talked about,
3967700	3973860	if the AI system is actually being used as an artificial intelligence to automate this,
3973860	3986020	or if it's being used as a movie prop to justify actions that the IDF already wants to take. It
3986020	3991540	doesn't matter because the material consequences at the end of the day are the same. Part of those
3991540	3998820	material consequences are getting a lot of people to not talk about it, to not pay attention to it.
3998820	4005780	It's not just justifying the action. It's not just directing the action. It is also getting a
4005780	4013620	lot of people to not pay attention to the action as well in whatever reason. If anything, a story
4013620	4020580	like this about Hapsara, about the gospel, if anything, this should be a clarion call for all
4020580	4029220	those people who are like, hey, Israel-Palestine conflict, that's not my job description. I study
4029220	4037620	technology. Well, here you go. Here's a technology to pay attention to. It should be bringing people
4037620	4044980	into the fold to be like, okay, fuck, all right, I study technology. Okay, I got to pay attention.
4044980	4048340	This matters, but it's done the opposite.
4048980	4055300	There's this line he has. It's in his The Taming of Tech Criticism piece, which every year
4056100	4064980	that passes by, his really condemnation and disgust in a very dry, Laconian way that reminds me of
4064980	4074100	Chomsky's own disgust with public intellectuals feels more and more right when he says that
4074100	4080500	disconnected from actual political struggles and social criticism, technology criticism is
4080500	4088660	just an elaborate but affirmative footnote to the status quo. In more than one way,
4089380	4094660	I think that has been the case, right? Because one of the things that I think has dominated,
4096420	4100340	and it's hard to even figure out, well, it's not hard. I mean, it's easy to talk about,
4100340	4104820	but it's also like, I think conservatives and right-wingers are pretty cynical in which it's
4104820	4109700	easy when you start talking about DEI, for example, and the ways in which a lot of people
4109700	4117780	have kind of slotted that or assumed that to be a social criticism. When in reality, it doesn't
4117780	4126100	matter what color the other faces at the table are at the end of the day, right? If the fundamental
4126100	4131140	system, well, take whoever's at the table and plug them into a system that still exploits
4131140	4137060	everyone else who looks a certain way outside of the table, right? You can have an AI ethics,
4137060	4144340	this call for, for example, for the OpenAI board to be half men and half women, to have POC on it.
4145380	4150100	What the fuck will that, what would that actually do though if we were being tech critics about
4150100	4154500	what OpenAI's designs and plans for artificial intelligence are, right?
4155220	4163620	What would that do to change Sam Altman's attempt to create a firm that has AI hardware
4163620	4167780	that every firm has to then rely on if they're interested in developing software?
4167780	4173620	And similarly, what would that mean or do for criticisms of Israel's apartheid state and
4173620	4180580	genocide? I mean, they let everyone serve in their military. Does that change the degree to which
4180580	4190180	they do war crimes? No. Would the AI ethics lens and focusing on this sort of diversity and inclusion
4190180	4196020	have any real possibility of impact? Would Elbit Systems be more humane in the weapons that it uses
4196020	4202340	against Palestinians if it had some Palestinians on the board? These seem a bit silly and maybe
4202340	4207700	unfair examples to use, but that is one of the places or one of the only places you end up going
4208260	4213860	for example, focusing on that DI element, right? If you expand it a little bit more broadly and
4213860	4220420	quibble about what's going on, as you said, a lot of people insist, well, it's a complicated issue,
4220420	4224260	that's political. I'm not really concerned about that. I'm just concerned about making sure there's
4224260	4230260	some sort of equity and outcome, right? But how are you going to achieve that if there's not an
4230260	4234900	actual political vision and struggle? I mean, part of the reason why Silicon Valley has been
4234900	4240420	so ascendant is because nobody seems to have another fucking vision, right? For what to
4240420	4245140	actually do with technology in our daily lives and how to integrate and organize our societies
4245140	4250340	around it or not around it, right? Where should technology be plugged in and where should it
4250340	4255300	shouldn't be? What types of weapons, what types of artificial intelligences, what types of systems
4255300	4259700	are we going to put a hard lock on and what types of systems will we ensure that other people can't
4259700	4263860	bypass when we have that hard lock on? What types of capital flows are we going to prohibit? What
4263860	4268740	types of business activity are we going to prohibit, right? None of these things really
4268740	4277380	bubble up, except in, of course, relatively radical segments, largely academics, right?
4277380	4281700	And activists who are able to articulate these visions, but will have them ignored by the
4281700	4286740	mainstream, right? Which is largely concerned with just build it perpetually until there's a
4286740	4289940	problem. And then when there's a problem, let the people who caused the problem write the rules
4289940	4297460	about how the problem should be handled, you know? And I worry, my greatest fucking worry with this
4298580	4305540	is that one, either people in that industry will see it in shrug, right? Or we'll use it
4305540	4310260	to do the brand building, right? That Khadija kind of talked about where they say, whoa, whoa,
4310260	4316820	you know, this is horrible. Not much we can do about it, but, you know, if we listen to my 10
4316820	4321780	steps, then we'd be able to prevent that happening in the United States. When the thing is,
4322740	4329300	you know, it's happening somewhere right now, you know? What, if anything, can we do about that?
4330020	4336100	I will not, I'm not going to pretend like I would even begin to really know, but the people who do
4336100	4341060	insist they know, and who pretend to know, and who create their whole identities and brands around
4341060	4347380	this have been silent and left us without anything. Yeah. And it is always that,
4347380	4352500	the exact what you just said there as well of like, you know, if we do these 10 steps,
4353060	4359220	then we can prevent this happening in the U.S., right? Like there is, so often there is this,
4359220	4365460	like, whether it's explicitly or it's just kind of beneath the surface, there is this kind of idea of
4365460	4372420	like, man, it'd be wild if that happened to us, you know? Like, I'm glad I can do some remote
4372420	4380820	criticism here. You know, I can take up my telescope and look abroad into exotic places
4380820	4388580	or foreign time periods and be like, man, it'd be wild if this happened, huh? But it is already
4388580	4393940	happening. Like, there is so much of that, that is the, like, it doesn't matter until you come.
4394020	4395540	Buy my mixtape.
4398580	4405700	But there is so much of that, like, of that, that like moral immediacy as well, where it doesn't
4405700	4410580	matter unless it's happening to you, or it doesn't matter unless you can conceive of it happening to
4410580	4415620	you. I mean, it's something we've talked about a ton before around like all of the AI doomerism
4415620	4421700	stuff. And, you know, it's the, you know, Sam Altman, Elon Musk, whoever, whatever, whatever,
4421700	4427460	right? The whole idea they have to create like an evil AI God that's going to exterminate the world
4427460	4433220	is because they are in such powerful and privileged positions that it's like literally
4433220	4442980	the only threat they can conceive of to themselves is an evil AI God who destroys everything in the
4442980	4448900	world, not just them, right? Everything in the world. And, you know, I think you see it a lot
4448900	4455060	in the way that people do talk about, like, AI ethics or the politics of AI or the consequences
4455060	4466580	of AI is, you know, so often it is about, like, the bad, hey, bad stuff could happen to other
4466580	4474180	people, or rather, what if the bad stuff happened to me, you know? And I think it is, you know,
4474180	4479060	this might be a good place to wrap it up. But I think it's also really telling as well where
4479060	4489780	you have a system like Hapsara, which its whole design is to generate Hamas targets for
4489780	4497860	assassination, right? And it has apparently an extremely broad definition of who is classified
4497940	4504740	as a Hamas operative or a relationship to Hamas. You know, it's like we were talking about before
4504740	4508980	where it's like, you know, as long as you can justify that there's like, you know, half of a
4508980	4514660	floor of a 10-story building was at one point related to Hamas, well, then you can take down
4514660	4521460	the whole building. I think a lot of people might be in for a real rude awakening, too, that, like,
4521540	4530260	you know, their idea that this activism is, you know, that they are doing a good thing
4530260	4535060	because they are caring about other, like, foreign people, you know, but except when they reach the
4535060	4542900	limits of care for foreign people or other time periods or other places or whatever it is that,
4542900	4549140	like, you know, they can't imagine that this stuff might come for them one day. And so that kind of
4549140	4560020	limits their ability to speak out about it, to rally against it, to draw attention to its,
4560020	4567620	you know, horrendous and atrocious actuality, right? Like, they can't imagine it might come
4567620	4574580	for them one day. Hey, I'm not a Hamas. I'm not a terrorist. I'm not Palestinian. I'm not a climate
4574580	4580660	refugee. You know, I'm not any of these things. I don't have to worry about that as much, you know?
4582020	4588740	But consider as well, it don't take long for all of a sudden those boundaries to get real loose
4588740	4595220	and real fluid and to start capturing a lot more people than you can think of. You know, I just
4595220	4604260	think of, like, all of the governments around the world, the UK, Australia, the US, like, all the
4604260	4610740	governments talking about these massive rallies for Palestinian rights, rallies for ceasefire,
4611780	4619940	rallies against the Israeli-led genocide. You know, just think about, for example, like,
4619940	4627380	high up people in the UK government, they're crying, the half million people marching,
4627380	4634900	the millions of people marching as all Hamas sympathizers, you know? Got a whole lot of Hamas
4634900	4640340	sympathizers all of a sudden, all these, you know, and it ain't just, you know,
4640980	4648260	cross-punk leftist out there. You know, if you've been out on the marches, it's just a lot of normal
4648260	4655620	middle-class families with their kids, you know, out there marching for Palestinian rights,
4655620	4661540	marching for a ceasefire, marching against genocide. You know, all of those people are
4661540	4668820	being painted as Hamas operatives or Hamas sympathizers. I mean, listen, it makes them,
4670020	4676420	it makes them a legitimate target for Habsara to spit out one day in that regard.
4677140	4683940	I have some, yeah, I should tweet out to the IDF. I have information about Donald Trump that might
4683940	4692340	make him a power target for you guys. May Allah awaken the people and help them to see the
4692340	4698340	evildoings of Israel and the United States. But yeah, no, I think you're right. All the data
4698340	4706020	Habsara needs to spit out Trump's name next. Trump Tower. It revealed to us that on the,
4706500	4714180	on the half of, in one room, in one corner office on the 67th floor, Trump sent out
4715940	4723860	a tweet that said, may Allah awaken the people, may Allah open the people's eyes and awaken them
4723860	4728900	to the evildoings of Israel and the United States. We got to take the whole thing down guys. I'm sorry.
4728900	4739060	Fair is fair. Yeah, I mean, this is, you know, we don't need to talk about like,
4739060	4744580	this is the danger of these systems, because the danger of these systems is already readily
4744580	4750260	apparent. It is clear and present, right? That like, you know, these systems,
4751140	4757060	and you know, are causing, right, whether they are causing it directly, they are causing it
4757860	4764580	in some kind of, you know, giving cover for it, whatever it might be, right? These systems are
4764580	4773700	already leading to the mass assassination, mass destruction, right? But it doesn't end there,
4773700	4781700	right? If you can't, if what it takes for someone to relate to this, to empathize, to sympathize,
4781700	4788740	to speak out against, to scream their head off about if what it takes is for you to conceive
4788740	4796900	that one day, it might not only affect exotic brown people, or it might not only be some,
4796900	4802900	you know, sci fi near future. If what it takes is for you to conceive of how you yourself might
4802900	4809300	get caught up in the system. It don't take a lot of imagination to see how that's not only possible,
4809300	4815700	but increasingly likely as we see governments act in more and more authoritarian ways,
4816260	4828820	use technology to justify and expand the powers that they have, use fascist policies and propaganda
4829540	4837540	to create targets to call people human animals. As the defensemen, as the Israeli defense minister
4837540	4843140	said after October 7th, quote, we are fighting human animals and we act accordingly.
4844180	4852340	To consider how that broad categorization of human animals is a fluid and dynamic category
4852340	4858500	that can begin to include a lot of people in a lot of different places under a lot of certain
4858500	4865860	circumstances. You don't have to think hard and you don't have to think long to understand how
4866420	4872980	these systems may not only come for you one day, they are already coming for you.
4872980	4879380	They are already coming for people who, you know, all around the world, they are already causing
4879380	4887300	and wreaking death and destruction. No, you're telling me that the IDF who trains with American
4887300	4894660	police departments might one day export the gospel, which is kind of, you know,
4895300	4899780	if it weren't so grim, it is kind of funny for them to export the gospel to the United States.
4899780	4905780	But, you know, that's besides the point. It's dark and grim, actually, right? You're telling
4905780	4914260	me that they would export that to America? Oh, man, unprecedented. Surely not something that,
4914500	4920340	you know, journalists like Anthony Loewenstein have written a whole book about. Surely not
4920340	4928020	something that we did a long episode with them about this whole very lucrative economy of exporting
4928020	4935780	the technologies of apartheid and genocide to the rest of the world. No, no, I can't imagine it,
4935860	4944180	Ed, which is why Aaron, I cannot imagine there and I do not speak. Right. Right.
4945780	4950820	Fucking hell. Well, I think I'm going to.
4953540	4957140	Don't worry, guys, the next episode will also be depressing.
4957700	4962820	Well, as long as the world keeps beating us down, we have to pass on those beatings to our dear
4962820	4967700	listeners. The negative project continues. You're absolutely right.
4987140	5000340	Thank you to our dear subscribers. And like I said, this episode will be released very shortly
5001060	5008500	after it goes up on the Patreon feed. So I will speak to you, all of our listeners who are
5008500	5016980	non-subscribers, please sign up and support the work that we do. It really does keep us going.
5016980	5023620	And doing these kinds of episodes, having these discussions. And so we appreciate that support,
5023620	5032020	as always. And more importantly, go fucking talk to people about this stuff. Help spread some
5032020	5040260	awareness, some outrage, some attention on these things that really need to be. I mean,
5040900	5048100	this shit is clearly, I think, just these are these are war crimes. They go against even our
5048820	5055940	completely inadequate liberal system of international law. These things violate that
5056820	5062900	to such an extreme degree in such an obvious way. Right. Like these are technologies that
5063780	5077700	do not deserve to exist and indeed should be outlawed, smashed in every way. These are weapons
5077700	5088340	of mass destruction, weapons of mass assassination. And as such, we need to talk about it. We need to
5088340	5094180	bring attention to it. We need to fight against it. We need to advocate against it, whatever it
5094180	5100340	takes. You know, but so with that, thank you everybody for listening. Thanks for your support.
5100340	5103700	And we will catch you next time later.
5190340	5199700	So
5212500	5213700	it's
5220340	5221700	you
