# FH Complete S02E02 - Frederike Kaltheuner zu Datafizierung und A.I. Snake Oil | Future Histories

Herzlich willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft. Mein Name ist Jan Groß und ihr hört heute die zweite Future Histories Live-Episode, die ich kürzlich in Hamburg aufgezeichnet habe. In diesem Fall, da war ich beim Mind the Progress-Kongress eingeladen und hatte die Freude, mit Friederike Kaltheuner als Gast zu sprechen. Friederike, die forscht, schreibt und denkt zu Fragen der Datafizierung und ist Expertin im Bereich Tech Policy. Sie hat unter anderem das Corporate Exploitation Program bei Privacy International geleitet, war Tech Policy Fellow bei der Mozilla Foundation. Gemeinsam mit Nele Obermüller hat sie auch ein Buch geschrieben mit dem Titel Datengerechtigkeit. Vielen Dank an dieser Stelle hier an die OrganisatorInnen des Kongresses für die Einladung und vor allem auch an Sophia für diese wirklich ausgezeichnete Organisation und Betreuung. 1.000 Dank. Bevor wir jetzt aber zum Gespräch mit Friederike kommen, hatte ich ja in der vergangenen Episode angekündigt, noch ein paar Worte zur gerade begonnenen zweiten Staffel von Future Histories zu sagen, ob sich da was geändert hat im Vergleich zur Staffel 1 und wenn ja, was. Falls euch diese Reflektionen über den Verlauf des Podcasts Future Histories nicht so sehr interessieren und ihr eigentlich nur Friederike hören wollt, dann nehme ich euch das nicht im geringsten Übel, sondern habe genau dafür einen Kapitelmarker gesetzt. Wenn eure App das unterstützt, dann könnt ihr da also jetzt vorspringen. Für alle, die es sehr wohl interessiert, willkommen bei diesem kurzen Einschub. Also vielleicht zunächst mal für euch zur Einordnung. Ich hatte damals, als ich Future Histories vor jetzt über zwei Jahren gestartet habe, ja eher so eine vage Idee davon, wie ich das ungefähr machen will. Und der Aufbau in Staffeln, der schien mir damals einfach sinnvoll, um zum einen eben die Möglichkeit einzubauen, dass man auch mal eine Pause machen kann. Und zum anderen wollte ich auch nicht, dass die Themen, mit denen ich damals gestartet bin, auf ewig in Stein gemeißelt sind. Eine neue Staffel, die bietet also auch die Möglichkeit, thematisch da Neuausrichtungen vorzunehmen. Und das ist im Fall von Future Histories nicht als harter Bruch zu verstehen, sondern eher als eine stetige Entwicklung der forschenden Suchbewegung dieses Podcasts hier. Es wird also auch in der zweiten Staffel drei Überthemen geben, aber zum einen werden sie auch weiterhin eher als grobe Orientierung dienen und eine Offenheit zulassen, die ich als essentiell empfinde. Und zum anderen leiten sie sich auch unmittelbar aus den unterschiedlichen Auseinandersetzungen, den Pferden und den Entwicklungen der ersten Staffel ab. Aus dem Thema Homo economicus, da hat sich zum Beispiel, ich hatte das an anderer Stelle schon erwähnt, über den Verlauf der ersten Staffel hinweg die Frage entwickelt, wie alternative Systeme politischer Ökonomie denn aussehen könnten. Politische Ökonomien der Zukunft wird also ein Überthema der zweiten Staffel sein. Ich bin ja absolut der Meinung, dass es nicht reicht, in der Kritik zu verharren, sondern dass es zwingend notwendig ist, konstruktive und produktive Vorschläge zu machen, wie man es denn anders machen könnte, gerade auch auf einer Makroebene wie der der politischen Ökonomie. Denn diese Makroebene, die es absolut unterversorgt, wenn es um Alternativen geht, finde ich, das gilt es zu ändern und ich möchte dabei zum einen bestimmte Stränge der ersten Staffel weiterverfolgen, die sich als fruchtbare Pferden herausgestellt haben. Konkret ist, dass die Auseinandersetzung mit dem Themenkomplex, den ich mittlerweile unter dem spielerisch provokanten Begriffspaar Freie Planwirtschaft zusammenfasse, da ist noch vieles offen und ich habe sehr, sehr viele Fragen an diesen Themenkomplex, die definitiv noch umgeklärt sind. Und daran anschließend gibt es auch eine andere Fragestellung oder einen thematischen Ansatz zu diesem Komplex zukünftiger politischer Ökonomien, einen anderen Ansatz, den ich ebenfalls in Staffel 1 wiederholt auch aufgegriffen habe, der aber auch absolut überhaupt nicht abschließend geklärt ist in irgendeiner Form. Und das ist die Frage nach alternativen Regierungskünsten, nach alternativer Governamentalität, wie es Frieda Vogelmann in Episode 11 nennt. Das sind also so zwei Aspekte, die ich aus der ersten Staffel mitnehmen möchte, aber ich will natürlich auch neue Pfade eröffnen, die für politische Ökonomien der Zukunft von Bedeutung sind. Das Ganze wird also explorativ sein, wie man so schön sagt. Und ich freue mich auch immer sehr über Hinweise. Also solltet ihr in dieser Richtung irgendwie gute Ansätze kennen, Zugänge, Bücher, TheoretikerInnen und so weiter, gerne immer mir schreiben unter jan-at-future-histories.today. Ein wichtiger Bereich, den es für diesen Themenblock in jedem Fall zu erarbeiten gilt, ist das Blicken über den Tellerrand, um nicht in so einer leider ja immer wieder sehr eurozentristischen Debatte eigentlich stecken zu bleiben. Ein wichtiger Aspekt wird also sein zu fragen, wie wird denn die Frage nach alternativen politischen Ökonomien in anderen Teilen der Welt gestellt und verhandelt. Der zweite Themenblock, der ergibt sich im Grunde unmittelbar aus dem ersten und widmet sich der Frage der Transformation. Ich finde es unglaublich wichtig, diese Ebenen miteinander zu verbinden, dass man sich also auf der einen Seite wieder traut, auch über Alternativen auf der Makroebene nachzudenken, dass aber gleichzeitig auch eine plausible Idee davon entwickelt wird, wie diese alternativen politischen Ökonomien denn in die Welt gebracht werden könnten, wie eine Transformation also ganz konkret aussehen könnte. Nicht das Blaupause, also bitte nicht falsch verstehen, nicht als ein Prozess mit einem finalen Ziel oder sowas, sondern als ein wechselseitiger Prozess zwischen gelebter alternativer Praxis im Hier und Jetzt und auch Projekten, die quasi an die Substanz dessen gehen, was es neu zu verhandeln gilt und im Entwickeln alternativer Zukunft auch jenseits der Nische. Ich glaube, dass das sich überhaupt nicht irgendwie widerspricht, sondern im Gegenteil einfach ganz fantastisch gegenseitig befruchten kann. Die Frage der Transformation ist ein sehr weites Feld und auch eine harte Nuss, finde ich. Da wird es also einiges zu besprechen geben und ich freue mich schon auf viele, viele spannende Episoden zu diesem Thema. Das dritte Themenfeld, das uns in der zweiten Staffel begleiten wird, das greift den technopolitischen Strang von Future Histories auf und verdichtet ihn entlang eines Forschungsprojektes, das ich gemeinsam mit Robert Seifert verfolge. Das Thema lautet das Regieren der Algorithmen und das freut mich ganz besonders, nicht nur, weil ich Robert Seifert sehr schätze und das Thema auch unglaublich gut in Future Histories passt, sondern auch, weil es bedeutet, dass hier zwei Sphären noch enger zueinander finden, die für mich persönlich einfach von großer Bedeutung sind, nämlich Future Histories als Projekt und die Forschung im Rahmen meiner Dissertation zu sozio-technischen Imaginationen algorithmischer Regierungskunst. Diese Dissertation, die ist nämlich Teil des Forschungsprojektes, das Regieren der Algorithmen. Und weil ich ebenfalls daran arbeite, Podcasten als Teil der erweiterten Forschungspraxis zu etablieren und zu plausibilisieren, passt das alles natürlich ganz großartig zusammen und freut mich wirklich sehr. Worum wird es also im Themenstrang das Regieren der Algorithmen gehen? Das Forschungsprojekt, das trägt den Untertitel eine Soziologie algorithmischer Regierungskunst und steht somit in ausgezeichneter Korrespondenz zur in Themenblock 1 bereits erwähnten Frage nach alternativen Regierungskünsten. Der Begriff des Regierens, der ist dabei angelehnt an Foucault weit gefasst und geht über eine rein politische Definition hinaus. Regieren bezieht sich hier ganz allgemein auf soziale Felder, Technologien und individuelle Handlungsformen, die der Selbst- und Fremdführung von Menschen dienen und Regierungskünste, die stellen dabei dann das reflektierte Nachdenken über die beste Form des Regierens dar. Algorithmische Regierungskünste tun dies wiederum unter Einbezug algorithmischer Verfahren als maßgebliche Elemente des Regierens. Und wir führen im Namen des Forschungsprojektes das Regieren der Algorithmen ja eine Kecke Zweideutigkeit mit, denn der Name das Regieren der Algorithmen, das kann sich ja beziehen sowohl auf das Regieren von Algorithmen, also im Sinne des Regulierens von Algorithmen, als auch auf soziotechnische Imagination des Regierens mit algorithmischen Technologien. Siehe mein Promotionsprojekt. Das heißt, wir kommen da aus verschiedensten Richtungen, was ich als sehr produktiv empfinde. Mehr dazu gibt es dann in einer kommenden Episode mit Robert Seifert als Gast. Ich freue mich schon sehr. Was mich auch sehr freut und das wollte ich auch schon längst ganz fröhlich verkünden, ist, dass Future Histories eine Förderung der Wiener Medieninitiative erhalten hat, um das Projekt etwas auszubauen und auch auf solidere Beine stellen zu können, sage ich mal. Daher stammt zum Beispiel auch der Umstand, dass jetzt zumindest mal für die nächsten 20 Episoden jede zweite Woche ein Future Histories Kurzvideo veröffentlicht wird auf YouTube. Gerne auch übrigens den Kanal abonnieren. Das ist definitiv auch eine Hilfe im Ausbau dieses Medienstranges, sage ich mal. Es gibt jetzt auch ein kleines Studio in einem Gemeindebau direkt beim Wiener Prater und die Förderung ermöglicht auch, dass ich endlich nicht mehr gezwungen bin, alles alleine zu machen und mich an den Rand der Überlastung zu treiben. Denn ich werde jetzt hier bei Future Histories von Clara unterstützt. Clara, vielen Dank für alles. Ich freue mich total, dass du mitmachst und dass du mich in all diesen Sachen unterstützt. Ich freue mich auch. Hallo. Die Förderung der Wiener Medieninitiative bewegt sich im Bereich dessen, was man gemeinhin wahrscheinlich Kreativwirtschaft nennen würde und so ist es integraler Bestandteil, dass ich mich im Zuge dessen mit einer Neugründung selbstständig gemacht habe. Die Firma, die daraus entsprungen ist, die trägt den Namen MetaLapsis und ihr findet sie unter www.metalapsis.net mit einer sehr gelungenen Homepage vertreten, für deren Gestaltung und Umsetzung ich Thomas, Daniel und Leon danken möchte. Und wo wir schon bei Webseiten sind, es gibt jetzt auch Infos zu meiner Person gebündelt unter jan-groß.de, geschrieben Gustav Richard Otto Otto Siegfried, also mit zwei O und einem normalen S. Auf eine Art fand ich es zwar auch ganz schick, muss ich sagen, dass es bisher nur so verstreute Informationen über mich gab im Netz, aber nun hat dann doch der pragmatische Zugang gewonnen. So, jetzt genug Eigenwerbung. Ich freue mich riesig auf die zweite Staffel, möchte ich noch mal sagen. Und mir verbleibt noch Marianne, Andrea und Nausi K.A. ganz herzlich in der Gemeinschaft der Patreon-UnterstützerInnen zu begrüßen. Und ich danke Fabian, Carmen, Rudolf und Wilfried für ihre Spenden und wünsche euch jetzt viel Freude mit einer neuen Episode Future Histories Live, diesmal mit Friederike Kalt-Heuner. Ja, herzlich willkommen auch von meiner Seite. Ich freue mich sehr, dass wir heute hier sein dürfen. Herzlich willkommen, Friederike. Danke für die Einladung. Ich freue mich sehr. Friederike, ich mag gerne mit einer ganz basic Frage einsteigen, die vielleicht gar nicht so einfach ist, wie sie im ersten Moment scheint. Denn gerade im Zusammenhang mit Daten, da scheint mir allzu oft zu einer gewissen Naturalisierung am Werke. Man sieht es an Framings, wie Daten sind, das neue Öl oder auch der Begriff Raw Data, Rotdaten. Also zunächst mal vorab. Was sind Daten und wie entstehen sie? Vielleicht ist es am einfachsten, mit einer ganz einfachen Aussage anzufangen. Wir leben in einer Welt, in der es noch nie so einfach war, so viel über jeden von uns zu wissen. Und das hat natürlich auch was mit Daten zu tun. Also der Begriff Datafizierung heißt, die Umwandlung von Räumen, Verhalten, Informationen in Daten. Wenn ich einen Vortrag zu dem Thema halte, habe ich eine Lieblingsfolie, die ich eigentlich fast immer verwende. Und auf dem Bild sieht man eine, das ist ein Foto von einer Stasi-Akte. Und die zeigt so ein bisschen, wie auf der einen Seite, wie arbeitsaufwendig es früher war, Informationen herauszufinden und wie trivial die Informationen zum Teil auch waren. Also da steht dann in der Akte, welches Buch liest jemand, wer sind so die Freunde, wo verbringen die so ihren Nachmittag. Und was Datafizierung jetzt ganz grob runtergebrochen heißt, ist, dass wir jetzt in einer Welt leben, in all diese Dinge, die früher sehr aufwendig und kostenspielig waren, herauszufinden. Diese Dinge werden automatisch über uns aufgezeichnet in Form von Daten. Und wenn wir über Daten sprechen, zum öffentlichen Diskurs, geht es eigentlich meistens um die Daten, die wir mehr oder weniger bewusst teilen. Also die Bilder, die wir teilen, was wir ins Internet stellen. Aber das ist eigentlich nur die Spitze des Eisbergs. Der viel größere Teil, der den meisten Menschen, glaube ich, gar nicht so bewusst ist, sind die Daten, die automatisch über uns aufgezeichnet werden. Unser Bewegungsmuster, nicht nur was wir kaufen, sondern wie sich unsere Maus bewegt, wo wir vielleicht zögern, was uns vielleicht vorher noch interessiert hat. Und dann die dritte Kategorie, die mich, ich glaube, das ist vielleicht eigentlich auch der Einstieg für mich persönlich zu dem Thema. Die dritte Kategorie sind all die Rückschlüsse, die man aus diesen Mustern ableiten kann. Also aus meinem Bewegungsmuster, aus meinem Netflix-Verhalten kann man sehr viel ablesen, zum Beispiel, ob jemand depressiv ist, ob jemand jetzt das Haus nicht verlassen hat. Man kann anhand meiner Telefondaten sehen, bin ich eher jemand, die sofort zurückruft? Oder muss ich angerufen werden? Und wen rufe ich an? Und das ist eigentlich das, was mich interessiert. Weil auf der einen Seite ist es so, wenn diese Vorhersagen stimmen, sind sie unheimlich genau und können Dinge aussagen über uns, die wir vielleicht selber gar nicht wissen oder nicht wahrhaben wollen. Gleichzeitig ist es aber auch so, dass diese Muster und Vorhersagen oft völliger Quatsch sind. Und man sieht das ganz gut anhand zum Beispiel der Online-Werbung, die ich sehe. Da gibt es manchmal Dinge, die sind unheimlich fast hellseherisch genau. Und dann wiederum gibt es einfach Quatsch. Also Facebook hat jetzt über 12, 13 Jahre Daten von mir und denkt immer noch, ich wäre ein Mann. Und dieses Spannungsfeld ist das, was mich interessiert. Also das Spannungsfeld zwischen Orwell und Kafka. Auf der einen Seite sind wir sehr lesbar geworden. Auf der anderen Seite ist das, was gelesen wird, auch oft völlig falsch. Und manchmal ist es einfach nur irritierend, dass es falsch ist. Manchmal geht es aber auch um etwas ganz anderes. Manchmal werden wir in Kategorien gepackt. Manchmal werden wir falsch einsortiert auf Arten und Weisen, die diskriminierend sind, die bestehende diskriminierende Strukturen reproduzieren. Und ich glaube, neben Klimawandel, Ungerechtigkeit, wachsender Ungleichheit, ist eben einer der wichtigsten und dringendsten Themen unserer Zeit, wie wir die Spielregeln dieser neuen Welt gestalten, die in ihren vollen Konsequenzen immer noch nicht viele Leute wirklich verstehen. Also wir leben einer radikal anderen Welt, als wir 2001 gelebt haben. Und es liegt an uns, diese Welt zu gestalten. Und deswegen finde ich das Thema Zukunft so spannend, weil im Deutschen das Wort Digitalisierung suggeriert manchmal, als wäre das ein Prozess, der uns passiert, der über uns kommt. Dabei ist es eigentlich andersrum. Es liegt an uns, ihn zu gestalten. Alles, was jetzt ist, hätte auch anders sein können. Es ist viel freier, viel offener. Und was mich motiviert oder meine persönliche Motivation ist, ich möchte eben mehr Menschen dazu bewegen und auch selber Teil dieser Gestaltung sein und das nicht einfach nur mich überkommen lassen. Da hast du jetzt verschiedene Sachen angesprochen, unter anderem auch dieses Spannungsfeld zwischen Genauigkeit und danebenliegen. Ich finde das auch unter einem anderen Aspekt interessant, weil ja auch auf Seiten der Kritikerinnen und Kritiker dieser Technologien das mitunter dann fast schon unbeabsichtigt scheint mir irgendwie passiert, dass die an den Mythen dieser Technologien eigentlich mitarbeiten, indem sie, ich glaube fast aus Versehen sozusagen, diese Erzählungen, diese Narrative für bare Münze nehmen und dann quasi im Aufschrei dagegen, wie genau man uns denn jetzt sehen könne, wie genau man jetzt Zukunft voraussehen könne und so weiter, eigentlich auf eine Art eben diese Mythologien auch mit verfestigen. Wie versuchst du das zu umschiffen? Wie gehst du mit dieser Problematik um? Kritik ist ja erstmal grundsätzlich positiv, aber es gibt natürlich Kritik und Kritik. Man sieht das immer anhand dieses Beispiels oder zwei Beispiele finde ich hier besonders gut. Das eine ist künstliche Intelligenz. Natürlich muss man das kritisch sehen, aber Kritik heißt nicht, dass wir jetzt Angst vor Terminator haben müssen oder dass KI jetzt bald alles, wie sagt man das auf Deutsch, also dass KI jetzt plötzlich unser ganzes Leben entscheiden wird oder bestimmen wird. Das ist die falsche Sorge, sondern die eigentliche Sorge ist, dass KI oft nicht funktioniert, oft richtig schlampig gebaut wird, Vorurteile, Diskriminierung reproduziert, also die Gefahr ist oft viel subtiler als man das denkt. Und dann die eigentliche Gefahr oder wir müssen gar nicht über Gefahren reden, aber ich glaube der Bereich, der am meisten kritisiert werden muss, ist die Tatsache, dass es ganz viele Fragen gibt, die wir nicht beantworten können, die nur eine ganz kleine Anzahl an Firmen sind überhaupt in der Lage diese Fragen zu beantworten. Ein Beispiel ist sowas Radikalisierung im Netz von Empfehlungsalgorithmen. Die Studien dazu sind extrem schwierig durchzuführen, weil personalisierte Algorithmen eben für jeden anders aussehen. Alleine schon ist es sehr schwierig, auch kollektiv zum Beispiel über Online-Werbung zu sprechen. Meine Online-Werbung sieht anders aus als deine, sieht anders aus als ihre. Und da gibt es oft Kritik in der Öffentlichkeit, sowas wie das Internet macht uns dumm, oder das Internet macht, oder soziale Medien machen X. Und ich finde diese Art von Kritik schwierig, weil die Frage ist ja, was ist denn überhaupt Social Media und was sollte es sein? Indem wir so monokausale Kritik üben, sehen wir die eigentliche Technik Social Media als etwas viel starreres als es eigentlich ist. Wir meinen damit eine Bandbreite an Produkten, die sich permanent verändern, die selbst vor fünf Jahren anders aussahen als jetzt. Das heißt, diese kausalen Aussagen sind schwierig. Also im Kern geht es für mich um zwei Sachen. Die eine Sache ist, es ist nicht nur, dass wir in einer Welt leben, in der man mehr über uns weiß, sondern der öffentliche Raum, und das ist ja nicht nur Raum, in dem wir sprechen, das ist auch der Raum, in dem sich soziale Bewegungen formen, in dem wir über die Welt lernen, jetzt diese Woche Afghanistan. Das liest man auf Twitter mit und das lesen auch Journalisten auf Twitter mit. Und es ist schon sehr erstaunlich, dass diese Räume von einer Handvoll an Firmen kontrolliert und gesteuert werden. Das ist historisch schon extrem einmalig. Das ist eine Art von Macht, die diese Firmen haben, die wir, ich glaube, die wir im vollen Ausmaß noch nicht richtig verstanden haben. Und die andere Sache, die ich so interessant finde, ist die Informationsungleichheit. Auf der einen Seite kann man sehr viel über uns wissen, auf der anderen Seite ist es sehr schwer überhaupt zu verstehen, wie zum Beispiel ein Handy funktioniert. Was passiert eigentlich auf dem Handy? Oder sehr wenig Menschen wissen eigentlich, hört mein Handy mir zu, wie wird eigentlich Werbung personalisiert? Und das kreiert eine Informationsasymmetrie, die natürlich auch ein Machtgefälle ist. Also das sind für mich diese Fragen um Macht und Gerechtigkeit. Das sind eigentlich die Kernfragen oder das ist da, wo die Kritik ansetzen muss. Es gibt so eine Demarkationslinie, die ich noch nie so recht habe begreifen können. Vielleicht kannst du mir da ein bisschen weiterhelfen und das ist die Wahlwerbung. Also die Mechanismen, die Tools, die eingesetzt werden in dieser Wahlwerbung, das sind Tools, die sind im normalen Online-Werbegeschäft total frei verfügbar für jeden. Also du kannst quasi diese Lookalikes oder sowas, das ist ganz normal, wenn du eine Facebook-Werbung schaltest, dass du das dann auswählen kannst. Wenn das aber wiederum dann auf den politischen Bereich übertragen wird, dann gibt es immer plötzlich so einen Aufschrei. Dadurch können jetzt irgendwie in einer Art und Weise die öffentliche Meinung manipuliert werden, wie das vorher noch nicht dagewesen sei. Es gäbe jetzt Microtargeting und das würde quasi diesen demokratischen Willensbildungsprozess in einer Art und Weise beeinflussen, die jetzt aber wirklich nicht mehr zulässig wäre. Und ich frage mich immer, wenn ich das höre, ohne jetzt sagen zu wollen, dass das eine komplett unberechtigte Kritik wäre oder sowas, aber ich habe noch nie begriffen, wie man diese Linie zieht. Also was ist quasi, was ist irgendwie okay? Früher gab es auch immer schon Medienkonglomerate, die hatten halt dann irgendwie eine Mehrheit der Tageszeitungen in Besitz und hatten dadurch eine gewisse Medienherrschaft, wenn man so will. Warum wird diese Demarkationslinie so gezogen in Bezug auf zum Beispiel Online-Targeting bei politischen Wahlkämpfen? Erstmal danke für die Frage. Das Thema ist mir extrem wichtig. Ich arbeite gerade für die EU-Kommission zu der Regulierung von politischer Online-Werbung. Man muss unterschiedliche Sachen unterscheiden. Es wurde ganz viel über Online-Werbung diskutiert im Kontext des Brexit-Referendums. Und ich habe jetzt jahrelang in England gelebt. Und es ist natürlich nicht so, dass Anti-EU, Anti-Einwanderer-Rechte, Populismus nur online stattfindet. Man muss nur in einen Kiosk gehen. Und die Tabloids sind voll von Missinformationen. Missinformationen und Lügen. Also das ist kein inhärentes Online-Problem. Was aber spannend ist oder was auch eine wirkliche Gefahr ist, und das ist so ein Phänomen, was man oft auch in anderen Bereichen sieht, zum Beispiel in der Polizeiarbeit. Die Regeln, die offline im Wahlkampf gelten, gelten nicht online. Beispielsweise, wenn ich jetzt hier ein Wahlplakat aufhänge, muss ich deklarieren, von wem das kommt und wer dafür bezahlt hat. Wenn ich, ich kann nicht einfach als Milliardär, der ich nicht bin, im deutschen Fernsehen jetzt einfach alle Werbeplätze kaufen und nur noch Werbung für Friederike als Kanzlerin machen. Das ist einfach nicht erlaubt. Weil es da Kontingente gibt, es gibt Plätze, das ist alles sehr streng reguliert. Oder man merkt ja auch jetzt im Bundeswahlkampf in Deutschland, es hängen eigentlich erst jetzt Plakate. Es waren nicht schon seit Monaten Plakate. Der Unterschied ist, dass online die Regeln einfach nicht greifen. Aus ganz unterschiedlichen Gründen. Was dann dazu führt, dass eben Parteien, und das ist in den USA passiert, dass zum Beispiel die Trump-Kampagne Millionen verschiedene Versionen von Werbung ausgestrahlt hat. Das ist noch ein weiterer Unterschied. Also offline, was auch immer ich auf Wahlplakaten behaupte, wen ich beleidige, wie radikal auch immer das ist, es hängt in der Öffentlichkeit. Und es kann damit gesehen und im öffentlichen Diskurs diskutiert werden. Der Unterschied zur Online-Werbung ist, weil die Online-Werbung eben personalisiert ist, ich kann eine Million Versionen derselben Werbung schalten und im Endeffekt jedem was anderes erzählen. Ich kann den einen Wählern das versprechen, den anderen Wählern das versprechen. Ich kann Gruppen gegeneinander aufhetzen, ohne dass man überhaupt etwas in der Öffentlichkeit davon mitkriegt, weil es eben so vergänglich ist und so schnelllebig ist. Die Werbung wird einen Tag geschaltet und dann wird sie nicht mehr geschaltet. Und vielleicht noch der letzte Grund ist, man kann durch, und das wurde auch in den USA gemacht, man kann durch Online-Werbung ganz gezielt auch testen, was so die Stimmung ist, worauf die Leute anspringen. Und Werbung wird ja nicht nur geschaltet, sondern das wird dann optimiert und das wird dann sehr genau gezielt an bestimmte Gruppen ausgeschaltet. Was ich damit sagen will, in der öffentlichen Debatte wurde das oft verkürzt auf politische Werbung ist eine Gefahr, weil die Menschen manipuliert, die dann anders wählen als sie sonst wählen würden. Das ist natürlich zu kurz gegriffen, das Problem ist viel komplexer und das zeigt so ein bisschen auch, wenn man über Polizeiarbeit oder vorausschauende Polizeiarbeit spricht, das Problem ist häufig, dass dieselben Regeln, die offline gelten, nicht online gelten. Und das quote-unquote online, das ist ja auch verschmolzen, dass plötzlich Dinge möglich sind, die so nicht möglich sind. Es ist offline nicht möglich, jedem einen anderen Wahlspruch zu zeigen. Das heißt, es bedarf irgendwie Regeln, es bedarf Intervention und so wie es momentan aussieht, machen das die Plattformen eben freiwillig und sie machen das auch nicht konsequent und auch nicht immer sehr zuverlässig. Und deswegen muss es halt Regeln geben, die das klar definieren. Auch wenn zum Beispiel dann bei Facebook mal ein anderer Chef ist, dass sich die Regeln dann nicht ändern. Aber ich mag die Frage, um nochmal darauf zurückzugehen, was ich an der Frage mag, ist, es stimmt, es gibt viel Digitalisierungskritik. Allein die Frage, so Digitalisierung gut oder schlecht, ist die völlig falsche Frage, sondern die Frage ist, wie, wie Digitalisierung, wie Technologien, was wollen wir eigentlich kollektiv als Gesellschaft und nicht das Empfinden als so eine unaufweichbare Bewegung. Und bei dieser Online-Werbung, also zumindest, das würde mich vielleicht auch noch interessieren, ich wüsste jetzt auch gar nicht, wie effektiv oder ob die, vielleicht eher so, ob die Erzählung dessen, wie effektiv das angeblich gewesen sei, wie sehr das mit der Realität übereinstimmt. Und tendenziell neige ich dazu, dass ich immer so ein bisschen die Intuition habe, dass es mir so scheint, als ob andere Aspekte, die eher sozioökonomische, sozio-politische Aspekte sind, die zu verschiedenen Entwicklungen führen, dass die unterschlagen werden, wenn man das so darstellt als, eben als sei quasi Trump, also jetzt ich bin absichtlich polemisch, Trump wäre gewählt worden, weil er über Social Media quasi die Leute gegeneinander aufgehetzt hat. Also dafür muss es ja ein Fundament geben, das in dem Fall, glaube ich, auch mit einer realen Not zum Beispiel zu tun hat, weil man kann Leute in Not besser gegeneinander aufhetzen, zum Beispiel. Die, sorry, jetzt habe ich meinen Faden verloren. Ich habe immer noch was hinterhergeschoben, immer noch was hinterhergeschoben. Es muss ja noch nicht passiert sein, das heißt aber nicht, dass es nicht doch auch noch passieren könnte. Also wir wissen, was technisch möglich ist und das Beispiel, was ich immer gerne bringe, ist, es ist belegt, es gab in den USA Abtreibungsgegner, die abtreibungswillige Frauen im Klinikbesuch mit Antiabtreibungswerbung bombardiert haben. Werden die deshalb jetzt nicht abtreiben? Wahrscheinlich nicht, es ist aber eine ganz perfide Form von Belästigung. Wahlen werden ja auch oft, es gibt immer mehr Wahlen, die werden in bestimmten Wahlkreisen durch wenige tausend Stimmen getroffen. Die Wahlerwerbung muss ja noch nicht mal sagen, wähl Trump, sondern die Wahlerwerbung kann auch einfach sagen, der ganze Politikbetrieb ist kaputt, geh doch gar nicht wählen. Und das macht das halt alles so kompliziert. Und ich glaube, das ist ein gutes Beispiel, weil das zeigt, wir wissen, technisch ist es eben möglich, sehr spezifische Gruppen sehr spezifisch anzusprechen. Keine Ahnung, wie effektiv das ist, aber das Problem ist, niemand kann es messen, außer die Plattformen selber. Aber hier geht es ja nicht um irgendwas, hier geht es um Demokratie. Es ist eigentlich extrem beunruhigend, dass wir gar nicht mal richtig wissen, welchen Einfluss Plattformen auf Wahlen hatten, weil nur die Plattformen selber überhaupt die Daten dazu haben. Das alleine für mich reicht schon aus. Es muss nicht ausgenutzt werden, wir wissen, dass es ausgenutzt werden könnte. Und das sollte nicht passieren. Total, also da würde ich natürlich sofort zustimmen. Wir sollten dafür sorgen, dass die Dinge eben in einer Art und Weise nachvollziehbar werden, wie sie es bisher leider nicht sind. Und das nährt ja am Ende dann eben auch diese Mythologien, weil die Plattformen haben natürlich ein Eigeninteresse daran zu tun, als wären ihre Werbung unglaublich effektiv und könnten extrem genau, also detailliert targetten und so weiter und so fort. Ich würde aber gerne jetzt dann noch zu einer anderen Demystifisierung übergehen, nämlich zu etwas, was du in einem Block-Eintrag AI Snake Oil genannt hast. Das ist ein Ausdruck, der mir sehr gut gefallen hat und sofort ins Auge gesprungen ist. Und du sprichst da auch vom Jahr 2020 als dem Jahr der AI-Desillusionierung. Vielleicht kannst du zum einen ein bisschen darauf eingehen, warum du meinst, dass 2020 dieses Jahr der AI-Desillusionierung war und vielleicht auch ein konkretes Beispiel geben für AI Snake Oil. Ich glaube, 2020 war das Jahr, also alleine empirisch das Schöne ist, wenn man schon so lange an diesem Themenkomplex arbeitet, dass man sieht, dass die Dinge immer in Wellen kommen. Also 2014 sprachen wir über Big Data. Niemand redet mehr von Big Data plötzlich, aber die Phänomene sind ja nicht weg. Dann kam eine Zeit, wo alles war AI, ohne auch kritische Äußerungen. Und dann gab es die Welle, wo man gesagt hat, na ja, aber AI kann diskriminieren, AI hat ethische Probleme etc. Also es gibt immer diese Wellen. Und für mich war 2020 schon ein interessantes Jahr, weil es wurde jahrelang behauptet, dass AI eigentlich jedes Problem lösen kann. Und dann 2020 stand und steht die Welt vor einem wirklichen Problem. Wir haben ja genug Probleme, aber so einer akuten Krise, wie die Pandemie. Und der Witz war, dass AI relativ wenig dazu beigetragen hat, die Pandemie zu lösen, weil nämlich Probleme hochkomplex sind. Und die Pandemie, es liegt ja nicht daran, AI kann die Pandemie nicht lösen, sondern es ist eine Kombination aus politischem Willen, auch Desinformation online. Es sind hochkomplexe gesellschaftliche Probleme. Es ist kein informationelles Problem. Wir kriegen die Pandemie nicht in den Griff, weil wir zu wenig wissen, sondern aus ganz vielen komplexen anderen Gründen. Und das hat, glaube ich, schon ein bisschen dazu zu der allgemeinen Stimmung beigetragen. Der Grund, warum mich das Thema interessiert, ich habe eben letztes Jahr ein Fellowship gemacht. Und das Fellowship-Projekt ist ein Buch, was ich herausgebe zum Thema KI-Pseudo-Wissenschaften. Und in der Einleitung, das kommt auf Englisch raus, und in der Einleitung des Buches steht, Also dieses Buch ist eine Intervention, weil es ist ein bisschen mehr abgeflaucht jetzt, aber es vergeht eigentlich kein Tag oder keine Woche, in der ich nicht irgendeinen Nachrichtenartikel auf Twitter lese, wo wieder behauptet, dass KI irgendetwas kann, was es auf keinen Fall kann. Von KI kann erkennen, ob wir unsere sexuelle Orientierung erkennen, KI kann erkennen, ob wir unsere sexuelle Orientierung erkennen, KI kann erkennen, ob wir unsere sexuelle Orientierung erkennen, KI kann etnie, da kommt man ganz schnell in sehr hochproblematische, rassistische Ecken. Oder auch ganz am Anfang der Pandemie waren auch so KI Videokameras, können entdecken, ob jemand Covid hat oder nicht. Das ist ja völliger Quatsch. Aber die Frage, die dem Buch oder die das Buch nachgeht, und ich habe auch ganz bewusst, durch die Pandemie konnte ich auch dieses Fellowship nicht so verbringen, wie ich es verbringen wollte und dachte, ich möchte dieses Projektgeld dann zumindest verteilen und dann auch mit anderen Leuten teilen. Ich habe bewusst unterschiedliche Autoren eingeladen, die eben dieser Frage nachgehen, warum gibt es einfach so viel KI-Pseudowissenschaften? Warum ist das so? Und die Autorinnen haben jeweils eine ganz unterschiedliche Erklärung. Und die erste Frage, mit der wir uns so ein bisschen auseinandersetzen in dem Buch ist, was ist eigentlich der Unterschied zwischen Pseudowissenschaften, Schlangenöl und Hype? Das sind ja ganz unterschiedliche Dinge, die unterschiedliche Kerne des Problems beschreiben. Also Schlangenöl, das ist im Deutschen weniger gängig, als es so im Englischen ist. Snake Oil, das beschreibt eigentlich unfaires Marketing, also Produkte. Schlangenöl, Haut, sehr viel Kosmetik, Frauenkosmetik ist Schlangenöl. Da steht, hier ist eine Wundercreme, die irgendetwas kann und die Creme kann eigentlich gar nichts. Das ist Snake Oil runtergebrochen. Hype ist natürlich nochmal was anderes. Hype ist gar nicht immer schlecht. Hype ist einfach, naja, auch Aufregung. Wir leben ja in einer Welt, in der Aufmerksamkeit das teuerste Gut ist. Irgendwie muss man ja auch gehört werden. Und dann die dritte Kategorie ist einfach Pseudowissenschaften. Also einfach Wissenschaft, die nach Wissenschaft aussieht, aber völliger Quatsch ist. Und diese drei Kategorien schauen sich eben das Buch an. Wir haben zum Beispiel einen Beitrag von einem Journalisten, der über KI schreibt für The Verge und so ein bisschen erzählt, wie es ist, wenn er Produktpitches bekommt. Zum Beispiel hier ist eine KI-gesteuerte Zahnbürste. Und in dem Artikel reflektiert er auch darüber, wie kann ich darüber kritisch berichten, ohne dem gleichzeitig noch mehr Aufmerksamkeit zu geben. Das ist irgendwie ein Aspekt. Da ist auch eine Autorin, die spricht, eine Ingenieurin, die sagt, ganz viel ist wirklich einfach verantwortungslos. Manchmal werden einfach verantwortungslose Produkte gebaut, schlampig gebaut. Und das fand ich ganz spannend, weil das ist natürlich was anderes, wenn ich das sage, als wenn das eine Ingenieurin sagt, die in diesen Teams gearbeitet hat. Also wir schauen uns unterschiedliche Aspekte an. Aber der Begriff KI AI Snake Oil oder KI Schlangenöl stammt von einem Professor aus Princeton, den wir auch in dem Buch interviewen. Der hat diesen Begriff geprägt in einem Vortrag, in dem er irgendwie heißt How to recognize AI Snake Oil. Und das Tolle an dem Vortrag ist, er nimmt so ein bisschen auseinander. Was ist eigentlich KI? Das Problem ist ja, dass das Wort hat eine ganz klare technische Definition, wird im allgemeinen Sprachgebrauch aber benutzt, um alles Mögliche zu bezeichnen. Es gab mal eine Studie, die hat gesagt, dass 60 Prozent, die ist glaube ich jetzt zwei Jahre alt, 60 Prozent aller europäischen KI Startups machen eigentlich gar nichts mit KI. Es gibt halt einfach viel Geld, wenn man KI draufschreibt. Und was er in diesem Vortrag gemacht hat, er unterscheidet, auf der einen Seite gab es wirklich in den letzten Jahren in sehr klar und eng definierten Problembeschreibungen hat der Einsatz von KI immense Fortschritte gemacht. Sowas wie ein Objekt zu erkennen. Oder wenn man sich anschaut, wie gut sich zum Beispiel Google Translate verändert hat. Ich war vor einem Jahr in China und man kann einfach in ein Gerät auf Englisch reinsprechen und das Gerät übersetzt automatisch auf Chinesisch. Das hätten wir noch vor zehn Jahren für unglaublich gehalten. Sein Punkt ist aber, das sind sehr klar definierte, eng abgegrenzte Aufgaben. Das sind keine offenen Probleme wie die Pandemie lösen. Und er beschreibt so ein bisschen, er unterteilt die Aufgaben in unterschiedliche Kategorien und sagt eben, es gibt eine Kategorie und das habe ich immer noch nicht raus, wie man das gut auf Deutsch übersetzt, wo er sagt so Predicting Social Outcomes. Also KI ist einfach grundsätzlich immer dubios, wenn es dazu angewendet wird, um die Zukunft vorauszusagen. Sowohl die kollektive als auch die individuelle. Weil das einfach nicht geht. Und das heißt sowas wie vorausschauende Polizeiarbeit oder so sagen, wer du bist, was deine sexuelle Orientierung ist, das ist einfach Quatsch. Und das hat nichts und nur weil wir Fortschritt darin gemacht haben, Objekte zu erkennen, heißt das nicht, dass wir automatisch auch in diesen anderen Fragestellen, in diesen inherent normativen und inherent sozialen Fragestellungen denselben Fortschritt machen werden. Das heißt, das Buch ist so ein bisschen eine Aufforderung, differenzierter zu betrachten, was ist eigentlich KI, was ist eigentlich der Fortschritt und was ist auch einfach völliger Unsinn. Und du hast recht, ich mag deine Frage, weil oft trägt die Kritik dann auch dazu bei, zum Hype, zur Überhöhung der Technik. Weil man sagt, wir müssen jetzt Angst vor Algorithmen haben, wir müssen Angst vor KI haben, das ist ja Quatsch. Es kommt nämlich einfach darauf an, worum es geht. Ja und auch in der Darstellung, was sie eben können, liegt die Kritik manchmal halt dann falsch, weil sie eben zu sehr quasi diesen Marketing-Sprech eigentlich kauft. Und zur Frage der Zukunft ist natürlich dann noch das perfide, was da vielleicht noch hinzuzusagen wäre, dass auf einer anderen Ebene es ja sehr wohl wieder funktioniert, nämlich dadurch, dass so getan wird, als könne man quasi Zukunft bis zu einem gewissen Grad vorausschauen, dann ja auch Politiken betrieben werden, die auf Basis dieser Pseudo-Vorhersagen handeln und dadurch dann wiederum de facto möglichkeitskorridore eingeschränkt werden. Und das ist natürlich schrecklich. Also es gibt dem der schönste Text, das heißt Cheap AI von einer Wissenschaftlerin, die heißt Abhiba Birhane, die schreibt, man redet manchmal so in der Linguistik von Cheap Talk. Also es ist sehr einfach, diese Produkte zu konzipieren und zu bauen, aber für diejenigen, die betroffen sind, haben sie eben wirkliche Konsequenzen von, weiß ich nicht, trans Menschen, die gar nicht erkannt werden, die nicht existieren in der Kategorisierung des Systems, bis hin zu wirklich übelst rassistischen Systemen. Und diese, nur wenn man KI draufschreibt, das ist mehr als nur ein Marketing-Trick. Das gibt dem den Anschein von Zukunft und von Wissenschaftlichkeit und von Neuheit. Dabei gibt es bestimmte Anwendungen, wo wirklich einfach nur überholte Bilder repliziert werden. Auf eine Art leitet das auch über, nochmal zur Frage der Daten. Eine ein bisschen gewagte Hypothese, die ich mal in den Raum stellen will, ist nochmal zu fragen, ob wir es denn tatsächlich mit Big Data zu tun haben oder ob es nicht vielleicht angebrachter wäre zu sagen, was wir vor uns sehen ist eher Small Data insofern, als dass die Player, die in der Lage sind, diese Mengen an Daten zu produzieren, das ist ja nichts, was irgendwie frei da draußen rumliegt und müsste nur eingesammelt werden, sondern es wird produziert, es wird erschaffen und dann ausgewertet. Und die Player, die überhaupt die Ressourcen haben, um das effektiv zu tun, sind entweder Staaten oder eben Großkonzerne. Und die haben ja ein spezifisch vorgefertigtes Eigeninteresse, das im Grunde eigentlich dann ja ein Gebiet erzeugt, was relativ eng gefasst ist, also deswegen eigentlich Small Data und was dann auf dieses spezifische Gebiet hin vielleicht immer detaillierter werden kann, das mag ich sehr wohl glauben, aber das eigentlich ein riesengroßes Feld, das jenseits dieser spezifisch formierten Interessen liegt, dass das damit eigentlich unmöglich erfasst werden kann. Und daraus schließt sich dann eigentlich die Frage an, brauchen wir andere Daten? Und dann eigentlich natürlich auch bräuchten wir andere Player, die in der Lage wären, diese Daten zu produzieren. Also ich würde sagen Big but shallow. Also es gibt wirklich, es gab noch nie so viele Daten. Dieser Begriff Big Data kommt auch daher, das erfordert ganz andere Verarbeitungsmechanismen und Techniken. Ich hatte mal ein ganz spannendes Gespräch mit einer Entwicklerin, die für die BBC arbeitet und für die BBC Empfehlungsalgorithmen erarbeitet. Und die Fragestellung, ich weiß nicht, ob das nie jemals verwirklicht wurde, aber die Fragestellung, die sie sich gestellt hat, was sind Personalisierungs- oder Empfehlungssysteme, die im öffentlichen Interesse sind? Und dann die Frage, die aufkam, also weiß ich nicht, ich gehe auf BBC News und dann werden wir auch, wie bei Netflix oder bei Amazon, empfohlen, was ich als nächstes sehen soll. Der Unterschied ist nur, dass die BBC anders als Netflix eine ganz andere Daseinsberechtigung und auch Mission haben. Und die Frage, die dann aufkam, war, naja, all diese Firmen, die sammeln ja so viel Daten von uns, wäre es nicht möglich, dass man seine Netflix-Daten an die BBC spenden könnte? Und die Antwort darauf ist, es ist Quatsch, weil Netflix eben, weil es auf ein ganz anderes Ziel optimiert ist, ganz andere Arten von Daten sammelt, die für ein Empfehlungssystem im öffentlichen Interesse oder im Gemeinwohlinteresse gar nicht richtig verwertbar sind. Ich habe mal nach meinem Studium kurz gedacht, ich möchte Data Scientist werden und habe bei Zeit Online ein Praktikum gemacht, wo es auch darum ging zu messen, ja, wie kann man Qualitätsjournalismus messen? Also man will ja nicht nur auf Klicks optimieren, die Zeit ist nicht irgendein Blog, so ein Clickbait-Blog, sondern eine Zeitung, die auch schwierige Themen behandeln möchte. Was ich so interessant fand aus dieser Erfahrung heraus war, dass die ganzen Tools, die es damals vor zehn Jahren intern gab, um überhaupt das Leseverhalten zu messen, alle aus dem E-Commerce-Marketing kamen. Das heißt, die Zahlen waren dann optimiert für ganz andere Szenarien, also Szenarien, wo man möchte, dass Leute so viel Zeit wie möglich auf der Seite verbringen, dass sie so oft wie möglich klicken. Dabei ist das eigentlich keine Erfolgsmetrik für ein Medium wie Zeit Online. Es ist bestimmt jetzt ganz anders. Aber jedenfalls, genau, es gibt sehr viele Daten, aber es gibt auch sehr viele Daten überhaupt nicht. Also das ist halt dieses Paradox. Also was ich zum Beispiel spannend fand in der 2015 oder auch jetzt in der Pandemie, ganz viele Gesundheitsämter haben keine kompatiblen Datensysteme und können die Daten nicht austeilen. Also genau, zu wenig und zu viele gleichzeitig. Das bringt mich dann jetzt zu einer anderen Frage, die eher auf diese systemische Ebene abzielt eigentlich, weil sich ja auch die Frage stellt, wie kommen wir dahin, dass diese anderen Daten auch produziert werden, dass aus einer anderen Logik heraus Daten produziert werden und dadurch dann eben auch andere technologische Infrastrukturen erzeugt werden können, die andere Zielmaßgaben haben. Und da möchte ich einen kurzen Satz erwähnen, den Felix Stahlder, ein Gast aus Future Histories, auch in seinem Buch Kultur der Digitalität geschrieben hat. Der sagte nämlich, nicht der Algorithmus ist pervers, sondern die Situation, in der er lebt. Und das lässt sich jetzt wiederum ein bisschen quer schließen zum Thema dieses Kongresses hier, denn hier geht es ja auch um die Frage konsequent, inkonsequent. Und was mich immer so ein bisschen gestört hat an diesem Framing ist, dass es für meinen Geschmack zu sehr in diese Richtung tendiert, dem Individuum diese Frage zu beantworten, ob jetzt das richtig gemacht wird oder nicht. Aber meiner Meinung nach sind diese Infrastrukturen derzeit ja absichtlich und extra einfach so aufgebaut, dass wir möglichst inkonsequent im Sinne des zum Beispiel Datenschutzes usw. handeln, wenn wir uns in diesen digitalen Welten bewegen. Das heißt, um quasi den letzten Schritt dann noch zu machen, sind wir nicht inkonsequent oder konsequent inkonsequent dann insofern, als dass wir diese systemische Ebene in der Fragestellung eigentlich allzu oft ausblenden und sollten wir nicht eigentlich auf dieser Ebene auch ansetzen, weil die jetzigen Logiken, die incentivieren das ja. Die viel wichtigere Frage finde ich, wer ist wir? Und das wir ist nämlich kompliziert. Also Risiken und sowohl Risiken als auch Chancen sind extrem ungleich verteilt. Und das ist die Hauptlektion aus fast zehn Jahren Arbeit an dem Thema, ist genau das. Beispiel, wenn man sagt, Gesichtserkennung für die allermeisten, für weiße Männer ist Gesichtserkennung sehr akkurat. Für nicht weiße Frauen sieht die Genauigkeit ganz anders aus. Das ist aber nicht nur da der Fall, das ist wirklich so ein Muster, was sich durch alles zieht. Beispiel, wir werden ja auch, da geht es oft darum so, es gibt dann diese Daten von mir und dann können die gegen mich verwendet werden. Das hängt natürlich auch von meiner Lebenssituation ab. Wenn ich beispielsweise finanziell unabhängig bin, dann kann mir das sehr herzlich egal sein, ob ich damit bewerte, ob meine Kreditwürdigkeit dadurch bewertet wird. Und besonders risikobehaftete Anwendungen werden auch in der Regel tendenziell immer auf bestimmte Bevölkerungsgruppen angewendet. Deswegen dieses Wir ist kompliziert. Und das, was für die einen vielleicht sehr angenehm ist, ist vielleicht auch für jemand ganz anderen lebensgefährlich. Also das Wir ist kompliziert. Und das andere ist, ich hasse dieses auf die Individualebene bringen. Und versuche auch aus dem Grund nicht mehr so viel über Daten zu sprechen, sondern viel mehr über Macht, über Infrastruktur. Weil sobald man über Daten redet, geht es dann schnell auf das Thema, ja, was soll ich denn mit meinen Daten machen? Weil jeder fühlt sich schuldig, alle haben das Gefühl, dass sie zu viele Daten irgendwie, das ist so wie recyclen. Ich sollte mehr recyceln, ich gebe mir sehr viel Mühe, aber manchmal mache ich es doch nicht. Dabei ist das eigentlich der völlig falsche Ansatz. Niemand hat Zeit, sich jeden Tag damit auseinanderzusetzen, was mit den eigenen Daten passiert. Das ist meine Arbeit und ich habe keine Zeit und kein Interesse daran. Und wir unterschätzen auch oft, dass die, genau, das sind systemische Fragen. Es ist oft, sogar wird es einem unmöglich gemacht, überhaupt eine Entscheidung zu fällen. Man sagt so, der Satz ist immer so in dem Security-Bereich, die NutzerInnen sind eigentlich das schwächste Glied in dem ganzen System. Und wir können nicht die Verantwortung darauf abwälzen. Und wenn man da jetzt in diese Richtung weitergeht, dann, finde ich, liegt da eigentlich auch noch ein Potential für ein eigentlich uneingelöstes Versprechen, wenn man so will. Weil also diese Frage in Bezug auf was diese Technologien und Technologiebündel, was die leisten können oder nicht, die ist natürlich auf der einen Seite wichtig zu verhandeln im Sinne des Demystifizierens. Auf der anderen Seite ist es ja auch so, dass da gerade unglaublich viele Ressourcen, Kreativität, Gestaltungskraft und so weiter, jetzt mal ein bisschen polemisch zugespitzt da hineinfließen, dass man Leute dazu bringt, auf irgendwelche idiotischen Online-Ads zu klicken. Also im Grunde gäbe es da ja auch noch eine Potentialität innerhalb alternativer Technologien und alternativer technologischer Infrastrukturen, die bis zu einem gewissen Grad innerhalb der jetzigen, auch politökonomischen Formatierung eigentlich nicht eingelöst werden kann. Wenn du in diese Richtung denkst, was zeigt sich dir dann? Das Wichtigste ist mir, dass ich nicht deterministisch bin, also auch auf Plattformen, die nach fürchterlichen Logiken funktionieren, auf denen es Hass gibt, die radikalisieren, gibt es trotzdem wunderbare, interessante, spannende Inhalte. Also das ist alles viel beweglicher, als es einem so scheint. Und ich arbeite ja im Thema Regulierung, aber weil ich schon glaube, dass, oder meine Erfahrung ist so ein bisschen das Einzige, was so funktioniert, wir haben es ja mit wirklich marktdominanten Firmen zu tun. Das ist ja keine normale Situation, in dem es hier gibt ein paar Optionen und wir können uns dafür entscheiden, welche wir am besten finden, sondern wir haben eine Realität geschaffen, in der, und das war wirklich diese Woche, ich habe so viel über Afghanistan nachgedacht, man muss sich wirklich fragen, was ist denn die Außenpolitik der Plattform, die die Taliban jetzt als Regierung anerkennen? Das zeigt nochmal, wie viel Macht diese Plattformen haben. Das ist ja absurd, dass wir überhaupt diese Frage stellen müssen, weil das das Medium ist, über das die ganze Welt Dinge erfährt. Und selbst wenn man eine Nachrichtenagentur ist, aber wenn man eine Nachrichtenseite hat, eine Zeitung, man ist abhängig vom Plattform zu den Lesern zu finden. Das ist schon nur unglaublich, also das ist völlig absurd. Also wir befinden uns nicht in so einem Markt, wo man sagen kann, das ist so, was könnten die Alternativen sein, sondern für mich ist schon der erste Punkt, es kann nicht sein, dass so viel Macht in der Hand ungewählter Firmen liegt, auch wenn die gar nicht nur schlecht sind und auch oft, das wird oft vergessen in Europa, dass es natürlich auch viele Länder gibt, in denen Social Media Firmen lange Zeit und auch immer noch Alternativen zu staatlicher Zensur sind. Also das ist komplexer, das sind nicht nur die Bösen, weil man will ja auch nicht, dass autoritäre Regime die Öffentlichkeit kontrollieren. Also es ist hochkomplex, aber so ganz grundsätzlich, wenn man nur, wenn ich jetzt einen Schritt zurückgehe und mir darüber nachdenken würde, in welcher Welt möchte ich leben? Ich möchte nicht in einer Welt leben, in der ich mich fragen muss, was Facebooks Außenpolitik ist und wie Facebook zur Taliban steht. Das ist einfach absurd. Und um zumindest dieser Macht etwas entgegenzusetzen, das Einzige, was funktioniert, sind börsennotierte Unternehmen, Regeln, Klagen, Regeln, Klagen und natürlich auch so ein bisschen veränderte Stimmung in der Gesellschaft, verändertes Nutzungsverhalten, aber ich glaube schon an Regulierung zu einem gewissen Grad. Das sind aber nicht, das sind nur die Spielregeln. Also Regulierung sind die Spielregeln der Digitalisierung. Und deswegen ist es unglaublich wichtig. Aber das ist nicht das Endziel, das ist nur so der erste Schritt, um überhaupt irgendwie die Möglichkeit für Alternativen zu schaffen. Weil wenn jedes Start-up davon träumt, von Google gekauft zu werden, dann werden wir auch keine Alternativen kriegen. Und von da aus? Wie bitte? Und von da aus? Also ich gehe mit, sozusagen kurzfristig, Regulierung sehr gerne und viel. Aber ich finde trotzdem noch die darüber hinausgehende Frage auch interessant. Also was für digitale Infrastrukturen bräuchten wir, jenseits der Frage, ob man jetzt irgendwie eine Marktkonkurrenz wieder herstellen kann, in Anführungsstrichen. Weil meine Vermutung wäre, dass auch das Herstellen einer mutmaßlichen Marktkonkurrenz trotzdem natürlich ja dann wieder Player zurücklassen würde, die am Ende über monetäre Incentivierung funktionieren und letztlich eigentlich auf einen Profitstreben hinaus ausgerichtet sind. Was ja wieder die Logik eigentlich gewaltsam sehr stark beschränkt oder begrenzt. Wir leben halt im Kapitalismus, ne? Wir leben halt im Kapitalismus. Also, for better or worse, da geht es dann um ganz Grundsätzliche. Grundsätzliche, klar. Sollte der Raum, und Raum ist ja schon schwierig. Was ist denn eigentlich, ich war so fasziniert von dem Vortrag, der eben war, wo es darum ging, da hatte eine Zuhörerin gefragt, ist denn WhatsApp Social Media? Das fand ich großartig, weil oft einfach diese Begriffe verendet werden. Was ist denn das überhaupt? Also was ist denn die Alternative, ich gehe so ein bisschen deiner Frage aus, aber über die Alternative von was sprechen wir denn? Also so Amazon, Facebook, das sind ja nicht Social Media Firmen. Das sind Technologiekonzerne, die Monopolien oder marktdominante Stellung in allen möglichen Bereichen haben. Und die öffentliche Diskussion, da geht es eigentlich immer fast nur um Social Media. Aber es ist ja völliger Quatsch, die ganze Infrastruktur dahinter, die Daten, die überall herkommen, die Datencenter, die Server, etc. Du merkst, ich bin so ein bisschen in Verlegenheit, weiß ich nicht, soll ich, es ist ja auch nicht mein, das ist was Kollektives. Wer bin ich, das ich jetzt sagen soll, wie das aussehen soll? Das Einzige, was ich sagen kann, ist, es gibt so ein paar Grundsätze und Prinzipien, die ich fände sinnvoll wären. Und ein Prinzip ist, es gibt eine Reihe von Fragen, die einfach, solange sie menschenrechtskonform sind, in unterschiedlichen Teilen der Welt eben anders beantwortet werden. Was finden wir akzeptabel, was empfinden wir als Hass, was sollte man nicht sagen dürfen, etc. Und das muss natürlich einer demokratischen Kontrolle unterliegen. Gut, ich lasse dich heraus. Aber am Ende, Frederike, stelle ich einer jeden und einem jeden immer noch die Frage, wenn du dir Zukunft vorstellst, was stimmt dich freudig? Ich muss wirklich sagen, diese Woche war ich, die ganzen 18 Monate waren wirklich bitter. Also die Pandemie war ganz schön hart, dann irgendwie auch noch politisch. Also wir leben schon in ziemlich harten Zeiten. Aber auf der anderen Seite merkt man dann halt auch, worum es geht und was wirklich wichtig ist. Ich bin einfach, das ist halt einfach nur meine Persönlichkeit, ich bin immer optimistisch, ich sehe immer die Möglichkeiten und was man noch ändern kann und was man machen kann. Sonst würde ich aber auch nicht zu dem Thema arbeiten, weil es wirklich zum Teil diffamierend ist. Also ich habe für eine Organisation gearbeitet, die Klagen eingereicht hat gegen Geheimdienste nach den Snowden-Enthüllungen. Und dann Jahre später haben sie Recht bekommen, aber währenddessen haben die Regierung einfach das Gesetz verändert. Also ja, es war illegal, aber jetzt ist es legal. Es ist schon so ein, ja, was gibt mir Hoffnung? Ich finde ganz aufregend die Fridays for Future Klimabewegung. Auch wenn es hier in unserem Gespräch geht es ja nicht um Klima, sondern um Technologien. Aber irgendwie habe ich das Gefühl, da kommt eine neue Generation, die viel fordernder ist, als ich das in dem Alter war. Und das gibt mir sehr viel Hoffnung. Und dann denke ich schon, dass sich in den letzten Jahren, es hat sich schon auch viel verbessert. Also es gibt viel mehr, wenn ich mit Politikern spreche, das Verständnis ist viel größer. Vor ein paar Jahren war das noch desaströs. Es gibt viel mehr Menschen in Entscheidungspositionen, die verstehen, worum es geht. Und es gibt auch ein größeres Verständnis dafür, dass der Status Quo so nicht richtig nachhaltig ist. Und das sind kleine Fortschritte und die geben mir Hoffnung. Wunderbar, dann sollten wir alle viel mehr fordern. Und ich danke dir, Friederike, für dieses Gespräch. Euch auch danke fürs Zuhören und Dasein. Das war Future Histories für heute. Vielen Dank fürs Zuhören, Show-Notizen und vieles mehr findet ihr auf www.futurehistories.today. Diskutiert mit auf Twitter unter dem Hashtag Future Histories oder im eigenen Subreddit. Ihr könnt Future Histories nicht nur auf allen großen Podcast-Plattformen hören und abonnieren, sondern auch auf YouTube, wo ihr neben den Episoden dann auch Kurzvideos zu Kernbegriffen einzelner Episoden findet. Schreibt mir gerne unter jan at futurehistories.today. Ich freue mich immer sehr über interessante Rückmeldungen und Hinweise. Wenn ihr Future Histories unterstützen wollt, dann könnt ihr das auf patreon.com-futurehistories oder auch via Spende auf unserer Homepage. Future Histories ist eine Produktion von MetaLapses, zu finden auf meta-lapses.net. Bis zum nächsten Mal. Ich freue mich. 

Episode Keywords:

#FrederikeKaltheuner #Datensouveränität #Data #ArtificialIntelligence #KI #KünstlicheIntelligenz #SnakeOil #DatenGerechtigkeit #Datafizierung #AI #NeuronaleNetze #DeepLearning #DigitalerKapitalismus #DasRegierenDerAlgorithmen #AlgorithmischesRegieren #Technokratie #DasRegierenDerAlgorithmen
