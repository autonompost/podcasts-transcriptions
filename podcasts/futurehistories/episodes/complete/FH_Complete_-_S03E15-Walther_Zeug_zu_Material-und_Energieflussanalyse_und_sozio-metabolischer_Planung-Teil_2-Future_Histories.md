# FH Complete S03E15 - Walther Zeug zu Material- und Energieflussanalyse und sozio-metabolischer Planung (Teil 2) | Future Histories

Herzlich willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft. Mein Name ist Jan Groß und ihr hört heute den zweiten Teil meines Gesprächs mit Walter Zeug zu Material- und Energieflussanalyse und sozio-metabolischer Planung. Wir haben im ersten Teil ja schon ausführlich über Walters HIGSA-Methode gesprochen und steigen im heutigen zweiten Teil des Gesprächs mit Anmerkungen dazu ein, dass in heutigen Datenbanken die Lebenszyklusanalysen zugrunde liegen. Zwar Arbeit erscheint, aber der komplette Bereich unbezahlter Sorgearbeit invisibilisiert wird und dass es daher auch ganz unbedingt neuer Datenbanken bedarf. Danach widmen wir uns dann dem von Walter zusammen mit Jakob Heyer verfassten Paper zu Ökobilanz und kybernetische Wirtschaftsplanung. Also viel Freude mit der heutigen Folge Future Histories, dem zweiten Teil meines Gesprächs mit Walter Zeug zu Material- und Energieflussanalyse und sozio-metabolischer Planung. Ich hoffe, das hatte ich gestern dazu gesagt, dass die Datenbanken ja keinerlei Reproduktionsarbeit, Sorgearbeit, Care-Arbeit erfassen und auch nur einen geringen Teil der Dienstleistungen, die ja tatsächlich in Produktionsprozessen enthalten sind. Aber das ist auf jeden Fall der Punkt, dass das ja vielleicht sogar in den Datenbanken, die wir aktuell haben, die allerwesentlichste Lücke ist, wo man sagen kann, man kann diese Datenbanken, so wie sie sind, eigentlich für eine Art postkapitalistischer Produktionsplanung so nicht verwenden, weil sie halt eben nur einen ganz bestimmten Ausschnitt der gesellschaftlichen Arbeit darstellen und das Bild auch teilweise extrem verzerren würden, wenn man nur das nimmt, weil halt eben es Arbeitsprozesse gibt, die vielleicht einer sehr hohen Sorge- und Care-Arbeit sozusagen bedarfen, die aber de facto in diesen Datenbanken unsichtbar gemacht wird. Und das ist ja auch keine Überraschung, weil das ist ja genau die Eigenschaft dieser im Kapitalismus geschaffenen Datenbanken, dass sie ja auch nur unter weitestgehend kapitalistischen Prinzipien bilanzieren und dazu gehört eben nicht die Sorge- und Care-Arbeit, weil diese Allokation der Arbeitszeit zu bestimmten Regionen und Sektoren erfolgt ja letztlich über eine monetäre Verrechnung des Bruttoinlandsprodukts. So kommen ja überhaupt erst diese Daten zustande, es sind ja keine Primärdaten. Und im Bruttoinlandsprodukt ist die Produktion von Pansern erfasst, auch die Produktion von Bleistüften, Matjes und Heizkörpern hat da halt eben nicht die Sorge- und Care-Arbeit. Und damit wird die sozusagen über diese Generierung der Daten aus dem BIP de facto schon oder aus dem GDP de facto schon unsichtbar. Was man machen müsste, um das Problem zu beheben, ist de facto eine tatsächliche Primärdatenerhebung mit einem, ich sag mal, emanzipatorischen Anspruch daran, der halt eben all das, was wir in der Linken als Arbeiten und Tätigkeiten mit gesellschaftlicher Relevanz diskutieren, auch erfasst. Die Datenbanken sind also nicht, ich sag mal, die Grundlage für diese sozialistische Produktionsplanung, sondern sie geben uns eigentlich nur bestenfalls eine Idee, wie sowas aussehen könnte, wenn wir es dann aber richtig und vernünftig machen mit allem, was dazugehört. Das heißt, wir brauchen auf jeden Fall neue Datenbanken, die dann eben auch Sorgtätigkeit beinhalten. Wir brauchen aber eben nicht nur diese neuen Datenbanken, sondern es gilt natürlich grundsätzlich, die Perspektive zu erweitern, hin zu einer Form von gesamtgesellschaftlicher, sozio-metabolischer Planung. Und du hast da zusammen mit Jakob Heyer ein Paper geschrieben mit dem Titel Ökobilanz und kybernetische Planwirtschaft. Vielleicht magst du uns da einmal kurz einführen, was sind so die grundlegenden Überlegungen? Vielleicht kannst du das einmal skizzieren, wie ihr über Ökobilanz und kybernetische Planwirtschaft nachdenkt. Also wir haben damit angefangen zu schauen, welche Stärken und Schwächen haben bisherige Konzepte von einer kybernetischen Planwirtschaft und welche Stärken und Schwächen hat diese LCA, LCSA oder HILSA-Methodik? Und was kann man de facto von beiden Elementen zusammenbringen, um insgesamt ein stärkeres Konzept zu entwickeln? Das heißt, es wird Elemente der kybernetischen Planwirtschaft geben, die wir bisher diskutiert haben, die wir so nicht weiter aufnehmen werden. Es wird aber auch Elemente aus dem LCA geben, die so in der kybernetischen Planwirtschaft mit einem emanzipatorischen Anspruch nicht umsetzbar sind. Also es geht da wirklich darum, diese Methoden auch noch mal grundlegend neu zu denken und weiterzuentwickeln. Aber prinzipiell ist es so, dass dieses Modell dieser kybernetischen dezentralen, zentralen Planwirtschaft, die sehr demokratisch ausgestaltet werden soll, drei Ebenen umfasst. Und diese drei Ebenen sind auch Ebenen, die wir auch aus bisherigen Modellen kybernetischer Planwirtschaft und von Planwirtschaften allgemein kennen, wie eben beispielsweise bei Ted DeVine oder Nightmare. Und die erste Ebene ist diese Ebene der zentralen Planung, die de facto zur Aufgabe hat, Makropläne zu erstellen. Und diese Makropläne sollen demokratisch entwickelte Prioritäten, Entwicklungsrichtungen sein, um Investitionen zu steuern, um Basisdienste regeln zu können, um sich auf beispielsweise planetare Grenzen zu einigen und insgesamt einfach die Proportionen und Parameter dieser Produktionssysteme in bestimmten Sektoren und Regionen demokratisch festzulegen. Die Planung auf der zentralen Ebene muss dafür auf jeden Fall in einem sehr hohen Maße deliberativ sein und eben auch demokratisch oder direktdemokratisch mit repräsentativen Prinzipien konstruiert sein. Das politische System dahinter, also ob das jetzt beispielsweise ein Redesystem ist oder andere Systeme, das denken wir jetzt noch nicht explizit mit. Das ist auf jeden Fall noch ein Punkt, den man weiterentwickeln muss, was wir in Zukunft gegebenenfalls auch tun werden. Damit sei bloß gesagt, das ist ein sehr ökonomisch gedachtes System, ohne jetzt irgendwie diese Trennung von Ökonomie und Politik machen zu wollen. Aber der Schwerpunkt liegt hier sozusagen auf der ökonomischen Ebene. Wichtig ist dieses dezentrale, zentrale System aber insbesondere deshalb, weil es, auch wenn wir den Schwerpunkt eigentlich auf die Dezentralität legen, es zentrale Funktionen bedarf, die man nicht dezentral lösen kann. Also beispielsweise muss man für Energiesysteme, die ja de facto aus lokalen Einheiten bestehen, die sie produzieren, die Energie, aber auch konsumieren die Energie, trotzdem über regionale Outputziele festlegen, weil das ja Netzwerksysteme sind und die man nicht ausschließlich regional dezentral planen kann. Also beispielsweise sowas wie Energiesysteme, die auch mit hohen Investitionen einhergehen, also auch mit hohen infrastrukturellen Aufwendungen, sowas muss man de facto zentral planen, weil ja auch nur eine zentrale Planung von solchen sehr übergreifenden komplexen Strukturen eine gewisse ökonomische Rationalität entfaltet, die es auf einer dezentralen Organisation nicht unbedingt schaffen würde. Man könnte sich das beispielsweise vorstellen an einem Eisenbahnnetz, was ausschließlich dezentral geplant würde und jede Kommune das Eisenbahnnetz für sich planen würde. Das würde natürlich nicht funktionieren. Also das ist die zentrale Ebene. Der große Unterschied zum sowjetischen Modell ist aber, dass eben nicht die gesamte Wirtschaft zentral geplant wird und vor allem diese physischen Outputziele für die lokalen Einheiten nicht zentral vorgegeben werden. Also das heißt, die zentrale Ebene würde nicht dem Betrieb der Schrauben produziert in einer bestimmten Region ganz genau vorschreiben, wie viele Schrauben die zu produzieren hätten, unter welchen Bedingungen, mit welchen Methoden, mit was für Maschinen und welche Inputs und Outputs es insgesamt dafür bräuchte. Also das wollen wir nicht. Das wäre die Kommandowirtschaft nach sowjetischem Vorbild, die halt eben dysfunktional ist, letztlich einfach schon deshalb, weil sie überhaupt gar nicht über die notwendigen Informationen und das lokale, dezentrale Wissen verfügt, was eigentlich notwendig ist, um in diesen lokalen Produktionseinheiten überhaupt eine effektive Produktion hinzubekommen. Abseits von diesem zentral geplanten Sektor ist der eigentliche Schwerpunkt aber die kybernetische, das heißt die parametrische und die adaptive Steuerung und vor allem Regelungen von vor allem der Rahmenbedingungen innerhalb dieser lokalen Einheiten dezentral dann eigenverantwortlich planen und wirtschaften und das aber tun mit dem Blick unter Berücksichtigung der zentralen Ebene. Denn wichtig ist ja, dass auch auf dieser dezentraleren Ebene eben die planetaren Grenzen nicht überschritten werden dürfen, genauso wie sie das halt eben auch auf der zentralen globalen Ebene nicht überschritten werden dürfen und dass diese Budgets sowohl global als auch regional eingehalten werden müssen. Also beispielsweise das Budget, was wir an CO2-Emissionen zur Verfügung stehen haben und das Budget, was wir an, das ist ja ein globales Budget, aber auch das Budget, die wir regional zur Verfügung stehen haben, also beispielsweise Landflächen oder Wasser, das sind regional begrenzte sehr unterschiedliche ökologische Budgets. Darum ist es auch wichtig, dass wir nicht einfach durchschnittswerte zentral ansetzen, beispielsweise für den Wasserverbrauch oder für das zur Verfügung stehende Wasser oder für die zur Verfügung stehenden Landflächen, Böden etc. pp. um dieser regionalen Differenzierung, um dieser regionalen Unterschiedlichkeit halt eben auch gerecht zu werden, sondern solche regional spezifischen Größen müssen dann halt eben auch regional bestimmt werden, aber als Information an die zentrale Ebene weitergegeben werden und dort in ihrer spezifischen Ausprägung eben berücksichtigt werden. Das ist die zentrale Ebene. Die zweite Ebene ist die Ebene der wissenschaftlich-ökonomischen Gesamtrechnung. Und diese Ebene der wissenschaftlich-ökonomischen Gesamtrechnung ist de facto eine wissenschaftlich-ökonomische Informationsebene zwischen der zentralen und dezentralen Ebene, die aber keine eigene ökonomische Funktion im Produktionsprozess hat, als dass dort Entscheidungen gefällt würden oder Dinge tatsächlich produziert werden, sondern die ist letztlich entscheidend für eine kypanetische und ein ökologisches Plansystem, um überhaupt kohärente, ganzheitliche und zugleich transparente Methoden in der gesellschaftlichen Buchführung realisieren zu können. Und diese gesamtgesellschaftliche Buchführung wird mit Echtzeitdaten gefördert und diese Echtzeitdaten kommen sowohl aus der dezentralen Ebene als auch aus der zentralen Ebene. Und was dort gemacht wird, ist, den Anspruch zu verfolgen, den gesamten Wirtschaftsprozess möglichst genau symbolisch beschreiben und modellieren zu können, das heißt also eine Art verschachteltes Modell des gesamten Produktionsprozesses darstellen zu können, der sowohl die lokalen Bottom-up als auch die globalen oder zentralen Top-Down-Elemente integriert. Die verschiedenen Ebenen und Einheiten können und sollen damit eine realistische, kohärente und effizite Planung, Koordination der Produktion ermöglichen, indem sie dieses möglichst detailgetreue Bild der Verhältnisse vorliegen haben, also sowohl auf der dezentralen als auch auf der zentralen Ebene, um einerseits die sinnvollen Makropläne zu ermöglichen, umgekehrt aber auch den lokalen Einheiten eine möglichst genaue Einschätzung ihrer spezifischen Stellung im Reproduktionsprozess zu erlauben und damit auch der Mikroebene eine sinnvolle Planung und Koordination der Aktivitäten zu ermöglichen. Und hier dient LCA oder HILSA letztlich einfach als eine Art Möglichkeit einer software- und datenbankgestützten Nutzung dieser Plattform für eine komplexe ökonomische Netzwerkorganisation, also das heißt für die Bilanzierung, die Verrechnung, beispielsweise der regionalen, planetaren und ökologischen Grenzen, der Knappheit natürlicher Ressourcen, aber halt eben auch für die Vernetzung der jeweiligen Sektoren und Regionen miteinander. Das ist auch gar nicht so unglaublich neu, denn schon heute gibt es ja beispielsweise dieses Enterprise Resource Planning, also das heißt auch im digitalen Kapitalismus gibt es bereits diese voranschreitenden, datengetretenen Management- und Planungstechnologien, die halt eben auf Informationstechnologien digitaler Steuerung von Unternehmen beruhen und beispielsweise in Clouds dieses Wissen schon zentralisieren, allerdings dort halt eben im Privateigentum befinden und mit dem Geschäftsgeheimnis eben nicht Transferenzen und nicht für eine gesellschaftlich bewusste Planung zugänglich werden. Die wesentlichste Ebene in der dezentral-zentralen, demokratischen, hypernetischen Planwirtschaft ist aber die dezentrale Ebene, also das heißt die Ebene der lokalen Einheiten, das heißt der selbstverwalteten Betriebe, die selbstverwaltet planen, koordinieren und wirtschaften und auch weitestgehend selbstständig und eigenverantwortlich agieren, aber halt eben unter Berücksichtigung der Makropläne, also das heißt der ökologischen Grenzen und den allokierten Budgets der Sektoren und Regionen, als auch unter Berücksichtigung der gesamtgesellschaftlichen Buchführung und der zur Verfügung gestellten Informationen und Parameter, das heißt auch unter ihren eigenen spezifischen lokalen Bedingungen, also indem sie selbst vor Ort demokratisch sozusagen probieren zu entscheiden, ob bestimmte Produktionsmethoden unter einer bestimmten Flächenverfügbarkeit, unter bestimmten Bodenbedingungen, unter bestimmter Wasserverfügbarkeit halt eben nachhaltig überhaupt darstellbar sind in dieser Region und vor allem erstellen diese lokalen Einheiten neben dem, was sie tatsächlich vom gesellschaftlichen Nutzen produzieren, detaillierte Pläne über Inputs und Outputs, kleinere Investitionen, Bestände, Umsätze, Leistungen etc. pp. Und genau diese Bilanzierung, diese detaillierten Pläne über Inputs und Outputs, die können über LCA-Datensätze direkt in den Betrieben erfasst werden und dann in die Datenbanken auf der zentralen Ebene und der Ebene der holistischen Gesamtrechnung integriert werden. Also das heißt, man hätte damit eine Datenbank gestützte regionale und überregionale Transparenz über die Produktionsprozesse und weil man diese hat, also auch über die Inputs und Outputs, könnte man dann dort eine Art stoffliche Verteilplattform für Zwischen- und Produkte herstellen. Also das heißt, eine Verteilplattform, wo andere Betriebe schauen können, welche Inputs und Outputs in einer bestimmten Region anfallen und sich der dann bedienen, um halt eben keine Märkte schaffen zu müssen für die Interaktion von Betrieben miteinander, sondern eben die Verteilplattform von bestimmten Inputs und Outputs, die anfallen, letztlich auch im Sinne einer Kreislaufwirtschaft, das heißt, offene Stoffströme miteinander zu verbinden und damit die ökologischen Auswirkungen einerseits zu reduzieren, andererseits aber die Effizienz und die Effektivität dieser Produktion überhaupt zu erhöhen. Und das aber nicht, wie das teilweise im Kapitalismus funktioniert, nach den verkürzten Kriterien des Profils, sondern halt eben tatsächlich nach dem Kriterium der stofflichen, energetischen und ich sag mal sozialen, also in der Arbeitszeit, Effizienz und Effektivität. Diese spezifische Form der Mehr-Ebenen-Organisation, wenn man so will, du hattest es jetzt schon angesprochen, die kennen wir innerhalb der Planungsdebatte auch aus anderen Modellen, du hattest Divine angesprochen, aber auch David Leibmann eben mit seiner Multi-Level Iterative Coordination, Multi-Level Democritic Iterative Coordination, das ist wichtig, das Democritic, auch dem Plattenkampf hat da so ein bisschen dran angeknüpft und auch dezidiert eben die Kybernetik mit hinein gebracht. Und ein interessantes Element dabei oder eine große Frage, die sich da natürlich immer stellt, ist die Frage der Vermittlung zwischen den Ebenen, weil du hast jetzt natürlich in einem nachvollziehbaren Optimismus das so dargestellt, als ob quasi die dezentralen Ebenen natürlich dann ihre Information von unten nach oben schicken, das auch vollkommen annehmen, dass bestimmte Parameter wiederum von oben angegeben worden sind und sie ihr Handeln quasi innerhalb dieser Parameter organisieren und koordinieren sollten. Das ist also jetzt erstmal recht harmonisch quasi dargestellt und das wäre natürlich super, wenn das auch selbstverständlich so funktioniert, aber stellt sich ja trotzdem die Frage, wenn es semi-autonom handelnde Akteurinnen auf der dezentralen Ebene gibt, die eben vielleicht auch andere Interessen haben mitunter oder einfach spezifische regionale Interessen haben, die eventuell mit den parametrischen Vorgaben der zentralen Ebene vielleicht im Konflikt stehen, welche Formen der Vermittlung es gibt, um trotzdem zu einer Form von funktionierendem Gesamtsystem kommen zu können. Also das war ja bekannterweise in der, also nochmal ganz klar ausgesprochen, hierarchischen Planung der Sowjetunion immer wieder ein Problem. Man hatte die sogenannten perverse incentives, also es gab da sozusagen definitiv feststellbare Konfliktlinien zwischen den dezentralen Akteurinnen und den zentralen Ebenen und die Debatte versucht, das ja in verschiedenster Weise aufzulösen. Wie geht ihr da dran innerhalb eures Modells, wenn es um diese Frage der Vermittlung zwischen den verschiedenen Ebenen geht? Also einerseits will ich vorwegschicken, dass ein ganz wesentlicher Teil der Vermittlung zwischen dezentraler und zentraler Ebene letztlich auch auf einer politischen Ebene stattfinden wird und diese politische Ebene ist eine, die wir aktuell noch weitestgehend ausklammern. Also welche Institutionen in welchen Beziehungen zueinander stehen und welche Akteure vielleicht auch in welchen Gremien oder in welchen Entscheidungsmustern welche Mächte auch transparent gemacht werden. Macht wird es auch immer geben, die Frage ist halt eben nur, ob sie transparent und demokratisch verteilt werden kann. Ich kann aber so ein bisschen probieren zu skizzieren, wie es wäre, zumindest auf der rein ökonomischen Ebene. Letztlich werden wir natürlich probieren, aufgrund der engen Verschaltung von zentraler und dezentraler Ebene diese Konflikte so klein wie möglich zu halten. Auch darüber, dass es eben nicht wie im sowjetischen Modell eine klare Hierarchisierung von zentraler und dezentraler Ebene gibt. Wenn dieses System aber gut funktioniert zwischen dezentraler und zentraler Ebene, vor allem über diese Ebene der wissenschaftlich ökonomischen Gesamtrechnungen, dann haben wir auf einer zentralen Ebene das Vorliegen dieser lokalen aggregierten Pläne, in der dann auch Unstimmigkeiten festgestellt werden, wo man auch Prognosen machen kann, Optimierungsvorschläge, die dann wieder an die dezentrale Ebene zurückgegeben werden können, dort zurückgespiegelt werden können. Und die Paktone Diskussion eigentlich idealerweise schon erfolgt, bevor sich Konflikte aufbauen, indem man sie frühzeitig identifiziert, da ja idealerweise diese Informationen auch in Echtzeit vorliegen. Es gibt ja dieses Sprichwort, dass jedes große Problem mal klein war. Und so könnte man versuchen, die großen Probleme quasi schon zu bearbeiten und zu identifizieren in dem Moment, wo sie klein angefangen haben. Natürlich wird es diese Probleme unter Umständen trotzdem geben. Aber wir denken schon, dass diese Autonomie und Initiative der lokalen Einheiten überhaupt erst die verlässlichen und kompetierbaren Informationen erzeugt, um überhaupt mit diesem lokalen, spezifischen Wissen aggregierten Daten auf dieser zentralen Ebene herstellen zu können. Und diese Konvergenz und Regelungen zwischen Makroplanung und Mikroaktivität effektiv zu koordinieren. Ein Teil davon wird das Token-System sein, auf das wir vielleicht noch zu sprechen kommen. Das wäre sozusagen die Art eher operationalistische Vermittlung zwischen zentraler und dezentraler Ebene, jenseits sozusagen dieser politischen Vermittlung, die wir hier noch ein Stück weit ausklammern. Vielleicht können wir ein bisschen genauer uns nochmal diesen Mechanismus der gesamtgesellschaftlichen Buchführung angucken, weil du hast verschiedene Elemente natürlich jetzt schon angesprochen. Du hast vor allem eben gesagt, solche Methoden wie HIXA und Lifecycle Analysis können dazu dienen, dass ezentrale AkteurInnen eben auch ein lokales Wissen über diese Lifecycle Analysis in den Planungsprozess und in diese gesamtgesellschaftliche Buchführung mit einspeisen. Das heißt, das ist ja sehr schön. Wir haben da quasi ein Element auch von Bottom-Up-Planung, ein Tool, dass sozusagen diese Bottom-Up-Planung auf einer bestimmten Ebene eben zumindest mal auch erlaubt und möglich macht. Welche anderen Aspekte gibt es denn doch, wenn man zu einem Punkt der gesamtgesellschaftlichen Buchführung kommen will? Vielleicht können wir versuchen, da mal so ein bisschen dieses Bild zu vervollständigen, weil also wir hatten ja jetzt schon zum Beispiel natürlich ausgewiesen, es braucht andere Daten. Das war ja ein großer Punkt. Also es braucht quasi noch ganze Felder, wie zum Beispiel die Sorgearbeit, die in heutigen Datenbanken überhaupt nicht aufscheinen. Aber es ist ja auch trotzdem noch eine offene Frage, was es noch auf einer methodischen Ebene weiter braucht, wenn man so eine gesamtgesellschaftliche Buchführung wirklich an den Start bringen will, weil, wenn ich das jetzt noch mal den Hörerinnen in Erinnerung rufen darf, zumindest jetzt bei Hilxer oder bei der Life-Cycle-Analysis, die du jetzt vorgestellt hattest, ging es ja eigentlich darum, dass man zwei Prozesse, die ähnlich sind, aber zum Beispiel unterschiedliche Materialien verwenden, miteinander vergleichbar macht. Das ist ja eigentlich dann eine ganz andere Aufgabe im Grunde als so eine Form der gesamtgesellschaftlichen Buchführung. Wie ist dieses System sozusagen aufgesetzt, damit es trotzdem in der Lage ist, diese Abbildbarkeit zu leisten, von der du sprichst, anhand derer dann eben unbedingt politische und demokratisch deliberative Prozesse sagen, angehängt sein müssen, um auf Basis dieser Informationen dann auch kollektive Entscheidungen treffen zu können. Was braucht es da noch? Einerseits müsste man vielleicht erstmal verstehen, warum wir überhaupt von Kybernetik sprechen und warum dieser Schwerpunkt auf dieser Kybernetik liegt, die wir im Paper auch nochmal genauer herleiten und substantiieren mit Konzepten. Also diese kybernetische Steuerung und Regelung von komplexen Systemen hat eigentlich eine zentrale Motivation, dass man eine Art Selbstregulierung von zumindest Teilsystemen so weit wie möglich vorantreiben kann, um und damit aber gleichzeitig eine Gesamtkoherenz insgesamt des gesamten Systems zu erreichen und auch eine kontinuierliche Kommunikation letztlich zu erreichen und die auch besonders effizient darzustellen. Diese Kybernetik kann man letztlich auch verstehen und das erinnert jetzt gleich so ein bisschen an die Commons, als eine Art Planung von Emergenz, also das heißt ein emergentes Verhalten von Akteuren auf der dezentralen Ebene ergibt sich ja aus der Interaktion dieser lokalen autonomen Einheiten innerhalb dieses dezentralen Plansystems und lebt vor allem davon, dass die Regeln der Interaktion und die Parameter dieser Kybernetik in einem Plansystem bewusst und demokratisch manipulieren und gestaltbar sind. Also das heißt, über die Kybernetik kann man versuchen diese Parametrisierung, diese Steuerung und Regelung dieser Systeme so weit wie möglich zu treiben und braucht dafür letztlich abstrakte Repräsentationen von Kosten, Nutzen und Grenzen. Und wir würden sagen, dass diese Abstraktion von Kosten, Nutzen und Grenzen de facto auch das Thema Universal Unit of Account hinausläuft und wie man das, ich hatte es ja bereits angedeutet, wir haben da dieses Token-System vor Augen, wie das ausgestaltbar ist mit der Hilfe von LCA. Es gibt ja eine lange Debatte und auch Kritik daran, inwiefern es überhaupt so eine Art universelle und umfassende kommensurabte Recheneinheit gäbe, weil es ja von dazu unendlich viele konkrete physische, ökologische, soziale Dimensionen gibt, die in diese Verhandlungen mit einfließen müssen und sich ja gar nicht so richtig auf eine Einheit oder auf einen abstrakten gemeinsamen Nenner bringen lassen, wie man das vielleicht beim Geld aktuell denkt, dass es so sei, aber das natürlich unglaublich viele Probleme mitbringt und das Geld halt eben nicht in der Lage ist, diese kommensurabilität tatsächlich herzustellen und diese Informationsverdichtung rational und vor allem transparent zu machen. Es gäbe aber eine Möglichkeit, über die Tokens letztlich eine Vermittlung zwischen dezentraler und zentraler Ebene insofern herzustellen, dass diese Tokens zwei Dimensionen oder Funktionen verfolgen oder erfüllen können. Die Dimension eins, bzw. Funktion eins ist, dass man die Tokens nutzen kann, als eine parametrisierte Aggregation der Kosten, also de facto eine Art sozial-ökologische, sozialistische Produktionspreise zu erstellen. Das könnte so aussehen, dass die Tokens letztlich eine aggregierte Information darüber darstellen, welchen Naturverbrauch, Stoff, Energieverbrauch und welche Arbeitszeitaufwendungen unter welchen konkreten Bedingungen für die Produktion bestimmter Güter notwendig sind. Also, ich sage es nochmal ganz kurz anders, ein Token stellt sozusagen den bestimmten Naturverbrauch, eine bestimmte Aufwendung von Stoff, Energie und Arbeitszeit dar. Die LCA-Methoden wie HESA, bzw. auch erweiterte Input-Output-Methoden, lassen ja es zu, diese vielfältigen Dimensionen nicht nur zu quantifizieren, also das heißt, wir hätten jetzt beispielsweise 20 unterschiedliche Stoffströme, Methan, CO2 beispielsweise, aber auch andere Gase, die zum Klimawandel beitragen. Der Klimawandel selbst ist eine Wirkungskategorie und diese Wirkungskategorie selbst stellt ja schon eine Aggregation dar, indem wir halt eben sagen, unterschiedliche Stoffströme führen zu dieser und jener Temperaturerhöhung. Also, man kann einerseits sozusagen mit LCAs auf diese Wirkungskategorien schon Informationen aggregieren, andererseits kann man aber auch ganz unterschiedliche Wirkungskategorien in den Tokens wiederum aggregieren, das heißt, man könnte eine Art synthetische Indikatorik erstellen, die letztlich einfach zum Ziel hat, die Komplexität zu reduzieren und das in so einem Planungs- und Rechnungswesen in dieser Budgetierung überhaupt handhabbar zu machen. Und was es letztlich geht, ist ja eine gewisse Vergleichbarkeit von Inputs und Outputs, von Kosten und Leistungen, also von diesen unzähligen unterschiedlichen Gütern, Dienstleistungen, Produktionstechniken in den Unternehmen zu erstellen. Man könne sich quasi die Berechnung oder die Zusammensetzung des Tokens als eine Art parametrischer, algorithmischer Verrechnung der unterschiedlichen Anteile vorstellen, also beispielsweise hätte man ökologische Aspekte, soziale Aspekte, bestimmte ökonomische Aspekte in einer Vielzahl von Indikatoren, die in einer bestimmten Qualität und Quantität, die für die Produktion eines Produktes notwendig sind, die wir ja wissen, also wir wissen diese Qualität und Quantität über die LCAs, die wir dann über Parameter sozusagen kombiniert in diesen Token aggregieren können, also in diesen Token verrechnen können. Der Token selbst enthält, also der eine Token selbst enthält dann nicht mehr diese Information, aber der Token ist, das kann man beispielsweise über Blockchain-Technologien realisieren, der Token selbst ist aber nicht nur dieser eine Token, der sich ergeben hat aus dieser Verrechnung dieser sozialen, ökologischen und ökonomischen Indikatoren, sondern dieser Token enthält eine Reihe von Metainformationen, die es letztlich zu jedem Zeitpunkt erlauben, diesen Token auch wieder zu disaggregieren, also beispielsweise von der Information ein Token wieder zurückzukommen zu, welche konkreten ökologischen, ökonomischen und sozialen Auswirkungen und Aufwendungen von Stoff- und Energiesprünge und Arbeitszeit stecken dahinter. Also das heißt, es geht um eine Differenzierung und gleichzeitig Komplexitätsreduktion in diesem System mit der Hilfe von Parametern. Wie genau so ein sozialistisches Preissystem aussehen kann, wird auch in Jakobs Paper, was aktuell im Erscheinen ist, nochmal genauer ausgeführt. Jetzt könnte man sich fragen, ok, aber was sind jetzt die Unterschiede eigentlich zum Geld von diesen Tokens? Prinzipiell kann man erst mal sagen, dass die Kommensurabilität ja im Tokensystem nicht wie im Kapitalismus ex post durch den Wert hergestellt wird und dann durch einen Marktaustauschprozess, sondern ja Ergebnis eines ex ante Planungsprozesses ist und eher eben der ex ante Bestimmung dieser Tokens als Aggregation von sozialen, ökologischen, ökonomischen Aufwendungen und Auswirkungen. Es würden dabei also nicht alle möglichen komplexen Faktoren unbewusst miteinander vermischt, wie das im Marktprozess der Fall ist, wo sich dann zwischen Angebot und Nachfrage halt eben auch nochmal den Geldpreis einstellt, der aber unter Ausschluss aller möglichen externen Effekte dann eben keine Rückschlüsse mehr darauf zulässt, welche sozialen, ökologischen und ökonomischen Risiken eigentlich dahinterstehen. Das heißt, die eine Dimension, die eine Funktion eins, ist der Token als Verdichtung, als Information über Naturverbrauch, Stoff, Energie und Arbeitszeitaufwendung, die parametrisch, also mit unterschiedlichen Faktoren dort einfließen und damit sozusagen eine Art ökologisch-sozialen Preis von Produkten darstellt. Das ist die eine Dimension. Die zweite Dimension ist aber, dass Tokens es auch zulassen, eine Art parametrisierte Regelung der Menge der Tokens, also das heißt der Menge des Naturverbrauchs und beispielsweise dem Einsatz von Arbeitszeit zu erlauben. Man kann sich das so vorstellen, dass wir also einerseits die Preise haben über die Tokens, andererseits aber direkt über die LCAs, jetzt ganz unabhängig von den Tokens, ja alle stofflichen, ökologischen, energetischen, sozialen Indikatoren aus den LCAs über das komplette Produktionssystem aggregieren können. Also wir ganz genau wissen in einer Art Ist-Zustand, welchen Verbrauch an Ressourcen wir haben und wie viel Arbeitszeit für unsere Produktion insgesamt eingesetzt wird. Diesen Ist-Zustand des Naturverbrauchs und beispielsweise der Arbeitszeit kann man dann einem Soll-Zustand gegenüberstellen und dieser Soll-Zustand, der kann dann demokratisch behandelt werden, also beispielsweise indem wir uns demokratisch darauf einigen, wie viel Arbeitszeit wir gesamtgesellschaftlich aufwenden wollen oder welche planetaren Grenzen wir halt eben einhalten wollen, beispielsweise das 1,5 Grad Ziel oder das 1 Grad Ziel oder das 0,5 Grad Ziel. Wenn man dann den Vergleich zwischen Ist und Soll machen, beispielsweise in Formen des Quotienten, aber es Solle und Ist, kann man daraus einen Parameter errechnen, mit dem man die Menge der Tokens, die insgesamt für den Konsum ausgegeben werden, also das ist so eine Art Konsumberechtigung auf der anderen Seite, das eine ist der Token auf der Produktionsseite, das andere ist sozusagen der Token auf der Konsumtionsseite als eine Art Konsumberechtigung. Wenn man diesen Soll- und Ist-Vergleich macht, kann man de facto nur die Menge der Tokens, die man für die gesellschaftliche Konsumtion regeln, das heißt daran anpassen, ob beispielsweise planetare Grenzen insgesamt überschritten werden oder halt eben wir uns doch innerhalb dieser planetaren Grenzen bewegen, ebenfalls, ob wir mehr Arbeitszeit verausgaben, als uns das eigentlich lieb ist oder weniger Arbeitszeit und somit die Menge der Tokens insgesamt erhöhen oder senken und damit halt eben regulieren, um die Größe des Produktionssystems selbst entsprechend der demokratischen verhandelten Rahmenbedingungen anzupassen. Also das heißt, es gibt ungefähr zwei Dimensionen, das eine ist der Token als Preis von Gütern und das andere ist die Menge der Tokens als Umfang des gesellschaftlichen Konsums und damit auch der Bestimmung des Umfangs des Produktionssystems selbst. Also vielleicht erstmal vorausgeschickt einfach die Frage, wenn die Tokens eine aggregierte Größe, sagen wir jetzt ein Token, wenn ein Token eine aggregierte Größe aus 120 verschiedenen Faktoren ist oder wahrscheinlich dann noch viel mehr, in welcher Hinsicht, also wie soll das dann diese Steuerungsfunktion in einer sehr aktiv gedachten Rolle, wie du das jetzt gerade zuletzt genannt hattest, erfüllen können, weil ja dann, wenn ich sage, okay wir erhöhen die Token, die Tokenausschüttung um 20%, ich dadurch eben nicht nur ein Parameter angreife, wie du es ja eben gerade genannt hattest, zum Beispiel die gesellschaftlich einzusetzende Arbeitszeit, sondern nachdem es sich ja um eine Aggregation von 120 verschiedenen Elementen sagen, die da hinein kollabiert worden sind, handelt, würdest du ja dann alle anderen 119 da hinein kollabierten Elemente auch mit erhöhen. Also insofern wäre das ja dann, würde das ja nicht das erfüllen, was du jetzt gerade zuletzt gesagt hattest, dass man die Sachen eben so detailliert angreifen kann, nur dadurch, dass man quasi die Token, den Umlauf, die Menge der sich in Umlauf befindenden Tokens erhöht. Das wäre jetzt erstmal so eine unmittelbare Verständnisnachfrage irgendwie und aber vielleicht damit verbunden auch in eine ähnliche Richtung gehend vielleicht auch die Frage, wenn ich 120 verschiedene Faktoren habe und ich möchte ja sozusagen diese multifaktorielle Qualität eigentlich erhalten wissen, weil man sagt, dass das sozusagen die Qualität einer sozio-metabolischen Planung ist, ja, und dann kollabiere ich das aber wieder in eine einzelne Recheneinheit und handle quasi mit der, dann entsteht, ähnlich wie ich es jetzt zu Beginn der Frage eben auch ausgewiesen hatte, entsteht ja eigentlich wieder eine Form von, ja, Grobheit, wenn man so will oder eben Fake-Kommensurabilität könnte man auch sagen oder zumindest die Tendenz in diese Richtung gehend, dass man, dass man dann aufgrund dessen, dass es in einer Recheneinheit kollabiert worden ist, so ein bisschen so tut oder auch vielleicht schnell dahin kommt, dass es so wirkt, als würde man so tun, dass man eben diese eigentlich nicht miteinander vergleichbaren Elemente dann doch meinen vergleichbar machen zu können. Lüch, kannst du das mal kurz noch mal skizzieren, weil das ist ja so ein Grundproblem dieser Frage einer Universal Unit of Account. Also diese Tokens sind prinzipiell erst mal nur als eine Informationsverdichtung zur einfachen Kommunizierbarkeit gedacht. Es gibt natürlich immer die Möglichkeit, dadurch, dass diese Daten uns ja vorliegen, in einer disaggregierten Form, eine gesellschaftliche Entscheidung darüber zu fällen, wie bestimmte Einzelaspekte eben besser oder anders gemanagt werden. Also dass es halt eben engere Grenzen für beispielsweise Biodiversität gibt, als es das jetzt für einen Klimawandel geben sollte. Also diese gesellschaftliche Entscheidung ist trotz der Informationsverdichtung auf den Token nach wie vor zugänglich, weil diese Informationen auch disaggregiert vorliegen. Also das ist in einer gewissen Weise würde ich sagen, hebt das das Problem des Gegenarguments der Inkommensurabilität auf, weil wir ja nicht nur die aggregierte Form haben, sondern die aggregierte Form zur einfachen Information, eben dieser eine Token, gleichzeitig existiert immer zur disaggregierten Information über das Besondere. Also das Allgemeine und Besondere existiert als Information parallel und ist beliebig disaggregierbar und aufeinander beziehbar. Der Unterschied ist nur, dass wenn ich beispielsweise in den Konsummarkt gehen würde oder dort wo wir dann unsere Produkte herholen, traue ich mir de facto nicht 20 Seiten Studien durchzulesen, welche ökologischen und sozialen Auswirkungen hinter der Produktion beispielsweise eines Fischs liegen, sondern das wird über diesen Token einfach kommuniziert und da uns ja auch nur eine bestimmte Anzahl von Token vorliegen für den Konsum, kann man so de facto die nachhaltige Konsumtionsmenge regeln und damit auch in einer gewissen Weise steuern. Wenn ich aber darüber gesellschaftlich diskutieren möchte, ob wir bei bestimmten ökologischen Auswirkungen bestimmte Grenzen beispielsweise überschritten haben oder bestimmte sozialen Indikatoren optimieren wollen, dann können wir das ja auf Ebene genau diese Indikatoren trotzdem tun. Also es sind quasi nur zwei Informationssysteme mit unterschiedlichen Anwendungsbereichen und unterschiedlichen Ebenen, die es auf der einen Seite vereinfachen sollen, im Alltag diese Informationen aggregiert mit der umgehen zu können und auf der anderen Seite für die gesellschaftlich bewusste Planung trotzdem im Detail halt eben die notwendigen Informationen zur Verfügung zu stellen auf Basis der einzelnen Indikatoren. Wie viele Indikatoren das dann sind, ob man diese Indikatoren, ob das wirklich unter 20 oder mehr sind oder ob die sich vielleicht auch sogar akkredieren lassen, zu 20 oder 30 ohne einen ganz wesentlichen Informationsverlust zu erleiden, das müsste man auch diskutieren. Ja, aber das ist nicht die Frage, die ich stelle. Die Frage, die ich stelle, ist eine andere. Die Frage ist, oder vielleicht frage ich es anders, ist jeder Token einzigartig? Das ist sozusagen die erste Frage. Wenn nicht jeder Token einzigartig ist, also er müsste das sein. Oder ich stehe total auf dem Schlauch. Entweder habe ich einen Prozess, in dem diese Vielschichtigkeit der Information, dieses multifaktorielle sozusagen an einem Punkt sozusagen ausgelöscht wird und in eine Eins übertragen, ein Token. Oder ich habe quasi eine Situation, in der ich einen, das nennt man glaube ich dann non-fungible Token habe. Also ich habe sozusagen, jeder Token ist einzigartig. Und wenn jeder Token einzigartig ist, weil er immer noch die Information um seine spezifische Zusammensetzung beinhaltet, dann habe ich auch quasi bestimmte Elemente nicht oder dann komme ich quasi in den Konflikt, wenn ich auf einer praktischen Ebene aber dann so tue, als könnte ich A gegen B kommensurabel machen und ich sage mal blöd eintauschen, weil ich dann auf einer Oberflächen-Ebene so tue, als wären sie das gleiche, beides ein Token. Aber in der auf gedröselten Ebene würde sich mir eigentlich zeigen, dass sie genau gar nicht das gleiche sind. Also es ist either or, es ist entweder oder. Eins von beiden müsste irgendwie zutreffen. Oder ich habe einen Knoten in meinem Kopf gerade. Vielleicht verstehe ich es auch nur nicht, aber das ist sozusagen der Punkt. Entweder ich habe quasi einzigartige Einheiten und dann ist es keine universal unit of account, sondern es ist eigentlich genau das Gegenteil. Oder ich habe sozusagen wieder auf einer bestimmten Ebene das Problem, dass ich inkommensurable Sachen so tue, als könnte man sie kommensurabel machen. Also ich muss vielleicht vorwegschicken, dass das genau die Debatte sein wird, die wir in diesem Paper, was wir in Zukunft dazu schreiben werden und in dem es diese Modellierung geben wird, nochmal genau angucken. Ich habe darauf keine endgültige Antwort und keine perfekte Lösung. Tatsächlich ist das ein Grundproblem, was ich glaube ich immer stelle, dieser Konflikt eben zwischen dem Allgemeinen und dem Besonderen und dieses Allgemeine, inwiefern das Besondere im Allgemeinen noch sichtbar wird und inwiefern man diese verschiedenen Allgemeinheiten dann miteinander vergleichbar machen kann, wenn man das will und wenn man das soll, wenn man sie halt gegenseitig kommensurabel macht. Ich würde sagen, es gibt unterschiedliche Optionen vielleicht mit dem Problem umzugehen. Das eine ist, wie sich dieser Token zusammensetzt, dass das für jedes Produkt unterschiedlich ist, indem eben diese Parametrisierung der Indikatoren, die da rein fließen, beispielsweise über eine gesellschaftliche demokratische Gewichtung für Produkte unterschiedlich ist und vielleicht auch adaptiert wird, je nachdem wie sich auch die Herausforderungen, die gesellschaftlichen Herausforderungen in bestimmten Produktionsprozessen auch verändern. Also dass sich de facto die parametrische Zusammensetzung des Tokens aus bestimmten Indikatoren selbst vielleicht in einer gewissen zeitlichen Dynamik unterliegt. Und das hätte gewisse Vorteile, weil dann der Token zwar eine spezifische Aggregation nach wie vor darstellt, also besonders ist, aber dann sich das Problem stellt, okay, wie du schon meintest, also ob der da noch mit den anderen Tokens vergleichbar ist. Also in der LCA-Logik denken wir an Inputs und Outputs. Und diese Inputs und Outputs, die sind zwar nicht vergleichbar, weil es gibt ja Produktionsprozesse, die ganz unterschiedliche stoffliche Inputs und Outputs haben. Was aber vergleichbar ist, ist deren Auswirkung auf soziale, ökologische und ökonomische Aspekte oder deren Auswirkung auf die soziale, ökologische und ökonomische Nachhaltigkeit. Also jetzt mal an dem Beispiel, du hättest einen Produktionsprozess, in dem Methan frei wird und du hättest einen Produktionsprozess, in dem CO2 frei wird. Methan hat eine bestimmte Auswirkung auf den Klimawandel, nämlich hat ein Kilogramm Methan den 20-fach höheren, die 20-fach höhere Auswirkung auf den Klimawandel als ein Kilogramm CO2. Aber die Auswirkung auf den Klimawandel lässt sich in Form von CO2-Äquivalenten widerspiegeln, weil letztlich ist das vergleichbar hinsichtlich der Konzentration von Treibhausgasen, wie dann halt eben die globale Temperatur um ein Grad erwehrt. Also es gibt, obwohl es unterschiedliche Stoffströme sind, die als Outputs, als Emissionen dort frei werden, sind sie vergleichbar hinsichtlich ihrer Auswirkungen auf den Klimawandel. Also für ökologische oder für stoffliche, für energetische Indikatoren, für die Auswirkung funktioniert das, denke ich durchaus. Inwiefern es sozusagen eine soziale Vergleichbarkeit gibt von beispielsweise bestimmten Arbeitsbedingungen, das wäre eine Frage, der man sich auf jeden Fall noch nähern müsste, weil das dann die Frage wäre, inwiefern man die soziale Auswirkung oder die Auswirkung von einer bestimmten Anzahl von Arbeitsunfällen vergleichen kann, halt eben mit der sozialen Auswirkung von der Umweltbelastung des Arbeitsplatzes vor Ort und damit halt eben auch den Auswirkungen auf die Gesundheit. Es gibt dort auch den Versuch, aktuell das in diesen abstrakten Größen zu machen, wie diese Daily-Indikator oder diese Daily-Größe, also diese Anzahl der Lebensjahre, die reduziert, also die Anzahl der gesunden Lebensjahre, die dann reduziert wird. Ich bin eben auch skeptisch, also ich sehe das auch skeptisch, ob man das wirklich machen kann. Aber das wäre eine entscheidende Frage, der man sich annähern müsste. Also inwiefern es sozusagen, obwohl die Stoffströme unterschiedlich sind, obwohl die Inputs und Outputs von Produktionsprozessen unterschiedlich sind, deren sozialen, ökologischen und ökonomischen Auswirkungen dennoch vergleichbar sind und eben diese sozialen, ökologischen und ökonomischen Auswirkungen als Maßzahl sozusagen parametrisiert in diesen Token, der dann wiederum vergleichbar ist mit allen anderen Token eingeht. Und das Argument, warum man das überhaupt machen sollte, ist ein Komplexitätsargument, oder? Also, weil man merkt jetzt, okay, da stößt man auf jeden Fall an alle möglichen Probleme an. Man läuft eben wieder Gefahr, sagen, dieses Apple-and-Oranges-Äpfel-und-Birnen-Problem irgendwie zu haben, dass es schnell dahin rutscht, dass da dann doch Sachen miteinander verglichen werden oder vergleichbar gemacht werden sollen, von denen man vielleicht das Gefühl hätte, dass sie eigentlich in dieser Form eben vielleicht doch nicht so gut verglichen werden können. Aber das Argument, welches ihr führt, warum ihr meint, das ist eine solche Form der verdichteten Parametrisierung, also der aggregierten Parametrisierung, weil das ist es ja, worum es geht, warum es das geben solle, ist ein Argument der Komplexitätsreduktion, oder? Also, das ist der letzte Punkt eigentlich, also der letztgültige Punkt, um den es sich dann dreht, oder? Genau. Wie aber unsere Meinung absolut notwendig ist, um im Alltag diese Gegenüberstellung der sozialen, ökologischen und ökonomischen Aufwendung oder Kosten von Produkten und der Möglichkeit, diese innerhalb von Planetaren und sozialen Grenzen zu konsumieren, also um das letztlich im Alltag zusammenzubringen. Das heißt, wenn ich beispielsweise im Supermarkt stehe oder im Markt stehe, oder quasi in diesem Versorgungszentrum stehe, indem ich mir dann meine Produkte hole, wie soll ich wissen oder wie kann ich wissen, dass es unter Umständen sozial halt eben, also dass die sozialen und ökologischen Kosten von beispielsweise einer Rinderwurst hundertmal höher sind als von einem Sellerie. Und dass es halt eben mir unter Umständen, dass es mir kommuniziert wird, dass es nicht möglich ist, jeden Monat 50 Würste zu konsumieren, es aber durchaus eben möglich wäre, beispielsweise mein Bedürfnis nach Nahrung über pflanzliche Nahrungsmittel zu decken. Also, da würde dann sozusagen in diesem Tokenpreis eben genau diese Informationen drin stecken über die sozialen, ökologischen Aufwendung der Produktion, die sonst nur vielleicht über ein 20-, 30-, 40-seitiges Beiblatt dokumentiert wird. Das ist die eine Seite. Und die andere Seite ist letztlich, dass man über die Ausschüttung der allgemeinen Tokenmenge für den Konsum sicherstellen kann, dass der gesamtgesellschaftliche Konsum, das heißt eben auch die gesamtgesellschaftliche Produktion, innerhalb Planetarer und sozialer Grenzen bleibt. Würde man das nicht, also würde man keine Tokens mit sich führen oder keine aggregierte Verrechnungseinheit, müsste man ja die Frage beantworten, wie kommuniziert man das, dass es halt eben nicht möglich ist, im Monat zwei Kühlschränke zu kaufen? Einfach nur über den Mangel an Kühlschränken? Na ja, also da gibt es ja schon noch unterschiedliche Aspekte zu der Frage. Also ist da jetzt implizit ein Subjekt angenommen, das im Grunde unstillbare Bedürfnisse hat und deswegen eigentlich quasi, wenn es nicht irgendwie diszipliniert werden würde, über die Verknappung von Tokens dann sozusagen permanent in Anführungsstrichen über die Stränge schlägt, ist das nicht irgendwie auf eine Art auch eine individualisierte Form der Betrachtung des Problems, dass man so zu sagen, als wäre quasi der der Individualkonsument, die Individualkonsument in sozusagen der Grund des Problems oder das, also der Nukleus des eigentlichen Problems, das ist eine spezifische Form von Framing, die das jetzt schon mit sich trägt, wenn man das in dieser Art und Weise präsentiert. Also ist die Tokenüberlegung eigentlich vor allem an eben Endkonsument in den Märkte und in Anführungsstrichen Märkte quasi gerichtet oder ist das das Argument oder geht es auch um Formen der Verrechnungsgrößen auf einer Produktionsebene und so weiter und so fort? Also ich will jetzt auch nicht da eine endgültige Position irgendwie zu einnehmen oder so, aber ich glaube schon, dass es da noch andere Perspektiven, also auch relevante und rücksichtigenswerte Perspektiven auf diese Frage gäbe als sozusagen eben da so eine individualisierte Konsumperspektive quasi mit ins Boot zu holen, wobei ich natürlich das auch verstehe, ja, und da müsste man dann nochmal drüber nachdenken, was es für alternative Mechanismen auch gäbe, um eben solche Formen des destruktiven Konsums oder so was zu reglementieren. Also ich finde jetzt zum Beispiel, wenn man, was weiß ich, an SUVs als jetzt dieses populistische, klassische Beispiel denkt, da würde man ja auch sagen, es geht eigentlich nicht um die Debatte was für ein Arsch die Person jetzt ist, die den SUV kauft oder so was, sondern warum produzieren wir überhaupt SUVs? Was ist das eigentlich für ein Quatsch, dass das als so eine Form von Alltagspanzer sich quasi durchgesetzt hat und wenn man sich das fragt, dann kommt man aber zu ganz anderen Fragen und zu ganz anderen Antworten auch, als wenn man sich dieser individualisierten Konsumperspektive nähert, weil Simon Schaub zum Beispiel in seinem Buch, kann ich mich erinnern, eine total interessante Passage dazu hat, wo erklärt worden ist, warum auf der Ebene von gesetzlichen Bestimmungen, weil sich irgendwann Änderungen eingestellt haben, die dann für Autohersteller die Produktion von SUVs quasi besonders lukrativ gemacht hat, ja, und dann gab es auf einmal plötzlich diesen Boom von SUVs und das ist eine ganz andere Form der Betrachtung, weißt du, wie ich meine? In unserem System würde ja die Frage dessen, was produziert wird, immer noch demokratisch entschieden über die Zuteilung und die Verteilung der Produktionsmittel, also der Investitionen zu bestimmten Produktionsbereichen, also die Produktion beispielsweise eines gesellschaftlich völlig unnützen SUVs, wäre darüber auch schon ausgeschlossen, wenn die Gesellschaft zu dem Schluss kommt, dass sie halt eben unnütz sind und sogar ökologisch und sozial nachteilig. Also das ist vielleicht der eine Punkt. Ich fand aber das, was du am Anfang meintest, noch viel, viel wichtiger zu bedenken, nämlich von welchem Subjekt oder vielleicht auch von welchem, ich sag mal, Stand der Geschichte gehen wir eigentlich aus, weil dieses Token-System ist kein System, auch diese LCA-Verrechnung, diese parametrische Verrechnung ist kein System, was vom Endzustand her gedacht ist, also ein utopisches Zustand sozusagen in einer befreiten Gesellschaft mit einer ganz anderen Subjektkonstitution, sondern das Token-System ist eigentlich gedacht als eine andere Art Transformationszustand. Also das heißt, in einer gesellschaftlichen Phase, in der wir es nach wie vor mit Subjekten zu tun haben, die ganz tief geprägt sind vielleicht von der kapitalistischen Produktions- und Beziehungsweise und wir nicht davon ausgehen können, dass sie in jeder Phase sozusagen gesellschaftlich rational handeln, sondern diese schwierigen Muster, auch Konsummuster sozusagen des Kapitalismus nach wie vor in ihnen verhaftet sind. Ich würde das gar nicht als so eine Art Endzustand darstellen, das Token-System, sondern als eher so eine Art Transformationslösung, die genau so lange beibehalten werden kann, bis sie vielleicht selbst obsolet wird. Ich hatte mich das ja schon am Beginn unseres Gesprächs einmal gefragt und vielleicht ist das jetzt auch der Punkt, das nochmal aufzubringen und da vielleicht nochmal kurz einfach drüber nachzudenken, weil also auf einer bestimmten Ebene hatte ich mich gefragt, wenn man jetzt wirklich nochmal so ziemlich weit hinauszoomt. Du fängst eigentlich an, wenn du dieses Higgs-Modell einführst, indem du sagst, okay, wir stoßen uns hier ab von einer spezifischen Form der Betrachtung, die auf einem, das nannte sich dann Three-Pillar-Modell, also drei-Säulen-Modell zu sagen, aufbaut, das bestimmte Sphären quasi so voneinander getrennt theoretisiert auch und im Grunde Berechnungen für soziale, ökologische und ökonomische Faktoren quasi vornimmt und die dann später mal zusammenwürfen zu können. Auf Basis dessen stößt du dich quasi davon ab und sagst, nein, es muss eigentlich eine Form der ganzheitlicheren Betrachtung geben. Wir müssen die sozialen, die ökologischen und die politischen und ökonomischen Faktoren quasi von vornherein immer miteinander in Beziehung stehend denken. Und das ist natürlich was, dem ich total folgen würde. Und meine Frage ist aber ein bisschen, ob wenn man in dieser Art und Weise eine parametrische gesellschaftliche Gesamtbilanzierung anstrebt, inwiefern man dort, und das auch noch quasi anreichert mit so einer Form von Token-System, inwiefern man dort dann Gefahr läuft eigentlich auf der Form, auf der Ebene der Bezugnahme. Du hattest eben Bini angesprochen. Bini würde eben sagen, auf der Ebene der Beziehungsweisen sozusagen im Grunde eine spezifische Form der Bezugnahme reproduziert, die man in anderen Kontexten vielleicht auch zu Recht sozusagen kritisieren würde. Und dies letztlich dann immer noch begründet, also hergeleitet aus Notwendigkeiten der Effizienz und der Effektivität und so weiter. Und die Frage wäre halt, wie ein solches System und wo ein solches System den Raum bietet, um den eigentlich wünschenswerten Entwicklungshorizont nämlich hin zu anderen Beziehungsweisen, wie du es jetzt eigentlich im Schluss, also in deiner letzten Frage auch ausgewiesen hast, in welcher Form und wo bietet ein solches System den Horizont des Entwicklungs anderer Beziehungsweisen, wenn es weiterhin diese spezifische Form der Formiertheit der Bezugnahme quasi reproduziert. Ich weiß nicht, ob das verständlich ist, ein bisschen kompliziert formuliert. Aber man hat so ein bisschen das Gefühl, dass es auf einer auf einer funktionalistischen Ebene, wenn man so will, bestimmte Logiken reproduziert, die eigentlich auf einer bestimmten Art und Weise vielleicht auch mit überwunden werden müssten, um zu dem zu kommen, zu dem man eigentlich kommen will. Also ich bin dann definitiv, also ich kann diese Kritik absolut nachvollziehen und würde mich dem sogar anschließen und sagen, nein, wir können in diesen Modellen nicht jede wünschenswerte Beziehungsweise oder nicht jedes mitgedachte Verhältnis zwischen bestimmten Aspekten formalistisch operationalisieren und als Parameter einpflegen. Also dem sind definitiv Grenzen gesetzt. Aber darum ist dieses Token-System ja nicht als System einer gesellschaftlichen Vermittlung gedacht, sondern als ein System einer Informationsbereitstellung. Also man könnte auch so sagen, dass das Token-System vielleicht ein Informationssystem unter vielen ist. Die Frage wäre ja auch, auf welche gesellschaftlichen Produktions- und Reproduktionsbereiche, ohne diese Trennung auch zwangsläufig aufmachen zu wollen. Man könnte ja auch sagen, Reproduktionsbereiche, so wie das Heidi Luther schon gut beschrieben hat. Man könnte auch absolut überlegen, auf welche Bereiche man dieses Token-System überhaupt anwendet. Also ob es vielleicht nur eine industrielle Güterproduktion zu einem gewissen Teil ist oder ob es nur beispielsweise gesellschaftliche Investitionen sind. Was ich mir zum Beispiel sehr schwierig vorstellen würde, ist dieses Token-System auf, wenn man das als isolierte Sektoren irgendwie aufmachen könnte, was allgemein schon schwierig ist, auch beispielsweise Kehrarbeit oder so anzuwenden. Also ich glaube dieses Token-System oder allgemein auch dieses System der Input-Output-Bilanzierung hat eine gewisse Begrenztheit. Und das eine ist sozusagen die Begrenztheit dessen, welche gesellschaftlichen Beziehungsweisen sich darüber überhaupt, also welche gesellschaftlichen Verhältnisse sich darüber überhaupt abbilden lassen und welche Grenzen das setzt und welche gesellschaftlichen Bereiche oder welche Produktionsbereiche sich damit überhaupt sinnvoll erfassen lassen. Also das ist auf jeden Fall was, was man mitdenken muss. Aber der entscheidende Punkt ist, würde ich sagen, im Unterschied zum Kapitalismus oder zu einem kapitalistischen Geldsystem, dass diese Tokens halt eben aufwendungs- und nutzenbasiert sind und in ihrer Zusammensetzung, in ihrer parametrischen Zusammensetzung demokratisch bestimmt und transparent sind, was beim Gelder halt eben alles nicht der Fall ist. Plus, dass das ja nur die rein ökonomische Ebene einer parametrisierten Vermittlung ist und wie gesagt die politische Ebene, also welche politischen Akteure, Institutionen sich hier in den Rätern oder was auch immer für ein System gegenüberstehen, hier noch nicht dazu gesagt ist und vielleicht am Ende auch eine viel größere Bedeutung für die gesellschaftliche Vermittlung haben als das Tokensystem selbst. Ja, also das sehe ich schon. Das hast du ja auch absolut richtig schon vorher ausgewiesen, dass es eben dann noch politische Institutionen und Rahmenungen geben muss, innerhalb derer dann eigentlich diese Information einfließt. Aber dann, also zum Teil gibt es dann glaube ich auch so ein bisschen vielleicht Probleme mit dem Wording oder sowas, weil sowas wie gesamtgesellschaftliche Bilanzierung suggeriert natürlich eine gesamtgesellschaftliche Bilanzierung. Und wenn dann aber eben du jetzt quasi anmerkst, dass du dir absolut nicht sicher wärst, ob man Fragen der Sorge, Tätigkeiten über ein solches System überhaupt adressieren sollte, dann kann man ja auf jeden Fall mal schon überhaupt nicht von der gesamtgesellschaftlichen Bilanzierung sprechen. Also das ist dann auf der Ebene quasi ein bisschen irreführend und umgekehrt ist es aber natürlich auch wieder ein Problem, wenn man sagen würde, aha okay, man reproduziert aber halt dann dadurch diese Abspaltungen wieder. Also wo man sagt, okay das ist sozusagen irgendwie eine eben getrennte Sphäre. Und auf eine Art war ja so ein bisschen die Hoffnung oder ist die damit verbundene Hoffnung, dass man multifaktorielle Formen der Perspektivierung in eine solche Systematik versucht mit einzubinden, dass das zumindest bis zu einem gewissen Grad halt es eben schaffen könnte sowas wie soziale und politische und ökologische Elemente eben doch mit hineinzuholen. Also auf der einen Ebene wollt ihr das ja und macht das ja auch, weil das bis zu einem gewissen Grad ja auch quasi methodisch versucht wird. Aber gleichzeitig merkt man auch, es stößt irgendwie auf einer bestimmten Ebene dann doch an die Grenzen. Ja absolut. Also ich würde sagen, um überhaupt sich der Frage nähern zu können, bis zu welchem Punkt man dieses System treiben kann oder inwiefern es sozusagen auch noch mal eine adaptive Anpassung braucht oder auf welche gesellschaftlichen Bereiche man das erstreckt oder ob es vielleicht doch möglich ist, eine Parametrisierung oder Quantifizierung, Qualifizierung in diesem Modellierung von beispielsweise allen sozialen Auswirkungen oder von den meisten sozialen Auswirkungen zu erfassen oder beispielsweise der Kehr- und Reproduktionsarbeit, müsste man das an einem tatsächlich praktischen Beispiel durchspielen. Das könnte ich mir vorstellen, ist einerseits eine Simulation, andererseits aber das tatsächliche Arbeiten mit realen Daten aus konkreten gesellschaftlichen Prozessen, aus Produktionsprozessen, aus der Vermittlung von Konjunktion, Produktion, Kehrarbeit. Und ich glaube erst dann, wenn man das sieht, also das heißt aus einem Praxisbeispiel, die Daten und die konkrete Betrachtung bekommen, in der dann tatsächlich alles rein spielt und halt eben nicht nur die verkürzte Darstellung, wie das in den aktuellen Datenbanken der Fall ist und sich dann die Gedanken macht darüber, okay, wir machen jetzt mal, wir versuchen jetzt eine gesellschaftliche Simulation auf Basis dieser komplexen Daten, dass man dann viel bessere und auch genauere und schlüssigere Antworten darauf findet, wie und ich würde aber auch generell immer noch sagen, ob dieses System überhaupt sinnvoll ist und funktionieren kann. Also ich will mich darauf gar nicht festlegen, letztlich ist es einfach eine Frage dessen, welche Systeme und Modelle eben welche Vor- und Nachteile bieten und das Token-System wird beispielsweise gegenüber des Commons Modells bestimmte Vorteile bieten, was die gesellschaftliche Koordination und Information angehen wird, hat aber unter Umständen massive Nachteile, was halt eben beispielsweise die Reproduktion nachteiliger Beziehungsweisen angeht, was in den Commons wesentlich besser darstellbar ist. Also die Frage ist auch, glaube ich, gar nicht unbedingt, ob sich Token-System, Modellierung, Parametrisierung, Kybernetik und Commons ausschließen, sondern eher an welchen Punkten sie sich sinnvoll ergänzen kann. Das ist aber eine Frage, auf die habe ich heute keine gute und schlüssige Antwort. Ja, das wäre auch glaube ich zu viel verlangt von dir. Ich glaube, wir haben einen ungefähr einen Eindruck zumindest davon bekommen, in welche Richtung es denn gehen könnte und auch das finde ich super, wie du sozusagen die eigene Selbstbefragung sozusagen da ja dann auch nicht ausklammerst, auch davon, welche Fragen eben eigentlich noch offen sind oder zumindest einige dieser Fragen, die noch offen sind. Ich stelle am Ende einer jeden Episode immer noch die Frage, du wirst es vielleicht kennen, wenn du dir Zukunft vorstellst. Walter, was stimmt dich freudig? Das ist immer die schwierigste Frage in jeder Folge von Future Histories, finde ich. Und ich bin auf alle Antworten immer sehr gespannt. Ich würde vielleicht so antworten, im Großteil meiner politischen Auseinandersetzung hat sich verändert und auch dadurch gestaltet, dass wir 2018 vielleicht noch gar keine Vorstellungen hatten davon, was 2019 relevante gesellschaftliche Themen sein könnten. Und dann kam Fridays for Future. Also das heißt, die Dynamik von Gesellschaften, die soziale Dynamik von Bewegungen ist so unvorhersehbar, dass the future unwritten ist. Und dass the future unwritten ist, das ist vielleicht das, was mich am allerfreudigsten stimmt oder anders gesagt, dass es diese Lokomotive der Geschichte nicht gibt. Also es gibt die Lokomotive der Geschichte weder sozusagen in der modernistischen, leninistischen Ausprägung des automatischen selbstständigen Fortschritts, an den zu glauben, sich als einen großen Druckfluss herausgestellt hat. Es gibt diese Lokomotive der Geschichte aber auch nicht in die andere Richtung, wie uns das vor dem Eindruck der aktuellen Realitäten als Linke vielleicht auch vorkommen will, dass es nämlich einen Automatismus hinsichtlich der Regression gibt und diese Lokomotive eigentlich nur gegen Abgrund fahren kann. Sondern sich frei zu machen davon, dass es diese Lokomotive der Geschichte überhaupt gäbe. Sondern dass das, was morgen passiert, erstens extrem unvorhersehbar ist und zweitens zumindest für einen ganz kleinen Teil gesellschaftlich gestaltbar bleibt. Das stimmt mich vielleicht noch am folgenden. Zu einem riesigen Teil gesellschaftlich gestaltbar bleibt. Walter, vielen Dank für das Gespräch. Das war Future Histories für heute. Vielen Dank fürs Zuhören, Shownotizen und vieles mehr findet ihr auf www.futurehistories.today. Diskutiert mit auf Twitter unter dem Hashtag Future Histories oder im eigenen Subreddit. Ihr könnt Future Histories nicht nur auf allen großen Podcastplattformen hören und abonnieren, sondern auch auf YouTube, wo ihr neben den Episoden dann auch Kurzvideos zu Kernbegriffen einzelner Episoden findet. Schreibt mir gerne unter jan at futurehistories.today. Ich freue mich immer sehr über interessante Rückmeldungen und Hinweise. Wenn ihr Future Histories unterstützen wollt, dann könnt ihr das auf patreon.com schrägstrich Future Histories oder auch via Spende auf unserer Homepage. Future Histories ist eine Produktion von Metalapsis zu finden auf metalapsis.net. Bis zum nächsten Mal. Ich freue mich. 

**Episode Keywords**

#WaltherZeug, #JanGroos, #FutureHistories, #Podcast, #Interview, #SozialerMetabolismus, #SoziometabolischePlanung, #GesellschaftlicherStoffwechsel, #Ressourcen, #SozialeÖkologie, #Nachhaltigkeit, #Material-Fluss-Analyse, #Life-cycleAnalysis, #Lebenszyklusanalyse, #Planwirtschaft, #Planungsdebatte, #PostkapitalistischeProduktionsweise, #PatDevine, #DavidLaibmann, #Arbeit, #Ressourcen, #Commons, #BedürfnisorientierteProduktion, #Carearbeit, #GesellschaftlicheTransformation, #Beziehungsweisen, #Stoffwechsel, #GesellschaftlicheNaturverhältnisse, #GesellschaftlicheBedürfnisse, #Sozial-ökologischeTransformation, #Bottom-upPlanning, #DemokratischePlanung, #Sozio-ökologischeProzessbilanzierung, #Bio-Ökonomie, #HILCSA, #JakobHeyer, #KybernetischeWirtschaftsplanung, #Dezentral-zentralePlanwirtschaft
