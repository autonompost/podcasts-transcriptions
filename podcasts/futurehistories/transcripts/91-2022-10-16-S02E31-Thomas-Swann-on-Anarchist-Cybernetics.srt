1
00:00:00,000 --> 00:00:08,000
Welcome to Future Histories, my name is Jan Gross and it is my great pleasure to welcome Thomas Swann in today's episode.

2
00:00:08,000 --> 00:00:14,000
He's the author of Anarchist Cybernetics, Control and Communication in Radical Politics,

3
00:00:14,000 --> 00:00:25,000
a book I enjoyed reading immensely since it merges two fields of interest that are frequently featured in this podcast, anarchism and cybernetics.

4
00:00:25,000 --> 00:00:36,000
And a quick shout out, since they have an episode talking about the book Anarchist Cybernetics and since I enjoy their podcast in general quite a lot,

5
00:00:36,000 --> 00:00:43,000
I wanted to point you all towards the Cybernetic Marxist Podcast General Intellect Unit.

6
00:00:43,000 --> 00:00:51,000
You'll find the link in the show notes together with a bunch of other interesting material about and around Thomas' work.

7
00:00:51,000 --> 00:00:57,000
And now please enjoy today's episode with Thomas Swann on Anarchist Cybernetics.

8
00:01:03,000 --> 00:01:04,000
Welcome, Thomas.

9
00:01:04,000 --> 00:01:06,000
Thanks very much Jan, thanks for having me.

10
00:01:06,000 --> 00:01:11,000
I'm really, really glad you enjoyed the book and really looking forward to talking about it.

11
00:01:11,000 --> 00:01:12,000
Thank you.

12
00:01:12,000 --> 00:01:15,000
Great. I'm very much looking forward to it as well.

13
00:01:15,000 --> 00:01:22,000
Even though, as I said, both anarchism and cybernetics have been featured in future histories and other episodes already,

14
00:01:22,000 --> 00:01:27,000
I think it would be still good to start with a kind of overview.

15
00:01:27,000 --> 00:01:33,000
Could you give us a brief idea of your understanding of cybernetics as well as anarchism?

16
00:01:33,000 --> 00:01:34,000
Yeah, of course. Yeah.

17
00:01:34,000 --> 00:01:41,000
And so I'm going to start with anarchism because I think that's that was sort of my starting point going into cybernetics.

18
00:01:41,000 --> 00:01:49,000
And so I think there's sort of two elements of anarchism which are which are important to highlight.

19
00:01:49,000 --> 00:01:57,000
And the first of these is what we can kind of consider the critique that anarchism gives us.

20
00:01:57,000 --> 00:02:07,000
So anarchism gives us a certain set of tools for helping us understand why society looks the way it does,

21
00:02:07,000 --> 00:02:15,000
why politics operates the way it does, why the economy functions in the ways that it does.

22
00:02:15,000 --> 00:02:24,000
So right from the very early days of anarchism, so back to the sort of middle of the 19th century with people like Pierre-Joseph Proudhon,

23
00:02:24,000 --> 00:02:27,000
we really see this critique coming through really strong.

24
00:02:27,000 --> 00:02:34,000
So it really is a way of looking at how capitalism was developing, how colonialism was developing,

25
00:02:34,000 --> 00:02:40,000
and being able to provide tools to say, OK, we can understand what's happening here.

26
00:02:40,000 --> 00:02:45,000
We can understand why hierarchies emerge in societies.

27
00:02:45,000 --> 00:02:53,000
We can understand the links between the kind of hierarchical domination that we see in the state,

28
00:02:53,000 --> 00:03:02,000
where we have a sort of centralized top-down government that dictates laws and controls the police, has a monopoly on violence.

29
00:03:02,000 --> 00:03:15,000
How that is very, very closely connected and perhaps even inseparable from how economic exploitation operates through capitalism.

30
00:03:15,000 --> 00:03:22,000
So how the means of production are owned by wealthy capitalists.

31
00:03:22,000 --> 00:03:29,000
And that means that everyone else, the working class, are selling labor and are exploited in that.

32
00:03:30,000 --> 00:03:37,000
So that capitalists can make profit off of the labor that other people are doing.

33
00:03:37,000 --> 00:03:46,000
So anarchism gives us a way of linking those and seeing that the emergence of capitalism and the emergence of the state,

34
00:03:46,000 --> 00:03:51,000
of the modern state, were very much the same process.

35
00:03:51,000 --> 00:03:56,000
And they're different things with different operating logics,

36
00:03:56,000 --> 00:04:06,000
but they reinforce one another and they've emerged historically together because they are mutually beneficial and reinforce one another.

37
00:04:06,000 --> 00:04:15,000
And I think recently we've seen that sort of critique element of anarchism expanded by thinking in much more detail

38
00:04:15,000 --> 00:04:23,000
about how things like patriarchy and white supremacy and colonialism are also tied up in this picture.

39
00:04:23,000 --> 00:04:30,000
So you have that in the sort of history of anarchism with people like Lucy Parsons and Emma Goldman bringing a kind of feminist

40
00:04:30,000 --> 00:04:36,000
and sometimes anti-racist critique into that sort of critical element of anarchism.

41
00:04:36,000 --> 00:04:41,000
But over the last couple of decades, probably we've seen that come through much, much stronger,

42
00:04:41,000 --> 00:04:49,000
particularly as anarchism has started to draw on sort of black radical politics, black feminism, intersectionality.

43
00:04:49,000 --> 00:04:58,000
So we've seen a lot of that sort of critique coming through of how anarchism can help us explain why the world looks the way it does.

44
00:04:58,000 --> 00:05:04,000
But the second element of anarchism, which I think is really important as well, and perhaps even more important,

45
00:05:04,000 --> 00:05:11,000
is finding ways to dismantle or destroy those particular systems.

46
00:05:11,000 --> 00:05:17,000
So the state, capitalism, patriarchy, white supremacy, anarchism also gives us tools to understand them,

47
00:05:17,000 --> 00:05:23,000
but also to how can we dismantle or destroy them and create alternatives.

48
00:05:23,000 --> 00:05:30,000
So how can we think about how we govern our communities, how we create agreements between each other,

49
00:05:30,000 --> 00:05:38,000
how we guarantee security, guarantee safety, security in terms of physical safety,

50
00:05:38,000 --> 00:05:43,000
but also food security, material security, things like that.

51
00:05:43,000 --> 00:05:52,000
So anarchism gives us the tools to also build something different, build a kind of alternative to the systems that we currently face

52
00:05:52,000 --> 00:06:00,000
and importantly build alternatives that don't have domination, don't have hierarchical control,

53
00:06:00,000 --> 00:06:07,000
don't have economic exploitation, don't have racist or patriarchal domination built into them.

54
00:06:07,000 --> 00:06:14,000
So how can we create alternative systems? And there's a very close link between the critique and those alternatives,

55
00:06:14,000 --> 00:06:22,000
because what anarchists were doing from the very early days, one of the things that distinguishes anarchism

56
00:06:22,000 --> 00:06:31,000
is the kind of utopian elements of imagining what kind of future society can we create.

57
00:06:31,000 --> 00:06:38,000
That wasn't something that the anarchists were just sitting around and trying to think up,

58
00:06:38,000 --> 00:06:41,000
hey, what would the best society look like?

59
00:06:41,000 --> 00:06:47,000
They were actually taking inspiration from how indigenous societies were organized,

60
00:06:47,000 --> 00:06:51,000
how peasant communities were organized before capitalism.

61
00:06:51,000 --> 00:06:59,000
So they were really saying, okay, there are these seeds for how society can be organized in more democratic,

62
00:06:59,000 --> 00:07:04,000
more horizontal ways. We're not inventing this new.

63
00:07:04,000 --> 00:07:11,000
This is something that exists in the past and exists still in everyday life in a lot of ways.

64
00:07:11,000 --> 00:07:21,000
So it's really how we can sort of expand that so that that is the main logic of how we organize ourselves.

65
00:07:21,000 --> 00:07:26,000
So that kind of covers anarchism, I think, and there's probably a lot more to say about it,

66
00:07:26,000 --> 00:07:29,000
but that's, I think, the sort of bedrock of it.

67
00:07:29,000 --> 00:07:36,000
So it is a philosophy aimed at how can we critique things like domination and exploitation,

68
00:07:36,000 --> 00:07:39,000
but also how can we create alternatives?

69
00:07:39,000 --> 00:07:42,000
How can we create non-dominating ways of living together?

70
00:07:42,000 --> 00:07:48,000
How can we create non-exploitative ways of living together?

71
00:07:48,000 --> 00:07:52,000
And I think so for me, there's a close link between that and cybernetics,

72
00:07:52,000 --> 00:08:00,000
because at least the way I understand cybernetics and the way I discovered it was through a focus on self-organization.

73
00:08:00,000 --> 00:08:11,000
So cybernetics emerged kind of in the post-World War II technological and scientific milieu,

74
00:08:11,000 --> 00:08:19,000
particularly looking at electronic systems and very early computer systems and mechanical systems

75
00:08:19,000 --> 00:08:29,000
for how those systems can be autonomous and self-organized and don't require constant human control.

76
00:08:29,000 --> 00:08:35,000
But it quite quickly sort of developed into thinking about, well, can we apply some of that to social systems?

77
00:08:35,000 --> 00:08:40,000
So can we think about how social systems can be self-organized?

78
00:08:40,000 --> 00:08:47,000
And I think the way cybernetics, well, what's really useful about cybernetics and thinking this through

79
00:08:47,000 --> 00:08:54,000
is that what it tries to do is identify the functions for effective self-organization.

80
00:08:54,000 --> 00:09:04,000
So what are the different kind of functions that any system, electronic, social, mechanical, biological as well,

81
00:09:04,000 --> 00:09:14,000
what are the sort of functions that any of these systems need to have in order to be able to organize themselves without external control?

82
00:09:14,000 --> 00:09:19,000
And that's the really important thing for me with cybernetics.

83
00:09:19,000 --> 00:09:25,000
The way cyberneticians have sort of gone into this and expanded on this,

84
00:09:25,000 --> 00:09:32,000
there's a lot more detail there around the role of feedback, the role of information flows and communication.

85
00:09:32,000 --> 00:09:43,000
But I think at its foundations, it really is a way of saying we can pick out the different essential functions of a self-organizing system.

86
00:09:43,000 --> 00:09:51,000
And then with social systems, that's in a question of, OK, how do we, if those functions don't exist already, how do we create them?

87
00:09:51,000 --> 00:09:59,000
If they already exist, how do we strengthen them? How do we make social systems better at self-organizing?

88
00:09:59,000 --> 00:10:08,000
Hearing these definitions of anarchism and cybernetics already gives us an idea of this, but maybe you could elaborate a bit further.

89
00:10:08,000 --> 00:10:14,000
What potential did you see in bringing those two together, anarchism and cybernetics?

90
00:10:14,000 --> 00:10:22,000
What made you work towards anarchist cybernetics, actually? And maybe what was the problem you wanted to see addressed?

91
00:10:23,000 --> 00:10:33,000
Yes, so I think what got me interested in cybernetics, and I think that, well, yeah, I think starting from here might help answer that question.

92
00:10:33,000 --> 00:10:45,000
So what got me interested was, more than a decade ago now, when there was the 2011 uprisings,

93
00:10:45,000 --> 00:10:52,000
we had the Arab Spring and the Indignados in Spain and then the Occupy movement.

94
00:10:52,000 --> 00:11:03,000
But there was also the riots in London in that year as well, which aren't often brought into this picture of the 2011 uprisings,

95
00:11:03,000 --> 00:11:08,000
because a lot of people look at them and say, well, they weren't explicitly political, they didn't make demands.

96
00:11:08,000 --> 00:11:14,000
It was more this kind of eruption of chaos.

97
00:11:14,000 --> 00:11:26,000
But I think that sort of doesn't really do service to how that kind of riot is very political, how it's born of a particular political situation.

98
00:11:26,000 --> 00:11:33,000
And it is a reaction to the kind of political forces that people are experiencing in their lives.

99
00:11:33,000 --> 00:11:46,000
But what really interested me about the London riots was, you had this experience over three or four days when essentially lots of groups of teenagers

100
00:11:46,000 --> 00:12:00,000
were able to sort of outperform or outorganize one of the most well-resourced, well-adapted, largest police forces in the world.

101
00:12:00,000 --> 00:12:11,000
And the way they did that, which drew my attention, was because of the confluence of a certain number of factors.

102
00:12:11,000 --> 00:12:20,000
By accident, they actually had in their hands these incredibly powerful communication tools.

103
00:12:20,000 --> 00:12:24,000
So BlackBerry phones at the time were very, very cheap.

104
00:12:24,000 --> 00:12:29,000
They were trying to sort of, this is when BlackBerry was first trying to expand the use of smartphones.

105
00:12:29,000 --> 00:12:32,000
So they made these phones incredibly cheap.

106
00:12:32,000 --> 00:12:46,000
So loads of these teenagers had BlackBerry smartphones and BlackBerry had its own messaging system, which was incredibly strong encryption.

107
00:12:46,000 --> 00:12:50,000
So people could send messages. There was no way for the police to see those messages.

108
00:12:50,000 --> 00:12:57,000
There was no way for BlackBerry to actually get into that system and see those messages because it was a system that BlackBerry was trying to develop

109
00:12:57,000 --> 00:13:02,000
and market at big corporations and governments and things like that.

110
00:13:02,000 --> 00:13:05,000
So they wanted it to be incredibly secure.

111
00:13:05,000 --> 00:13:17,000
But what that meant was that you had these young people in London and other parts of the UK as well were able to network in real time incredibly effectively.

112
00:13:17,000 --> 00:13:23,000
So they were able to share information. They were able to communicate safe routes through the city.

113
00:13:23,000 --> 00:13:27,000
They were able to communicate the position of police around the city.

114
00:13:27,000 --> 00:13:33,000
And that allowed them to evade the police and escape arrest for quite some days.

115
00:13:33,000 --> 00:13:40,000
It didn't last that long, but it was still quite incredible that it managed for as long as it did.

116
00:13:41,000 --> 00:13:50,000
And that kind of tied in with a lot of sort of narratives around the time around network politics and how these new technologies,

117
00:13:50,000 --> 00:14:00,000
there was a sort of second wave of internet technologies which were becoming much more common and more accessible, but also much more mobile.

118
00:14:00,000 --> 00:14:07,000
So people had internet technologies in their pockets suddenly for the first time.

119
00:14:07,000 --> 00:14:15,000
And so there was a lot of talk around 2011 and the years around that about this new kind of networked form of politics.

120
00:14:15,000 --> 00:14:25,000
And yes, it was more information was shared very fast and allowed people to respond and adapt to situations very, very quickly

121
00:14:25,000 --> 00:14:33,000
without needing to have a centralized control structure that was taking information in and then giving orders out.

122
00:14:33,000 --> 00:14:41,000
But then also we saw with things like Occupy and the Arab Spring and Dignados, that also brought a democratic element in because

123
00:14:41,000 --> 00:14:49,000
partly because of these technologies, but also just because of the kind of politics that people were working with at the time.

124
00:14:49,000 --> 00:14:57,000
These movements were much more radically democratic than a lot of uprisings and revolutions that we've seen in the past.

125
00:14:58,000 --> 00:15:06,000
That period is typically referred to as the movement of the squares because one of the things that was typified by was people occupying

126
00:15:06,000 --> 00:15:16,000
public squares in different parts of big cities and typically across the world, people were holding assemblies.

127
00:15:16,000 --> 00:15:19,000
They were making decisions democratically.

128
00:15:19,000 --> 00:15:23,000
There weren't really leaders in a traditional sense.

129
00:15:23,000 --> 00:15:31,000
And people, everyone, at least in theory, everyone could participate in how these social movements were governed.

130
00:15:31,000 --> 00:15:44,000
So they were very self-organized in a very anarchistic sense, even if they weren't all explicitly anarchist or drawing on anarchist politics.

131
00:15:44,000 --> 00:15:50,000
But I think that sort of, for me, sort of drew me into cybernetics.

132
00:15:50,000 --> 00:16:02,000
And it was through reading the work of Colin Ward, a very, very influential British anarchist in the post-war years, 60s through to the 80s or 90s.

133
00:16:02,000 --> 00:16:09,000
Colin Ward is one of the most influential figures in British anarchism in this period.

134
00:16:09,000 --> 00:16:18,000
And he writes a lot about self-organization and he sort of drops the word cybernetics a couple of times and things that he wrote, but doesn't really expand on it in much detail.

135
00:16:18,000 --> 00:16:23,000
But I think just reading that and the word cybernetics, I was like, oh, that sounds interesting.

136
00:16:23,000 --> 00:16:28,000
That's quite a sexy term that I've not heard mentioned before.

137
00:16:28,000 --> 00:16:44,000
And that sort of drew me in and realized, well, there were a handful of engagements with cybernetics by anarchists kind of from the very early 1960s onwards, probably through the 1980s.

138
00:16:44,000 --> 00:16:50,000
And it was around linking how cybernetics sees self-organization.

139
00:16:50,000 --> 00:17:08,000
So as I mentioned in this sort of way of identifying what are the sort of functions for effective self-organization, but also just that very basic point about systems are at their most effective in dealing with change, dealing with complex environments.

140
00:17:08,000 --> 00:17:22,000
When they have a high level of flexibility and a high level of autonomy built into the systems and self-organization allows for that because you don't need to have a central sort of organizing core in a system.

141
00:17:22,000 --> 00:17:42,000
Because if you're dealing in a complex environment, the sort of information flow into that central organizing core and then the decision making and the orders that then come out of it, that's a very slow process or it can be a very slow process.

142
00:17:42,000 --> 00:17:50,000
And a lot of the work of some of the cyberneticians that I've sort of focused on, we can talk more about them in detail if you'd like.

143
00:17:50,000 --> 00:18:05,000
But they kind of identify, well, if a system is in a complex environment that's changing very fast and it's trying to filter information through some central control hub,

144
00:18:05,000 --> 00:18:13,000
you know, by the time that information is taken in, processed and orders are fed back out, the situation will have changed again.

145
00:18:13,000 --> 00:18:16,000
And so those orders won't be actually relevant.

146
00:18:16,000 --> 00:18:29,000
So the way systems cope with that is by being self-organized so that the different parts have a high level of autonomy to actually respond to change as they see fit.

147
00:18:29,000 --> 00:18:34,000
So they have some level of autonomy whereby they can say, okay, it's a complex environment.

148
00:18:34,000 --> 00:18:37,000
It's suddenly changing and we don't have to wait for orders.

149
00:18:37,000 --> 00:18:43,000
We don't have to send information up the chain and wait for a decision to be made and come back down to us.

150
00:18:43,000 --> 00:18:49,000
We can just make a decision and operate in this complex environment ourselves.

151
00:18:49,000 --> 00:18:55,000
And I think that kind of autonomy is also one of the strong links with anarchism.

152
00:18:55,000 --> 00:19:04,000
And it's something we saw in the, you know, these 2011 movements, you know, the London riots, these different groups of teenagers, which were running around, were autonomous.

153
00:19:04,000 --> 00:19:06,000
There wasn't a central control structure.

154
00:19:06,000 --> 00:19:18,000
They were autonomously, because of the information that was being shared in these communication networks, they were able to move around the city autonomously, avoid the police, you know, get to safe places, have escape routes.

155
00:19:18,000 --> 00:19:26,000
So they were able to coordinate themselves in a very decentralized and autonomous way.

156
00:19:26,000 --> 00:19:35,000
So I think that's exploring that in more detail as a sort of potential for anarchist engagement with cybernetics.

157
00:19:35,000 --> 00:19:42,000
Very interesting, because I thought that your first interest, but this was just me reading your book.

158
00:19:42,000 --> 00:19:52,000
I thought your first interest or the gateway through which you came to cybernetics would have been exactly what you talked about in the last sentences.

159
00:19:52,000 --> 00:20:04,000
Because, I mean, one of the more popular readings of these movement of the squares is that while these were experiences that are super important,

160
00:20:04,000 --> 00:20:13,000
still, they argued to have been very ineffective and that they kind of failed in some way.

161
00:20:13,000 --> 00:20:23,000
And that was me thinking when reading your book that your engagement with cybernetics was also you thinking that cybernetics would be of help.

162
00:20:23,000 --> 00:20:36,000
Exactly on this question, on this problem of how to effectively organize these approaches that you're actually in favor of through applying a cybernetic lens, so to speak.

163
00:20:36,000 --> 00:20:43,000
I would guess this was somewhat one of the things that drove you to cybernetics as well.

164
00:20:43,000 --> 00:20:52,000
Yeah, it was. Yeah. So I think that question of how successful these movements were is really, really important.

165
00:20:52,000 --> 00:20:55,000
I think we can look at it in a number of ways.

166
00:20:55,000 --> 00:21:08,000
And I think one of them is to think how effective or how successful were they at bringing about some kind of large scale political or economic change.

167
00:21:08,000 --> 00:21:14,000
And we can look across the world and see, well, yeah, there's sort of very, very mixed results there.

168
00:21:15,000 --> 00:21:24,000
So obviously, in the very immediate term, some of the movements in North Africa and the Middle East were able to overthrow governments.

169
00:21:24,000 --> 00:21:33,000
Whether the situations they've got now are in line with the aspirations of those movements, that's obviously incredibly debatable.

170
00:21:33,000 --> 00:21:48,000
And we also see, obviously, some of these in places like Libya and Syria, the outcomes has been civil war and huge amount of violence and destruction and people having to flee their homes in massive numbers.

171
00:21:48,000 --> 00:22:01,000
So it's obviously like, yeah, whether there was a sort of immediate political change that was in line with the demands or the desires of those movements, that's incredibly debatable.

172
00:22:01,000 --> 00:22:14,000
I think if we look at somewhere like, well, in the UK or the United States as well, we can see, well, part of a sort of outcome of these movements was a kind of delayed response in a sense.

173
00:22:14,000 --> 00:22:32,000
But then, from 2015 up until 2020, we had this sort of new left-wing populist surge in the UK around Jeremy Corbyn and in the US around Bernie Sanders and some other similar politicians.

174
00:22:32,000 --> 00:22:52,000
So we can see that's kind of, I mean, and there is stuff in those sort of populist surges around more direct democracy, more decentralized democratic systems, certainly economic systems that are much, much fatter and involve more opportunity for participation.

175
00:22:52,000 --> 00:23:01,000
But yeah, definitely these movements didn't achieve what they set out to achieve in very concrete terms.

176
00:23:01,000 --> 00:23:18,000
But one of the other things that they were trying to do, which I think they did succeed in, was trying to imagine an experiment with new ways of organizing societies.

177
00:23:18,000 --> 00:23:28,000
So Occupy is the example that I've looked into the most, but we see similar things in the different movements of the squares around the world.

178
00:23:28,000 --> 00:23:38,000
Occupy was able to create a kind of microcosm of radically democratic, radically participatory society.

179
00:23:38,000 --> 00:23:52,000
And it was something important. This is, again, where I think this sort of anarchist politics isn't coming from the position of saying, we've come up with this perfect utopian blueprint.

180
00:23:52,000 --> 00:23:59,000
Now let's put it into practice. It was very much an experiment. It was very much saying, well, let's try these different ways of doing democracy.

181
00:23:59,000 --> 00:24:04,000
Let's try them out and let's adapt them as we go on.

182
00:24:04,000 --> 00:24:19,000
So something we see with Occupy is, you know, it started with the General Assembly, which, you know, was, you know, these were, you know, large meetings run for the most part by consensus decision-making.

183
00:24:20,000 --> 00:24:33,000
Everyone had to be in agreement for a certain proposal to actually be passed. And these were meetings involving, in the case of Occupy Wall Street, thousands of people were taking part in these meetings, sometimes multiple times a day.

184
00:24:33,000 --> 00:24:42,000
And these were incredibly effective, you know, incredibly complex and detailed decisions were being made in these assemblies.

185
00:24:43,000 --> 00:24:52,000
People were dealing with complex legal things, complex financial matters, and they were able to do this fairly effectively.

186
00:24:52,000 --> 00:25:14,000
But as time went on with Occupy Wall Street in particular, they started to see, well, this large General Assembly perhaps isn't the most effective way of doing a lot of the day-to-day coordination and administration of, you know, a large encampment of people.

187
00:25:14,000 --> 00:25:26,000
So they created, you know, sort of a smaller spokes council where it would be, you know, delegates from different working groups and different parts of the camp would be involved in making these more kind of strategic decisions.

188
00:25:26,000 --> 00:25:33,000
The General Assembly still happened, but they were more for, you know, more sort of broader political discussions and decisions.

189
00:25:33,000 --> 00:25:41,000
Then the spokes council was a way of making the strategic decision-making much more effective and much more coordinated.

190
00:25:41,000 --> 00:25:59,000
So I think it's important to see these movements, part of the success of them is that they were trying and testing and adapting and experimenting with, you know, really, really radical ways of thinking about how we can organize society in very democratic, very participatory ways.

191
00:25:59,000 --> 00:26:12,000
And I think that's part of the legacy we have to sort of hold on to and see, okay, how is that sort of legacy of rather than just talking about maybe these, you know, new forms of democracy would work?

192
00:26:12,000 --> 00:26:24,000
Well, you know, people have tried them in large, large groups under very, very difficult circumstances, have tried them and adapted them and come out with, you know, sort of solutions to a lot of the problems that emerged.

193
00:26:24,000 --> 00:26:34,000
I think another thing about the sort of failure of these movements, the kind of odds they were up against were massive, right?

194
00:26:34,000 --> 00:26:49,000
I mean, when Occupy Walls, when the Occupy movement in the U.S. was finally put down, you know, that was a huge coordinated police action, you know, across the whole of the U.S.

195
00:26:49,000 --> 00:27:04,000
At exactly the same time, police forces, you know, highly militarized police forces with, you know, very, very advanced sort of capabilities in terms of, you know, crowd control and dealing with large groups of people.

196
00:27:04,000 --> 00:27:09,000
You know, they moved in and dismantled and destroyed these camps all at the same time.

197
00:27:09,000 --> 00:27:25,000
And I think to try and imagine how the Occupy movement could have withstood that and could have survived in some kind of real form beyond that is that's very difficult to imagine what that could have looked like.

198
00:27:25,000 --> 00:27:30,000
I mean, the way it did survive was into something like Occupy Sandy.

199
00:27:30,000 --> 00:27:53,000
So when Hurricane Sandy hit New York, the mutual aid network that emerged, which was, you know, for several days was the main sort of coordination of, you know, aid and support and shelter and resources for people who were affected by this hurricane.

200
00:27:53,000 --> 00:27:58,000
That was organized by people who had been part of the Occupy Wall Street movement.

201
00:27:58,000 --> 00:28:07,000
And they were applying a lot of this stuff around, you know, decentralized organization, you know, autonomous network coordination.

202
00:28:07,000 --> 00:28:09,000
They were applying that to that mutual aid effort.

203
00:28:09,000 --> 00:28:17,000
So that's something, one of the really important things that did emerge out of Occupy in the U.S. at least.

204
00:28:17,000 --> 00:28:26,000
Yeah, and I think it's super important that we look at the actual experiences and not just ditch them as if everything failed.

205
00:28:26,000 --> 00:28:44,000
And it's super important to kind of learn out of these experiences since we actually do want to build structures that do live on and survive, that do not kind of end when one coordinated effort through the state destroys the actual camps.

206
00:28:44,000 --> 00:28:51,000
In this case, we do need and do want structures that survive beyond such a blow.

207
00:28:51,000 --> 00:29:07,000
And for this, we need to enrich the analytic aspect of looking at the movement of the squares and enrich the tactics, the strategies and in your language, the grand strategies that we apply in order to achieve these goals.

208
00:29:07,000 --> 00:29:12,000
So let's dive a little deeper into the components of anarchist cybernetics.

209
00:29:12,000 --> 00:29:19,000
I mean, cybernetics is kind of by definition a very broad field when it comes to anarchist cybernetics.

210
00:29:19,000 --> 00:29:25,000
You are specifically interested in a subfield, a subfield called organizational cybernetics.

211
00:29:25,000 --> 00:29:32,000
And within this subfield, you focus on the work of Stafford Beer and his viable system model.

212
00:29:32,000 --> 00:29:41,000
So could you give us an overview of the VSM, the viable system model and how it informs anarchist cybernetics?

213
00:29:41,000 --> 00:29:46,000
Yeah, so the viable system model, I think, is really, really interesting.

214
00:29:46,000 --> 00:29:59,000
So what it does as a kind of model of how any kind of system can be organized is it tries to sort of separate out the different functions within a system.

215
00:29:59,000 --> 00:30:10,000
And very broadly it does. So there's two very broad parts of this kind of model, of this picture of an effective self-organizing system.

216
00:30:10,000 --> 00:30:17,000
So one is the kind of operational part. So you have, you know, the actual day to day operations of any system.

217
00:30:17,000 --> 00:30:25,000
So if we're thinking about, you know, something like, I mean, yeah, we could look at something that occupied Wall Street,

218
00:30:25,000 --> 00:30:31,000
but I think something I'm really interested in at the moment is thinking about how this applies to worker cooperatives.

219
00:30:31,000 --> 00:30:34,000
So I'll kind of take that example a bit.

220
00:30:34,000 --> 00:30:41,000
So if we imagine a kind of cafe that's run in a kind of, you know, collective cooperative way.

221
00:30:41,000 --> 00:30:52,000
So the day to day operations would be, you know, obviously, you know, you know, producing food, you know, making drinks, serving customers, you know, opening and closing, cleaning, things like this.

222
00:30:52,000 --> 00:30:57,000
So you have these sort of day to day activities.

223
00:30:57,000 --> 00:31:01,000
And then you also have how these are sort of coordinated in a very immediate way, right?

224
00:31:01,000 --> 00:31:13,000
So you have to make sure, for example, if a customer puts in an order for, you know, a meal and some drinks, that, you know, okay, who's making the drinks and who's making the food?

225
00:31:13,000 --> 00:31:24,000
There has to be some coordination there so that, you know, they kind of arrive at the right time and the person's not, I don't know, sitting with their food for an hour before the drink comes or the other way around.

226
00:31:24,000 --> 00:31:29,000
So there has to be some sort of basic coordination between these different functions.

227
00:31:29,000 --> 00:31:37,000
But then what the VSM does, which I think is really interesting, is it says, okay, so this is the operational part, these basic functions and how they coordinate.

228
00:31:37,000 --> 00:31:51,000
But we also have a kind of meta systemic part, which is the kind of broader or more strategic coordination of sort of system or organization as a whole.

229
00:31:51,000 --> 00:32:06,000
So if we take this example of the kind of, you know, cooperative cafe, this would be thinking about questions of how does the sort of business strategy develop within this collective?

230
00:32:06,000 --> 00:32:19,000
So it might be that they have weekly meetings where they, you know, reflect on what's happened during the week, you know, do things like, you know, monitor how much stock is left, how much has been sold,

231
00:32:19,000 --> 00:32:26,000
whether some things are more popular than others and whether there's any sort of conflicts between different parts of the operation.

232
00:32:26,000 --> 00:32:37,000
And it allows them to sort of reflect on that outside of the day to day context and sort of step out of that and say, OK, well, now we're going to look at this as a kind of system as a whole.

233
00:32:37,000 --> 00:32:47,000
And we're going to have this systemic overview of everything that's happening rather than just the day to day immediate coordination.

234
00:32:47,000 --> 00:32:54,000
And I think that sort of meta system is what is really important with the viable systems model.

235
00:32:54,000 --> 00:33:06,000
So I think it's the kind of thing that is often there's often not that separation between the day to day operations and the sort of meta systemic strategy or coordination or monitoring.

236
00:33:06,000 --> 00:33:16,000
Often when a lot of in a lot of ways, things like cooperatives or anarchist collectives are described in terms of organization.

237
00:33:16,000 --> 00:33:24,000
There's a kind of mixing of these and they're kind of bound up together and they're not really not really distinguished at all.

238
00:33:24,000 --> 00:33:37,000
And I think when that happens, often what it means is that some of the key functions that, as I said, cybernetics identifies don't happen or don't happen well enough or happen at the wrong time.

239
00:33:37,000 --> 00:33:50,000
So I think separating these things out allows us to sort of say, OK, we can identify what the key functions of this meta systemic strategy are and we can make sure that they happen in the right ways.

240
00:33:50,000 --> 00:34:04,000
And importantly, from an anarchist perspective or from the perspective of a worker owned cooperative, how can we make sure these functions are organized in a democratic and participatory way?

241
00:34:04,000 --> 00:34:13,000
So rather than just saying the typical business, well, there's the day to day activities and then there's the management activities.

242
00:34:14,000 --> 00:34:19,000
And that's sort of management decisions and management strategy.

243
00:34:19,000 --> 00:34:29,000
There's a select group of people who are a kind of elite within the organization who have the decision making power over what happens there.

244
00:34:29,000 --> 00:34:36,000
From an anarchist perspective, separating these things out allows us to say, well, we can have these functions.

245
00:34:37,000 --> 00:34:57,000
We can be doing things like developing a long term strategy, monitoring performance in different ways, making decisions about how we can coordinate things better, how we can move resources around in better ways, how we can communicate in better ways.

246
00:34:57,000 --> 00:35:03,000
But we can do all these things in democratic and participatory ways.

247
00:35:03,000 --> 00:35:17,000
So it doesn't mean that we have the operational parts of the organization, which is the workers and then the meta systemic strategy parts, which is the managers.

248
00:35:17,000 --> 00:35:32,000
Essentially, we have the same people doing both, not at the same time, because that's when it becomes too complicated and too difficult to manage, but at a certain point stepping out of the operational roles and into the strategy roles.

249
00:35:32,000 --> 00:35:39,000
So as I said, this could be weekly meetings, monthly meetings, maybe once a year there would be a kind of larger strategy discussion.

250
00:35:39,000 --> 00:35:47,000
But you have these sort of moments when people can step out of their operational roles into the more strategic roles.

251
00:35:47,000 --> 00:35:54,000
And that allows for that kind of coordination to happen in democratic ways.

252
00:35:55,000 --> 00:36:06,000
You mentioned at some point within your answer that sometimes these things get mixed up and then some of the functions actually do not really happen and are not being addressed.

253
00:36:06,000 --> 00:36:17,000
And I would add that sometimes, depending on the context, you even have the situation that people are opposed to actually applying some of these functions.

254
00:36:17,000 --> 00:36:30,000
I mean, in the example of the cafe, it's a bit more relaxed, I would say, because people might intuitively grasp that there is a need for some kind of higher level coordination as well.

255
00:36:30,000 --> 00:36:43,000
But if you take the example of a society as a whole and try to apply this lens, then you will come to questions of hierarchy versus autonomy and stuff like that.

256
00:36:43,000 --> 00:37:02,000
And then specifically within anarchist communities, you might have some strong reaction actually against having this higher level, so to speak, coordination function being applied because it is perceived as a form of unwanted hierarchy.

257
00:37:02,000 --> 00:37:05,000
So I think it would be fruitful.

258
00:37:05,000 --> 00:37:10,000
And this is something you do within the book in a very good way, I would say.

259
00:37:10,000 --> 00:37:27,000
I think it would be fruitful to use the VSM as a diagnostic tool in order to look at some of the key principles that are relevant for anarchist organization from a different perspective, from the perspective of anarchist cybernetics in this case.

260
00:37:27,000 --> 00:37:36,000
Because I think you can, by doing that, address some of the more fundamental open questions within anarchist organization.

261
00:37:36,000 --> 00:37:39,000
So maybe you could elaborate a bit.

262
00:37:39,000 --> 00:37:45,000
What does it look like to apply the viable system model to anarchist self-organization?

263
00:37:45,000 --> 00:37:50,000
Maybe you could give us an overview of an anarchist viable system model.

264
00:37:50,000 --> 00:38:09,000
Yeah, so the way that I've done it in the book, and that's just a product of the fact that it's a written document like a book, is very much me on the outside looking at something like the Occupy movement or like I've just done for this cooperative cafe.

265
00:38:09,000 --> 00:38:16,000
You're looking at it from the outside and seeing how does this work in terms of a viable, effective system.

266
00:38:16,000 --> 00:38:24,000
But the way that it really ought to be applied is in a much more participatory and involved way.

267
00:38:24,000 --> 00:38:36,000
So rather than someone like myself standing on the outside and analyzing the organization, it's something that the people in the organization should be doing collectively.

268
00:38:36,000 --> 00:38:42,000
So part of their discussions might be, okay, how can we start to understand the different functions?

269
00:38:42,000 --> 00:38:54,000
And one of the incredibly useful tools in doing this is work that was developed by John Walker.

270
00:38:54,000 --> 00:39:04,000
So John Walker was somebody who was working in a number of cooperatives in the north of England in the 1980s, 1990s,

271
00:39:04,000 --> 00:39:13,000
and got in contact with Stafford Beer because he started to learn about cybernetics and thinking that maybe this could work for cooperatives.

272
00:39:13,000 --> 00:39:21,000
And what John Walker's done is he's written a sort of handbook on the viable systems model for cooperatives.

273
00:39:21,000 --> 00:39:29,000
And it's not explicitly anarchist, but I think it does chime incredibly well with anarchist politics.

274
00:39:29,000 --> 00:39:39,000
And so what John sort of suggests is he does an incredible amount of detail because he's tried this with different cooperatives time and again.

275
00:39:39,000 --> 00:39:44,000
So he's worked out in terms of this is the process that actually works.

276
00:39:44,000 --> 00:39:49,000
But he basically just goes through a number of steps that you would do with a group.

277
00:39:49,000 --> 00:39:58,000
So if you're in a cooperative, you can look at John's viable systems model guide and go through different steps, answer different questions.

278
00:39:58,000 --> 00:40:08,000
And what that means essentially is doing things like trying to identify the environment that you're operating in as an organization.

279
00:40:08,000 --> 00:40:11,000
What are the different factors involved in that environment?

280
00:40:11,000 --> 00:40:17,000
How does the environment change? And then also positioning yourself as an organization within that.

281
00:40:17,000 --> 00:40:22,000
So what are the sort of interactions you have with the environment?

282
00:40:22,000 --> 00:40:30,000
At what point of the organization are you engaging with different situations that are maybe changing in different ways?

283
00:40:30,000 --> 00:40:41,000
So to take the example of the cafe, for example, they might say, well, part of our environment is the customers that are coming in to the business.

284
00:40:41,000 --> 00:40:45,000
And we have people who are engaging with them.

285
00:40:45,000 --> 00:40:50,000
We have cooks who are making food for them, people making drinks, people taking orders from them.

286
00:40:50,000 --> 00:40:56,000
You have these different ways of interacting with that environment.

287
00:40:56,000 --> 00:41:04,000
And that's the kind of starting point, I think, for thinking about how this viable systems model process can work within an organization.

288
00:41:04,000 --> 00:41:12,000
Because once people start to do that and John's viable systems model guide goes through a lot of steps and a lot more detail.

289
00:41:12,000 --> 00:41:16,000
But you start to sort of actually identify the different functions.

290
00:41:16,000 --> 00:41:24,000
So you start to say, OK, what are our different operational parts of our organization?

291
00:41:24,000 --> 00:41:30,000
As I said, it might be people serving customers, people making the food, people making the drinks, people doing the cleaning.

292
00:41:30,000 --> 00:41:37,000
So you can start to sort of map out the different operational parts of the organization.

293
00:41:37,000 --> 00:41:44,000
And the way John talks about this is you actually have massive sheets of paper and you write all this down.

294
00:41:44,000 --> 00:41:49,000
You start to start to actually map out what the organization does day to day.

295
00:41:49,000 --> 00:41:52,000
And then you can start to think, well, how do these interact?

296
00:41:52,000 --> 00:41:56,000
So what are the points where these different functions interact with each other?

297
00:41:56,000 --> 00:42:02,000
So when do the different operational parts come into contact?

298
00:42:02,000 --> 00:42:05,000
And that just starts allowing you to see, OK, is there any other clashes?

299
00:42:05,000 --> 00:42:07,000
Is there any sort of conflict here?

300
00:42:07,000 --> 00:42:12,000
Are there any areas where actually the way they come into contact isn't the most effective?

301
00:42:12,000 --> 00:42:14,000
It creates more problems than it solves.

302
00:42:14,000 --> 00:42:20,000
So you can start to sort of help with some of the coordination that way just by mapping out those interactions.

303
00:42:20,000 --> 00:42:32,000
But then you can also go to the next kind of meta-systemic level and start to say, OK, within the organization, where is it we are doing strategy, for example?

304
00:42:32,000 --> 00:42:36,000
Where is it we are thinking about long term planning?

305
00:42:36,000 --> 00:42:39,000
Is this something we are doing?

306
00:42:40,000 --> 00:42:43,000
And again, you can sort of map this out in the big piece of paper.

307
00:42:43,000 --> 00:42:48,000
Well, OK, we have this monthly meeting where we do this.

308
00:42:48,000 --> 00:42:51,000
Or maybe we don't. Maybe we need to start doing it.

309
00:42:51,000 --> 00:43:00,000
Maybe we need to have a monthly meeting where we talk about strategy, where we look at what's happening outside the business and the environment, but also what's happening within it.

310
00:43:00,000 --> 00:43:02,000
So what kind of changes are happening?

311
00:43:02,000 --> 00:43:07,000
Is there any conflicts? Are there any difficulties? Are there any issues that are developing?

312
00:43:07,000 --> 00:43:10,000
You can have that internal and external view.

313
00:43:10,000 --> 00:43:15,000
And also you can start saying, how are we actually monitoring what's happening?

314
00:43:15,000 --> 00:43:23,000
Do we have any functions within our organization for actually keeping a track of what's happening day to day?

315
00:43:23,000 --> 00:43:27,000
So that we can then say, well, this works really well.

316
00:43:27,000 --> 00:43:30,000
This doesn't work really well. This could be better this way.

317
00:43:30,000 --> 00:43:33,000
This could be more effective if it was done like this.

318
00:43:33,000 --> 00:43:45,000
If you start mapping out these functions of how are we monitoring things, how are we developing a long term strategy, it allows you to see, OK, maybe we could be doing these better.

319
00:43:45,000 --> 00:43:48,000
Or maybe if we're not doing them, we can start doing them.

320
00:43:48,000 --> 00:43:52,000
Maybe we can learn from what other cooperatives are doing around us.

321
00:43:52,000 --> 00:44:02,000
And I think these are these are the steps that something like an anarchist collective or cooperative, even just a community of people living together, could be going through.

322
00:44:02,000 --> 00:44:09,000
So it's taking that time to actually sit down and have discussions about what is it we're doing day to day?

323
00:44:09,000 --> 00:44:11,000
How is that coordinated?

324
00:44:11,000 --> 00:44:17,000
Could that coordination be made more effective now that we've started to map it out and actually look at it?

325
00:44:17,000 --> 00:44:22,000
And in this kind of, you know, have this sort of overview.

326
00:44:22,000 --> 00:44:25,000
But then also, how are we actually monitoring things?

327
00:44:25,000 --> 00:44:28,000
How are we checking that things are working OK?

328
00:44:28,000 --> 00:44:30,000
That could be monitoring performance.

329
00:44:30,000 --> 00:44:33,000
Also, just checking, is everyone happy in the organization?

330
00:44:33,000 --> 00:44:36,000
Does everyone still feel fulfilled?

331
00:44:36,000 --> 00:44:38,000
Does everyone still feel at home in this community?

332
00:44:38,000 --> 00:44:44,000
You can start checking for these things in more conscious ways, I think.

333
00:44:44,000 --> 00:44:48,000
And then building a strategy that takes all of this into account.

334
00:44:48,000 --> 00:44:50,000
Well, you were answering.

335
00:44:50,000 --> 00:45:00,000
I'm thinking like, all right, this very much sounds like something that already happens within our societies today in the form of business consulting, so to speak.

336
00:45:00,000 --> 00:45:06,000
And this is, of course, not a coincidence, because there would be was a business consultant as well.

337
00:45:06,000 --> 00:45:22,000
So I think it would be important to kind of tie this back to why this kind of thinking is actually also fruitful for trying to achieve some of the normative goals of anarchism as well.

338
00:45:22,000 --> 00:45:33,000
Because otherwise people might hear you talk and think, oh, well, Thomas is trying to get into the business of business consulting.

339
00:45:33,000 --> 00:45:40,000
So how is this in line with coming to a post-capitalist anarchist cybernetic world, so to speak?

340
00:45:40,000 --> 00:45:44,000
But it actually is helpful as well.

341
00:45:44,000 --> 00:45:49,000
And I think it would be important for us to kind of carve out how and why.

342
00:45:49,000 --> 00:46:03,000
And one way of doing it would be through taking some of these core principles and trying to figure out what they mean within anarchism and what they mean within cybernetics.

343
00:46:03,000 --> 00:46:18,000
So you already mentioned self-organization a couple of times and how this was one of the gateways that led you to cybernetics because you immediately thought, all right, this is something of an interesting overlap.

344
00:46:18,000 --> 00:46:25,000
So could you maybe explain what self-organization means within the different fields?

345
00:46:25,000 --> 00:46:32,000
Yes. So I think in cybernetics, self-organization is just quite a technical term.

346
00:46:32,000 --> 00:46:38,000
It's quite a sort of descriptive technical term for how a system is organized.

347
00:46:38,000 --> 00:46:43,000
And, you know, an electronic system or a mechanical system can be self-organized.

348
00:46:43,000 --> 00:46:50,000
So the sort of classic example is the steam engine, which has a certain part of the mechanism.

349
00:46:50,000 --> 00:46:55,000
It's a thing called a governor, which is basically a way to regulate speed.

350
00:46:55,000 --> 00:47:05,000
So as the engine speeds up, the governor, you know, kind of, well, it's hard to sort of describe it without a picture in front of me.

351
00:47:05,000 --> 00:47:15,000
But as the engine speeds up, the governor responds to that speed and the way it responds slows the system down.

352
00:47:15,000 --> 00:47:19,000
So it's a way where the system can regulate itself.

353
00:47:19,000 --> 00:47:29,000
Thermostats do that as well. Okay, you know, thermostats, when the room gets above a certain temperature, the air conditioning will come on and bring the temperature back down.

354
00:47:29,000 --> 00:47:38,000
So in cybernetics terms, that's self-organized, right? Because no one's having to manually adjust the speed of the engine.

355
00:47:38,000 --> 00:47:47,000
I'm not in my room having to constantly go back and turn the air conditioning on when it gets too hot and then turn it off again when it's too cold.

356
00:47:47,000 --> 00:47:50,000
The thermostat does that itself.

357
00:47:50,000 --> 00:47:56,000
Obviously, that's very different from how we think about self-organization in political terms.

358
00:47:56,000 --> 00:48:13,000
So when we're talking about self-organization in political terms, it's, on the one hand, taking in that kind of technical definition of saying, okay, how can a collective, a community, a cooperative, a social movement,

359
00:48:13,000 --> 00:48:32,000
how can it perform the tasks that it wants to perform, achieve the goals that it wants to achieve in a sort of self-regulating way where it doesn't need a leadership clique or a leadership party to actually do the controlling.

360
00:48:32,000 --> 00:48:38,000
It just does it itself through how it's organized and how it communicates.

361
00:48:38,000 --> 00:48:59,000
So there is that technical element in there, but there's also importantly the political element, which is very much saying, well, okay, self-organization is actually about everyone being able to participate in the decisions that have any impact on their lives.

362
00:48:59,000 --> 00:49:08,000
So it's about a sort of participatory and democratic way of organizing in any kind of community or collective.

363
00:49:08,000 --> 00:49:25,000
So in that way, self-organization is less about how technically efficient it is or effective it is and much more about, well, it allows us to develop ourselves in a sort of free and autonomous way, both collectively and as individuals.

364
00:49:25,000 --> 00:49:32,000
And for the anarchists, this is very, very closely linked to ideas of human flourishing.

365
00:49:32,000 --> 00:49:48,000
So how can we actually develop ourselves as some kind of rounded, happy individuals with the kind of resources for genuine well-being?

366
00:49:48,000 --> 00:49:56,000
How can we do that in a community which is collectively self-organized?

367
00:49:56,000 --> 00:50:09,000
So how is my individual freedom linked to the collective process of self-organization where we are as a group free and autonomous and making our own decisions?

368
00:50:09,000 --> 00:50:20,000
So I think self-organization is these two different things. It's on the one hand, the technical thing of this is the most effective way of organizing systems.

369
00:50:20,000 --> 00:50:34,000
And also the political thing of this is the way that communities or collectives can be organized that gives us the most freedom, that gives us the most opportunity.

370
00:50:34,000 --> 00:50:42,000
Yeah, that gives us the most opportunity for collective and individual autonomy and fulfillment.

371
00:50:42,000 --> 00:50:46,000
And I think anarchism has always had its eye on both of these.

372
00:50:46,000 --> 00:50:58,000
So even if you look back to some of the classical anarchists, like Peter Kropotkin, who was an anarchist geographer writing at the end of the 19th century and started the 20th century,

373
00:50:58,000 --> 00:51:15,000
he very much sees anarchism as being a politically desirable system of governance, whereby people have more freedom, people are happier, people have more well-being, people are able to look after themselves much better, they have better economic standards.

374
00:51:15,000 --> 00:51:28,000
But also a much more effective way of organizing society, because he says, well, the state is this very slow, very cumbersome, very blunt tool for trying to organize society.

375
00:51:28,000 --> 00:51:40,000
If we can do this autonomously, we allow for much more harmony with nature. It allows us to have a much better alignment with how nature operates.

376
00:51:40,000 --> 00:51:51,000
And we can build our communities in ways that are more sustainable with the way that change and the way that self-organization happens in natural systems as well.

377
00:51:51,000 --> 00:52:05,000
Maybe I would add, and this is maybe already a learning, so to speak, also from the experiences, for example, in the movement of the squares.

378
00:52:05,000 --> 00:52:15,000
Since you point out that ideally you have these two elements of self-organization as two sides of the same coin.

379
00:52:15,000 --> 00:52:27,000
So you have the normative ideal of self-organization as well as effective self-organization through allowing a form of distributed control, so to speak.

380
00:52:28,000 --> 00:52:43,000
I would maybe add that I understood the book as if you wanted to say that you can have both of these, but in order to get them, you would have to organize in a specific way.

381
00:52:43,000 --> 00:52:54,000
So it's not that you can just merely decentralize as people might have thought about anarchism for actually a long period.

382
00:52:54,000 --> 00:53:04,000
You cannot do merely that and think that you can have the effective side of self-organization as well.

383
00:53:04,000 --> 00:53:12,000
But you would have to think about the ways in which the organization is structured in a very specific way, and that's why you take the VSM.

384
00:53:12,000 --> 00:53:15,000
And I already mentioned control.

385
00:53:15,000 --> 00:53:29,000
I think it would be good to maybe take a look at this term as well, because this is something that might lead to some misunderstandings specifically amongst anarchist circles, I would say.

386
00:53:29,000 --> 00:53:40,000
Because, of course, there might be a reflex to think that control is like immediate control of domination, the domination of one person over another.

387
00:53:40,000 --> 00:53:45,000
But within cybernetics, this is thought of very differently.

388
00:53:45,000 --> 00:53:51,000
So could you maybe elaborate how the term control is being used in the context of anarchist cybernetics?

389
00:53:51,000 --> 00:53:53,000
And then we will go from there.

390
00:53:53,000 --> 00:53:55,000
Yeah, so I think you're totally right.

391
00:53:55,000 --> 00:54:07,000
I think there's a few sort of pieces of terminology in thinking about anarchist cybernetics that do rub up against how we typically think of anarchist politics.

392
00:54:07,000 --> 00:54:10,000
And I think control is definitely one of them.

393
00:54:10,000 --> 00:54:18,000
So typically, we think of control as command and control hierarchies, where control means domination.

394
00:54:18,000 --> 00:54:29,000
It means someone subordinating someone else, someone following the orders from someone above them, that person above them is in control of them.

395
00:54:29,000 --> 00:54:36,000
And I think what cybernetics allows us to do is think about that in a very, very different way.

396
00:54:36,000 --> 00:54:58,000
So control is much more, as I've sort of discussed already, the way self-organization operates in systems, according to cybernetics, the most sort of effective way for self-organization to operate is without any kind of centralized or external control.

397
00:54:58,000 --> 00:55:02,000
So we think, well, what's actually happening in these systems?

398
00:55:02,000 --> 00:55:06,000
They are still coordinated. They are still making complex decisions.

399
00:55:06,000 --> 00:55:15,000
They are still responding in a coordinated and collective way to changes and complexity in their environments.

400
00:55:15,000 --> 00:55:18,000
And that is all happening through control.

401
00:55:18,000 --> 00:55:22,000
So the system, in a sense, controls itself.

402
00:55:22,000 --> 00:55:30,000
So that's where self-organization, so self-control, and it's much less even the term self-control.

403
00:55:30,000 --> 00:55:36,000
And we think of self-control as like the individual trying to control our passions in some way.

404
00:55:36,000 --> 00:55:49,000
It's much less of that. It's much more, you know, if we're in a group of people and we make a decision collectively, we agree on something and we do that, then we have control over ourselves.

405
00:55:49,000 --> 00:55:54,000
We've been able to do something coordinated and in an effective and democratic way.

406
00:55:54,000 --> 00:55:57,000
So that's how control operates.

407
00:55:57,000 --> 00:56:03,000
I think there's a few sort of metaphors for how control operates in cybernetics.

408
00:56:03,000 --> 00:56:14,000
So Elena Leonard, who's one of the sort of foremost authors within the sort of organizational cybernetics tradition, described it as a kind of balancing.

409
00:56:14,000 --> 00:56:19,000
So if you imagine one of the sort of metaphors is like someone skiing downhill.

410
00:56:19,000 --> 00:56:23,000
So, I mean, I've never skied, but I can kind of imagine what skiing is like.

411
00:56:23,000 --> 00:56:25,000
You know, you're kind of moving from side to side.

412
00:56:25,000 --> 00:56:35,000
You're kind of adapting to the environment, shifting with how the ground changes, what's in front of you.

413
00:56:35,000 --> 00:56:41,000
You're in some kind of self-organized control where you're feeding back from the environment.

414
00:56:41,000 --> 00:56:43,000
You're taking in what's happening around about you.

415
00:56:43,000 --> 00:56:45,000
You're steering yourself in subtle ways.

416
00:56:45,000 --> 00:56:51,000
It's not sort of there's not somebody on the outside pulling your strings, essentially.

417
00:56:51,000 --> 00:57:00,000
I think another really, really nice metaphor for this, and this is in a book by a Dutch anarchist, Roel van Daan.

418
00:57:00,000 --> 00:57:03,000
So he wrote a book called Message of a Wise Kabouter.

419
00:57:04,000 --> 00:57:11,000
So Kabouter is a kind of gnome, and he describes Peter Kropotkin as a kind of gnome-like figure.

420
00:57:11,000 --> 00:57:14,000
So gnome's like sort of short with big beards.

421
00:57:14,000 --> 00:57:22,000
And for van Daan, there's an element of gnomes live in a more harmonious way with nature.

422
00:57:22,000 --> 00:57:28,000
But he describes it, possibly a very, very Dutch example, in terms of riding a bicycle.

423
00:57:28,000 --> 00:57:31,000
So he says, OK, so you're riding a bicycle.

424
00:57:31,000 --> 00:57:34,000
Obviously, you're steering, so you're in control that way.

425
00:57:34,000 --> 00:57:37,000
But there's also there's wind coming in from different sides.

426
00:57:37,000 --> 00:57:45,000
The wind maybe blows you, and so you lean very, very slightly to one side to sort of counteract the wind.

427
00:57:45,000 --> 00:57:52,000
Maybe you go around a corner, so you lean in a slightly different way to allow yourself to go around the corner on the bicycle.

428
00:57:52,000 --> 00:57:56,000
All of these are parts of a sort of very subtle system of control.

429
00:57:56,000 --> 00:57:59,000
It's taking information from the environment.

430
00:57:59,000 --> 00:58:00,000
The wind's blowing this way.

431
00:58:00,000 --> 00:58:02,000
I'm feeling that in myself.

432
00:58:02,000 --> 00:58:07,000
I'm feeling myself be shifted one way so I can subtly lean the other way.

433
00:58:07,000 --> 00:58:09,000
It's not even necessarily totally conscious.

434
00:58:09,000 --> 00:58:13,000
It's something we probably do quite well, at least if we're used to cycling.

435
00:58:13,000 --> 00:58:17,000
We do it quite naturally without thinking about it.

436
00:58:17,000 --> 00:58:23,000
And I think that kind of control, so imagining someone cycling and responding to the wind

437
00:58:23,000 --> 00:58:27,000
and managing to keep themselves going, I think is really, really important.

438
00:58:27,000 --> 00:58:32,000
But I think the metaphor of the bicycle is really, really interesting for me because

439
00:58:32,000 --> 00:58:36,000
it tells us how important the environment is here.

440
00:58:36,000 --> 00:58:43,000
So if you imagine cycling on a bicycle track or a bicycle lane,

441
00:58:43,000 --> 00:58:49,000
if that bicycle lane had incredibly sharp corners in it,

442
00:58:49,000 --> 00:58:52,000
you'd really, really struggle to get around those corners.

443
00:58:52,000 --> 00:58:57,000
You'd have to step off the bike and turn the bike around and then start again.

444
00:58:57,000 --> 00:59:01,000
I'm sure in Germany you've got really, really good bicycle lanes.

445
00:59:01,000 --> 00:59:07,000
In the UK, we either have none or if we do have them, they're just useless and terrible.

446
00:59:07,000 --> 00:59:12,000
So I think for me that tells us how important the environmental conditions are

447
00:59:12,000 --> 00:59:18,000
to how we can have that self-organized kind of control.

448
00:59:19,000 --> 00:59:23,000
It's not just about what we do as an organization, as a collective,

449
00:59:23,000 --> 00:59:27,000
it's also about the environment we're in and how the environment is structured.

450
00:59:27,000 --> 00:59:32,000
Does the environment allow us to have some kind of self-organization

451
00:59:32,000 --> 00:59:38,000
and have that kind of balancing idea of control?

452
00:59:38,000 --> 00:59:44,000
And there are some very nice kind of phrases within your book as well

453
00:59:44,000 --> 00:59:48,000
which try to give an idea of how this relation is thought of.

454
00:59:48,000 --> 00:59:52,000
For example, control is in each function not top-down

455
00:59:52,000 --> 00:59:57,000
or the control function is spread throughout the architecture of the system.

456
00:59:57,000 --> 01:00:02,000
So this very much highlights this idea of not having one centralized body

457
01:00:02,000 --> 01:00:07,000
that gives out orders and everybody else is supposed to follow.

458
01:00:07,000 --> 01:00:14,000
However, and this is something that we definitely will have to talk about

459
01:00:14,000 --> 01:00:18,000
and which is very interesting I think in the way that you approach this,

460
01:00:18,000 --> 01:00:24,000
anarchist cybernetics does not say that there is full autonomy for everybody

461
01:00:24,000 --> 01:00:32,000
so that everybody could simply do what he or she or they might want to do in a given situation

462
01:00:32,000 --> 01:00:38,000
and actually approach some form of highly individualistic autonomy so to speak.

463
01:00:38,000 --> 01:00:47,000
Instead, you try to approach the question of autonomy as well as the question of freedom and hierarchy

464
01:00:47,000 --> 01:00:51,000
and you try to approach these questions from a different angle.

465
01:00:51,000 --> 01:00:57,000
So you propose, for example, functional hierarchy instead of structural hierarchy.

466
01:00:57,000 --> 01:01:03,000
So maybe let's take a look at these different elements and start with the question of hierarchy.

467
01:01:03,000 --> 01:01:07,000
What's the difference between the two forms of hierarchy that you describe,

468
01:01:07,000 --> 01:01:14,000
functional hierarchy and structural hierarchy, and why might functional hierarchy serve us better?

469
01:01:14,000 --> 01:01:18,000
Yes, so the distinction between functional and structural hierarchy,

470
01:01:18,000 --> 01:01:25,000
so that's something that comes from Gordon Pask who is another of the really sort of influential cyberneticians

471
01:01:25,000 --> 01:01:31,000
in the post-World War II years, a very close friend of Stafford Beers.

472
01:01:31,000 --> 01:01:38,000
His interest is more in communication systems and electronic systems.

473
01:01:38,000 --> 01:01:43,000
He's less interested in social systems although he uses them as examples an awful lot

474
01:01:43,000 --> 01:01:45,000
and he is very political in what he writes.

475
01:01:45,000 --> 01:01:51,000
He makes this distinction to try and say we have the sort of structural hierarchy within a system

476
01:01:51,000 --> 01:01:57,000
which is within an organization is how we would typically think of a hierarchical organizational chart.

477
01:01:57,000 --> 01:01:59,000
So you have the boss at the top.

478
01:01:59,000 --> 01:02:05,000
You maybe have sort of senior managers and below them you maybe have middle managers

479
01:02:05,000 --> 01:02:08,000
and then you have maybe workers at the very bottom.

480
01:02:08,000 --> 01:02:11,000
But essentially you have a sort of top-down decision-making structure.

481
01:02:11,000 --> 01:02:16,000
So it's hierarchical in the sense that decisions are made at the top

482
01:02:17,000 --> 01:02:22,000
and then those decisions are fed down through the hierarchy to people at the bottom

483
01:02:22,000 --> 01:02:24,000
who just have to implement those decisions.

484
01:02:24,000 --> 01:02:29,000
They don't have any autonomy, any say in anything, no decision-making power.

485
01:02:29,000 --> 01:02:31,000
They just implement those decisions.

486
01:02:31,000 --> 01:02:38,000
So that's a structural hierarchy and that's obviously the kind of thing that anarchists are,

487
01:02:38,000 --> 01:02:43,000
as a kind of starting point for anarchism, very much opposed to.

488
01:02:44,000 --> 01:02:47,000
Functional hierarchy is something quite different.

489
01:02:47,000 --> 01:02:57,000
So functional hierarchy is instead saying that there is a kind of logical ordering of decision-making

490
01:02:57,000 --> 01:03:04,000
whereby some decisions come logically prior to other decisions.

491
01:03:04,000 --> 01:03:10,000
So one way of thinking about this is in terms of kind of strategy and tactics distinction.

492
01:03:10,000 --> 01:03:17,000
As I mentioned looking at the VSM, you have this higher function metasystemic part of the system

493
01:03:17,000 --> 01:03:23,000
which is where things like grand strategy and strategy are developed.

494
01:03:23,000 --> 01:03:29,000
In terms of thinking about this as a kind of effective organization,

495
01:03:29,000 --> 01:03:35,000
those are decisions that come before the operational or tactical decisions.

496
01:03:35,000 --> 01:03:41,000
So in order for us to know what tactics are going to be best to us,

497
01:03:41,000 --> 01:03:49,000
in order for us to know how we can best operate in the kind of day-to-day of an organization,

498
01:03:49,000 --> 01:03:52,000
we need to have a strategy first.

499
01:03:52,000 --> 01:03:57,000
So we develop a strategy that tells us these are our goals, these are our aims,

500
01:03:57,000 --> 01:04:01,000
these are the values and principles that we have, these are our priorities.

501
01:04:01,000 --> 01:04:04,000
This is what we need to maximize and minimize.

502
01:04:04,000 --> 01:04:13,000
And that helps us decide on what kind of tactics, what kind of day-to-day actions we can take.

503
01:04:13,000 --> 01:04:17,000
So in a sense, there's a sort of hierarchical ordering there.

504
01:04:17,000 --> 01:04:21,000
Strategy comes above tactics.

505
01:04:21,000 --> 01:04:29,000
And obviously in typical organizations, that functional hierarchy and the structural hierarchy are meshed together.

506
01:04:29,000 --> 01:04:34,000
So you have the strategic decisions are taken by the bosses, by the managers,

507
01:04:34,000 --> 01:04:40,000
and the tactical stuff, the actions, the day-to-day actions are things that workers are doing.

508
01:04:40,000 --> 01:04:46,000
And they just take the orders and do the actions as they're told to do.

509
01:04:46,000 --> 01:04:53,000
What I think anarchist cybernetics opens up, I think this is something that's in cybernetics anyway,

510
01:04:53,000 --> 01:05:01,000
but I think an anarchist focus in cybernetics helps us reinforce this and helps us see how important this is.

511
01:05:01,000 --> 01:05:07,000
I think we can have the functional hierarchy so we can have the logical ordering of decision-making

512
01:05:07,000 --> 01:05:13,000
where one decision has to be made in order for us to be able to make the other decision.

513
01:05:13,000 --> 01:05:16,000
So one decision is higher than the other.

514
01:05:16,000 --> 01:05:21,000
We can have that logical ordering, can have that hierarchy of decision-making

515
01:05:21,000 --> 01:05:25,000
without the structural hierarchy.

516
01:05:25,000 --> 01:05:28,000
So as I said, looking at the VSM and that example of the CAFE,

517
01:05:28,000 --> 01:05:33,000
the people who are doing the day-to-day activities, the people who are doing the tactical action,

518
01:05:33,000 --> 01:05:38,000
which is functionally lower than the strategic decision-making,

519
01:05:38,000 --> 01:05:43,000
they are the same people who are doing the strategic decision-making.

520
01:05:43,000 --> 01:05:49,000
There's not a manager who's making those strategy decisions, there's not a boss who's making those decisions.

521
01:05:49,000 --> 01:05:54,000
It's the same people who are doing the serving, the making the drinks, the cooking,

522
01:05:54,000 --> 01:06:02,000
they at a certain point stop doing that and they go into a meeting or they go into a discussion,

523
01:06:02,000 --> 01:06:07,000
they go into some kind of forum where they're doing the strategy stuff.

524
01:06:07,000 --> 01:06:12,000
So it's very much saying we can have the functional ordering of decision-making

525
01:06:12,000 --> 01:06:16,000
where some decisions have to come first and then we can make other ones,

526
01:06:17,000 --> 01:06:24,000
but everybody in the organization can be involved at all levels of that functional hierarchy.

527
01:06:24,000 --> 01:06:32,000
So it doesn't require a structural hierarchy where certain decisions can only be made

528
01:06:32,000 --> 01:06:36,000
by people higher up in the organization.

529
01:06:36,000 --> 01:06:45,000
And I want to add maybe for the audience that is on the critical side of things when it comes to cybernetics,

530
01:06:45,000 --> 01:06:54,000
I want to add that since we do already have cybernetics very much within our world today

531
01:06:54,000 --> 01:07:01,000
acting as actually maybe even already at least in some parts hegemonic principle,

532
01:07:01,000 --> 01:07:05,000
I would like to add that if you take a look at capitalist cybernetics

533
01:07:05,000 --> 01:07:11,000
and the way in which huge companies like Google, Facebook, Amazon, whatever,

534
01:07:11,000 --> 01:07:17,000
apply cybernetic thinking that they do exactly what you just mentioned.

535
01:07:17,000 --> 01:07:21,000
They collapse functional hierarchy and structural hierarchy

536
01:07:21,000 --> 01:07:26,000
and they try to make use of elements of functional hierarchy

537
01:07:26,000 --> 01:07:31,000
where lower elements within the organization might have some limited autonomy

538
01:07:31,000 --> 01:07:37,000
in order to become more effective, but they do still keep the structural hierarchy

539
01:07:37,000 --> 01:07:41,000
in which at the end you do have the bosses, you do have the managers,

540
01:07:41,000 --> 01:07:44,000
you do have the people who will tell you what to do,

541
01:07:44,000 --> 01:07:48,000
and this is very much structured along strong hierarchy.

542
01:07:48,000 --> 01:07:54,000
So this is something I actually want to point out at this point, I would say.

543
01:07:54,000 --> 01:08:03,000
And again, I think this also shows how this lens is actually very fruitful as an analytic lens

544
01:08:03,000 --> 01:08:05,000
because it makes you see the difference.

545
01:08:05,000 --> 01:08:09,000
So this is something I really like when reading your book.

546
01:08:09,000 --> 01:08:15,000
And still, when it comes to anarchist cybernetics,

547
01:08:15,000 --> 01:08:22,000
we do have to point out that, as I said, it's not about having unrestricted autonomy

548
01:08:22,000 --> 01:08:26,000
since you do have these elements of grand strategy,

549
01:08:26,000 --> 01:08:32,000
you do have these elements everybody will have to be on board with, so to speak,

550
01:08:32,000 --> 01:08:40,000
and because of that, you automatically have some boundaries in terms of your own individual autonomy

551
01:08:40,000 --> 01:08:49,000
because it actually is a logical result of having decisions being made collectively beforehand

552
01:08:49,000 --> 01:08:58,000
and yourself having to kind of align with this overarching identity and principles of the organization, so to speak.

553
01:08:58,000 --> 01:09:01,000
So maybe let's talk about this relation.

554
01:09:01,000 --> 01:09:07,000
Let's talk about this question of autonomy that is implicit within this relation

555
01:09:07,000 --> 01:09:13,000
because both in anarchism and cybernetics, autonomy plays a very crucial role.

556
01:09:13,000 --> 01:09:20,000
However, again, we find very different understandings of what autonomy means in the respective fields.

557
01:09:20,000 --> 01:09:24,000
Stafford B identifies three constraints on autonomy,

558
01:09:24,000 --> 01:09:27,000
and this is specifically interesting when it comes to anarchist cybernetics

559
01:09:27,000 --> 01:09:32,000
because some of these constraints seem to, at least at first sight,

560
01:09:32,000 --> 01:09:37,000
go against the grain of some of the core principles of anarchist organization.

561
01:09:37,000 --> 01:09:40,000
Again, we have to say.

562
01:09:40,000 --> 01:09:48,000
But I think you do a good job in the book in pointing out why these constraints are actually not only necessary,

563
01:09:48,000 --> 01:09:51,000
but also compatible with an anarchist approach.

564
01:09:51,000 --> 01:09:54,000
And these constraints are, and I will read them out.

565
01:09:54,000 --> 01:09:57,000
This is a quote by Stafford Beer.

566
01:09:57,000 --> 01:10:04,000
The first of the constraints would be autonomous parts must operate in coordination with other autonomous parts.

567
01:10:04,000 --> 01:10:11,000
The second one is autonomous parts must operate within the intentions of the whole organization.

568
01:10:11,000 --> 01:10:13,000
And this would be the third one.

569
01:10:13,000 --> 01:10:19,000
Autonomous parts must face the possibility of being excluded from the organization as a whole.

570
01:10:19,000 --> 01:10:22,000
So these are the three constraints.

571
01:10:22,000 --> 01:10:27,000
What is the understanding of autonomy in anarchist cybernetics?

572
01:10:27,000 --> 01:10:37,000
Yes, I think as you sort of suggested, it first does seem like it clashes with how we may understand autonomy or freedom.

573
01:10:37,000 --> 01:10:40,000
I think I'm collapsing these terms, autonomy and freedom.

574
01:10:40,000 --> 01:10:46,000
There's a discussion about whether there's a distinction between them, but I'm kind of collapsing them a bit.

575
01:10:46,000 --> 01:10:59,000
There is a definite question here about does the understanding of autonomy that's in cybernetics fundamentally clash with how we understand it in anarchism?

576
01:10:59,000 --> 01:11:09,000
So I think going through those three principles that you just read out, I think for the first two, there's not necessarily a problem there.

577
01:11:09,000 --> 01:11:15,000
So, you know, saying that the autonomous parts have to be in coordination with other autonomous parts.

578
01:11:15,000 --> 01:11:25,000
You know, that's just that sort of fundamental thing of saying, okay, my autonomy shouldn't constrain your autonomy and your autonomy shouldn't constrain my autonomy.

579
01:11:25,000 --> 01:11:41,000
So, okay, we can be autonomous, but we have to sort of coordinate that autonomy so that, you know, like me trying to be free or be autonomous doesn't prevent you from being free or being autonomous.

580
01:11:41,000 --> 01:11:45,000
We have to just make sure there's some kind of coordination there.

581
01:11:45,000 --> 01:12:01,000
And that might mean certain limits on what we can do as individuals, but ultimately it's there so that, you know, there's a sort of maximum amount of autonomy that means that everyone can still enjoy it.

582
01:12:01,000 --> 01:12:08,000
The second part I think also doesn't necessarily immediately suggest a clash with anarchism.

583
01:12:08,000 --> 01:12:17,000
So thinking about, well, the autonomous parts of an organization need to operate within the intentions of the whole organization.

584
01:12:17,000 --> 01:12:24,000
So that's something kind of, you know, fairly accepted within a lot of anarchist organizations.

585
01:12:24,000 --> 01:12:33,000
Yes, different parts of a federation or different branches of an organization will have some autonomy.

586
01:12:33,000 --> 01:12:42,000
They'll have some sort of freedom to make their own decisions in their own environments and their own environmental niches.

587
01:12:42,000 --> 01:12:45,000
But they're still part of the organization as a whole.

588
01:12:45,000 --> 01:12:57,000
And there's going to be some decisions which are kind of higher level of and a certain functionally higher level of decision making, where they might not have complete autonomy.

589
01:12:57,000 --> 01:13:00,000
So because they're still part of the whole organization.

590
01:13:00,000 --> 01:13:11,000
So, for example, if this is an anarchist trade union, for example, there's going to be different branches of that trade union, which have autonomy to do maybe organize on different priorities.

591
01:13:11,000 --> 01:13:23,000
They pick their own campaigns, divide up, you know, workloads in their own autonomous ways, raise money themselves, manage their finances themselves in autonomous ways.

592
01:13:23,000 --> 01:13:30,000
But there's going to be some kind of key organizational principles that they don't have autonomy over.

593
01:13:30,000 --> 01:13:35,000
So, for example, I'm thinking of the industrial workers of the world here.

594
01:13:35,000 --> 01:14:01,000
You know, part of their sort of fundamental, you know, the fundamental starting point for this for their politics is that people who are bosses or people who have any power over any direct power over hiring and firing workers can't be a member of the union, because then they're on the boss side rather than on the worker side.

595
01:14:01,000 --> 01:14:14,000
So if a particular branch of the IWW said, you know, we'd we'd quite like to invite this boss and because he seems like a nice person, got seems like they've got good politics, talks good, we're friends with them.

596
01:14:14,000 --> 01:14:16,000
We want to them to be a member.

597
01:14:16,000 --> 01:14:19,000
That's not going to be possible within that organization.

598
01:14:19,000 --> 01:14:26,000
So their autonomy is restricted there by virtue of the fact that they're part of this larger organization.

599
01:14:26,000 --> 01:14:32,000
So I think that's not necessarily an issue for or doesn't present itself as an issue for anarchists.

600
01:14:32,000 --> 01:14:39,000
I think the third principle that you mentioned is perhaps where we might imagine there's a more fundamental clash.

601
01:14:39,000 --> 01:14:47,000
So the idea that there's a kind of ultimate restriction on autonomy, which is being excluded from the organization.

602
01:14:47,000 --> 01:15:06,000
So there's a point when for whatever reason, a certain part of the organization or a certain individual might be excluded, might be kicked out of the organization, whatever kind of organization as a federation, collective, whatever.

603
01:15:06,000 --> 01:15:15,000
And that's something I think some anarchists may at first find issue with because they'd say, well, no, we don't want to be excluding people.

604
01:15:15,000 --> 01:15:23,000
We don't want to be, you know, doing that horrible thing of saying to someone, yeah, you're no longer part of the group.

605
01:15:23,000 --> 01:15:26,000
We don't want you in this organization.

606
01:15:26,000 --> 01:15:31,000
We're going to evict you or expel you or whatever.

607
01:15:31,000 --> 01:15:39,000
But actually this is something which happens, maybe not regularly, but it is a tool within the kind of anarchist toolbox.

608
01:15:39,000 --> 01:15:51,000
So particularly if we think about things like when certain individuals have been accused of committing sexual assault, for example,

609
01:15:51,000 --> 01:16:02,000
and maybe haven't been part of the sort of the kind of transformative justice process within a collective is saying, we'll have some kind of accountability process.

610
01:16:02,000 --> 01:16:07,000
We'll have some kind of process of mediation and where hopefully we can still all live together.

611
01:16:07,000 --> 01:16:16,000
You know, the person who committed the assault can hopefully learn what they did wrong and, you know, grow as a person and won't do that again.

612
01:16:16,000 --> 01:16:26,000
The person who is who is the victim accepts that that process is fair and thinks, yeah, OK, we can we can still exist as a collective.

613
01:16:26,000 --> 01:16:29,000
But then there might be a problem, a point where that breaks down.

614
01:16:29,000 --> 01:16:40,000
And actually, it's impossible for, you know, the person who committed the sexual assault to actually remain part of that collective or part of that community.

615
01:16:40,000 --> 01:16:46,000
It's no longer considered safe for the other people, for them to be part of that community.

616
01:16:46,000 --> 01:16:55,000
And that's that's the kind of worst case scenario, perhaps in terms of thinking about anarchists and radical approaches to justice.

617
01:16:55,000 --> 01:16:57,000
But it is something that happens.

618
01:16:57,000 --> 01:17:09,000
And when that happens, you know, expelling a person from the organization and evicting them from from the community is a kind of tool that people have in that circumstance.

619
01:17:09,000 --> 01:17:19,000
So it is something that it's something we don't don't like to acknowledge as being, hey, here's the things we can do.

620
01:17:19,000 --> 01:17:23,000
We can do this, this and this. And one of them is we can expel you if you do these things.

621
01:17:23,000 --> 01:17:36,000
But it is there. It is there as a kind of if if if this goes as horribly as we can possibly imagine and we can no longer have this person in the organization, in the community, in the collective,

622
01:17:36,000 --> 01:17:47,000
then expelling them is is an option. And for most anarchist groups, that will be part of how they how they can resolve these kind of conflicts.

623
01:17:47,000 --> 01:17:50,000
As I said, worst case, but it is still there.

624
01:17:50,000 --> 01:18:08,000
So I think that that potential for expulsion is is something we maybe don't want to be doing, but it's something we recognize as anarchists that there may still be a necessity for that at certain times.

625
01:18:08,000 --> 01:18:16,000
And I think it does raise a lot of issues of, well, where does that person go? Right. Does that person just is that person just out in the wilderness now?

626
01:18:16,000 --> 01:18:33,000
Are they how how are they going to learn from this? How are they going to change? Does it really does it really change the underlying structural situations around things like like sexual assault and violence?

627
01:18:33,000 --> 01:18:47,000
How does it help us transform as a community? It raises a lot of questions, but it is still still an important part of trying to deal with conflict and deal with justice and more more anarchistic ways.

628
01:18:47,000 --> 01:19:05,000
And maybe because this might lead to forms of misunderstanding as well, because when you talked about part one within these constraints about autonomous parts must operate in coordination with other autonomous parts,

629
01:19:05,000 --> 01:19:15,000
and you framed it in a way that points out that you have your freedoms, I have my freedoms, and as long as they don't infringe on each other, it's all fine.

630
01:19:15,000 --> 01:19:28,000
But the part within the book about autonomy very much highlights how individual freedom is a product of collective freedom and not vice versa.

631
01:19:28,000 --> 01:19:38,000
And and I think this is just something that I would like to add, because it might otherwise lead to misunderstandings.

632
01:19:38,000 --> 01:19:48,000
When people hear you talk about these individuals and not infringing on the freedom of others, because this is, of course, one of the ways that it is being conceptualized.

633
01:19:49,000 --> 01:20:04,000
For example, in liberalism, you have these nomads, these individual nomads that are enacting in contractual relations with each other and very much thought of through a lens of methodological individualism.

634
01:20:04,000 --> 01:20:08,000
And that's not the way that you approach it, I would say.

635
01:20:08,000 --> 01:20:11,000
Yeah, definitely. I think that that's really important.

636
01:20:11,000 --> 01:20:22,000
So when we do look at something like those sort of restrictions on individual autonomy, it's not coming from that methodological individualist starting point.

637
01:20:22,000 --> 01:20:31,000
It's very much saying any kind of individual freedom is a product of the collective existing, of being part of a community.

638
01:20:31,000 --> 01:20:38,000
So it's not that you have these autonomous individuals who come into an organization and then have to coordinate.

639
01:20:38,000 --> 01:20:46,000
It's that the organization or the community produces the kind of autonomy and the freedom that these individuals have.

640
01:20:46,000 --> 01:20:59,000
But part of that process of producing that freedom is a coordination so that the sort of freedoms and autonomies are kind of balanced and work together and don't conflict with one another.

641
01:20:59,000 --> 01:21:03,000
And I think that's something we see in anarchism going way back.

642
01:21:03,000 --> 01:21:23,000
That recognition of individuality and individual freedom are a product of community and a product of collective organization rather than the kind of liberal starting point, which is we're individuals and we can maybe for our mutual benefit cooperate.

643
01:21:23,000 --> 01:21:26,000
It's much more cooperation comes first.

644
01:21:26,000 --> 01:21:41,000
And this is also, I think, very much important because it points towards the importance of how this collective element comes about.

645
01:21:41,000 --> 01:22:04,000
Because if it comes about in a participatory way, then the likelihood of the individuals that are engaging with this collective of agreeing with the limitations on their own autonomy is, of course, much higher than if not.

646
01:22:04,000 --> 01:22:11,000
And I think this very much relates to this question of grand strategy or within the VSM.

647
01:22:11,000 --> 01:22:23,000
It's called system five and how these overarching goals, this grand strategy actually comes about, how it is being developed.

648
01:22:23,000 --> 01:22:52,000
Because this is the crucial point where anarchist cybernetics is very much different from, as I already pointed out, for example, capitalist cybernetics, because this level of grand strategy, this level five within the VSM, is very much part of a participatory process as well and needs to come about through such a process.

649
01:22:52,000 --> 01:23:12,000
And I think immediately some questions pop up as well, because if you think of it in a larger context, if you think of anarchist cybernetics as something that might eventually inform society wide organization, then the question of scale comes into mind immediately.

650
01:23:12,000 --> 01:23:41,000
Because if you want the level five elements, the grand strategy elements to come about in a participatory way through consensus decisions, for example, then you will have a problem if you have a large quantity of people and you will have to find ways to address this in a way that still leads to this legitimization through process that is actually a constitutive element of anarchist cybernetics.

651
01:23:41,000 --> 01:23:50,000
So how would this level five function, this grand strategy come about within anarchist cybernetics also on a scale?

652
01:23:50,000 --> 01:24:13,000
Yeah, so I think one of the best examples I think of, well, I think the starting point is thinking, well, what is this system five? So what is grand strategy? So the way I understand it and the way it's stood in cybernetics is thinking about the identity or the ethos of a particular organization or particular community.

653
01:24:13,000 --> 01:24:31,000
So what are the kind of core principles? What are the, what is the sort of paradigm or worldview of a particular community? What is the core elements of how that community views itself and understands itself as a community with a certain identity?

654
01:24:31,000 --> 01:24:41,000
And that's because that embodies things like, you know, values and principles, thinking about, you know, that sort of functional hierarchy of decision making.

655
01:24:41,000 --> 01:25:04,000
You know, that sort of, that system five level of, or grand strategic level of values and principles, identity, that then determines what kind of practical strategies are going to be developed in an organization, which then in turn determines what kind of tactics are going to be appropriate within the organization.

656
01:25:04,000 --> 01:25:17,000
So there's a strong link between the day to day activities and how they are considered to be appropriate for the organization and the kind of identity and the ethos and the values and principles that that organization has.

657
01:25:17,000 --> 01:25:27,000
So how that actually comes about in anarchist cybernetics is really, really, really important question.

658
01:25:28,000 --> 01:25:40,000
There are elements of it which are, which make up an almost a kind of common sense within a particular, you know, political milieu or political tradition.

659
01:25:40,000 --> 01:25:52,000
So some of it's going to be things that maybe isn't ever, ever even explicitly discussed or isn't even ever, you know, the subject of an actual concrete decision that people make.

660
01:25:52,000 --> 01:26:04,000
It might be that the people involved come into an organization or come into a setting or decide to form a kind of community or just want to think about who are we as a group.

661
01:26:04,000 --> 01:26:08,000
We already exist as a group, but let's think about who we are as a group.

662
01:26:08,000 --> 01:26:15,000
There might be things that are just so taken for granted that they never have to be a decision made about them.

663
01:26:15,000 --> 01:26:19,000
They're just a common sense almost.

664
01:26:19,000 --> 01:26:39,000
So, for example, you know, thinking about, again, going back to the example of the Industrial Workers of the World Trade Union, you know, part of the sort of common sense, the sort of taking for granted common sense of that organization is the particular political view of economic exploitation, right?

665
01:26:39,000 --> 01:26:53,000
There are, you know, wealthy capitalists who own the means for production, and there are the working class who have to sell their labor in order to survive.

666
01:26:53,000 --> 01:27:05,000
I think if you go to a IWW meeting, even a big sort of strategic meeting today, they're not going to be saying, okay, do we still agree with this? Do we still do it? Do we need to reaffirm our agreement to this principle?

667
01:27:05,000 --> 01:27:09,000
That's just the kind of common sense for that whole politics.

668
01:27:09,000 --> 01:27:13,000
So that's part of their identity, part of their worldview.

669
01:27:13,000 --> 01:27:17,000
But there's going to be elements of it that do need to be discussed at some point.

670
01:27:17,000 --> 01:27:24,000
And I think one of the fruitful ways of thinking about that is through things like constitutions.

671
01:27:24,000 --> 01:27:27,000
So you said about how groups constitute themselves.

672
01:27:27,000 --> 01:27:33,000
And part of that is thinking about, well, what values do we all agree on?

673
01:27:33,000 --> 01:27:45,000
What kind of identity do we all share as people in this organization or different organizations within a kind of federation of some kind?

674
01:27:45,000 --> 01:27:48,000
So that process can be quite explicit in those terms.

675
01:27:48,000 --> 01:28:05,000
And if we look back at something like Occupy Wall Street, they had participatory, collective, democratic processes of writing and agreeing on a declaration.

676
01:28:05,000 --> 01:28:20,000
So it's kind of trying to mirror the idea of the US Declaration of Independence, which was obviously written by a few white men, a lot of them slave owners, all kind of wealthy landowners.

677
01:28:20,000 --> 01:28:29,000
What Occupy did was say, okay, we need to create a declaration for ourselves as a community, but we're going to do that in a democratic way.

678
01:28:29,000 --> 01:28:35,000
We're going to do that in a participatory way, and it's going to be based on everyone taking part in that process.

679
01:28:35,000 --> 01:28:44,000
So that's a much more explicit way of doing that kind of system five grand strategy of saying we can define who we are as a community.

680
01:28:44,000 --> 01:28:52,000
We can define what our core principles are, what our values are, and we can write that in a document.

681
01:28:52,000 --> 01:28:56,000
So they produced the kind of declaration of Occupy Wall Street.

682
01:28:56,000 --> 01:29:02,000
So that was their sort of founding document.

683
01:29:02,000 --> 01:29:04,000
So I think there's ways that you can do that in organizations.

684
01:29:04,000 --> 01:29:11,000
I know in sort of smaller organizations like workers cooperatives, there's going to be some kind of constitution.

685
01:29:11,000 --> 01:29:25,000
There's going to be some kind of founding statement or statement or principles, which at some point in the organization, you might either need to write from scratch or you might need to, if it already exists,

686
01:29:25,000 --> 01:29:29,000
you know, go back to it and change things as time goes on.

687
01:29:29,000 --> 01:29:32,000
So those documents aren't necessarily fixed forever.

688
01:29:32,000 --> 01:29:40,000
They can maybe change in some ways, although some elements might be less changeable than others.

689
01:29:40,000 --> 01:29:42,000
But I think how you then scale that up.

690
01:29:42,000 --> 01:29:46,000
So it worked well for, you can imagine it working in a small workers cooperative.

691
01:29:46,000 --> 01:29:51,000
If there's like 10 people, you say, well, we can get together for a day and we can just work this out.

692
01:29:51,000 --> 01:29:52,000
Okay, great.

693
01:29:52,000 --> 01:29:53,000
Occupy Wall Street.

694
01:29:53,000 --> 01:29:56,000
Okay, a few thousand people took part in that.

695
01:29:56,000 --> 01:29:58,000
Still relatively small groups.

696
01:29:58,000 --> 01:30:06,000
And they developed really, really good ways of making sure everyone could take part, making sure everyone could feed ideas in, but still relatively small group.

697
01:30:06,000 --> 01:30:17,000
How do we do that at the scale of something like the size of a city or even a country?

698
01:30:17,000 --> 01:30:29,000
Well, then we need to think about some of the really, really interesting examples around the world of more participatory processes for writing a national constitution.

699
01:30:29,000 --> 01:30:45,000
So none of these are anarchists in any way, but I think they do have a lot of really important lessons for anarchism in the sense that they start to show us how a community at that scale.

700
01:30:45,000 --> 01:31:00,000
So, you know, hundreds of thousands, maybe millions of people can do this kind of system five grand strategy and how they can do that in a way that's more participatory than it traditionally has been done.

701
01:31:00,000 --> 01:31:14,000
So traditionally, a document like a national constitution is maybe written by a small number of constitutional legal experts and maybe some involvement from politicians.

702
01:31:14,000 --> 01:31:21,000
Maybe there's some kind of consultation that feeds into it so that the people in the country have some kind of say in it.

703
01:31:21,000 --> 01:31:28,000
Maybe it goes to, you know, vote afterwards for people have to approve this new constitution.

704
01:31:28,000 --> 01:31:40,000
But with a lot of cases around the world, there's a lot of examples of people trying to say, how can we open this process up and make it much more participatory?

705
01:31:40,000 --> 01:31:49,000
Involve much more people, not just in throwing ideas in and then approving the document, but actually taking part in writing it.

706
01:31:49,000 --> 01:31:56,000
And I think one of the examples I've studied, there's lots of others, but one of the examples I've studied is Iceland.

707
01:31:56,000 --> 01:32:01,000
So they went through a process which hasn't been successful yet.

708
01:32:01,000 --> 01:32:04,000
But it was a really interesting process nonetheless.

709
01:32:04,000 --> 01:32:12,000
After the 2008 financial crash, they decided to try and rewrite the national constitution.

710
01:32:12,000 --> 01:32:15,000
But the way they did that, they wanted it to be more participatory.

711
01:32:15,000 --> 01:32:27,000
They thought, well, we want everyone in the country to have more of a direct say in how this document looks, because this document is ultimately saying, this is who we are as a community.

712
01:32:27,000 --> 01:32:33,000
And this is what we believe in. And these are our fundamental principles and values.

713
01:32:33,000 --> 01:32:36,000
So they tried to find ways of making it more participatory.

714
01:32:36,000 --> 01:32:47,000
It still wasn't, you know, participatory in the way that anarchists would like, but it does start to point us in the direction of, you know, this is something we can do now.

715
01:32:47,000 --> 01:32:50,000
And we've got the tools to do this now.

716
01:32:51,000 --> 01:32:57,000
We can use a lot of the kind of digital tools that have been developed recently, a lot of the communication technologies.

717
01:32:57,000 --> 01:33:05,000
These make it much easier for lots of different people in a large area to take part in the discussion.

718
01:33:05,000 --> 01:33:11,000
And it doesn't need to be, you know, everyone in one big, you know, general assembly.

719
01:33:11,000 --> 01:33:17,000
We're not talking about having a Zoom call with like three million people trying to trying to agree on something.

720
01:33:17,000 --> 01:33:22,000
You can sort of decentralize this and split this up into small working groups.

721
01:33:22,000 --> 01:33:28,000
So it might be different parts of the community in different geographical areas have their discussions.

722
01:33:28,000 --> 01:33:36,000
And then they have delegates that feed those discussions into some kind of slightly more centralized council or committee.

723
01:33:36,000 --> 01:33:39,000
There may be different special interests groups.

724
01:33:39,000 --> 01:33:54,000
You might have, you know, like Occupy Wall Street did, you had People of Color Caucus so that people of color in Occupy Wall Street had some kind of representation in the decision making structures.

725
01:33:54,000 --> 01:34:04,000
So you can have, there's different ways of sort of organizing that kind of mass participation that's still democratic, that's still participatory.

726
01:34:04,000 --> 01:34:11,000
But that doesn't mean we're just saying let's get everyone together and try and discuss and agree on something.

727
01:34:11,000 --> 01:34:16,000
So it's a more and more effective way of doing it that kind of breaks it up in little ways.

728
01:34:16,000 --> 01:34:21,000
And also a process that makes sure that it's not always the same people that engage in it.

729
01:34:21,000 --> 01:34:28,000
Because, I mean, that's a bit of a problem with the participatory approach is that at least as societies are organized right now,

730
01:34:28,000 --> 01:34:41,000
if you simply say let's do it in a participatory fashion, then you will have some people that have actually the luxury to have free time in order to participate and others do not and stuff like that.

731
01:34:41,000 --> 01:34:44,000
So this needs to be addressed as well, of course.

732
01:34:44,000 --> 01:34:59,000
But OK, so I mean, what I can hear here is that you're leaning towards some form of anarchist constitutionalism in order to address this question of system five and grand strategy, actually.

733
01:34:59,000 --> 01:35:06,000
We kind of talked a lot about organization up until now within this conversation.

734
01:35:06,000 --> 01:35:14,000
But your book actually has a second part, which is not about organization, but about communication.

735
01:35:14,000 --> 01:35:22,000
And some might remember Norbert Wiener's book title, Cybernetics, Control and Communication in the Animal and the Machine.

736
01:35:22,000 --> 01:35:27,000
And you equally highlight both of these elements, control and communication.

737
01:35:27,000 --> 01:35:30,000
So maybe let's turn towards the communication part.

738
01:35:30,000 --> 01:35:33,000
What is it that communication does?

739
01:35:33,000 --> 01:35:38,000
What role does it play in anarchist cybernetics?

740
01:35:38,000 --> 01:35:50,000
So I think really fundamentally for cybernetics in general, thinking about self-organization is at the same time thinking about communication.

741
01:35:50,000 --> 01:36:02,000
So thinking about how information is gathered and processed and shared and distributed within a system is incredibly central to that.

742
01:36:02,000 --> 01:36:12,000
So one of the sort of primary mechanisms within a self-organized system is feedback loops.

743
01:36:12,000 --> 01:36:19,000
So, you know, what was talking about when I talked about the kind of steam engine governor or the thermostat, that's a kind of feedback loop.

744
01:36:19,000 --> 01:36:21,000
And it operates through information.

745
01:36:21,000 --> 01:36:39,000
So, you know, the thermostat, as the temperature in the room increases, there's the sort of temperature sensor in the thermostat that sends information to a different part of the thermostat, which turns the air conditioning on, for example.

746
01:36:39,000 --> 01:36:53,000
So that communication in that sense of information being taken in from the environment and shared in the system and then an action being the outcome of that information is really fundamental to cybernetics.

747
01:36:53,000 --> 01:37:13,000
And some of the more sort of technical and I think sort of, yeah, looking at cybernetics in terms of electronic systems and mechanical systems, a lot of the focus was on how do we make these communication pathways and channels more efficient?

748
01:37:13,000 --> 01:37:24,000
So how do we minimize noise in these systems? How do we ensure that information is, you know, intact when it gets to the point of the system where it needs to be?

749
01:37:24,000 --> 01:37:32,000
So how does it get from, you know, the sort of sensor that's measuring something in the environment?

750
01:37:32,000 --> 01:37:38,000
How does that information then get to the part of the system where the action needs to happen?

751
01:37:38,000 --> 01:37:53,000
So that's really important for a lot that's a more technical side of cybernetics, but I think it's also incredibly important in thinking about how self-organization operates in social systems.

752
01:37:53,000 --> 01:38:02,000
Because everything I've kind of talked about so far in terms of organization, this is all requires interaction between parts of a system.

753
01:38:02,000 --> 01:38:07,000
And that interaction is communication.

754
01:38:07,000 --> 01:38:11,000
Sometimes it will be people literally talking to one another.

755
01:38:11,000 --> 01:38:19,000
Sometimes it will be, you know, monitoring of different parts of the environment or what's happening within the organization.

756
01:38:19,000 --> 01:38:24,000
Sometimes it might be, you know, just a kind of physical interaction.

757
01:38:24,000 --> 01:38:31,000
I mean, one of the examples I often think of is working behind a bar.

758
01:38:31,000 --> 01:38:40,000
So I don't know if you've ever worked in a bar, but, you know, when you first start working with people and it's busy, you're constantly bumping into each other.

759
01:38:40,000 --> 01:38:44,000
You have this sort of physical and eventually you sort of learn to move around each other.

760
01:38:44,000 --> 01:38:50,000
You sort of have this, yeah, you kind of self-organize as a kind of system behind the bar.

761
01:38:50,000 --> 01:39:02,000
But, you know, that sort of physical bumping in, that's the kind of communication as well, because that's sending a information signal of, right, I need to move this way instead, or we need to go a different direction kind of thing.

762
01:39:02,000 --> 01:39:23,000
So all of this kind of coordination, all this self-organization is about, you know, communicating and making sure information moves through the system in, you know, effective ways that allow people to know what's happening and make decisions as a result of what's happening.

763
01:39:23,000 --> 01:39:39,000
So also in terms of strategy, you know, strategy can't happen effectively if we don't have, you know, information that's being communicated from the day-to-day activities and from the environment itself.

764
01:39:39,000 --> 01:39:45,000
You know, strategy can't happen within a kind of bubble where there's no information coming into it, right?

765
01:39:45,000 --> 01:39:53,000
It has to have information and that means you have to have some kind of communication, you know, effective communication systems within an organization.

766
01:39:53,000 --> 01:40:05,000
So in, you know, small collectives and the kind of small workers cooperative, that might be very, very simple where the communication is just we talk to each other, you know, we tell each other what's happening.

767
01:40:05,000 --> 01:40:12,000
We have a meeting every week where we go around and everyone says, okay, this is what happened this week and this went wrong.

768
01:40:12,000 --> 01:40:17,000
And so the information is shared within the system, quite simply.

769
01:40:17,000 --> 01:40:31,000
But if we think about sort of larger systems, we need to think about, okay, how do we create specific communication channels so that the right information is going to the right places?

770
01:40:32,000 --> 01:40:36,000
So the right information is collected, but also presented in the most effective ways.

771
01:40:36,000 --> 01:40:46,000
And also, you know, an important part for cybernetics is how do we sort of manage the amount of information?

772
01:40:46,000 --> 01:40:50,000
So we don't want to be flooded with too much. We need to kind of filter some stuff out.

773
01:40:50,000 --> 01:40:59,000
We need to dampen down some of that massive variety of information so that we can actually use it in effective and practical ways.

774
01:40:59,000 --> 01:41:08,000
But developing communication systems so that information can be taken and travel around the organization to the places it's needed.

775
01:41:08,000 --> 01:41:12,000
People can make decisions based on the right information.

776
01:41:12,000 --> 01:41:15,000
That's incredibly important. And that's all communication.

777
01:41:15,000 --> 01:41:20,000
Some of it's talking, some of it will be different, different forms of communicating information.

778
01:41:21,000 --> 01:41:31,000
And I think related to that, and this is also I think important in order to highlight that cybernetics itself also is not innocent.

779
01:41:31,000 --> 01:41:36,000
It kind of formats things in specific ways.

780
01:41:36,000 --> 01:41:47,000
It makes you look at processes in specific ways and thereby having certain imperatives inscribed in it as well.

781
01:41:47,000 --> 01:41:51,000
And some of them might be desirable, others maybe not.

782
01:41:51,000 --> 01:42:06,000
So maybe just to highlight this as well, that a process of reflection upon this processes of formatting within cybernetics would be useful as well.

783
01:42:06,000 --> 01:42:17,000
And one of the things or one of the ways that you do reflect upon this is when it comes to the specific way that information is thought about within cybernetics,

784
01:42:17,000 --> 01:42:27,000
because very much at the beginning of cybernetics, there is information theory developed by Claude Shannon,

785
01:42:27,000 --> 01:42:33,000
which does a formatting when it comes to information.

786
01:42:33,000 --> 01:42:44,000
And it's a specific type of formatting that has a specific idea of what is noise and what is not and what should be eliminated because it is termed noise.

787
01:42:44,000 --> 01:42:54,000
So it kind of introduces an idea of what is to be used and what is to be left aside and to be eliminated.

788
01:42:54,000 --> 01:43:06,000
And you take this example of noise in order to point out that actually, no, the way in which cybernetics looks at this question of noise is actually problematic

789
01:43:06,000 --> 01:43:14,000
because it eliminates aspects of the existing world, so to speak, or the surroundings that we live in.

790
01:43:14,000 --> 01:43:28,000
It eliminates aspects of these surroundings that are actually very much useful and fruitful and should be taken into account when it comes to the way that we approach, in this case, anarchist cybernetics.

791
01:43:28,000 --> 01:43:43,000
And for this, you look at different ways that noise can be framed and you develop an idea of a form of noise that actually should be part of the way that we approach anarchist cybernetics.

792
01:43:43,000 --> 01:43:51,000
And this is called pink noise. So could you maybe elaborate on what we have to imagine if we think about pink noise?

793
01:43:51,000 --> 01:44:00,000
Yes, this is actually based on some work that some people who are involved in the Indignados movement in Spain developed.

794
01:44:00,000 --> 01:44:10,000
So this was looking at the social media activity that was related to that movement.

795
01:44:10,000 --> 01:44:22,000
And what they were able to do was suggest in very broad terms that there's essentially three different types of noise in these social media communication systems.

796
01:44:22,000 --> 01:44:30,000
So if you imagine in terms of what I've just said about communication and information, social media is one of the ways that we share information.

797
01:44:30,000 --> 01:44:42,000
But if we were to go on Facebook or Twitter, it's impossible for us to see and grasp everything that everybody is sharing.

798
01:44:42,000 --> 01:44:46,000
There's just far too much, far too high quantity of information there.

799
01:44:46,000 --> 01:44:54,000
Even just if we've got Facebook with our close friends, there's still a huge amount that people could be sharing there.

800
01:44:54,000 --> 01:45:00,000
And it's very difficult for us to actually see and process all of that in a kind of effective way.

801
01:45:00,000 --> 01:45:10,000
And so what these data scientists and activists were able to do was look at the sort of, and I think it was just focused on Twitter,

802
01:45:10,000 --> 01:45:23,000
that kind of social media information ecosystem in a sense, and see well there's different outcomes from the information being shared.

803
01:45:23,000 --> 01:45:31,000
And that very much depends on the way that noise is handled within these systems.

804
01:45:31,000 --> 01:45:38,000
So let's say there's the sort of two extremes here. There's the kind of white noise, which is just incredibly chaotic.

805
01:45:38,000 --> 01:45:44,000
So there's no real, so the person looking at information isn't really able to see any kind of pattern at all.

806
01:45:44,000 --> 01:45:48,000
It just looks like random sort of snapshots of information.

807
01:45:49,000 --> 01:45:56,000
If you imagine this as different tweets, maybe you're not really able to see, okay, I can't really see an actual thread emerging here.

808
01:45:56,000 --> 01:45:59,000
I can't see an actual narrative emerging from this.

809
01:45:59,000 --> 01:46:08,000
It looks like it's just thousands of people spewing out lots of different opinions and thoughts and experiences and everything.

810
01:46:08,000 --> 01:46:16,000
And I can't, I don't have an overall picture of this is what's actually happening within this kind of social movement.

811
01:46:17,000 --> 01:46:24,000
And they say, well, that kind of very chaotic white noise, that doesn't really allow you to organize in any kind of effective way.

812
01:46:24,000 --> 01:46:34,000
The kind of organization that goes along with that is going to be very sporadic, very, very spontaneous, very chaotic, not coordinated in any kind of way.

813
01:46:34,000 --> 01:46:37,000
So it's not really any kind of actual self-organization.

814
01:46:37,000 --> 01:46:43,000
It's just lots of people responding and reacting and running about chaotically.

815
01:46:43,000 --> 01:46:54,000
At the other extreme of that, they say, well, you can have a communication system where things are highly regulated and highly organized.

816
01:46:54,000 --> 01:47:12,000
So you maybe have some kind of, whether it's actually a sort of central control agency that's deciding to filter the information in a very, very specific way so that you only see a very, very narrow subset of the information.

817
01:47:12,000 --> 01:47:31,000
That might be, I don't know, if the communication ecosystem was controlled by a political party or something, they might say, well, we've got our goals as a political party and we're only going to give you information that we think is going to be beneficial to that.

818
01:47:31,000 --> 01:47:49,000
So that creates a form of organization, but creates an incredibly rigid form of organization where if everyone's only seeing one narrative from the information, then that only gives them the resources to act in a very, very narrow range of ways.

819
01:47:49,000 --> 01:47:59,000
So they can only really act in very specific ways, which for something like a political party is quite useful because they kind of want people to be doing very specific actions.

820
01:47:59,000 --> 01:48:03,000
They don't want people to be doing their own thing in different ways.

821
01:48:03,000 --> 01:48:08,000
They want people to be very, very, very coordinated, highly coordinated and controlled.

822
01:48:08,000 --> 01:48:16,000
If you imagine a political party during an election cycle, they want people to be putting out the same message because that's what happened.

823
01:48:16,000 --> 01:48:18,000
The party needs to be happening at that moment.

824
01:48:18,000 --> 01:48:24,000
They need everyone to be on message, everyone to be responsible in very specific ways.

825
01:48:25,000 --> 01:48:37,000
But then from a cybernetics perspective, that kind of very rigid organization, everything we've kind of discussed so far today, that's not a very effective mode of organization.

826
01:48:37,000 --> 01:48:46,000
It might be able to hold together for a very short period of time, but ultimately it's too rigid to be able to respond to any kind of change effectively.

827
01:48:46,000 --> 01:49:01,000
So ultimately it's going to either maintain itself through very direct control of the people involved or it's going to break down because it can't respond to a changing environment.

828
01:49:01,000 --> 01:49:15,000
And so a very sort of narrow control of information, these people sort of suggest, produces or is more beneficial to that very, very rigid form of organization.

829
01:49:15,000 --> 01:49:22,000
So you have these two extremes, the white noise, which is very chaotic, very sporadic, no sort of coherent narrative.

830
01:49:22,000 --> 01:49:31,000
And if people have that information, that's going to lead to very spontaneous, very chaotic action, not coordinated action.

831
01:49:31,000 --> 01:49:37,000
On the other extreme, you have very, very controlled, very rigid narrative in terms of information.

832
01:49:37,000 --> 01:49:45,000
And that's the kind of brown noise. So very kind of solid, coherent noise.

833
01:49:45,000 --> 01:49:59,000
But it's one narrative, it's one sort of channel of control in a sense, and that either produces or reinforces or is beneficial for very rigid, very top down, very controlled forms of organization.

834
01:49:59,000 --> 01:50:03,000
In between these, you have something called pink noise.

835
01:50:03,000 --> 01:50:06,000
And that's where you have a sort of balance between these two.

836
01:50:06,000 --> 01:50:12,000
It's not dominated by one specific narratives, the information isn't filtered.

837
01:50:12,000 --> 01:50:20,000
So there's only one narrative coming through, but it's not as chaotic as the white noise.

838
01:50:20,000 --> 01:50:28,000
So what you have in the information is you might have a series of narratives that are a bit more autonomous and a bit more self generating.

839
01:50:28,000 --> 01:50:31,000
But there is a sort of coherent set of narratives.

840
01:50:31,000 --> 01:50:37,000
So you as a person looking at this information can see, OK, I can see what's happening here.

841
01:50:37,000 --> 01:50:42,000
It's not so chaotic that I don't have any idea, but I'm also not only getting one narrative.

842
01:50:42,000 --> 01:50:48,000
I'm seeing different things and I'm able to, through seeing these different things, understand what's happening.

843
01:50:48,000 --> 01:50:52,000
I can actually use this information effectively.

844
01:50:52,000 --> 01:50:58,000
And so these people who are involved in the Indignados process are able that kind of noise in a system.

845
01:50:58,000 --> 01:51:03,000
We have some kind of coordination, but it's not super rigid.

846
01:51:03,000 --> 01:51:11,000
That produces or reinforces the kind of self organization that we've been talking about today.

847
01:51:11,000 --> 01:51:18,000
Because people are able to see from the information, OK, I can see that this is useful, this narrative is useful.

848
01:51:18,000 --> 01:51:20,000
We can use that or that's relevant to us.

849
01:51:20,000 --> 01:51:24,000
We can draw on that and that allows us to organize.

850
01:51:24,000 --> 01:51:31,000
And I think that's really important because it's very, very speculative and it's very vague.

851
01:51:31,000 --> 01:51:41,000
It's not, you know, prescribing a specific way that information channels can be organized or that systems should be designed.

852
01:51:41,000 --> 01:51:42,000
It's very, very vague.

853
01:51:42,000 --> 01:51:51,000
But it is saying there is a relationship between how information is organized and filtered

854
01:51:51,000 --> 01:52:00,000
and how that information can be practically used or developed on or built on.

855
01:52:00,000 --> 01:52:06,000
So if we have information that's in the form of a kind of pink noise, where there's some sort of differentiation,

856
01:52:06,000 --> 01:52:19,000
some variety, some sort of diversity in the information, but we can still pick out coherent narratives or coherent stories coming through from the information.

857
01:52:19,000 --> 01:52:21,000
Then we can act on it in constructive ways.

858
01:52:21,000 --> 01:52:27,000
We have the resources from that information to be able to self organize.

859
01:52:27,000 --> 01:52:37,000
While you're talking, I'm kind of trying to figure out whether or not people might actually be able to understand what you're talking about,

860
01:52:37,000 --> 01:52:46,000
because if I'm not mistaken, the way in which you use the term information is already a very specific one.

861
01:52:46,000 --> 01:52:53,000
You have a high degree of information if the signal is actually not that clear,

862
01:52:53,000 --> 01:53:02,000
if there's a lot going on beyond the actual content of the signal, so to speak.

863
01:53:02,000 --> 01:53:04,000
So that's high information.

864
01:53:04,000 --> 01:53:14,000
And this is something that you now, based on these researchers, try to inspect a bit more closely

865
01:53:14,000 --> 01:53:21,000
and try to take a look at whether or not there might be something useful in it and actually stating yes, there might be.

866
01:53:21,000 --> 01:53:30,000
If it's not too chaotic or too stable, but presents itself in a way that is already again maybe formatted

867
01:53:30,000 --> 01:53:35,000
or presents itself in a way that strikes a balance between the two,

868
01:53:35,000 --> 01:53:42,000
then it should be incorporated into the organization of the structure,

869
01:53:42,000 --> 01:53:48,000
additional to what would be termed in the classical information theory, the signal.

870
01:53:48,000 --> 01:53:53,000
So I think this is something we need to kind of point out towards the audience,

871
01:53:53,000 --> 01:54:00,000
because it already operates on the level where this idea of information theory and what is signal and what is noise

872
01:54:00,000 --> 01:54:05,000
and what should be rejected and whatnot is taken for granted.

873
01:54:05,000 --> 01:54:08,000
And I believe that most of the people are not familiar with that.

874
01:54:08,000 --> 01:54:13,000
But maybe you could correct me if I'm wrong. Did I get that right?

875
01:54:13,000 --> 01:54:16,000
Yeah, it's incredibly, incredibly difficult, I think.

876
01:54:16,000 --> 01:54:21,000
And it's something I'm not 100% convinced I've got my head around,

877
01:54:21,000 --> 01:54:29,000
because when we think of information, we think about the content that's communicated.

878
01:54:29,000 --> 01:54:34,000
So if I give you information, I'm telling you something and there's a certain content there.

879
01:54:34,000 --> 01:54:40,000
And in some of this early information theory, that wasn't what they were talking about.

880
01:54:40,000 --> 01:54:45,000
And that makes it really, really difficult to work out when some of these authors

881
01:54:45,000 --> 01:54:50,000
and people like Stafford Beer, who were to some degree building on their work,

882
01:54:50,000 --> 01:54:57,000
are talking about information, it's difficult to often say, OK, what exactly are they talking about here?

883
01:54:57,000 --> 01:55:05,000
I think the sort of most useful way of thinking about it is thinking about what this means in practice for us

884
01:55:05,000 --> 01:55:07,000
and what noise means in practice.

885
01:55:07,000 --> 01:55:15,000
So as you said, noise in a communication system is normally the thing that we want to eliminate.

886
01:55:15,000 --> 01:55:22,000
So if you imagine that it doesn't happen now, but in the past, when you turn the TV on,

887
01:55:22,000 --> 01:55:30,000
there might be a certain amount of static, that sort of fuzzy, white, staticky noise and the image that went with it.

888
01:55:31,000 --> 01:55:38,000
And you would try and, going back quite a while, you would try and adjust your TV aerial

889
01:55:38,000 --> 01:55:44,000
so that the picture comes through and you don't have that static, fuzzy noise.

890
01:55:44,000 --> 01:55:50,000
So you're trying to eliminate the noise. You're trying to say, well, we want the signal and we don't want the noise.

891
01:55:50,000 --> 01:55:54,000
And obviously that's great for TV, right? Because we need that.

892
01:55:54,000 --> 01:55:59,000
Because we wanted to see the signal, we wanted to watch the TV program at that moment.

893
01:55:59,000 --> 01:56:04,000
Or on radio, it still works in exactly the same way.

894
01:56:04,000 --> 01:56:11,000
But I think what a more critical look at noise and information allows us to do is say,

895
01:56:11,000 --> 01:56:15,000
there's always a kind of built-in logic to doing that.

896
01:56:15,000 --> 01:56:21,000
So it's fine if we're trying to find a particular TV station or a particular radio station.

897
01:56:22,000 --> 01:56:25,000
And we want that specific and we know what it is we want.

898
01:56:25,000 --> 01:56:31,000
We can filter out the noise, we can adjust the dial or the aerial, and we'll get the signal that we know we want.

899
01:56:31,000 --> 01:56:35,000
But often in terms of communication information, that's not the case.

900
01:56:35,000 --> 01:56:38,000
We don't know what it is we're looking for. We're trying to learn something new.

901
01:56:38,000 --> 01:56:41,000
Someone trying to tell us something that we don't know what it is already.

902
01:56:41,000 --> 01:56:48,000
So when it's actually people sharing information, we need to be much more careful about what we're eliminating.

903
01:56:48,000 --> 01:56:56,000
So if we're thinking about social media, OK, the noise doesn't look like, you know, white, fuzzy, static.

904
01:56:56,000 --> 01:57:02,000
The noise instead looks like, well, I've got a timeline of tweets that I'm scrolling through

905
01:57:02,000 --> 01:57:08,000
and I can't work out what's important, what I need to focus on, what I need to put my attention on,

906
01:57:08,000 --> 01:57:16,000
and what is just kind of, you know, useless advertising or stuff that doesn't interest me.

907
01:57:16,000 --> 01:57:21,000
And it's very difficult to tell. So when we're scrolling through, it's very difficult for us to work out.

908
01:57:21,000 --> 01:57:28,000
This is something I need to be looking at, and this is something that has no relevance to me,

909
01:57:28,000 --> 01:57:34,000
isn't relevant to what I'm interested in or what I'm wanting to do in the world.

910
01:57:34,000 --> 01:57:41,000
I think one thing we have to be careful with noise in is thinking about, OK, are we filtering out things

911
01:57:41,000 --> 01:57:46,000
that just don't make sense to us, but which could actually be really important for us?

912
01:57:46,000 --> 01:57:51,000
You know, so we have to kind of be aware of, like, you know, we don't want to end up in the echo chamber

913
01:57:51,000 --> 01:57:57,000
where we're filtering out things that, oh, well, I don't really agree with that, but I'll filter it out.

914
01:57:57,000 --> 01:58:02,000
And then I'm actually missing a huge part of the picture of what's happening in the world.

915
01:58:02,000 --> 01:58:08,000
But the other really big danger is that how things like Facebook and Twitter

916
01:58:08,000 --> 01:58:17,000
and other similar platforms operate is they are already filtering out a lot of what they think of as noise.

917
01:58:17,000 --> 01:58:24,000
And that's incredibly political. It's like anyone who scrolls through their Facebook feed now will see,

918
01:58:24,000 --> 01:58:29,000
OK, there's a lot of adverts, right? There's much more than there was 10 years ago.

919
01:58:30,000 --> 01:58:40,000
Now it's like every two or three items on a news feed is a sponsored advert for something.

920
01:58:40,000 --> 01:58:43,000
And we haven't always decided that we want to see that, right?

921
01:58:43,000 --> 01:58:50,000
The algorithm that Facebook has and the fact that there are companies who pay money for that advertising,

922
01:58:50,000 --> 01:58:55,000
that's what decides what filters through the noise, right?

923
01:58:55,000 --> 01:59:03,000
So things that we might find really important are filtered out by these corporations, essentially,

924
01:59:03,000 --> 01:59:10,000
in order for us to see what they think is important, what they want us to see, the advertising, for example.

925
01:59:10,000 --> 01:59:15,000
And a lot of political content is being filtered out in this way.

926
01:59:15,000 --> 01:59:22,000
So a lot of stuff that is very relevant to the political and economic situation we find ourselves in

927
01:59:22,000 --> 01:59:30,000
and to learning about that and to trying to change that is being filtered out by these systems in favor of

928
01:59:30,000 --> 01:59:36,000
sponsored adverts, spam, celebrity gossip, things like this.

929
01:59:36,000 --> 01:59:43,000
So thinking about that sort of information and noise stuff, I think the technical side is really interesting

930
01:59:43,000 --> 01:59:49,000
because it's fun to try and get our heads around how people were using these terms and what they were meaning

931
01:59:49,000 --> 01:59:53,000
and why that was important for what came afterwards.

932
01:59:53,000 --> 01:59:57,000
But really, the interesting thing is, well, what does this mean in practice?

933
01:59:57,000 --> 02:00:04,000
And if we're talking about how do we filter noise in a communication system,

934
02:00:04,000 --> 02:00:11,000
given that for us, the main communication system now is social media still.

935
02:00:11,000 --> 02:00:18,000
The fact that there's corporations like Facebook and Twitter and then all the companies that are paying to advertise,

936
02:00:18,000 --> 02:00:23,000
that sort of corporate process is what's doing the filtering.

937
02:00:23,000 --> 02:00:27,000
It's not something we have any control over at all.

938
02:00:27,000 --> 02:00:32,000
So we might need to have some filtering, so it might just be too much.

939
02:00:32,000 --> 02:00:37,000
We can only look at a certain amount of stuff and actually process it mentally.

940
02:00:37,000 --> 02:00:41,000
So we need to do some kind of filtering. That's fine.

941
02:00:41,000 --> 02:00:43,000
But it needs to be something we have control over.

942
02:00:43,000 --> 02:00:48,000
So there needs to be some kind of, and again, this is incredibly speculative,

943
02:00:48,000 --> 02:00:53,000
there needs to be some kind of way that the algorithms that are doing the filtering

944
02:00:53,000 --> 02:00:58,000
are somehow subject to some kind of democratic control.

945
02:00:58,000 --> 02:01:03,000
So that even though we know what we're getting is filtered,

946
02:01:03,000 --> 02:01:07,000
the noise that's filtered out is something we've at least agreed to.

947
02:01:08,000 --> 02:01:14,000
We've at least said, yeah, I've had some democratic say in how the algorithm operates.

948
02:01:14,000 --> 02:01:16,000
I know why it works.

949
02:01:16,000 --> 02:01:22,000
It works in a way that we think is politically and ethically beneficial.

950
02:01:22,000 --> 02:01:25,000
So the filtering is fine.

951
02:01:25,000 --> 02:01:31,000
It's like an email spam folder, which actually filters out the spam.

952
02:01:31,000 --> 02:01:33,000
That's fantastic, right?

953
02:01:33,000 --> 02:01:36,000
Because it allows us to only see the emails that are important.

954
02:01:36,000 --> 02:01:40,000
So we need to have something like that, I think, for these kinds of social media platforms.

955
02:01:40,000 --> 02:01:42,000
Absolutely, we do.

956
02:01:42,000 --> 02:01:49,000
So the decision over what is seen as noise and what is not is absolutely political.

957
02:01:49,000 --> 02:01:51,000
I would definitely agree.

958
02:01:51,000 --> 02:01:56,000
And maybe this would lead us into a different terrain.

959
02:01:56,000 --> 02:02:02,000
Maybe I would add that even before that,

960
02:02:02,000 --> 02:02:09,000
one would have to think about the things that are not information and not communication

961
02:02:09,000 --> 02:02:15,000
and provide ways in which they can be included in the processes

962
02:02:15,000 --> 02:02:18,000
that we use as organizational processes as well.

963
02:02:18,000 --> 02:02:24,000
Because if you only consider communication and information,

964
02:02:24,000 --> 02:02:28,000
this is already a form of filtering as well, I would say.

965
02:02:28,000 --> 02:02:33,000
But this is a different topic, I would say.

966
02:02:33,000 --> 02:02:39,000
In order to enable the kinds of communication anarchist cybernetics relies on,

967
02:02:39,000 --> 02:02:44,000
you stress the need, and this was implicit in your answer right now already,

968
02:02:44,000 --> 02:02:48,000
you stress the need for alternative social media platforms.

969
02:02:48,000 --> 02:02:50,000
So maybe you could give us a sketch.

970
02:02:50,000 --> 02:02:56,000
What could they look like and what are the functional elements that they should provide?

971
02:02:56,000 --> 02:03:04,000
So I think the question of what kind of communication systems are functionally useful

972
02:03:04,000 --> 02:03:07,000
for the kind of self-organization we've been talking about,

973
02:03:07,000 --> 02:03:13,000
it's both really, really important but also incredibly difficult to start to do, I think.

974
02:03:13,000 --> 02:03:17,000
So when I started looking at this topic,

975
02:03:17,000 --> 02:03:22,000
and this was in 2011 around the Occupy movement and things,

976
02:03:22,000 --> 02:03:28,000
and at that point still, there was a lot of hope in social media.

977
02:03:28,000 --> 02:03:32,000
So still at that point, there was a lot of criticism of it,

978
02:03:32,000 --> 02:03:36,000
but it was still a sort of idea that things like Facebook and Twitter

979
02:03:36,000 --> 02:03:40,000
can be productive for a kind of radical politics.

980
02:03:40,000 --> 02:03:43,000
I don't think anyone believes that now, I think.

981
02:03:43,000 --> 02:03:48,000
Now we're really in the sort of dystopian nightmare scenario

982
02:03:48,000 --> 02:03:56,000
of how these platforms have developed and the ways they produce mental health crises

983
02:03:56,000 --> 02:04:12,000
and conflict and political outcomes is much bleaker now than it was 10 years ago,

984
02:04:12,000 --> 02:04:16,000
although I think a lot of that was probably even on the horizon then.

985
02:04:16,000 --> 02:04:25,000
So I think it's quite difficult to imagine what kind of platforms would be better than them,

986
02:04:25,000 --> 02:04:30,000
what kind of platforms would work that would fulfill some of the same functions

987
02:04:30,000 --> 02:04:37,000
but do so in a way that is much more conducive to a kind of radical anarchist politics

988
02:04:37,000 --> 02:04:43,000
and the kind of self-organization that's involved in anarchist cybernetics.

989
02:04:43,000 --> 02:04:50,000
I think I also have to preface these kind of discussions with saying that I'm not a platform developer,

990
02:04:50,000 --> 02:04:55,000
I'm not an app designer, I don't know anything about computer coding or design or anything like that.

991
02:04:55,000 --> 02:05:04,000
So it's my sort of perspective on it is very much for the kind of political and organizational functions

992
02:05:04,000 --> 02:05:10,000
that these kind of communication systems would need to have.

993
02:05:11,000 --> 02:05:14,000
I think there's a lot of different ones in terms of thinking about,

994
02:05:14,000 --> 02:05:22,000
well, what does self-organization look like in practice for anarchist collectives and social movements

995
02:05:22,000 --> 02:05:31,000
and also at a larger scale of things like participatory and democratic constitution making.

996
02:05:31,000 --> 02:05:33,000
What do those things look like?

997
02:05:33,000 --> 02:05:39,000
And then how could a platform help facilitate some of that?

998
02:05:39,000 --> 02:05:44,000
Because I think that's something that comes through in Stafford Beer's work a lot.

999
02:05:44,000 --> 02:05:50,000
So when he was writing as far back as the 1950s when computers were still in their infancy,

1000
02:05:50,000 --> 02:06:00,000
but even then he was clear in saying, well, the way computing is developing is it's not developing

1001
02:06:00,000 --> 02:06:09,000
in the direction whereby it's going to be helping us do the sort of basic functions of a human society.

1002
02:06:09,000 --> 02:06:21,000
It's helping us make work more efficient maybe or helping us produce more and do more in terms of our working lives.

1003
02:06:21,000 --> 02:06:28,000
But it's not necessarily actually helping us communicate as a society or share ideas or share knowledge or things like that.

1004
02:06:28,000 --> 02:06:37,000
So I think that's the important thing is what sort of perspective or starting point are we coming from with thinking about technology?

1005
02:06:37,000 --> 02:06:42,000
And it has to be how does it help us do things like self-organization?

1006
02:06:44,000 --> 02:06:50,000
That said, it's still incredibly difficult to work out exactly what that would look like.

1007
02:06:51,000 --> 02:07:01,000
And I think the reason for that is there's quite a strong disconnect between platforms that have been developed,

1008
02:07:01,000 --> 02:07:11,000
that are very, very successful at the sort of more practical or functional side of self-organization.

1009
02:07:11,000 --> 02:07:19,000
So we have things like Lumio, for example, which is developed by Workers' Cooperative.

1010
02:07:19,000 --> 02:07:31,000
It's designed specifically to help cooperatives and sort of movements and communities that are organized in cooperative and democratic ways to help them function.

1011
02:07:31,000 --> 02:07:35,000
And it does that very well in terms of the sort of technical and functional aspects.

1012
02:07:35,000 --> 02:07:38,000
It's a fantastic platform.

1013
02:07:38,000 --> 02:07:46,000
But what it doesn't have is the kind of social aspect that something like Facebook or Twitter still has.

1014
02:07:46,000 --> 02:07:59,000
So there's a reason that a lot of the alternative social media platforms are things that have branded themselves as alternative social media platforms

1015
02:07:59,000 --> 02:08:06,000
that have been focused on activists in some way or focused on activist organizing.

1016
02:08:06,000 --> 02:08:15,000
I think there's a reason that not many of them have actually been successful because they haven't effectively mirrored this sort of social dynamic.

1017
02:08:15,000 --> 02:08:25,000
So one of the things that I think is incredibly important and also one of the sort of dangers of something like Facebook or Twitter.

1018
02:08:25,000 --> 02:08:33,000
I feel like I'm already very sort of old school with this, talking just about Facebook and Twitter,

1019
02:08:33,000 --> 02:08:39,000
because I know there's like a host of new platforms like Twitch and stuff that people use in TikTok.

1020
02:08:39,000 --> 02:08:43,000
That's just sort of outside of my sort of wheelhouse.

1021
02:08:43,000 --> 02:08:49,000
I think I'm feeling very old when I talk about social media now even, which didn't feel that way 10 years ago.

1022
02:08:49,000 --> 02:08:56,000
But yeah, if we look at these sorts of platforms, the reason they're successful is people socialize on them.

1023
02:08:56,000 --> 02:09:01,000
People spend time with their friends on them. People make friends on these platforms.

1024
02:09:01,000 --> 02:09:05,000
They're not just communicating in very functional ways.

1025
02:09:06,000 --> 02:09:13,000
Something that we think is incredibly important is people are wasting time on these platforms, which is what you do with friends, right?

1026
02:09:13,000 --> 02:09:19,000
When you get together with your friends, you don't say, right, we're going to organize something here.

1027
02:09:19,000 --> 02:09:24,000
We're going to do some detailed, very efficient organizing.

1028
02:09:24,000 --> 02:09:30,000
You might do that, but most of the time when you get together with your friends, you're having stupid conversations.

1029
02:09:30,000 --> 02:09:36,000
You're telling stupid jokes. You're just not really doing anything, just wasting time together.

1030
02:09:36,000 --> 02:09:41,000
I think that's actually incredibly important for how we build relationships.

1031
02:09:41,000 --> 02:09:47,000
It's like you're getting together to not really do anything, to just sort of be together.

1032
02:09:47,000 --> 02:09:52,000
I think things like Facebook and Twitter work great for that, and they exploit that, right?

1033
02:09:52,000 --> 02:09:59,000
Because you then become addicted to it and you get drawn in and they channel that activity in very specific ways.

1034
02:09:59,000 --> 02:10:04,000
But that's the real challenge, I think, for some kind of alternative platform.

1035
02:10:04,000 --> 02:10:15,000
It can do all the functional stuff for self-organization very, very well, but it's still not the kind of place that people want to actually hang out and spend time.

1036
02:10:15,000 --> 02:10:19,000
Or it's much more difficult to use those platforms in that way.

1037
02:10:19,000 --> 02:10:39,000
I think that's the big challenge is, well, A, how do we sort of mirror some of that to get people away from these sort of mainstream corporate platforms that are channeling information in specific ways and producing behavior in very specific ways?

1038
02:10:39,000 --> 02:10:44,000
How do we get them away from that, but still keep that social aspect?

1039
02:10:44,000 --> 02:10:52,000
Because people aren't going to just give up because I think people who give up on social media are fantastic.

1040
02:10:52,000 --> 02:10:57,000
I think these are brilliant people and they should be lauded for their ability to do that.

1041
02:10:57,000 --> 02:11:06,000
But for most of us, that would mean no longer having contact with a huge number of our friends because I've got friends all around the world.

1042
02:11:06,000 --> 02:11:16,000
And if I wasn't seeing them post memes and jokes on Facebook, I'd probably never have contact with these people anymore.

1043
02:11:16,000 --> 02:11:18,000
I think that'd be really sad.

1044
02:11:18,000 --> 02:11:21,000
So it is like, how do we mirror the social aspect?

1045
02:11:21,000 --> 02:11:35,000
How do we make these platforms things that people want to spend time on, but also that people don't become addicted to, that people are able to say, OK, I can do this online and it's fun and it gets me some great contact.

1046
02:11:35,000 --> 02:11:42,000
I have some great friendships that can build relationships, but I'm still doing stuff outside of that.

1047
02:11:42,000 --> 02:11:46,000
That's not my entire life because that in itself is very, very damaging.

1048
02:11:46,000 --> 02:11:53,000
That's sort of been being solely locked in on a kind of digital platform or that sort of mode of communication.

1049
02:11:53,000 --> 02:12:02,000
So I think that's the real challenge in terms of less about the sort of specifics of the architecture now and more about

1050
02:12:02,000 --> 02:12:14,000
how do we have something that fulfills that social function and that does that in a way that doesn't exploit us or doesn't take advantage of the fact that we need that social content.

1051
02:12:14,000 --> 02:12:23,000
And when it comes to the coordination part of things, I mean, this would be an interesting aspect as well of a potential platform.

1052
02:12:23,000 --> 02:12:31,000
You are right now very much focusing on like a functional equivalent to classical social media, so to speak.

1053
02:12:31,000 --> 02:12:50,000
But I mean, it would be very interesting to provide platforms that are able to facilitate these processes that are actually important for anarchist cybernetics in terms of coordination, in terms of decision making,

1054
02:12:50,000 --> 02:13:07,000
for example, helping with these questions of grant strategy, with coordinating different activities on different levels, all of the stuff that will be an essential part of effective self-organization, so to speak.

1055
02:13:07,000 --> 02:13:20,000
And I think this would be an area where alternative platforms will be of help and need to be of help as well if we consider the question of scalability that we talked about before.

1056
02:13:20,000 --> 02:13:27,000
Yeah, definitely. And I think that's where we have seen the most sort of promise in terms of alternatives.

1057
02:13:27,000 --> 02:13:45,000
I mean, I think that the difficulty is that although a lot of this sort of development work, developing web platforms, it feels very accessible and very democratic because all you need is a computer and you just need the time to do it and to learn some of the coding and things.

1058
02:13:45,000 --> 02:13:55,000
Actually, the platforms that work well and that are effective and successful cost a huge amount of money to develop.

1059
02:13:55,000 --> 02:14:10,000
So even something like Lumio, which is probably the most successful in terms of something that's designed specifically to support cooperative type ways of organizing, it was still relatively small budget compared to a big social media platform,

1060
02:14:11,000 --> 02:14:22,000
but it was still quite a lot of money and time went into it. So there's still that big barrier to, I think, fully experimenting with different platforms.

1061
02:14:22,000 --> 02:14:29,000
So even though it feels like, well, we can just try different things out, there's a lot of barriers to actually doing that.

1062
02:14:30,000 --> 02:14:42,000
But I think that's where there's the most sort of promise, as I said, I think it is, I mean, Lumio is the success story here because it is, the functionality is fantastic.

1063
02:14:42,000 --> 02:14:57,000
It works really, really well. What I think is really important is it integrates with other platforms, which is really important because I think the way I sort of characterize it in the book is a bit too much focusing on,

1064
02:14:57,000 --> 02:15:10,000
can we create one platform that can do everything? And I think that the sort of reality now is, well, can we actually have a handful of platforms that integrate together?

1065
02:15:10,000 --> 02:15:20,000
So you're not having to have, for example, you know, Lumio, which is essentially a kind of forum type sort of format where you have different threads within a forum and different subgroups.

1066
02:15:21,000 --> 02:15:30,000
People can be members of different groups, which is really important. It also allows for decision making. So it has different models of decision making built into it.

1067
02:15:30,000 --> 02:15:40,000
So people can make proposals within a thread and, you know, they can be subject to consensus or majority or whatever.

1068
02:15:40,000 --> 02:15:47,000
But there's different democratic mechanisms within Lumio for actually making decisions as well as just having discussions.

1069
02:15:47,000 --> 02:16:00,000
But, you know, if we were thinking about, well, how can that be the sort of complete package? We would say, well, you know, given so much of the work that we're doing now is online or distance or working from home.

1070
02:16:00,000 --> 02:16:06,000
Does Lumio then need to have a kind of video conferencing functionality built in?

1071
02:16:06,000 --> 02:16:23,000
I think that's where it would get incredibly difficult to develop a single platform that actually has all of that functionality because it would maybe be a very, very, very, you know, server intensive platform, which would cost a lot to run, cost a lot to develop.

1072
02:16:23,000 --> 02:16:37,000
So is it better to think, OK, we can have other platforms like Jitsi, for example, which is, you know, kind of open source video conferencing platform.

1073
02:16:37,000 --> 02:16:46,000
You have things like Framapad, which is a kind of, you know, again, open source version of Google Docs, something like that.

1074
02:16:46,000 --> 02:16:57,000
Can we just integrate these platforms together better so that we're not having to constantly be going, OK, well, we'll use this platform for this and this one for this.

1075
02:16:57,000 --> 02:17:02,000
And then we've got really important information in two different places.

1076
02:17:02,000 --> 02:17:06,000
Can we just have these integrated somehow rather than being the one platform?

1077
02:17:06,000 --> 02:17:17,000
But how do we just create that kind of synchronization so that we can maybe work primarily within Lumio, but then go to a different platform for the video conferencing?

1078
02:17:17,000 --> 02:17:25,000
But we're still accessing it through Lumio somehow without having to completely go out of that ecosystem.

1079
02:17:25,000 --> 02:17:36,000
So I think that's where is the most sort of practical potential is sort of how do we network between different platforms to provide all these functions.

1080
02:17:36,000 --> 02:17:47,000
So things like, you know, having discussions that are, you know, productive and effective and moderated in fair ways, that everyone has a chance to speak,

1081
02:17:47,000 --> 02:18:01,000
but that we can also make effective democratic decisions that everyone feels they've had a genuine chance to take part in, where we can, you know, store documents for agreements that we've made, that we can quickly see, OK, this is who agreed to what.

1082
02:18:01,000 --> 02:18:03,000
These are the agreements that we made as a group.

1083
02:18:03,000 --> 02:18:08,000
We can quickly check back on things where we can where we can.

1084
02:18:08,000 --> 02:18:15,000
One of the core functions of the viable system model is being able to monitor what's happening in the organization.

1085
02:18:15,000 --> 02:18:20,000
How do we build that into, you know, is that already in Lumio?

1086
02:18:20,000 --> 02:18:22,000
Do we have that functionality there?

1087
02:18:22,000 --> 02:18:24,000
Do we need to maybe build on that?

1088
02:18:24,000 --> 02:18:38,000
Do we need to bring something else in that can where we can have that monitoring and be able to easily see it where it's transparent and people don't feel that it's that they're just being monitored by a kind of algorithm or something.

1089
02:18:38,000 --> 02:18:42,000
So I think that's those are the kind of difficult questions at the moment.

1090
02:18:42,000 --> 02:18:47,000
Yeah, and I would definitely agree that it needs to be a combination of different approaches.

1091
02:18:47,000 --> 02:18:53,000
So I think in some situations, there might be already existing alternative like Jitsi.

1092
02:18:53,000 --> 02:18:55,000
I think this is a very good example.

1093
02:18:55,000 --> 02:19:09,000
OK, we do not need to invent another open source video conferencing platform, but it would make sense to integrate it in in the platform that tries to provide it all as a user experience,

1094
02:19:09,000 --> 02:19:21,000
because this I think is pretty much important that it would be very helpful if we had one platform that is able to provide these different services in an open source kind of way.

1095
02:19:21,000 --> 02:19:27,000
Plus X plus additional services that do not yet exist in an open source fashion.

1096
02:19:27,000 --> 02:19:33,000
So I'm not sure if we did this already sufficiently.

1097
02:19:33,000 --> 02:19:34,000
It's difficult to say.

1098
02:19:34,000 --> 02:19:38,000
Actually, we have this example of the movement of the squares.

1099
02:19:38,000 --> 02:19:43,000
You also gave an example when it comes to a cooperatively run cafe.

1100
02:19:43,000 --> 02:19:53,000
But still, I think there is a layer, a level when it comes to anarchist cybernetics that we kind of touched upon, but did not yet spell out in full.

1101
02:19:53,000 --> 02:19:56,000
I mean, this probably will not be possible.

1102
02:19:56,000 --> 02:20:05,000
But still, I would be interested if if we take a look at the level of society as a whole, where could we go from here?

1103
02:20:05,000 --> 02:20:25,000
If we if we consider these insights of cybernetic of anarchist cybernetics and if we try to extrapolate these insights into a future that that is also on a society wide level organized along these principles of anarchist cybernetics.

1104
02:20:25,000 --> 02:20:27,000
So how would that look like?

1105
02:20:27,000 --> 02:20:34,000
And how how would a process that that tries to make use of these insights look like?

1106
02:20:34,000 --> 02:20:46,000
How could this brought into existence in order to get to a point at which to quote Allende, at last, the people are in control?

1107
02:20:46,000 --> 02:20:57,000
So I think one of the most interesting sort of examples along these lines is the mutual aid networks that grew up during during the covid pandemic.

1108
02:20:57,000 --> 02:21:07,000
So obviously these these were, you know, depending on where these happened and who was involved, they were more or less radical in different ways.

1109
02:21:07,000 --> 02:21:16,000
But this was a moment which I think anyone obviously no one anticipated that some people did anticipate the pandemic and they weren't listened to.

1110
02:21:16,000 --> 02:21:19,000
But, you know, nobody really expected it to happen.

1111
02:21:19,000 --> 02:21:30,000
But also, I think no anarchists expected the sort of term mutual aid, which is something that comes from Peter Kropotkin's work, which is a really, really strong part of the anarchist tradition.

1112
02:21:30,000 --> 02:21:42,000
For that word to suddenly have this massive, massive global currency and loads of people using it and thousands upon thousands of groups around the world and using using this term.

1113
02:21:42,000 --> 02:21:47,000
So that was really, really interesting that that sort of happened and nobody expected it.

1114
02:21:47,000 --> 02:22:04,000
But it is the kind of thing, I mean, that, as I sort of said said earlier, you know, when these anarchists like Kropotkin were describing the kind of societies that they wanted to build, they weren't just imagining these.

1115
02:22:04,000 --> 02:22:09,000
They were saying, well, this is how things have worked in the past, or we can see examples of it already happening.

1116
02:22:09,000 --> 02:22:13,000
We should do more of this and mutual aid is one of those examples.

1117
02:22:13,000 --> 02:22:16,000
So, you know, Kropotkin says, well, mutual aid is happening all the time.

1118
02:22:16,000 --> 02:22:27,000
We're constantly helping each other in a kind of mutual way without the need for payment, without the need for sort of any kind of direct compensation.

1119
02:22:27,000 --> 02:22:29,000
We just help each other collectively.

1120
02:22:29,000 --> 02:22:35,000
That's a normal thing that, you know, humans do, other animal species do, plants do.

1121
02:22:35,000 --> 02:22:46,000
So I think how those mutual aid groups developed is really, really important because these were by and large very autonomously organized.

1122
02:22:46,000 --> 02:22:59,000
So there wasn't, I mean, one of the failures of government was that there wasn't any kind of coordination for those first few weeks of lockdowns in a lot of countries, definitely in the UK.

1123
02:22:59,000 --> 02:23:01,000
There wasn't any central coordination.

1124
02:23:01,000 --> 02:23:10,000
It took a long time for government to actually think about how they need to be supporting people during something like, you know, lockdown.

1125
02:23:10,000 --> 02:23:24,000
And so these mutual aid groups emerged, you know, semi-spontaneously a lot of the time with people who already had experience or already had worked together in similar things to try and make sure people's basic needs were provided for.

1126
02:23:24,000 --> 02:23:37,000
So ensure people had food if they weren't able to leave the house, ensure that people had social contact, you know, guaranteeing that people could get medication that they needed if they weren't able to go to the pharmacy.

1127
02:23:37,000 --> 02:23:53,000
So a lot of these kind of, you know, basic functions were being provided by groups of volunteers, you know, people getting together without any central coordination quite autonomously, you know, often making decisions in very democratic ways.

1128
02:23:53,000 --> 02:23:58,000
You know, networking horizontally with other groups nearby.

1129
02:23:58,000 --> 02:24:00,000
So it was really interesting to see how this happened.

1130
02:24:00,000 --> 02:24:16,000
And I think that's the kind of thing that is the most concrete of thinking about what could this, you know, anarchist cybernetic stuff, what could this look like at a kind of larger scale in the most immediate term.

1131
02:24:17,000 --> 02:24:22,000
And I think it's building on those kind of mutual aid networks.

1132
02:24:22,000 --> 02:24:29,000
Now a lot of them ended up, you know, falling apart when they were no longer directly needed.

1133
02:24:29,000 --> 02:24:35,000
A lot of the time governments came in and started to take on coordinating roles.

1134
02:24:35,000 --> 02:24:44,000
A lot of people in the sort of NGOs and charities started to sort of take more leadership type coordinating positions.

1135
02:24:44,000 --> 02:24:49,000
So the mutual aid groups often weren't radical to begin with.

1136
02:24:49,000 --> 02:25:04,000
But it was definitely a sort of process of de-radicalization, moving away from something that could be seen as this is potentially an alternative way we can start organizing society, start looking out for each other collectively.

1137
02:25:04,000 --> 02:25:13,000
Definitely moved away from that. But there's still that sort of germ there of, well, we did that, you know, two years ago at the start of these lockdowns.

1138
02:25:13,000 --> 02:25:22,000
So there clearly is that potential in societies to build these kind of autonomous self-help communities.

1139
02:25:22,000 --> 02:25:29,000
And cybernetics is, I think, really essential to working out how they can be at their most effective.

1140
02:25:30,000 --> 02:25:54,000
So the kind of things I was describing with the viable systems model and John Walker's work in particular for thinking about how something like a cooperative or like an anarchist type collective could use the viable systems model to help them design their own processes and design their ways of organizing and ways of working.

1141
02:25:54,000 --> 02:26:03,000
Mutual aid groups could be doing that kind of thing so that they can actually be more conscious and more aware of this is how we are at our most effective.

1142
02:26:03,000 --> 02:26:14,000
This is how we need to be organizing to be doing what we want to do, to be providing the kind of support that we want to be providing for each other.

1143
02:26:14,000 --> 02:26:20,000
And I think that has the potential to say, OK, we can do it in this, you know, small aspect of our lives.

1144
02:26:20,000 --> 02:26:25,000
Can we just start organizing public services in this way?

1145
02:26:25,000 --> 02:26:33,000
Can we start, you know, we managed during COVID to ensure that everyone had access to medication.

1146
02:26:33,000 --> 02:26:41,000
Well, can we maybe just organize that kind of logistics network for distributing essentials like medication?

1147
02:26:41,000 --> 02:26:46,000
Can we organize that in a democratic and non-hierarchical way?

1148
02:26:46,000 --> 02:26:50,000
You know, we did it during COVID. Maybe we can do that more generally.

1149
02:26:50,000 --> 02:27:00,000
So maybe those mutual aid networks give us the sort of framework to start thinking about this is how we could be reorganizing society in different ways.

1150
02:27:01,000 --> 02:27:04,000
Again, the question is how much of that?

1151
02:27:04,000 --> 02:27:22,000
It remains to be seen what the legacy of those mutual aid networks is going to be, because it's still very fresh and we're still in the very unusual circumstances of coming out of the pandemic or potentially still going into just the next phase of the pandemic.

1152
02:27:23,000 --> 02:27:25,000
But I think that's potentially in the long term.

1153
02:27:25,000 --> 02:27:28,000
What's the legacy of the mutual aid?

1154
02:27:28,000 --> 02:27:37,000
Can that be something we build on to think about how we coordinate the various functions of the lives that we have together?

1155
02:27:37,000 --> 02:27:46,000
And there's a last question that I ask all of my guests, and that is, if you think about the future, what makes you joyful?

1156
02:27:46,000 --> 02:27:55,000
I think that's a fantastic question, and it's one that I'm going to be very, very bleak on and say nothing.

1157
02:27:55,000 --> 02:28:03,000
I think at the moment we're in, it's hard to see much hope.

1158
02:28:03,000 --> 02:28:15,000
So even though I was talking about mutual aid and there's potentially the possibility of expanding that to how we reimagine society and reimagine the way we live and work together.

1159
02:28:15,000 --> 02:28:21,000
Having the hope that that's going to happen is a very different question, I think.

1160
02:28:21,000 --> 02:28:30,000
I mean, just the situation we're in as we're recording this, you know, where the UK is facing 40 degree temperatures for the first time.

1161
02:28:30,000 --> 02:28:37,000
There's, you know, big parts of the world of having up to 50 degree temperatures that have never had that before, really.

1162
02:28:37,000 --> 02:28:51,000
It's just terrifying how bleak the future is and whether there's the potential of stopping that kind of, you know, dramatic and catastrophic climate change,

1163
02:28:51,000 --> 02:29:04,000
or whether we're at the stage now of we need to try and minimize it maybe and somehow come through the other side in some way as effective working societies.

1164
02:29:04,000 --> 02:29:08,000
Whether that'll happen, I'm really not sure and not very hopeful, sadly.

1165
02:29:08,000 --> 02:29:13,000
And also, you know, what we're talking about in terms of the digital platforms and technologies.

1166
02:29:13,000 --> 02:29:20,000
I mean, the temperatures that we're seeing around the world now, you know, electrical circuits start melting, technology stops working.

1167
02:29:20,000 --> 02:29:27,000
So is this slightly a kind of fantasy we're indulging in?

1168
02:29:28,000 --> 02:29:36,000
Yeah, I apologize. That's incredibly bleak note to end on, but it's where I sort of feel at the moment, I think, sadly.

1169
02:29:36,000 --> 02:29:43,000
No need to apologize. Everybody can answer whatever he, she or they might with this question.

1170
02:29:43,000 --> 02:29:47,000
So this is absolutely super interesting to me to hear as well.

1171
02:29:47,000 --> 02:29:55,000
And I have to add, you're not the first one to not being positive about this question.

1172
02:29:55,000 --> 02:29:59,000
So this is absolutely a valid answer as well.

1173
02:29:59,000 --> 02:30:08,000
Yeah, I think, I mean, one thing that is, I think, a sort of change in my lifetime that seems to be just going in the right direction, I think,

1174
02:30:08,000 --> 02:30:20,000
is if I see how much more adept people are now thinking through things like gender and sexuality.

1175
02:30:21,000 --> 02:30:30,000
I mean, that's just incredible. If I think back to the experiences that I saw when I was in school and how, you know,

1176
02:30:30,000 --> 02:30:36,000
homophobic it was and then hearing from friends who are teachers,

1177
02:30:36,000 --> 02:30:41,000
knowing about how young people nowadays are dealing with things like gender and sexuality.

1178
02:30:42,000 --> 02:30:48,000
I mean, that gives me a lot of hope. That's incredibly encouraging to just see those dramatic,

1179
02:30:48,000 --> 02:30:53,000
dramatic advances in such a short space of time.

1180
02:30:53,000 --> 02:30:56,000
So that's one thing to be hopeful about, perhaps.

1181
02:30:56,000 --> 02:31:01,000
Nice. Thomas, thank you so much for being part of Future Histories.

1182
02:31:01,000 --> 02:31:04,000
Yeah, thank you so much for inviting me on. I really, really enjoyed this.

1183
02:31:04,000 --> 02:31:09,000
And thanks for taking the time to read the book and come up with such interesting questions.

1184
02:31:09,000 --> 02:31:11,000
I really, really enjoyed discussing that.

1185
02:31:11,000 --> 02:31:20,000
And I really, really appreciate the time that you've put into going through the book and giving it so much consideration.

1186
02:31:20,000 --> 02:31:24,000
Well, I'm happy to. As I said before, I immensely enjoyed reading the book.

1187
02:31:24,000 --> 02:31:26,000
So thank you, too. Thank you so much.

1188
02:31:32,000 --> 02:31:35,000
That was our show for today. Thanks a lot for listening.

1189
02:31:35,000 --> 02:31:39,000
If you want to support Future Histories, you can do so on Patreon.

1190
02:31:39,000 --> 02:31:43,000
For this, visit patreon.com slash future histories.

1191
02:31:43,000 --> 02:31:50,000
Or you can simply tell a friend that you like the show and that he, she or they might like it as well.

1192
02:31:50,000 --> 02:31:52,000
Thanks a lot and hear you in two weeks.

