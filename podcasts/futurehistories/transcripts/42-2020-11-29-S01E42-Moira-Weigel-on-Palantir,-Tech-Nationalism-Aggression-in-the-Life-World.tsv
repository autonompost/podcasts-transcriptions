start	end	text
0	7000	Welcome to Future Histories. My name is Jan Groos and I am very pleased to welcome Moira Weigel as today's guest.
7000	12000	Moira is an author, researcher and co-founder of Logic magazine.
12000	21000	She currently holds a position as a socio-technical security researcher with the independent research organization Data Society
21000	29000	and will take up a position as an assistant professor of communication studies at Northwestern University in Boston next year.
29000	36000	There are so many interesting works by Moira that we will unfortunately not be able to cover them all today.
36000	42000	Her book, Labor of Love, The Invention of Dating, has been published in 2016.
42000	49000	And her most recent book, which she wrote together with Ben Tarnoff, is called Voices from the Valley.
49000	53000	Tech workers talk about what they do and how they do it.
53000	58000	However, today's interview is going to be about another work from Moira's rich oeuvre.
58000	65000	The essay Palantir goes to Frankfurt School and I'm very excited to talk about it with Moira today.
65000	71000	But before we start, I'd like to thank Fabian, Adrian and Carmen for their donations.
71000	75000	And I would like to welcome Christine as a patron of Future Histories.
75000	77000	Thanks a thousand times.
77000	87000	And now please enjoy today's episode with Moira Weigel about Palantir, tech nationalism and aggression in the life world.
92000	94000	Welcome, Moira.
94000	96000	Thank you so much for having me.
96000	101000	And I should say the book about dating, if anyone's interested, is out in German, actually.
101000	105000	It's called Dating eine Kulturgeschichte in Germany.
105000	108000	But anyway, thank you so much for having me.
108000	114000	Moira, I got hooked as soon as I saw that your essay was about the ideological roots of Palantir.
114000	116000	But not everybody knows this company.
116000	122000	Maybe you could start by describing what Palantir is and what they do.
122000	123000	Yeah, absolutely.
123000	131000	So Palantir is a software company, an enterprise software company that specializes in big data analytics.
131000	141000	And so what that means effectively is that they develop software for large organizations like the US Department of Defense, for example,
141000	152000	but also for banks and large businesses to help them interpret their data, control who accesses data, how, visualize it, and so on.
152000	154000	There are three big parts of the business.
154000	161000	One is called Palantir Gotham, and that mostly works on defense, government contracts, counterterrorism.
161000	168000	One part is called Palantir Metropolis, and they work with hedge funds and banks and businesses.
168000	176000	And one part is called Palantir Foundry, which is used by other corporations like Airbus, for instance.
176000	178000	There's so much more to say about it.
178000	183000	You know, it's founded by Peter Thiel, Alex Karp, Joe Lonsdale, and Stephen Cohen,
183000	192000	this group that comes out of Stanford and was sort of connected through what's sometimes called the PayPal mafia, the company PayPal.
192000	200000	In the early 2000s, it's founded in 2003 and gets its first big funding from Incutel,
200000	206000	which is the counterintelligence agency, CIA's venture capital arm in the United States.
206000	211000	So it's founded in this moment of the beginning of the war on terror in the United States.
211000	216000	But anyway, I'll wait and answer whatever questions you have about it.
216000	222000	But the reason I say all this is I think it's important to understand about them that they're an enterprise software company.
222000	231000	They are not a company like Google or Facebook, whose business model is to gather data about individuals and develop ads and predictions.
231000	238000	They are a company that wins large contracts from large organizations to interpret data partly through humans.
238000	240000	It's not all automatic.
240000	247000	And so I think I say that because I think that difference is very important to their ideology and to the kind of power they represent.
247000	255000	And I think it's it's a difference that has gotten lost in in some of the media coverage of Palantir in the past.
255000	260000	So I'm happy to say more about it. But that's that's my broad overview of what Palantir is.
260000	266000	In your essay, you closely analyze Alex C. Carp's dissertation Aggression in der Lebenswelt.
266000	269000	Alex Carp is the CEO of Palantir.
269000	276000	And I would like to read a small section from the dissertation you also quoted in your essay on Palantir.
276000	284000	So the quote goes, This work began with the observation that many statements have the effect of relieving unconscious drives,
284000	290000	not in spite, but because of the fact that they are blatantly irrational.
290000	293000	That sounds highly relevant for our societies today, I think.
293000	300000	What is Carp's dissertation about and why is it relevant to an understanding of algorithmic governmentality?
300000	303000	It's a really rich question that you ask.
303000	308000	And I just I want to say sort of two quick things before I dive into it.
308000	313000	I think, you know, I study, I'm trained in studying philosophy and the history of ideas.
313000	317000	And we all like to think philosophy and the history of ideas matters a lot.
317000	326000	Right. But I think I just want to say I think this question of how Carp specific philosophy or Peter Thiel specific philosophy
326000	331000	actually comes into play in a company like Palantir is is complexly mediated.
331000	336000	I mean, of course. But I think there's something I worry about in my own work, frankly.
336000	345000	I worry about this as I as I do what I do, where there's such strong myths of genius in Silicon Valley,
345000	352000	this idea that these sort of genius men just come and and, you know, manifest their ideas
352000	355000	and these totally new and futuristic kinds of software.
355000	359000	And I think that's a myth. I think there's it's important to consider the possibility
359000	364000	that Carp was just like Peter's friend who was around when it was time to make this company.
364000	368000	And and it used software and procedures from PayPal.
368000	374000	But it's like there was some stuff that worked at PayPal and there was all this money going into counterterrorism in the U.S. government.
374000	377000	I say all this to to check.
377000	386000	I don't want to overstate the importance of his philosophy, which I think if folks happen to have watched any of the marketing materials
387000	392000	that Palantir puts out around there around there going public, which happened in September 2020,
392000	400000	that is a kind of advertising ploy that they use him for quite a lot, that he's the philosopher, you know, the sort of deep thinker.
400000	406000	And and to put it kindly, I think there are good reasons he didn't go into academia.
406000	414000	But but I think so I did all that to say I think there's this complicated and really fascinating question of like,
415000	417000	how do ideas get translated into technologies?
417000	420000	And it's not a direct not a direct process.
420000	429000	And I think we can think, too, about the technical like how ideas come to shape how actual technologies are deployed.
429000	436000	And we can think, too, about kinds of organizational practices within the firm and what sort of the sociology of the firm
436000	441000	and how that might or might not be influenced by things that the founders believe.
441000	448000	But I think at a very broad level, one thing that was initially interesting to me about the dissertation or grab my attention
448000	454000	is that it seems like almost too close and almost shockingly close analog for what the company does.
454000	465000	Right. The dissertation uses this concept of jargon from Adorno to ask how, you know, again, really oversimplifying.
465000	472000	But Adorno has this reading of Heidegger's language where he says that an existentialist language broadly where Adorno says
472000	482000	these kinds of terms that are that are popular in existentialist language like dwelling and home and being are actually a kind of mystification.
482000	491000	And what is hidden in those terms is are all these realities of modern domination and violence and exploitation.
491000	498000	And so for it to pick just one example for Adorno, when Heidegger talks about dwelling and dwelling and being
498000	508000	and the sort of precarity of being for Adorno says, you know, this is a mystification of the fact, and I'm simplifying,
508000	515000	but it's sometimes useful to simplify Adorno, that in a modern society, you know, all kinds of people are at risk of being homeless
515000	523000	and precarious and losing their homes, losing their jobs, being actually exposed to to second nature, if not nature.
523000	534000	And and Heidegger's language sort of wraps this up in a in a misty sheen and makes it seem like some sort of spiritual transhistorical unchangeable thing.
534000	537000	Right. So Adorno has this analysis of language.
538000	548000	Karp wants to take this concept and say, how can we look at specific language acts and see, take them apart,
548000	555000	see how language works in particular instances to find not realities of social domination,
555000	563000	you know, what Adorno would call objective forms of social domination, but rather unconscious aggression that people can't admit.
563000	570000	The case study that Karp uses for this, which may be more known to a German speaking audience,
570000	577000	is the speech that Martin Weiser gave in 1996 in Frankfurt when he got the prize of the German book trade,
577000	584000	which is this famous or notorious speech where Martin Weiser says, in short, you know,
584000	589000	all of you listeners expect me to get up and apologize for the Holocaust, but I'm not going to.
589000	593000	And this is kind of sanctimonious and insincere.
593000	599000	And I think he calls it the Holocaust pletigo or something that there are these pressures to be sort of preachers of disaster.
599000	601000	And I'm not going to do it.
601000	609000	And this, of course, is a famous episode in the cultural history of Germany in the 1990s and debates about political correctness and historical memory.
609000	621000	But Karp wants to take this language act and ask what kinds of unconscious aggression or violence are expressed in this language act.
621000	629000	We might say it's maybe not that subtle, actually, but Karp does a reading of Weiser where he says,
629000	639000	you know, we can follow the linguistic moves he makes about his speech and see how his language expresses an unconscious aggression,
639000	647000	you know, an anger at being made guilty, collectively guilty, having to remember the Holocaust publicly that he can't say directly.
647000	650000	He says indirectly through these ways.
650000	655000	And one thing that's amazing about it is Karp then steps back and makes no normative assessment of this at all.
655000	657000	He just leaves it. He sort of says, well done.
657000	660000	It was a good, an effective piece of jargon.
660000	665000	But I think so what's quite interesting inside this is a very long answers.
665000	675000	But what's quite interesting is that when I first look at it, at this dissertation, I think this is almost too perfect as like an analogy to what the work of data analytics is.
675000	686000	Right. Like what Palantir does is analyzes these or builds software to analyze and make sense of all this dispersed data that purports to reveal.
687000	699000	Dangers of terrorism or, you know, much more banal things for their corporate clients like, you know, which airplane door is going to have a problem with it coming out of this factory, something like that.
699000	703000	But the majority of their business, at least until recently, has been for government.
704000	718000	So we can say, you know, what the company does is analyze large data sets and actually, in a sense, try to build diagnostic tools that make visible different aspects of relationships within data.
718000	728000	So to the extent that we can think of big data as a kind of unconscious, which I think is its own philosophically complicated question, which we can get into.
728000	737000	But I think that there is a kind of suggestive resonance or analogy between between the dissertation and the work Palantir does.
737000	750000	And if his dissertation basically is saying, you know, all social groups are formed through unconscious violence, looking at jargon lets us see how if we wanted to be reductive, we could say Palantir assumes, you know, the world is
750000	761000	driven by terrorism and kinds of violence. That's a fact. And this company is going to build tools to let the U.S. Department of Defense see how and that's a simplification.
761000	769000	But I do think that there is a striking analogy between that academic work and then what the company actually does.
769000	780000	I think the question that I was asking myself is, is there a fundamental difference in how it is being done in Palantir than how it is being done with Google?
780000	796000	Because they just to pick some other huge company, you know, because in the way that that Alex Karp is trying to present himself in the public sphere, he's always acting as if they are doing these things differently and that the others are, you know, kind of harshly
796000	806000	going over this nuances of how you should actually handle data and what you can actually understand through the analysis of data.
806000	813000	And I mean, in the way he's presenting himself, he's acting as if they are kind of doing it fundamentally different.
813000	829000	But as just as far as I understood it from the information that I got, I kind of got the impression that they are more or less kind of acting in a similar way when it comes to the presumed production of truth.
830000	833000	Yeah, that's a great, a great question.
833000	837000	I think there's both an empirical and a philosophical question.
837000	844000	And your question, I will start with the empirical and see if I can work out to the philosophical.
844000	850000	So I think there actually are very important differences between Google and Palantir.
850000	855000	And I think since a theme of this, this program is hegemony and power.
855000	867000	I'm keen to talk about them because I think it's something that's not very well understood, but it's going to be really important to understandings for techno power going forward.
867000	872000	We can think of the business model, you know, to be very vulgar materialist about it.
872000	874000	Let's think of the business model.
874000	876000	How does Google make money?
876000	884000	Google mostly makes money through search and keywords and through advertising through targeted advertising.
884000	903000	And so what Google does for the most part is that, you know, what they are incentivized to do through their business model is to collect as much information as possible about individual users so that, you know,
903000	912000	They predict very specifically when I search for baby diapers, you know, that this is the kind of baby diaper I want and I will buy it or something.
912000	914000	You know, this is the ad tech model.
914000	917000	There's a whole other question of how good ad tech actually is.
917000	921000	I've just published a book through Logic magazine.
921000	923000	Not that I wrote that Tim Huang wrote.
923000	929000	Someone else wrote called, in fact, I have it right here, but I guess it's a podcast, so no one can actually see me.
929000	945000	Call the subprime attention crisis, which is by someone who used to work at Google and is arguing that actually the value of the attention that companies like Facebook and Google sell has been hugely inflated and is going to crash and cause systemic economic problems like the housing
945000	957000	But so the Google business model is premised on and incentivizes Google's gathering as much information as possible about us as individuals and about other matters.
957000	962000	We think about, you know, Facebook to Facebook is obsessed with what they call time spent.
962000	970000	They're incentivized to keep everyone in their application for as long as possible so they can gather as much data as possible to spin into these ad tech products.
970000	983000	I don't have the figures ready to mine, but like 90 to 100% of their revenue I want to say like 97% of Google's revenue is still ad tech, even though they do all these other things now too.
983000	986000	Palantir is a very different business model.
986000	993000	That's not how Palantir makes money, gathering information about individuals and selling it to other other people.
993000	1011000	Palantir makes money because they go, let's say, to the US military and say to the US military, look, you have at this point, nearly 20 years of, I'm making this up, I don't know if this is a real example, but 20 years of camera footage of all these places in Iraq and Afghanistan that you invaded.
1011000	1014000	You have all this battlefield data.
1014000	1019000	It's a mess. It's not cleaned up. It's not able to be interpreted very easily.
1019000	1034000	And so what we're going to do for, I think their most recent contract with the US military is something like $850 million over 10 years, is we are going to work with you, and we will send engineers like consultants to work with you, to build the best of the best of the best.
1034000	1050000	The US military is something like $850 million over 10 years, is we are going to work with you, and we will send engineers like consultants to work with you, to build software systems for your company that help you make sense of that data.
1050000	1053000	That's what Palantir does. That's how they make their money.
1054000	1069000	There was this debate I saw among many investors about whether they were overvalued because actually their products rely on a lot of human labor, like a lot of what they're selling are these, what they call forward deployed engineers who go to work with a particular company.
1069000	1088000	So, and this is a fundamentally different business model, and it creates different incentives. And it's also why, you know, if listeners have paid some more detailed attention to Palantir, CARP and others around Palantir often make this big deal about how they care about privacy and they care about civil liberties.
1088000	1098000	And again, I think that's something when people who, for good reasons, do not spend as much time thinking about Palantir as I do, say sort of like, what are they talking about?
1098000	1109000	That's real. That's not a lie. They don't. Their business model isn't to know everything about me so that they can sell, you know, a diaper company the chance to sell me diapers.
1109000	1121000	Their business model is to build, so sell to large enterprises, the tools that, or governments, the tools that those large entities will use to interpret all the data they have.
1121000	1137000	And this is a very different model. And so I think, and then I'll stop going on, but I think part of why Palantir, Amazon is also very interesting to me in this way, and I'm writing about Amazon a bit at the present.
1137000	1143000	But I think that Palantir represents this other mode of techno power.
1143000	1158000	I've been playing with calling it ontological power, where, you know, we now have, in contrast to when I started Logic magazine and started working on this, there's actually now quite a lot of public tech criticism.
1158000	1163000	You know, we have had Shoshana Zuboff's book Surveillance Capitalism.
1163000	1179000	We have a lot more public awareness and critique, I think, of how companies may be infringed on individual privacy, how they may be, you know, the way Shoshana Zuboff describes it, interfere with our free will.
1179000	1195000	What Palantir does is not the same as that. And it represents this other form of power that is no less threatening, I would say more threatening, but where they will build the ways that government agencies communicate with each other and share data and so on.
1195000	1207000	I think it's also important to see this because I think it helps us start to understand why their philosophy, ideology, culture is so different from a company like Google.
1207000	1217000	If the way you make money is that you let everyone in the world, except in the PRC, except in the People's Republic of China, although they'd love to be there, I'm sure.
1217000	1232000	But if you let everyone in the world use your search platform and then build ad tools based on the data you gather about them to sell to people who sell them products, you don't have a strong ideology.
1232000	1251000	You can make money off of everyone. Maybe I want to buy a socialist book. Maybe my neighbor wants to buy a neo-fascist book. It doesn't matter to Google. You can have this very sort of libertarian open philosophy and culture, which Google historically has had, changing a bit now that they're trying to get into cloud and defense contracts, which I think is important.
1251000	1271000	But Palantir is not doing that. They're selling to very large clients, corporate clients, government clients, and what they're selling is different. And once I think you see that, once I could see that after doing more research on them, the things that had bewildered me about how culturally different they were from companies like Google and Facebook start to make more sense.
1271000	1291000	They have a material basis based on the business model and based on the form of power they represent. And there's a good reason why they seem to represent something different from the Californian ideology, sort of libertarian open liberal libertarian consensus that I think historically we've associated with Silicon Valley. They're very different.
1291000	1316000	In what I understand as algorithmic governmentality, there's a certain way of trying to extrapolate from the behavior of others, your behavior, for example. So the assumption is that through collecting enough data on people who have similar past behaviors than you do, they're trying to extrapolate a possible future of Moira.
1317000	1337000	Within this action, there's a transition from prediction to prescription, actually, because based on the assumptions that are made, then their architectures are built based on this assumption. And it might be totally incorrect, you know, because the past of others is not Moira's future.
1338000	1347000	It might be self-fulfilling, you know, if you can't get a loan and then she goes further into debt, so her credit score is worse and worse, it will get harder to get a loan.
1347000	1376000	Absolutely, exactly. And there's a, and I think that's it's a specific epistemology of how to approach the idea of data. And I'm wondering whether this is being shared at Palantir as well, because, and I'm asking this because they are acting as if they are handling things differently, not only when it comes to the question of privacy, not only when it comes to the business model, which
1376000	1403000	is not collecting these huge amounts of data. But to me, it seemed when I was researching the topic a bit, you know, in preparation for this episode, to me, it seemed as if what Alex Carp actually is trying to say is that those people, they don't understand what data actually is. And when they are acting in the way we just talked about this specific idea of
1403000	1421000	governmentality, they are getting things wrong. Yeah. And I'm asking myself, what is he saying then? What is he saying? Is he saying that they are having a different approach and a different epistemological approach on how to handle data within Palantir? And that's actually a big question.
1421000	1447000	And it's totally related to the dissertation, I guess, in some way, because there's this kind of behaviorist idea within the dissertation that people do actually not know themselves correctly, and that their behavior is telling more about them and that the drives that are within them are so subconscious that they are not actually able to be aware of it.
1447000	1458000	And that through the correlation within the data, you might be able to see the form and that the form is actually the message.
1459000	1478000	I certainly see the connection to the dissertation, and I'm trying to think about how it connects to Palantir about what kind of attitude is it toward data to assume that certain kind of inferences can be made and that they are descriptive as opposed to prescriptive.
1478000	1494000	You know, I think I talk about in my article, this idea which others like Cathy O'Neill and Wendy Choon have written about, but this idea that machine learning can only replicate the past is a pretty familiar idea, right?
1494000	1504000	Because any machine learning algorithm is trained on existing data sets and how you train the algorithm to be right, as you see, did it reproduce the past results from this data set we have?
1504000	1524000	This is why, to use an example that I like to use with engineering students, when I speak to them, I sometimes ask, how would you design a non-racist predictive policing algorithm or really any kind of algorithm having to do with policing in the United States?
1524000	1538000	And often, you know, they think about it like, oh, well, could you use this? Could you exclude this and control it? And the point of the exercise is to show, in my view, there is no way you possibly could because everything about any data in the United States is
1538000	1548000	riven by the history of chattel slavery and economic inequality and so on and so forth. There's no data you could use to train something to predict a different future.
1548000	1564000	Wendy Choon, the theorist of technology, has this line I like where she says, what if we looked at machine learning systems the way we look at climate change models? Not like they're predicting something true, but that they're predicting something we want to prevent.
1564000	1573000	You know, this is like a bad thing about the past. We don't want to replicate. So I think you're phrasing, and this is very interesting in the context of Karp's dissertation.
1573000	1588000	I talk about this a bit in my piece because the dissertation suggests, actually, or at least Adorno's reading of jargon suggests a critique of precisely this kind of decontextualization, right?
1588000	1607000	So, you know, if Adorno's talking in a rather different context, but if he says, you know, dwelling has this meaning for Heidegger, but it's been totally abstracted from the context of people losing their homes and being homeless.
1607000	1620000	And therefore it sort of mystifies the way Heidegger talks about dwelling, mystifies and spiritualizes this fact, which is actually about the history of human oppression and exploitation.
1620000	1630000	I think we could see some really interesting analogies to the way machine learning and algorithmic governmentality might work.
1630000	1639000	There are some interesting experiments I want to mention in trying to do something closer to what Wendy Choon is talking about.
1639000	1655000	I think, for instance, suggesting what if you took a predictive policing algorithm, but then instead of using it to say, oh, you should police these people more heavily, used it to say, oh, you need more social services here.
1655000	1658000	You know, to allocate resources for redistribution or something.
1658000	1660000	This is just speculative.
1660000	1667000	But I think, so the analogy, if Adorno says about Heidegger, he takes this concept and decontextualizes it and spiritualizes it.
1667000	1673000	We could say that's what forms of algorithmic governmentality do with the data they're built on, right?
1673000	1698000	They're built on, say, a particular history of structural racism in the US and decontextualized from that become sort of an engine for predicting who is more likely to commit a crime or something in a way that makes that seem as if it's just true and reliable and not connected to these very specific histories of oppression and exploitation.
1698000	1710000	In terms of how closely that relates to the work Palantir does, to be quite honest, I think this is a question I'm still trying to answer in some of my research because they've done work with police departments.
1710000	1729000	And there's a horrifying, when you were making a joke earlier, Jan, about someone else's past predicting Moira's future, I was thinking of this horrifying interview that some Palantir representative gave in 2015 about their predictive policing program in New Orleans.
1729000	1752000	And a critic, it was on national public radio in the United States, NPR, and a critic pointed out the kinds of predictive analytics you're using are well known to disproportionately lead to policing of Black people and Hispanic people and poor people.
1752000	1762000	And isn't that a problem? And this spokeswoman, whose name I'm forgetting, said, well, as long as your cousin isn't a drug dealer, you'll be fine.
1762000	1770000	Which was amazing to me to have someone say that on public radio, as long as your cousin isn't a drug dealer, you'll be fine.
1770000	1778000	And so a very different idea of innocence and guilt and justice and will than the US legal system is supposed to operate with.
1778000	1793000	And so I think there is evidence that they have done some work historically that corresponds to the kind of epistemology of data we're talking about.
1793000	1809000	But I do, as I understand it, think that a lot of their business is not so much about building these tools of prediction as building means of interpretation for large entities.
1809000	1818000	And what kind of epistemology that involves is a really interesting question that I want to think more about, right?
1818000	1827000	Because it involves all kinds of assumptions about what data matters, about what is connected to what, who should be able to access what.
1827000	1836000	I used earlier the example of immigration authorities accessing health data, like what parts of government should be able to speak to one another.
1836000	1842000	But my first reaction is that it may be a bit different than that algorithmic governmentality.
1842000	1847000	It may be more about the power to set standards and set terms.
1847000	1856000	I'm thinking now of James C. Scott's famous book Seeing Like a State, but it's like, you know, who gets to set how the state sees people's data?
1856000	1862000	Seems like maybe it introduces a slightly different problematic, but that's something I'm still thinking through very much.
1862000	1865000	So that's a provisional answer.
1865000	1872000	Let's dig a little deeper into these alt-right tech liaisons.
1872000	1876000	Maybe for our listeners, just some general information.
1876000	1892000	In general, the Silicon Valley is thought to be kind of more liberal, and the programming and software developers scene is more or less seen as liberal, libertarian, or maybe even anarchist leaning.
1892000	1894000	And we will maybe come back to this later.
1894000	1903000	But there are also other tendencies, like the so-called neo-reactionaries, which formed around a software developer with the pseudonym Menchus Mobock.
1903000	1913000	His real name is Curtis Jarvin, and Jarvin's neo-reactionary world of thought has also been taken up by the philosopher Nick Land, for example,
1913000	1924000	who in turn will be known to many people through his work on accelerationism or the CCRU, the Cybernetic Culture Research Unit, which he co-founded in the 1990s.
1924000	1937000	And then there is Peter Thiel, you already mentioned him, co-founder of PayPal and also co-founder of Palantir, and a prominent figure in the right-wing conservative, in this case, ultra-libertarian camp.
1937000	1949000	Peter Thiel, for his part, was one of the few who backed Donald Trump when he was running for president in 2016, and subsequently also advised him at least for a time.
1949000	1957000	And Menchus Mobock, he was a guest of Peter Thiel on the election evening 2016 to view the election results.
1957000	1967000	So there are very short distances between radical reactionary positions such as those of Mobock and central positions of power.
1967000	1975000	What kind of worldview is this so-called neo-reactionary dark enlightenment, and what influence does it have in the tech industry?
1975000	1993000	It's a great question, and I'm so glad you mentioned that Curtis Yarvin and Peter Thiel watched the election together because it was a friend of mine, Joe Bernstein, who first reported that in 2017 when he got access to all these Breitbart emails, and I thought that was a delicious find.
1993000	2013000	And all of the things that he dug up, interestingly, just to add to it, I remember one of the other emails that this reporter got from Breitbart was an email afterwards between Milo Yiannopoulos and Menchus Mobock, Curtis Yarvin, where Milo was saying, well, Peter Thiel isn't that enlightened, right?
2013000	2021000	He's not that far, right? And Curtis Yarvin said, oh no, you'd be surprised, he's more enlightened than you'd think, just plays it very close, just is very careful about it.
2021000	2039000	And I'll add just one more fun fact, which is that when the New Yorker journalist Andrew Marantz went to the deplorable, which was this big party for the alt-right thrown at the Trump inauguration in January 2017, Peter Thiel was apparently there just being very quiet and not socializing in the background.
2039000	2048000	So it's a funny scene in Andrew's book where he runs into Peter Thiel at the deplorable and tries to talk to him and Peter Thiel sort of vanishes and avoids him.
2049000	2059000	I think these social networks are complex and it's an area I'm still doing research in.
2059000	2065000	I think it's hard to generalize because there are a lot of different ideologies floating around.
2065000	2087000	And my macroscopic view is that, you know, since roughly the 1990s, if there was this kind of liberal-libertarian consensus that maybe reflected a certain neoliberal hegemony or compromise, which, you know, we saw throughout U.S. politics, the third way, Democratic, Republican, getting along.
2088000	2097000	Sort of cultural liberalism, economic, old-fashioned liberalism, compromise that Richard Barber, who you've had on, I'm sure can speak to better than I will.
2097000	2103000	That since 2016, we've seen a kind of crap up of this common sense in the United States.
2103000	2107000	And I think a lot of different formations are coming out of that.
2107000	2122000	And it's not entirely clear, especially under a Biden administration or whatever strange era we're entering now, preferable to another Trump administration, but nonetheless, strange era, in my view, we're entering how that will play out.
2122000	2151000	I think that there's a very strong, I don't know whether to call it elitist, monarchist kind of tendency that someone like Mentis Moebuck represents that takes, again, from critical theory aspects of the critique of liberal modernity, but rather than saying, as, for instance, Habermas does, that then the project of philosophy has to be to help achieve democracy, you know, achieve liberal democracy.
2151000	2161000	A promise of it that's never been achieved, instead just takes the critique and says, and this is why modernity and liberal democracy are bankrupt projects.
2161000	2170000	I think that there is a strong tendency and one could be philosophical about it.
2170000	2181000	You know, there are these Leo Strauss reading groups among venture capitalists in Silicon Valley where they read Strauss and talk about Plato and the Republic of Philosopher Kings.
2181000	2192000	You know, I think one could be, and Thiel has a version of this in his reading of Girard, you know, in terms of how the powerful visionaries will always be treated as scapegoats and so on.
2192000	2197000	I think that one can go to a lot of philosophy and talk about their ideas.
2197000	2206000	One could also, you know, say these are a bunch of mostly white male engineers who think they know what to do and shouldn't have to listen to anyone else.
2206000	2211000	I sometimes question how much philosophy we need to explain the worldview.
2211000	2224000	But I think, yeah, there are, there's certainly a lot of social proximity between the Thiel Founders Fund Network and these sort of right wing networks in the tech industry.
2224000	2231000	A number of sort of prominent figures have turned out to be software engineers or come from that world.
2231000	2235000	I think, yeah, that's interesting.
2235000	2241000	I think there's this question about Thiel that's come up specifically and about his nationalism.
2241000	2244000	You know, what's his name?
2244000	2260000	Lucky Palmer, who started Oculus and left, he left Facebook basically over, I forget what the company officially said, but afterwards Lucky Palmer said publicly, you know, it was because they were angry that I was an open Trump supporter and I left.
2260000	2263000	He has called it tech nationalism.
2263000	2266000	There's a new kind of tech conservatism or tech nationalism.
2266000	2283000	I think given Peter Thiel's public support of Trump and the funding he's put into campaigns like those of Chris Kobach, who's a very anti-immigration politician in Kansas and the United States, and the ways he sort of placed people in the White House.
2283000	2296000	He placed this chief technical technology officer, CTO, in the White House, that there's been this question of like, well, how does nationalism fit with that kind of libertarianism, which is supposedly anti-statist and anti-government?
2296000	2318000	I think the idea that corporations should take over government is actually pretty consistent with this kind of libertarianism and pretty consistent with the sort of monarchist view of someone like mold bug that, you know, the state is failing and you need these engineers who are more competent or sort of philosopher king types to take it over.
2318000	2329000	So I think it's actually maybe less contradictory than it appears on its surface, but I do think there's this new nationalist emphasis or has been under the Trump administration.
2329000	2335000	Again, what will happen under the Biden administration will be interesting to see.
2335000	2341000	I think my prediction is that it won't make that much difference actually to their business.
2342000	2347000	But maybe in terms of ideological tone or how they talk about it, it'll be different.
2347000	2349000	I don't know. Yeah.
2349000	2351000	But there's certainly lots of proximity.
2351000	2359000	And I think a similar partial appropriation of critical theories, critique of modernity, is a continuity with the Karp thesis.
2359000	2363000	I've gone on way too long as usual, so sorry.
2364000	2382000	Ultimately, I'm interested in the various ideological shades of these questions because I think there's actually quite obviously a new competition of meta narratives, you know, the spot that has been taken by neoliberal variants of different sorts.
2382000	2393000	It's quite open now because I mean, of course, now we have Biden and it seems as if a neoliberal approach kind of again got their way somehow.
2393000	2404000	But I don't think that like in the medium and long run, it is a narrative that is still convincing to the majority so that there is an open spot in terms of meta narratives.
2404000	2418000	And that's why I'm also interested in the way that Palantir, Karp and Thiel and others like that try to present themselves as if they have a different kind of meta narrative, also for people in the tech industry specifically.
2418000	2429000	And we already have given much space to this reactionary and near reactionary positions, which I think is important because there are many dangers arising there.
2430000	2434000	But I think it's also important to look to different positions.
2434000	2439000	And that is actually what you're doing with Ben Tarnoff in Voices from the Valley.
2439000	2443000	And I have to say I didn't yet read it. I didn't have the time to read it.
2443000	2451000	I only listened to interviews with Ben and you and I'm highly excited about the book and I'm very much looking forward to reading it.
2451000	2459000	What other positions have you encountered in your work on the book, perhaps especially with regard to this open question of meta narratives?
2459000	2464000	It's absolutely this moment of new openings for opening for new meta narratives.
2464000	2468000	And we're seeing those on the left and the right and somewhere between.
2468000	2478000	And I think also it's important for me as a materialist anyway to attend to what this has to do with changes in the technology and in the business of Silicon Valley.
2478000	2481000	Silicon Valley started as a government project, right?
2481000	2484000	It was funded by the US military in the beginning.
2484000	2490000	It went through this process of privatization and deregulation in the 1990s.
2491000	2498000	In that moment of neoliberal consensus forming, if we want to call it that.
2498000	2501000	But it may be entering another phase.
2501000	2509000	And I think with the rise of new machine learning technologies and particularly new cloud computing technologies,
2509000	2517000	the sort of competition for the large government contracts that the client Palantir has may represent a new iteration technologically
2517000	2520000	and in terms of business model as well as ideologically.
2520000	2523000	And of course, ideology is always tied up in these matters.
2523000	2535000	And I think I say this just because I think this battle of meta narratives is often reported on in the media about Silicon Valley or has been reported on as a kind of culture war.
2535000	2539000	You know, it's like, oh, these are just different things people think at these companies.
2539000	2546000	And I think that it's actually really important to keep paying attention to how it interacts with the business and the technology.
2546000	2550000	So to take and then I will answer the question about socialism and more optimistic alternatives.
2550000	2558000	But to take a more current example, Amazon recently brought onto its board Keith Alexander,
2558000	2568000	who was an architect of the National Security Administration, architect of the spying, you know, global spying that that Edward Snowden revealed in 2013.
2569000	2578000	And there is a faction within, you know, this is very clearly, in my view, a bid by Amazon to win more government contracts.
2578000	2582000	They lost this cloud computing contract to Microsoft a year or two ago.
2582000	2588000	So hiring the chief NSA guy is a bid to try to win those government contracts.
2588000	2597000	There is a battle about it happening within Amazon because some engineers are very who are more sort of libertarian digital rights privacy type.
2597000	2605000	People are pissed that the sort of most famous guy, most famous for spying on the entire world is is now on their board of directors.
2605000	2616000	But this isn't just a matter of competing beliefs, although it is that it also is making it a lot harder for Amazon Web Services to do business in Europe,
2616000	2628000	where there's the general data protection regulation and there's just been this new lawsuit knocking down Privacy Shield, which was an old privacy framework for managing data sovereignty and privacy in Europe.
2628000	2639000	So it's one of these cases where it is the advent of cloud computing, you know, the growth of cloud computing and these new virtualization technologies creates new business opportunities or the client for that is the state.
2639000	2646000	The client for that isn't the individual user who is the user of Google search or Facebook.
2646000	2652000	That kind of technology lies on large enterprise customers to make its money.
2652000	2657000	And you see this extensively political or cultural clash where you have some people in Amazon.
2657000	2662000	A lot of people in Amazon used to work in the military and police who say, you know, maybe they're patriotic.
2662000	2666000	And then you have people saying how terrible to have someone who's a famous spy.
2666000	2675000	And that looks like a culture where but it is also fundamentally wrapped up in these business questions about whether how they're going to sell cloud to the US or the rest of the world.
2675000	2677000	And so that's just a random example.
2677000	2688000	But I think as we think about these new meta narratives, it's also really important to always keep in mind how they link up with the state of technologies and how they link up with the business opportunities.
2688000	2710000	Similarly, in Google, if we look at these worker struggles or sort of high profile conflicts that happened in the past few years, for instance, over Project Maven, which was a contract to provide a vision recognition software to the US military that some engineers and others within the company objected to.
2710000	2712000	And there was sort of a public struggle over this.
2712000	2715000	And Google did not end up competing for that contract.
2715000	2720000	This was often reported as a kind of culture war between liberal Silicon Valley and more national Silicon Valley.
2720000	2730000	But it's fundamentally tied up with how Google is going to continue to find new ways to make money off of all the data they have and ways they know how to read and manage data.
2730000	2739000	So all that to say, I just always want to reemphasize that these meta narratives are very tied to business and to, you know, ideology is material.
2739000	2764000	But that said, I think as much attention as the neo reaction and the right wing folks have drawn, there also has been, and I sort of alluded to it indirectly there, a lot of left wing organizing and activity within Silicon Valley in the past four or five years, not solely in reaction to the election of Trump, but certainly catalyzed by the election of Trump.
2764000	2776000	But it's quite striking, you know, often for many reasons when we hear about Silicon Valley in the media, what we're really hearing about is the ownership class of Silicon Valley, the CEOs of Silicon Valley.
2776000	2780000	They're the only ones who are allowed to talk to the press most of the time.
2780000	2786000	And but actually Silicon Valley is made up of a bunch of different kinds of people.
2786000	2796000	And one, and a lot of them like young people in the United States in general are left of center sort of left even of the neoliberal consensus and one statistic.
2796000	2805000	I like to cite, which Ben Tarnoff, who I did this book with, wrote about back in 2016 is that more.
2805000	2812000	Let me put this the right way of the top organizations by number of employees who donated to Bernie Sanders.
2812000	2817000	So employers were the largest number of employees donated to Bernie Sanders.
2817000	2820000	The top five were all tech companies and the nurses union.
2820000	2823000	So his nurses and then software engineers.
2823000	2827000	And I think that represents a real thing.
2827000	2828000	And part of it's about age.
2828000	2833000	You know, the tech industry is young and young people in this country tend to be tend to be more left.
2833000	2837000	But I also think there's room.
2837000	2848000	I think there are these laughter and energies in the tech industry to that logic magazine and my new book have tried to tap into and document and show to people because it's so rarely shows up in the press.
2848000	2854000	And and that we can it's interesting to think too about how those connect to new technological possibilities.
2854000	2857000	I mean, I personally actually don't think this is a perfect answer.
2857000	2862000	But some people say, you know, Amazon has a perfect planned economy, just nationalize it.
2862000	2865000	You know, it's not it's not an inevitability.
2865000	2867000	I don't think that that's a serious idea necessarily.
2867000	2876000	But but there are all kinds of potentialities and possibilities in these technologies and the scale at which they they draw people together.
2877000	2884000	And it's not a given that they lead to a handful of tech emperors running everything.
2884000	2888000	So our book talks to ordinary people in the tech industry about different experiences.
2888000	2890000	And I could certainly say more about that.
2890000	2894000	But I already talked quite long enough in answer to that question.
2894000	2901000	What I find incredibly exciting is the newly found self-confidence of tech workers as a key industry.
2901000	2910000	And the sociopolitical power and ability that arises from from this fact, how can this power be activated and for what?
2911000	2913000	It's a good question.
2913000	2924000	You know, through Logic magazine, somewhat in my new book, and then through the magazine over the years, we've really tried to document some of these different political actions by tech workers.
2924000	2932000	And this term tech worker in English is itself a kind of polemical term, right?
2932000	2938000	Historically, the industry has been very segregated or separated by different skill levels.
2938000	2943000	There's been this strong ideology that highly paid workers in the tech industry aren't really workers.
2943000	2949000	You know, they're creatives, creatives, knowledge workers doing their knowledge thing.
2950000	2961000	And and, you know, don't mind the thousands of people working in the cafeteria or on the campus or indeed, you know, in in customer support who make this all run.
2961000	2968000	I think so this term tech worker itself has a kind of polemical aim, which is to say everyone who works in technology is a tech worker.
2968000	2970000	They can have material interests in common.
2970000	2979000	It really came out of this organization called Tech Workers Coalition founded in the Bay Area in 2014.
2979000	2984000	And it was, at least to my knowledge, that's and I'm pretty sure it's correct.
2984000	2988000	That's the sort of first time that a lot of people use use this term.
2988000	2993000	It's an organization co founded by a former cafeteria worker and an engineer.
2993000	3007000	And from the very beginning, a big part of their ethos is about bringing together sort of higher paid tech workers and the people who are usually thought of tech workers with all the other folks whose whose labor makes it possible.
3007000	3009000	And there was a lot of knowledge sharing.
3009000	3027000	I think the blue collar workers tended to have a lot more experience in agitation and organization than the engineers did and unionizing campaigns for those workers, which happened in Silicon Valley in 2015, 2016, 2017 at Cisco, Facebook, IBM, some other big companies.
3027000	3030000	There were unions for the for the blue collar staff.
3030000	3036000	That was a really big learning experience, I think, for a lot of the engineers.
3036000	3041000	I think that it's it's a new kind of consciousness that can go in all kinds of directions.
3041000	3052000	One early thing we saw after the Trump election and actually the very first Tech Workers Coalition protest I ever went to was at Palantir headquarters.
3052000	3060000	I was there to write about it, not as a protester, but was at Palantir headquarters in Palo Alto the day before the Trump inauguration.
3060000	3065000	So I guess that was January 20th, 2017, I think.
3065000	3082000	One concern that a lot of tech workers, engineers expressed, was concerned about being made to gather and use data or building products that would be used to police and harass people in ways that they did not support and did not intend.
3082000	3099000	So for instance, at that Palantir protest, people spoke about this idea of a Muslim database, which Trump had been talking about on the campaign trail and Palantir's possible complicity in building such a database.
3099000	3105000	I think one thing that's been very interesting to watch is that, you know, engineering work is so modular generally.
3105000	3110000	It's like engineers work on these very little pieces of software that plug into these very big systems.
3110000	3123000	And I think, and I don't mean this as a criticism at all, but I think in that kind of work system, it's very easy to kind of lose sight of what the bigger picture is, or it's very easy for a worker not to know what the bigger picture is.
3123000	3133000	But I think that, A, having this threat of Trump using these tools to political ends that people didn't want was politicizing.
3133000	3146000	And I think also, and person after person I talked to, talked about this specific meeting that happened between Trump and the tech CEOs, and that happened on December 9th, 2016, and Peter Thiel arranged it.
3146000	3158000	But person after person I talked to separately brought up these photographs that came out of this meeting, and these photographs of their liberal bosses sort of going to kiss up to Trump after he was elected.
3158000	3169000	And I think that, as silly as it might sound, sort of just this awareness that it's like they were workers in a business, and those businesses were going to comply with who was in power.
3169000	3183000	And there's all this ideology about engineers as creative workers who aren't really like workers, they're doing their own thing, but actually, at the end of their day, their bosses would say, no, you're going to make that, that they were actually workers.
3183000	3188000	I think the election of Trump had sort of a catalyzing effect on that in all sorts of ways.
3188000	3195000	And I mentioned earlier the protests at Google, there were these actions at Google, even before the Google walkout about sexual harassment.
3195000	3208000	There were these actions around Project Maiden, which was this vision recognition software in development, potentially for the military didn't happen, and then Project Dragonfly, which was a censored Chinese search engine.
3208000	3214000	And there have been a lot of other actions like that against specific projects at tech firms.
3214000	3218000	So I think there are a lot of directions it can go. That's one way it's gone.
3218000	3227000	I think another key insight, at least at the beginning of that movement, was that engineers realized they could use their sort of privileged position to advocate for certain things.
3227000	3236000	I think Google has shut down on it a lot since then, but I used to hear people say, you know, how many engineers did it take to shut down Google search for a day? Not that many.
3236000	3246000	They're like a trillion searches a day. You know, if you think about like a dock worker, like where the points of leverage and economy are, it's actually not very many people right there.
3246000	3251000	So anyway, yeah, those are some thoughts on it. I think that it's evolved in different directions and will continue to.
3251000	3262000	I think what COVID means for it is a really open question because, of course, yeah, it's had a lot of implications. People aren't on their campuses anymore. More work is remote.
3262000	3271000	I think it's possible it'll lead to permanent sort of de-skilling of even certain technical jobs or outsourcing of that at a more rapid pace.
3271000	3277000	But yeah, there's been a lot of new activity in that area since 2016, for sure.
3277000	3285000	Maura, there's a last question that I ask everybody who's on the show. If you think about the future, what makes you joyful?
3285000	3290000	Ah, what makes me joyful about the future?
3290000	3310000	I think, you know, I think in my personal life, I could have my own answers. I think looking at the political scene, I think that this sort of crack up of a neoliberal hegemony that was in many ways harmful and felt constricting.
3310000	3318000	And that's happened since 2016 has opened up a lot of new possibilities. And some of those are frightening and bad.
3318000	3329000	But some of those are really promising and exciting. And so I think with a measured kind of optimism, because I don't want to play down all the suffering and sort of frightening things that have happened.
3329000	3342000	I think that looking at young people, including tech workers, but also including, you know, young climate strikers and sort of these young feminist activists and so on.
3342000	3350000	Looking at those folks and how they're using technological tools or when they work in the industry, building new kinds of tools.
3350000	3361000	These are things that make me feel optimistic, if I'm having to be optimistic. I'm very pessimistic all the time.
3361000	3373000	But yeah, those are things that make me feel joyful, as well as the thought of whenever it is we get to be in large rooms for a dance party or a bookstore reading.
3373000	3384000	Again, I have dreams about going to a bookstore full of people to hear someone read. So yeah, those are some things that make me feel joyful.
3384000	3389000	Nice. Moira, thanks a lot for being part of Future Histories.
3389000	3396000	Yeah, thanks for having me. This was fun.
3396000	3403000	That was our show for today. If you want to know more about Future Histories, please visit futurehistories.today.
3403000	3414000	You can support Future Histories at Patreon. For this, go to patreon.com slash future histories and let me know what you think about this episode and the show in general.
3414000	3426000	For this, use Twitter, hashtag Future Histories or Reddit or send me an email to future underscore histories at protonmail.com.
3426000	3427000	See you next time.
