Welcome to Future Histories, my name is Jan Gross and it is my great pleasure to welcome
Antoinette Rovois in today's episode.
It's a Future Histories live episode that you are about to hear, meaning it has been
recorded in front of an audience, in this case, in the context of the workshop Biological
Life and Political Cybernetics that took place in December 22 in Vienna.
And I want to thank the organizers Anna Verena-Nosthoff, Eugenia Stamboljeff and Vessel Reyes for
the possibility to take part in this, it has been great, thanks a lot.
And I am happy to announce that this is not a single workshop, but a series of workshops
on the topic of political cybernetics and that I myself will organize an instance of
this series at Kiel University as part of the research project Governing Algorithms.
I'll definitely keep you updated on that.
I also want to send a quick shout out to the Critical Data Lab, which I'm also affiliated
to and which was, through Anna Verena-Nosthoff, also involved in the organization of the Political
Cybernetics Workshop in Vienna.
Many thanks to everybody involved in general, it has been a pleasure.
Before we start, I would like to welcome Manchu and Dahlia as patrons of Future Histories
and I want to thank Fabian, Lucas and Karl for their kind donations.
And now, please enjoy today's episode with Antoinette Rovois on Algorithmic Governmentality.
Welcome to Future Histories, my name is Jan Gross and it is my great pleasure to welcome
Antoinette Rovois in today's episode.
She is a permanent research associate at the Belgian National Fund for Scientific Research
and a researcher and professor at the University of Namur in Belgium.
Her work centers around evolving normativities at the interface of legal theory, philosophy
and science and technology studies using, for course, insights on questions of government.
She has developed an analytic framework called Algorithmic Governmentality, which we will
explore in today's conversation.
Welcome Antoinette.
Thank you.
Thank you for having me.
It's a great pleasure.
Let's maybe start with a broad definition for people who are not familiar with your
work.
What is algorithmic governmentality?
Well, I must first say that my intention with that concept or that notion or that non-concept
rather of algorithmic governmentality has never been to find the right epochal ladder
for something like a social totality.
If I speak of governmentality, it is precisely in order to avoid delimiting the social as
a totality.
I don't speak of algorithmic society any more than of a surveillance society.
Algorithmic governmentality does not, in the sense that I use the term, designate a particular
mode of government which would have more or less replaced or been juxtaposited to the
forms of sovereignty, pastorate, discipline, normalization, control and so on that Foucault
and in fact, Foucault himself did not consider that sovereignty, surveillance, discipline,
control and so on corresponded to a strict chronologic periodization.
It was not for him a series in which the elements follow one another.
It is rather a complex edifice in which the center of gravity shifts in the systems of
correlations between legality, discipline, security, control and I would add with Felix
Guattari integration and I would add with a lot of you, with most of you, recursivity.
These shift at the core of governmental rationalities.
The way I try to inherit of the non-concept of governmentality from Foucault is I must
concede right away quite unfaithful, at least partially, to the original meaning ascribed
to the term by Michel Foucault in the series of lectures he held at the Coll√®ge de France
in 1978 and 1973 and I would say that because since I wrote about algorithmic governmentality
first, it was a long, long time ago, my own thinking has evolved and I have come to understand
that in fact algorithmic governmentality or algorithmic capitalism was not a mode of ordering
of the world.
It is not a mode of organization, but it's rather a tactic or a system of disorganization
of organized and strategic disruption, which is highly profitable to the ones who Mackenzie
work called the vectorialist class.
But of course, we are all part of this and I will try to develop that a little bit later.
So I refer to, also I must say right away that I refer to governmentality mainly as
a methodological perspective that orients our attention away from the classical invariance
of political science, the state, institutions, the subjects.
From a governmentality perspective, the state, institutions, the subjects are not presupposed
or pre-existent to governmentality.
They are rather it's byproducts.
So governmentality allows me to try to diagnose or to produce a kind of clinics or analytics
of a series of semiotic, epistemic, normative, strategic, anthropological, ethical shifts
in the processes or techniques of signification, that is production of meaning, in techniques
of power or domination and in techniques of the self.
Foucault's notion of governmentality or what he calls governmental rationality, which corresponds
in this sense to what, for example, Castoriadis calls the imaginary institution of society
is above all, for me, a way of making consistent, of articulating, of showing the entanglement
in each era of a set of techniques of signification, meaning making, techniques of production,
techniques of power and techniques of self.
This being said, what I have as a target are indeed the new effects of reliability or credibility
in the post-truth era where we are, as is often said, the unprecedented effects of power
or operationality without authority, and therefore responsibility, or the force without law,
and an individualization or molecularization and deterritorialization without subjects.
Therefore, I speak with others of inhuman biopolitics, the instrumental unit of power
being not anymore the population, individuals, or the bodies, but only meaningless data.
So this being said about governmentality, now, why algorithmic governmentality?
My algorithmic governmentality with my colleague Thomas Berns, we had in mind a kind of hypothesis
a hypothesis of a government of the social world based on the algorithmic meaning automatic
processing of the massive data proliferating from our behaviors by behaviors, I understand
all the interactions we have with the environment, relationships, interactions, trajectories,
and so on.
So processing of massive data proliferating from our behaviors rather than on politics,
law, social norms, in a multitude of sectors of activity and government.
We therefore call algorithmic government or algorithmic governmentality a mode of government
which is productive not of norms, neither of standards or rules, which in fact fails
to adjudicate and which is fed essentially by raw data, by which I mean,
intrapersonal and significant but quantifiable signals.
Also, algorithmic governmentality operates by anticipatory configurations of possibilities
through anticipatory optimization of environments rather than by regulation, permission, prohibition,
and so on.
But as I will tell, no, my current thought about it is rather that, in fact, it's not
even trying to govern anything, it's rather trying to render power absolutely agile, able
to be resilient to any kind of transformation, any kind of emergence.
So that's really the speculative term that algorithmic governmentality marks.
So we have also defined in some of our papers algorithmic governmentality very broadly
as a certain type of normative or apolitical rationality founded or grounded on the automated
collection, aggregation, and analysis of big data so as to model, anticipate, and
preemptively affect possible behaviors.
So, of course, when reading and rereading Foucault and Deleuze, I realized it was not
very, very original.
In fact, already in 1979, Foucault announced this on the horizon of liberal governmentality
what appears is not at all the idea or the project of an exhaustively disciplinary society
in which the legal network, enclosing individuals, would be related and extended from within
by, let us say, normative mechanisms, nor is it a society in which the mechanisms of
general normalization and exclusion of the non-normalizable would be required.
On the contrary, on the horizon is the image or the idea or theme of a society in which
there would be optimization of systems of difference, in which the field would be left open
to auxiliary processes, in which there would be tolerance for minority individuals and
practices, in which there would be action not on the players of the game but on the
rules of the game, and finally, in which there would be intervention not on the type of
internal subjugation of individuals but intervention of an environmental type.
In the next lesson, Foucault reminded of the heterodox definition of economics given by
Gary Baker, the science of systematicity of responses to environmental variations, a
definition Foucault told us which can perfectly include the behavioral techniques that had been
promoted in particular by Skinner about whom Foucault also writes that he was hostile to the
use of statistics, that he considers that individual behaviors must be studied, which presupposes
that we control the environment in which we place the subject and that we define measures
of response which are informative. When a subject moves in his environment, some of his behaviors
produce detectable changes in the environment, the reinforcement contingencies. The operant
response is a class of responses defined by the consequences they have for the subject and issued
in a given situation without being causally dependent on a stimulus in the situation.
That's really the kind of data behaviorism that I have tried to describe, in which in fact
insights replace knowledge and in fact it completely disturbs that the idea that
Foucault had that in fact power is always based and co-produced with knowledge.
Here the conjunction of knowledge and power is completely exploded. There is no need for
knowledge to govern and it's even the opposite. It's a way through which contingency and
non-knowledge and ignorance become the target of speculative and leveraging strategies.
So we are not exactly in the situation described by Foucault. Why? Of course we perceive all that
modulation that we have left modernist way of government and so on, but I would say we are
even further than what he anticipated in 79. Why is it? Because in fact there is no action
on the rules of the game or if there are actions on the rules of the game,
these rules are not even any more detectable or subjectively recognizable by the players.
Why is that? Because in algorithmic governmentality what we notice is that even
metrics against which behaviors or performances are evaluated, ranked, scored and so on,
metrics have become increasingly plastic. They are not fixed. They are not knowable in advance.
They are moving and evolving according to the behaviors of all others. What that means is
that we are not any more confronted with the kind of subject produced by algorithmic governmentality
is completely at odds with the notion of the homo hemoconomicus described by Gary Becker,
the homo economicus who had to invest rationally in his own human capital by being able to
anticipate what kind of returns his investment would grant him. No, people never know how they
will be evaluated and the metrics are so moving that in fact we can have the impression that this
shift from modernist normativity towards recursive plasticity of abnormativity,
that cybernetic mode of government, it can appear really emancipatory but it is paid,
it is at the cost of transforming individuals into people who are completely addicted
to credit so they have to find credit to gain attention, to gain audience, to be
noticed, it means to occupy a node in the network. So in fact it's a kind of anomaly,
that's the reason why in beginning to respond too long to your question, I said it's a system
of disorganization. It's a system of disorganization because it fragments all subjectively and
collectively recognizable forms into pure decontextualized signals which are re-aggregated
at an industrial scale which is not personal nor collective nor nothing, which are pure speculative
in which pure speculative spaces are created, speculative spaces of opportunities and risks.
I have the impression that I have transformed this discussion into a monologue so don't
hesitate to interrupt me if you wish. Well I'll just wait until you have finished making your
point so that's all right with me. Okay so maybe in order to give some
consistency, some materiality to what I'm saying here, I guess just a few examples.
For example there is a new system of employee monitoring developed by Amazon in its warehouse
and in the vehicle of their delivery drivers. In the online presentation Amazon presents the
monitoring system as humanizing the interaction transportation companies have with their drivers
to enhance driving performance. Indeed what matters in this humanization is to enable
artificial intelligence systems to better understand or rather better act as if they
understood the humans in their interactions with their environment. Of course what matters to
Amazon is not at all understanding or legibility of each individual employee, their motivations,
their intentions or the singularity of their experiences. In fact individual warehouse
workers are eminently substituable or replaceable anyway. It is not their singularity that Amazon
has an interest in nor is Amazon primarily interested in acquiring knowledge about the
productivity of the workforce in general but rather it's interested in rendering individual
workers every move computable in a data behaviorist paradigm. This is the kind of
data behaviorism allowing humanization of interactions contemplated by Amazon.
To humanize in this discourse means to scale power down to the molecular level,
to leverage particularities not singularities but particularities. Conveniently from the
perspective of a neoliberal management these particularities escape both subjective identification,
recognition and collective perception and discussion.
It is of course as I said not the singularity of individual experiences that are of interest to
Amazon nor the regularities observed in the workforce population but rather the mostly
subliminal particularities of behavioral responses to environmental stimuli. The individual and
collective trade unionist and so on subjects how they may or may not acknowledge experiences
their own and so on do not matter at all. They disappear from powers gaze. Singular and collective
experiences drastically fall in value and power operates on the mode of machining enslavement
rather than social subjection. So enabling everything to be connected to communicate
or synchronize with everything else in almost real time the computational term appears to
disqualify all kinds of representations including predictions based on statistical representations
which never pretend to be adequate to the world but merely to provide approximative representations
of it with an objective of neutrality. All these even statistical representations are felt as
anarchisms sorry archaisms in favor of a post-representational recursive paradigm of
disintermediated access to the digital real in high resolution which is also a high dissolution
at the pre-semiotic stage emancipated from the symbolic order from the tyranny of the signifier
from the imperialism of language itself. So and I will end maybe my attempt to
to not define algorithmic or neutrality by this I would say that
the aim but I will maybe later further explain this the aim is not so much to manage or influence
the individuals and groups but to render power absolutely agile capable of leveraging the
contingency of individual and collective behaviors whereas data drivenness attest to the replacement
of both the commodity form and currency by assets all that matters is the convertibility
of contingent data into speculative assets so the hallmark of power in algorithmic regime
is not so much that it would look at us spy on us but rather that it literally bypass the visual
epistem the phenomenological perceptual systems of recognition of qualification of judgment of
categories in favors of systems of recursive computation as a consequence algorithmic
governmentality is quite indifferent to what is present to what appears consistent and real to
our ordinary senses as it shifts towards the forward-looking detection of contingent patterns
as novel latent speculative spaces which are in no way subjectively or collectively recognizable
so yes maybe I don't know if this fits as a broad indication of
what algorithmic governmentality is about as a problem. Yes well let me jump in I would be
interested at this point in in two things one would be that in one of your texts at some point
you coming from this critique of algorithmic governmentality you continue to argue for a
quote-unquote return to reality so I would be interested actually what you mean by reality in
this case so what is it coming from this critique that you try to bring forward maybe as a I don't
know how to call it then counter ontology I don't know maybe so maybe you could state what you mean
with reality in this case this is one of the the questions that I have and the other one would be
that when reading the texts from time to time I was asking myself whether or not these descriptions
that you give of algorithmic governmentality I got the impression that they do absolutely fit
for some form of imaginary of algorithmic governing but that if we look at the
actual practice that this is not really an adequate description of how things are really
going going down and one example for this would be this phrase of raw data is an oxymoron and you
yourself state that the people who are actually working with these technologies are very much
aware that there that there are so many hands reaching into the algorithm that there is always
a co-production between the algorithm and the the humans who are working with it so that there is
not actually this place of perfection that you kind of describe when talking about algorithmic
governmentality who seems to be omnipotent when hearing about the critique and of course it's
powerful but it's not omnipotent and it didn't yet succeed in getting rid of the human I would say so
there is already this aspect of interpretation there's already this aspect of entanglement
there's already this aspect of human co-production always in place already in capitalist cybernetics
as well yes of course I hear what you say but I
I think that that's the most maybe the most difficult thing to to to to transmit
in fact what I say what I speak about what I speak about and I speak about it in my text as well
it it's a technical ideology it's a technical ideology of big data it means that what I speak
about is the kind of pretension but a pretension that even you know the designers of the of the
technology data scientists and so on they they are not naive realists they they know they know that
in fact big data doesn't mean exhaustivity that automatization or or algorithm don't
mean doesn't mean objectivity that non-selectivity or less obvious selectivity
doesn't mean impartiality and so on I think in fact and and that's the reason also why I
I refer to problematization the basic question I ask to myself first is is why is you know the
turning to algorithm and ambient intelligence artificial intelligence big data and so so on
why are these solutions presented as solutions without
and appearing as something absolutely obvious whereas they are presented by solution as solutions
but the kind of problem to which they are presented as a solution against which which they are
presented as solutions is never clearly stated and my my perception is that it is precisely
because in our society we we have a hatred for averages we all want to be unique and recognized
as unique we don't want to be part of a category anymore we want we all we all want personalization
and so on means that in fact there is a radical crisis of representation and by this I mean
not only the perception that all kinds of representations through which we perceive the
world is misleading is ideological is is politically suspect and so on it's not that
I think that there is behind this success of the algorithmic turn there is a kind of mystic
a mystic of immanence a mystic or a belief that it is in it would be possible at last
to touch rationally on the world and the things in themselves it is very close to the
speculative turn and the speculative realism in philosophy that's the reason why I'm writing
was about algorithmic realism but it's it's very it's of course absolutely absolutely
ideological of course the human is everywhere the human is in the it's the human who who designs or
who inscribes the the objective function the objective function of the algorithm
what is it it is the it's the indication of or the cost function it indicates what has to be
what has to be maximized what has to be minimized what has to be
optimized of course that objective function is nothing but the the formalization of the
sectoral sectorial interest or the sectorial logic of of the actor who's using the algorithm
so there there is there is a human there there is the human of course in social reality itself
and the mere fact the mere transcription of social reality of social
into into digital data which appear as facts I speak of a new kind of facticity
the simple transformation of reality of that reality social reality complex and so on into
data doesn't purge doesn't
expurgate that reality from all the domination the repose of domination relation over dominations
and so on in fact as you say data raw data don't exist it it's not only that raw data is always
of course it is it's a it's a patient work of
of this indexization anonymization and so on producing raw data is a is a hard work
but it's not it's not only that it's also that producing raw data is organizing the amnesia
of data with regard to their the condition of their production that's the reason why it's
I say it's a it's ideological it hides its own conditions of of production so
so it's not that I in the question you you sent me I read that I don't only criticize the concept
of a truth founded in probability I I never I I never criticized the concept of a truth
founded in probability because following Foucault for me truth the notion of truth
is always the result of truth regimes truth regime it's truth is always produced it's something that
is added to the world it's nothing nothing that you can find in the world and that's the also you
know the the false promise of of big data or the idea of the ideology of the technical ideology of
big data is the idea that knowledge shouldn't have to be produced anymore that it can be discovered
in the data that it's always already imminent in the data and provided you use the right algorithm
you will you you you will find or knowledge will or truth will will arise spontaneously
that's exactly that kind of naive realism that I'm combating
the as as strongly as I can and you find that that same kind of naive realism
in a lot of of techno-critics who really work on on the idea of rendering algorithms
fair accountable transparent and so on meaning that they want to correct the algorithms with
the idea of with the idea that if algorithms are fair are just are you know are accountable and so
on then we will have a perfect access an objective access to what is you know without human
intermediation that's that this that's really mad that's the madness because I think first of all
there are several reasons of course the first obvious reason is that the notion of just the
notions notions such as justice or concepts such as justice fairness and so on are dialectical
concepts dialectical concepts are not easily formalizable into what george school nicolas
george school again call uh uh uh arithmo uh arithmomorphic concepts arithmomorphic concepts
in george school against uh uh uh civilization are concepts which are exactly what you know
the result of an optimizations of an algorithmic optimization is you know just one result yes or
not that's algorithm that's sure you know you don't have to discuss but justice is not something like
it's really dialectical it means that it's it is a concept um which has a
which is distinct of course but not discretizable not discretizable
and that's that that's hugely important maybe i can yes i will read you i i had that um that
passage of a george school george school again uh and for george school again the the the
arithmomorphic character of a concept is linked to the fact that there is a definitive discrete
border between what this and what is not what it is not what it is and what it is not the possibility
of defining a big univocal relation between a set of concepts and a numerical scale makes it
possible for example to attest to the arithmomorphic character of the concept in this set
um but but there are another kind other another world of concept which are all the concepts that
we we human use as we are uh uh because we are not inhuman and those not inhuman concepts are all
are all uh dialectical i think so um so for for reality uh i think it was a misunderstanding
there was a misunderstanding there uh if i the reality i i don't i don't remember having written
that but uh if i help you for a return to reality the kind of reality i would like to return to
is the reality that is added to the world added by our own collective productions of meaning so
um that's the dialectical reality i i would uh i would argue for there are a series of conditions
for this kind of additional uh additional uh reality to to occur
and the first conditions are special and temporal we need scenes to discuss about
dialectical concepts uh but maybe i go too too far in my answers i don't know if if it
fits what you had in mind well if it was merely a misunderstanding you think then we could continue
to other questions and i would just maybe to clear something up and since we are here on
in the workshop on um cybernetic politics i just wanted to ask if i maybe understood it wrong
right now in your answer when you pointed towards a kind of naive realism which is kind of close to
speculative realism which you say is an kind of this naive realism is an aspect of algorithmic
governmentality as well as of some of the critics i'm actually wondering because i always thought
that cybernetics actually does not really care about ontology in this sense but is absolutely
fine with something that would be called a probable truth so it's not about really kind of trying to
unveil some kind of essence i always thought that this is absolutely not a logic found within the
cybernetic paradigm but as i said instead it would totally be fine with a version that simply works
or works better than the other one so this is what i meant with a truth founded in probability
and i would say that this is really a fundamental difference so i was wondering if you think that
algorithmic governmentality is in this respect different from cybernetics or why you say that
they are trying to kind of get to the to the real because i always thought it's not about that
no indeed it's not about that i think we have to understand quite clearly the epistemic ambition
or strategic ambitions behind these machines as when they are used in a capitalist context
of course in fact with the advent of big data and machine learning
emergencies are detected in real time in a nanomic complex and purely metric digital space purely
which is the result of an abstraction but also of all kinds of of production of raw data as you as
you said which is compression and so on so but but which is purely metric which is a space which
is envisaged that's not from the topological angle of continuity and stability but from the time
based angle of contingency instability and continuously recons reconducted crisis
as a host exo adams explaining one of his paper so in that context what we have to understand
is that data doesn't don't function as as signs there they don't function as signifiers
for for something rather they function as pure differences or deferments of meaning
that are never given in their completion so to explain that a little bit i have i have to i think
go back to a comparison between um what for example adolf ketley
concept or the order between the deterministic metaphysics that for example adolf ketley
heads when founding or participating to the to the foundation of statistics and what happens
in machine learning the speculative ambitions of machine learning i think are really at odd
with the mid 19th century of ambitions of studying studying social physics like adolf ketley
whose project was to study men in his various degrees of aggregation from the individual state
to the highest state of combination which includes the whole of humanity on the contrary algorithmic
governmentality radically embraces uncertainty incommensurability contingency it it also attests
to a new mode of preemptive intervention which is no longer legitimated or justified as the ability
to act on the basis of precise knowledge of the future but on the contrary as an invincible
certainty as to what must be done in the absence of such certainty as martin conings says quite
clearly in capital and time so and the temporalities of course recursive which
changed everything so um in fact it's a dynamic mode where continuous learning where continuous
learning and production of reliability without truth including truth about people's behaviors
replace the production of temporary truth and their justifiability verifiability contestability
i would say what relates algorithmic governmentality also to cybernetic is of course the
overcoming of the notion that that of the of the separation of calculation and things
of of contents and matter and so on it resets a new kind new ontology but which is completely
disarticulated from from the notion of of of a human subject
so i don't know if it responds to you to your question i'm sure it does somehow definitely
um i would be interested because i think you have described a lot of your critique already i would
be interested in what you argue for actually so i would be interested in what is your proposition
what would you bring in against algorithmic governmentality well um i i think of course
my posture here is more descriptive of something uh which is uh which is which amounts to
capitalism on capitalism and neoliberalism realism on algorithmic steroids i know it's
not fashionable to say that uh but i think we would need uh maybe a constitutional moment
a moment uh well a moment wherein we think about a concept what is a constitution a constitution
is a text by which the present the people who are present and who sign the constitution limit
their own power they limit their own power they promise a little bit like you know
charged nature with that task of producing an animal who can promise and keep its promise
constitution does that in fact it it forces those who sign to consider
a lot of things which are irreducible to the mere optimization of the current situation or the state
of state of facts uh it allow for the consideration uh a political constitution allow for the
consideration of those who have not yet left any digital trace that can be enrolled in the calculation
of the optimal it means that it allows to preserve the space and time which would not
be preoccupied by the bulimic appetites by those who have been granted including by algorithmic
algorithmic systems granted with the force without law which allows them to transform
the virtual the not yet there the possibilities into into surplus value
so it's it's uh i think we have to find ways to enforce uh new uh a new intelligence of
limits a new intelligence of limits because uh this intelligence of limits which life itself
has very well as a kangelem has shown us that normativity of life itself but we have to to
to to find that there are several kinds of because i'm a lawyer by so i maybe i'm a bit
distorted as all lawyers but i'm distorted uh uh and i try to go back to my own discipline you know
as a as a safe island um but we have instruments uh the constitution we have the notion of
institution what is an institution it's all that algorithmic governmentality tries to um
to render obsolete in fact um the notion of according to david yume uh the role of institutions
is in fact to force the agents you me uh elon musk uh donald trump everyone to force people
to transcend the partiality of their natural sympathies you know um david yume was not for
the social contract because he among other reasons he thought the problem of our society of society
is not the egoism of individuals in fact people are not egoistic because they can sacrifice
themselves for for the the ones they care for for their children and so on the problem is the
partiality of these natural sympathies and only institutions can force people to refrain uh from
their uh impulsion or compulsion to optimize that is to to to take the most they can of the present
and of the future and of everything that is that is there and only only institution can force them
to consider what is not already there for them to consume in fact so we we need that we need that
no we need to rethink the role of kind of institutions and but fast because we don't
have much time in front of systems in fact that push everyone uh towards self-optimization and
consumption of of everything that's what i said at the beginning algorithmic
governmentality is a way of fragmenting all collectives immunizing i would say capitalism
against all and every form that should and and would in fact interrupt its flaws that is the
world the material world and its limits the social the social the collective it fragments the
collective it's a it's a high resolution which is also a high dissolution and life itself in fact
life itself with with its own uh negantropic regulations that i i really believe that
nick land was right when he said that there is a common teleology between cybernetics and capitalism
and that terrible uh teleology is really necropolitic i believe so that that's the
reason why we urgently need to reconcile with the notion that uh anyway we have to invent
the forms including the political forms the institutional forms the constitutional forms
which uh institute our life in common and alain supior had it right when he said the
anthropologic function of law is to articulate together the different facets of human being
these facets being the physiological the symbolic and the social if we agree to translate or to
consider that all these different facets or layers are transcriber or reducible into
reducible to pure flaws of of digital computable data and that this is enough for us to to to
to govern ourselves i think we do a big mistake i think i would have to kind of dig a little
deeper into this answer because um i guess it's not as simple as simply reverting back to like
the law as it was the uh sovereign as it was the individual as it was so if we want to find
answers to this as you frame it kind of assault of algorithmic governmentality then first of all we
would have to ask are they the the proper tools in terms of are they adequate for the task and then
of course i think we had we would have to rethink them because i mean they are not innocent in
themselves the law is not innocent the the the liberal subject for sure is not innocent and so
on so i would like to know at some point maybe this would be a good good example at some point
you state that you think that actually we would have to stick with the fictional individual
because it's kind of operationable it serves a purpose and that we need this purpose and
while knowing that it is a fiction we still need it and i was wondering how far you would go with
these things because i think it's kind of a play with fire but maybe positively speaking it's
staying with the trouble in terms of done a hero way but i would be interested um whether or not
we would have to kind of rethink these elements that you bring forward against algorithmic
governmentality yes i think my response will be much simpler than your answer
i'm afraid but i must state what's a subject for me what's the form subject for me the form subject
is the content is void subjects are processes in constant overcoming of themselves subjects are
becomeings there are processes of individuation processes of subjectivation and so on so
notion of subject is eminently dynamic so i'm not nostalgic at all of the subject conceived as the
as the liberalism conceived it as its fundamental unit unitary master of its own intentionality
separated from others and so on not at all my notion of the subject is completely different and
i have come to consider that the subject the role that the subject plays the subject is a point of
view it's nothing else than a point of view so the world needs the subjects because the subject
is the point of view from which objects may appear despite their ontological indetermination
um as barad and so on uh would say and at the same time subjects need objects because also
objects reflect their own position so it's a it's really a notion of the subject as um
both as power subject as power of individuation or as a potentiality of individuation has never
completely enclosed in any present but it's a process that is lived and experienced and
constructed and deconstructed all the time over time over always over time so my notion of the
subject is a heterochronic notion it's absolutely heterochronic that's the reason why uh the uh
absorption in in the pure vortex of real time of everything by algorithmic governmentality
is absolutely inhuman it's not habitable because we we are we are over time so that notion of the
subject i think the subject like an actor it is because i'm a lawyer the notion of person persona
person is the mask it's a mask that people put on their face when they have to act uh on a stage
on a stage but also on the stage of the of the of a judicial court for example
the notion the person is is inseparable from all the kinds of editorializations
that we perform all the time but we are we are nothing else we are nothing else than these
editorializations there is no subject without a form the form is the subject so that's the reason
why the legal subject for example is is a functional fiction it's something that the law needs
but it's but but the law knows that it's a fiction it's a place it's a location from which
to make one's situation or the situation of the people who share an existential experience of
discrimination for example together being a person before the law is being able to give account
of injustice felt injustice felt problems to in fact it's a way of mattering and of determining
or contributing to the definition of what matters what's a problem and what needs solution so it's
quite pragmatic i would say but not only it's not only pragmatic i think it's also in a way ontologic
but it's an ontology which is absolutely non-essentialist before asking my last
question i would love to go to a place where we have been today in this workshop already
i'm very much interested in this question of alternative arts of government and there's this
famous quote by fukuh which i read out today earlier already and the quote goes what
governmentality is possible as a strictly intrinsically and autonomously socialist
governmentality in any case we know only that if there is a really socialist governmentality
then it is not hidden within socialism and its texts it cannot be deduced from them it must be
invented and quote and as i understand it your critique is a critique of algorithmic governmentality
as a techno capitalist governmentality and not all of it will necessarily apply for other uses of
these technologies in other contexts so maybe let's turn to the the question of construction again
to the question of alternative in a positive sense what could this invention of desirable
alternative governmentalities look like well i completely rejoined you when saying that you
know and that's the the virtue of problematization is is to avoid technological determinism or you
know today technologies are the ideal uh how you say scapegoat all the problems are
we project all our problems on technologies it's because of of social networks that democracy is
dysfunctional it's because of no no it's much broader than that uh of course so i i think
there's no fatality in the fact that these uh technologies today are used in order to
to boost uh capitalism and to accelerate uh to accelerate uh towards uh towards apocalysm
apocalypse by apocalypse i mean precisely not the end of the world but the the end of the end of
capitalism in fact um the smartness the smartness of these technologies is precisely
that's uh through big data and machine learning we can become
aware we can see regularities of the world which are only observable on on huge numbers
so it's a question of scale so in fact what they produce also what they can produce are alternative
maps of the world and of events which can be very interesting for i give you an example there are a
lot of discussions today about the possibility the legitimacy or the opportunity of using
algorithmic systems in in the judicial uh in the judicial system algorithmic decision making
as to help judges for example and so on to take decisions um in fact what would be interesting
what is interesting is that big data analytics allow for example to give to to to give to the
judges a mirror of how the law functions you know it can give it can give very precious
informations about the state of the law as it is practiced what kind of decisions are taken and so
on so as a as a we can look at ourselves in big data and it gives us an image a certain image
which is not deprived of a point of view because algorithms have point of view
uh point the point of view of an algorithm i would say it's its objective function it depends of oh
how the algorithm has been constructed and so on it depends on what kind of sensors are used to
collect the data what kind of data are considered noise and what kind of data are considered signals
and so on so there are point of view but it can allow us to be uh alerted
about specificities or singularities of the world that we would not or of our
or of our own behaviors that we would not notice otherwise so it can increase our intelligence
instead of depriving us from intelligence the risk being of course that we overestimate the
objectivity the scientificity of these productions no they are not more scientific not more objective
than human judgment it's just that the world is looked at from a different perspective
when looked at from the perspective of an algorithm we have to know about all the
biases the basis of the humans but the basis of the algorithms as well and there are a lot there
are a lot and and they're difficult to to detect sometimes because for example the distinction
between uh what is a signal and what is noise is not decided by an institution in algorithmic
governmentality it's it is just uh it is set it is that distinction is set in a in a way which is
undergenius to the the socio-mediatic reality so it's evolving all the time so it's quite
difficult to know exactly what the point of view of the algorithm is and that's the difficulty
that's the difficulty but that difficulty is quite interesting in itself because it it it instills
it instills trouble if we are if we keep attentive to these difficulties
so that's the reason why i i don't meditate for algorithmic transparency for example which is
it's a complete stupidity from my perspective not only it's unattainable because the the
inductive logic is not even easily translatable into into a linear language understandable by
the humans but but it would be really attenuating the enchanting alien logic or the enchanting
view from somewhere else which we really need in order to to to boost our imagination also so i
think it it can if algorithmic systems can de-automatize our own thinking that would be
quite great okay in order to have some time for open discussion i will ask my last question
question which is always if you think about the future what makes you joyful
that's maybe the hardest one for the moment if i think about the future what makes me
joyful i think maybe but i'm not the the first one to say that uh that that impression that
the apocalypse has already arisen and that we are what remains i think slavosh dzek said that
and i find that a nice logic because you know if you think that the catastrophe the absolute
catastrophe has already arisen which is not impossible in fact then we have nothing left
to lose you know except that we we now have to organize ourselves to um to become to become
human to become human to to stop behaving like inhuman persons and there is much work i think
to attain to that non-inhumanity i prefer to speak of non-inhuman uh because it's less
segregative than affirming a human essence but i really like that double uh double negation i
think it's that double negations are are really uh are really interesting and really dialectical
and there may be the core of of of what makes us human that ability you know it's also zizek who
said that and i agree with him uh what you know what an artificial intelligence will never never
understand is the difference between uh coffee without cream and coffee without milk
but we can we understand there is a difference because we are affected differently by the lack
of cream or the lack of milk depending of our tastes um so that's what we have to preserve
i think and that's that's that's dialectic that's dialectics and i think uh well that's one thing
that makes me happy another thing that makes me happy uh or even joyful is are of course my my
kids whom i i find so so intelligent and so marvelous and yes that's it i guess
okay antonette thank you so much for being part of future histories
thank you thank you for your patience and your attention
that was our show for today thanks a lot for listening if you want to support future histories
you can do so on patreon for this visit patreon.com slash future histories or you can simply tell a
friend that you like the show and that he she or they might like it as well thanks a lot and
hear you in two weeks
