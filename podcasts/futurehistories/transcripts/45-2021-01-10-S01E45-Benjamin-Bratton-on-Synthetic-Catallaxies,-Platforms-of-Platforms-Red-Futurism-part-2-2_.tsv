start	end	text
560	1940	Welcome to Future Histories.
1940	5360	My name is Jan Gross, and what you are about to hear today
5360	7680	is the second part of an interview I did
7680	11360	with Benjamin Bratton in the context of a guest lecture
11360	13080	that I was invited to hold
13080	16200	at the Goldsmiths College in London.
16200	19440	Before we start, I want to thank Carmen, Florian,
19440	22800	and David for their kind donations.
22800	26560	But now please enjoy the second part of the interview
26560	30440	with Benjamin Bratton on Synthetic Catalaxy's
30440	34680	Platforms of Platforms and Red Futurism.
40000	42600	With more than one of my guests, I have hit a wall
42600	45400	when asking how post-human political constellations
45400	46920	could actually look like.
46920	49660	Your writing and thinking, as we just experienced,
49660	51420	is very illuminating in that regard,
51420	53740	and it absolutely confirms my suspicion
53900	56740	that the idea of the individual in the strict sense
56740	59180	needs to be overcome in order to really get
59180	62720	to fundamentally different sociopolitical arrangements.
62720	66180	You advocate for the disindividuation of the user position.
66180	68220	Could you explain what you mean by that?
69480	70320	Sure.
71660	74700	So this also goes back to the interface layer discussion
74700	78060	that we had about the ways in which the interface layer
78060	82860	can be, is a kind of map, operates as a kind of map
82860	84480	of the way in which the system works.
84480	87060	And I don't mean to, it sounds abstract,
87060	90340	but I mean it, again, just to remind your listeners
90340	92460	in this very simple sense of,
92460	94260	there's lots of things you can do with your computer,
94260	97500	but the graphical user interface presents you trillions
97500	100300	of things you could do, build a bomb, do whatever.
100300	103020	But the graphical user interface presents you
103020	106880	with this mechanism of several dozen menu options
106880	108740	that you sort of pick and choose.
108740	113740	So it's, part of it is that in this,
113780	117460	a little bit has to do with the history of interface design,
117460	122460	there is a presumption that is built into
124140	126420	the interface structure that we're talking of,
126420	130540	that the way in which the system should present itself
130540	135540	to human users is one human user at a time.
135700	140060	That the fact that our culture of interface design
140060	143240	is built around this sort of individuated,
143240	147220	psychologized, single-serving homo sapien user,
148100	151980	separated from other single-serving homo sapien users
151980	154500	in and of itself is not,
154500	159240	is not, we take it as a highly naturalized condition,
159240	161520	but it's not necessarily,
162460	165020	it's not necessarily historically,
165940	170400	it's a highly contingent kind of arrangement.
170400	174020	We have lots of interfaces that are meant for plural,
174020	177140	a plurality of users, like traffic signals.
177140	179300	A traffic signal is an interface system
179300	181580	that doesn't make any sense for one user,
181580	183460	I mean, for users at a time.
183460	185580	The whole thing, like it's green light for me
185580	187540	because it's red light for you and yellow,
187540	191180	and something that we all recognize that the way
191180	193420	in which the street interface is presented to me
193420	195580	is conditional in relationship to other users.
195580	200580	And we are, once you sort of, when it's green light for me,
201460	203460	I am a green light user of the street
203460	205340	and you are a red light user of the street.
205340	207300	And therefore I know what you're going to do
207300	209300	because you're a red light user.
209300	213340	And we're all in a way interpolated through this interface
213340	217020	as being red light, green light drivers in this sort of way.
217020	220340	But also we understand and can negotiate the relationship
220340	223140	with each other in this differential.
223780	224620	If it's made clear.
224620	227180	So the traffic again is a kind of simple example
227180	230460	of what a plural interface would be.
230460	235100	Now, in a stupid sense, Facebook attempted to make,
236300	238620	in a way attempted in social network software,
238620	241140	attempts to make interfaces
241140	243540	that are meant for pluralities of users,
244620	247740	but do so in a way that I think are actually,
247740	251860	that actually concretizes and refortifies
252420	255700	the fiction of the autonomous individual
255700	257940	in relationship to those, in relation to the kind of thing.
257940	261220	It produces a subjectivity.
261220	263100	And in our society, as I mentioned,
263100	266020	subjectivity and agency are utterly conflated.
266020	269540	And within the kinds of interpolations of the user
269540	271220	that you see in social media software,
271220	273580	that this conflation is not only re-emphasized,
273580	278580	but there's a construction of a social subjectivity,
278580	283460	of a social subjectivity of this individuated user
283460	286540	as this kind of encaps, self-encapsulated,
288660	292300	sort of piloting creature of its own data
292300	296420	and its own presentation of self-identity
296420	298700	in relationship to this.
298700	302700	One of the arguments that I sometimes make,
302700	307380	find myself making arguments against the,
307380	311900	making arguments against those whose primary concern
311900	314340	with the social function of planetary's computation
314340	316300	is in terms of surveillance.
317940	321100	And the argument that I make is basically twofold.
321100	322620	One is that,
326900	328260	one is ultimately,
328260	330260	I mean ultimately comes down to the term surveillance
330260	332060	has been overinflated to describe
332060	334500	so many different kinds of ways in which we would sense
334500	336540	and model and construct images of the world,
336540	338060	that it's beginning,
338060	339540	that we have a kind of a surveillance,
339540	341300	anti-surveillance bubble.
341300	343980	That climate science and the way in which we would sense
343980	345180	and model and structure the world
345180	347260	is also a giant surveillance regime,
347260	349020	if you really want to think about it this way.
349020	351300	But the key point in relationship
351300	352660	to what we're discussing is
354100	356580	using planetary scale computation
356580	359220	for the sensing, modeling and prediction
359220	361940	of what individual homo sapiens
361940	365140	are likely to wanna look at next and click on next
365180	367620	in which kind of video or funny picture
367620	369260	they're gonna wanna see next
369260	374260	is incredibly tragic misuse
374540	376740	of planetary scale computation as a whole.
379420	381820	It goes deeper than the fact
381820	383620	that these people are being surveilled, right?
383620	387020	And so you think of the Shoshana Zuboff kind of critique.
387020	391340	The problem is not just that you have these individual people
391340	394180	are constructed and are being observed and tracked
394180	395540	and surveilled and manipulated
395540	396660	by these large scale platforms.
396660	397660	This is a problem.
397660	400220	This is a tragic misuse of the apparatus.
400220	403740	The deeper problem is that society is,
403740	406340	is it through this individuated interpolation
406340	408500	of the user as the user as this figure
409540	412900	is that society is being defined and constructed
412900	417620	as the aggregation of these atomic individual subject,
417620	420780	agent, actors in the first place.
421380	424420	It's a misrecognition of what a society is.
424420	428420	It's a misorganization of how it is that the relations
428420	432940	between a social species such as humans is constructed.
432940	437420	It is absolutely 100% predicated, I believe,
437420	442420	upon the kind of self-congratulatory self-atomizing logics
445460	449460	of liberal individualism and legal subjectivity,
449460	452700	which of course is why someone like Shoshana Zuboff
452700	454700	can't make this critique at that level
454700	459700	because as someone from the world of the law,
460340	464700	this formulation of society as an aggregation
464700	467100	of self-transparent and self-sufficient
467100	470780	atomic liberal individualisms is a sacred concept.
471860	474980	And so the only thing that she's able to do is to say
474980	479100	that these sovereign individuals have been
479540	484540	manipulated into forming improper contractual relationships
485940	487020	with these institutions,
487020	490020	these manipulated contractual relationships,
490020	495020	and that we need to resolve this jurisprudence
499180	501180	to make these contractual relationships
501180	503500	between these sovereign individuals and these platforms,
503500	505740	in fact, more fair and more transparent.
505740	507420	And I'm arguing is that, no,
507420	509820	it's this hyper-individuation of society
509820	511260	through that usually that's the problem
511260	513300	and that's a much deeper problem.
513300	515820	This is something I think that Ghani and I also agree on,
515820	517860	I think, in terms of some of the things
517860	519060	that he's written about Zuboff.
519060	523500	I think it's that we probably have a common interest
523500	528500	and common point about that as well.
530540	532580	So part of the question then,
532580	535300	to your question of this multiplication of the user layer
535300	536140	here has to go with,
536140	540900	is also an understanding of ways in which we can learn
540900	543180	to think about our subjectivity and our agency
543180	544580	in relationship to these systems
544580	549100	that is not through this lens of this kind of figure.
549100	553580	Now, the other thing I should say is two points on this,
553580	556940	I think, examples that I think will kind of specify
556940	559180	what I mean as possible alternatives here.
560660	564500	One is, and I just finished this book on the pandemic,
564500	565940	which I just wrote for Verso,
565940	568140	which will be coming out in June.
568140	570260	It's a book called The Revenge of the Real,
570260	572460	post-pandemic politics.
572460	574380	And one of the things I talk about in this book
574380	577300	is what I call the epidemiological mode of society.
577300	581020	That is one of the things that we learned from the pandemic
581020	585860	was to see society the way epidemiologists see society.
585860	588100	Epidemiologists don't see society
588100	593100	as a bunch of atomic monads
594620	596500	that happen to once in a while
596500	599500	enter into contractual relationships with one another.
599500	603620	They see society as a kind of landscape of organisms,
603620	606020	each of which is a medium
606020	608140	for the transmission towards one or the other.
608140	610700	But they see it in terms of a kind of
610700	613900	aggregate biological population scale
613900	616940	that indeed is, I think, a good lesson for us to learn.
619180	621740	It's a conceptualization of society
621740	623380	that we should bring forward with us
623380	626220	into a post-pandemic world,
626220	629820	and I think is one that is more accurate,
629820	632620	more social, and more viable
632620	637620	than the kind of atomic individual version of this.
637940	640260	The other point in terms of the plurality of interfaces,
640260	642380	part of the longer term, what now,
642380	644340	what should we do next question is,
645580	647580	it's not enough to take back our data,
648900	651020	because the data that we would be taking back
651060	652500	is not the data we need.
654540	656300	Because something like Facebook,
656300	658060	and this is also where Zuboff and I
658060	660420	would depart from each other,
660420	662460	it's not enough that Facebook,
662460	665980	because Facebook has mismodeled society so tragically,
665980	668820	that its model of society as this aggregation
668820	672820	of acquisitive atomic individuals
672820	676180	is such an inaccurate model of society,
676180	680140	that I could say, here you go, you got it all.
680300	684220	Here is all of the information on all of the Facebook users,
684220	686660	all four and a half billion of them or whatever,
686660	689140	all the likes and all the cat videos
689140	692020	and all the conspiracy memes and all the rest of this.
692020	693860	Here it is, you have it.
693860	697300	The government of whatever, EU, take it all.
697300	698140	You've got it.
698140	701060	Now use this to solve climate change.
701060	702580	Go.
702580	704860	You can't, it's the wrong data.
704860	709860	Data about what it is about this model of society
710460	712860	is not the data that we need.
712860	714860	And this is kind of the other,
714860	718860	so taking it back from Facebook is useless.
718860	721100	What we need is to produce the right data.
721100	723580	What we need is to actually understand
723580	725620	what data would we need
725620	728060	in order to actually enter in these transformations.
728060	730580	And so simply think is that to simply,
730580	734620	again, to reclaim the property of the data
734620	737300	that Facebook has produced about us
737300	742060	isn't enough because in essence it's the wrong data.
742060	743940	So anyway, those are some thoughts on this question
743940	747820	about the user position, the necessity for its plurality,
747820	749660	the problems of its over-individuation
749660	752660	and where my thinking sort of aligns and differentiates
752660	755660	from some other people who have thought about it.
755660	756740	Super interesting.
756740	759500	And I will skip the question on the UBI,
759500	762220	which would be a kind of riddle
762220	764620	on how to actually apply it on.
764660	767340	I can say something real quick about it if you like.
767340	770300	So because it connects with the catalaxy idea.
770300	772140	Part of, I think the more convincing argument
772140	773540	about universal basic income
773540	775940	also has to do with a kind of distortion.
776940	780260	And I think it's a distortion in the value
780260	783620	that society gets from its own participants,
784900	786740	that there is a distortion in this.
786740	789300	And I don't know if you call it a price distortion.
789300	790900	I think that might be a bit awkward,
790900	794340	but it is a distortion of value at the very least.
794340	799340	When you have a comp lit PhD making coffee
800140	803660	because that's the best job that she can get,
803660	808500	even though the contributions that she could make to society
808500	813500	are so much greater than the provision of cups of coffee,
814500	816020	there's a distortion at work.
816020	820220	Or when you have a genius,
820220	825220	some genius kid doing other kinds of menial work
825660	828140	because they need to support themselves,
828140	831740	because the provision of basic food, shelter,
831740	835740	healthcare or whatever is only available to them
835740	840740	because they are trading most of their working hours
841020	843540	for the provision of these basic things.
843540	847180	Society as a whole is not getting from them
847180	849340	what we should be getting from them.
849340	854340	That there is an entire second economy worth of value
856780	861660	that is being suppressed by the under participation
861660	866180	of people doing things that are trivial
866180	870740	compared to their real talents and capacities to contribute.
870740	872460	And so I see this in some ways,
872460	875420	you could see this in a way as a distortion
876060	880220	of social value that is much greater
880220	881660	than anything high equity side
881660	883340	with the socialist pricing problem
883340	885340	of how much the bananas should cost.
886340	889700	This is trivial compared to what we're missing out
889700	892980	from a lifetime of work of people doing something
892980	896460	that quite easily could be done by machine
897340	900460	if we were allowing them to do so.
900460	904420	And I think when I think about the long-term value
904420	907300	of something like UBI in terms of how to measure this,
907300	909660	how to price it or kind of something like this,
911580	913420	this is the sort of the bigger picture
913420	916020	that I'm trying to keep in mind
916020	919180	is not having to do with does it cost more or less
919180	921540	than some other kind of welfare policy?
921540	922700	Does it cost more or less
922700	923980	in the relationship of this as well?
923980	926180	But rather that in the long-term,
926180	928180	what does the world look like
928180	933140	when the true social catalaxy is possible?
933140	936780	When it's actually possible for people to contribute
936780	939140	to the production of society one with the other
939140	942180	in ways in which half their time is not being produced
942180	944980	on something idiotic and trivial and depressing.
946860	947740	In order to get there
947740	950460	and you touched up on it before already,
950460	952460	we need different kinds of data.
952460	955900	And so let's talk about data governance
955900	958540	since this is actually essential to more or less
958540	960700	all of the topics we discussed today.
960700	962220	If I understand it correctly,
962220	964780	you state that on a very fundamental level,
964780	968580	there's basically always a kind of Potemkin ontology at work,
968580	970180	which, and I quote you here,
970180	974140	attempts to reduce reality to the level of complexity
974140	977660	that the control system is capable of thinking with,
977660	978500	end quote.
979380	981620	You touched upon this already before
981620	984060	quite at the beginning of our talk.
984060	987100	I'm asking myself if this leaves us with a battle
987100	989500	around the agency of different models
989500	992140	that are used to interpret data
992980	997100	and I'm also asking myself if and how one can successfully
997100	999980	incorporate the reductiveness of one's model
999980	1003380	into the way the model is being applied.
1004660	1006220	Sure.
1006220	1007060	Yeah, good question.
1007060	1011300	So there's a kind of a philosophical approach to this
1011300	1013740	and more of a practical approach to this
1013740	1016300	and maybe they can converge at some point,
1016300	1019100	but just to sort of restate the question
1019140	1021900	in a different way that,
1023620	1024780	first of all, I should say that,
1024780	1027260	I think part of the way in which approach this
1027260	1029900	is to think of data not as something that's extracted,
1029900	1031260	but as something that's produced.
1031260	1034260	Data is produced about a phenomenon.
1034260	1036940	Data doesn't exist out in the wild like strawberries
1036940	1039420	where you can go and pick it and bring it back.
1039420	1040780	It is produced in such a way
1040780	1044420	that you can have 10 data scientists
1044420	1046620	approach the same strawberry field
1046620	1048140	and ask them to make a model of it
1048140	1050780	and you get 20 different models of the strawberry field,
1050780	1053940	each one of which might be statistically,
1053940	1056420	scientifically accurate based on the questions
1056420	1057980	and preconditions that it's asking
1057980	1059900	and what it's looking for.
1059900	1063220	And it's not necessarily one is more true than the other
1063220	1067460	anyway more than like, you can say the word strawberry,
1067460	1070540	you can say the phrase strawberry field in English
1070540	1073020	and French and German and Dutch and Italian
1073020	1075100	and they're all true.
1075100	1077660	It's not that, obviously English is more true
1077660	1079060	than all of the other ones.
1079940	1082980	I'm joking, but none of the languages are more,
1082980	1085260	the ontologies of the language are none of them
1085260	1086300	are more true than the other.
1086300	1089140	They are sort of producing a symbolic differentiation,
1089140	1090420	a symbolic reference of this one.
1090420	1093460	This is how I think about quantification as well
1093460	1094500	in a certain sense,
1094500	1097660	though that there are ways obviously then
1097660	1102660	that the value of the model works
1103660	1108660	not only in terms of its capacity for rhetorical rhetorically
1108780	1112420	but also for its value in terms of realism
1112420	1117420	and direct mimetic relation to the described.
1118180	1122260	This is why we have things like astronomy and so forth.
1122260	1124100	So what I mean by that is this,
1124100	1126020	there's at least three different kinds of models
1126020	1127300	that we want to be talking about here
1127300	1129060	in terms of governance.
1129060	1131340	There are descriptive models, predictive models
1131340	1133220	and projective models.
1133220	1134900	And they have different social functions,
1134900	1137020	they have different epistemic functions
1137020	1139140	and they have different political functions
1140100	1141780	and scientific functions.
1141780	1144700	A descriptive model basically is a model
1144700	1149340	that's value is produced according to its correspondence
1149340	1151500	to a mind external reality.
1152340	1156100	In that heliocentrism is a reductive model
1156100	1159060	of the solar system that it can be described
1159060	1162260	by a series of styrofoam circles.
1163140	1165380	It's a highly reductive model of the solar system
1165380	1167660	but it's one that is more accurate
1167660	1171820	in its representation of the solar system
1171820	1176340	than a geocentric model of the solar system is in this way.
1176340	1179540	Its correspondence to the real is the basis of its value.
1181500	1184060	And that there's a politics of this
1184060	1185740	in the sense to which it obviously has to do
1185740	1187220	around the issues of climate science
1187220	1189460	and our ability to, for example,
1189460	1194380	is to produce a model at planetary scale
1194380	1198820	of planetary material ecological processes
1198820	1201540	that we believe to be accurate in the same way
1201540	1203580	in which heliocentrism is accurate
1204620	1208860	that would therefore give us confidence
1208860	1211260	for acting recursively on its behalf
1212900	1216500	because we have confidence in its representational capacity.
1216500	1218580	But importantly, it's also one that,
1218580	1220700	as I've mentioned before, that that model,
1220700	1224060	just the way in which heliocentric astronomy
1224060	1225180	could never have been produced
1225180	1227740	without the technical abstraction of the telescope,
1229100	1232980	the concept of climate change and planet earth science
1232980	1236540	and that capacity for us to understand those processes
1236540	1240780	with a realist model at any degree of sophistication
1240780	1243180	is also dependent upon the technical abstraction
1243180	1244860	of planetary scale computation.
1246500	1247340	That's in fact, again,
1247340	1249820	what planetary scale computation is for.
1249820	1252020	There's also then a predictive model.
1252020	1254100	So predictive models have to do with the value
1254100	1255980	of the predictive model is not necessarily
1255980	1258620	in how much they correspond to the real,
1258620	1261580	but in how much they allow you to anticipate
1261580	1263020	what is likely to happen.
1264300	1265940	A simulation is to some extent,
1265940	1267700	a kind of a blurring between the predictive
1267700	1269420	and the realist model in this regard.
1269420	1271140	It's particularly in terms of climate structures,
1271140	1274540	but more stronger predictive model
1274540	1275940	is more like what Wall Street does
1275980	1276980	where they're trying to figure out
1276980	1280540	what the likely price of Bitcoin is going to be next month
1280540	1283740	or whether it's gonna make more sense
1283740	1288740	to put money in Microsoft or Alibaba or something
1290060	1293380	where the value of it has more to do
1293380	1295260	with just the ability to predict
1295260	1296620	what is likely to happen next.
1296620	1298540	It's a kind of perspective heuristic.
1299580	1301980	But then there's also then the projective model.
1301980	1305900	The projective model is a normative model.
1305900	1308380	It's a model that's not describing
1308380	1311980	what is happening right now empirically.
1311980	1313380	It's not a model that's describing
1313380	1315460	what is most likely to happen.
1315460	1317660	It's a model describing what should happen,
1318580	1320980	what should happen, a drawing of what should happen.
1320980	1323140	And so architecture, for example,
1323140	1326420	most of its expertise is with the perspective model.
1326420	1328420	It's you don't hire an architect
1328420	1331020	to make a model of a building that already exists.
1331020	1332580	You don't hire an architect to make a model
1332580	1334820	of a building that's most likely to happen.
1334820	1336540	You hire them to make a model of the building
1336540	1337540	that should happen.
1338620	1342140	And part of the role in I think both for politics,
1342140	1345540	for design, even for political science
1345540	1350540	is in the construction of projective models
1350700	1355700	and prospective models based on descriptive models
1355700	1360700	and grounded in descriptive models
1361220	1365980	such that we have some ability not only to predict
1365980	1369700	what is likely to happen in the case of climate catastrophe,
1369700	1372620	but also to actually model what should happen.
1372620	1375700	And so your question about where does governance
1375700	1377940	and politics fit into this direction of data,
1377940	1380180	I think there's at least three different answers
1380180	1383140	to this question in relationship to the descriptive model,
1383140	1385180	the projective model and the projective model
1385180	1389180	that there's a logic for of how it is that we,
1389180	1391420	for example, how it is that we might describe
1392380	1393980	the planetarity that we want,
1393980	1398980	describe what a viable planetarity is in a normative sense,
1399540	1402660	in a projective sense, in an aspirational sense
1402660	1405420	through the models, through its models
1406620	1409060	that is also dependent upon the use of models
1409060	1414060	to actually produce some kind of reliable description
1415060	1416820	of the circumstance.
1416820	1421260	And you can imagine, you can imagine,
1421260	1422740	sort of skipping forward a little bit here,
1422740	1425580	but you can imagine the ways in which this kind of,
1425580	1427580	where algorithmic governance,
1427580	1430300	which again would imply both how we govern algorithms
1430300	1433060	and how we algorithms become part of the governing function
1433060	1436260	more generally, how it is that algorithmic governance
1436260	1440820	could become so ingrained in how it is that we function,
1440820	1443820	how it is the city functions, how it is that states function,
1443820	1446100	how it is the corporations function and so forth and so on
1446100	1449100	that you can imagine something like a political party
1450060	1454820	that is basically a software stack
1454820	1457780	where you could imagine you've got four political parties
1457780	1462020	all vying for being for the city government.
1462020	1463780	And each one of these political parties
1463780	1465620	is in essence running a simulation
1465620	1469940	of what they think the city of the next few years
1469940	1472260	is going to be based on the variables
1472260	1473940	that they think is important
1473940	1476900	based on what their political ideology is,
1476900	1479580	running this in a sort of massive simulation
1479580	1480980	of what this future would be.
1480980	1482260	And then the voters decide,
1482260	1485860	I'm going to like party number three wins the election.
1485860	1488700	And once you win the election, your servers go live.
1489660	1494660	And that in fact, and that becomes the basis of the city.
1494660	1498860	I mean, this is one way of sort of thinking about that,
1498860	1500660	thinking about that kind of dynamic.
1501580	1503980	There's a bigger question though, again,
1503980	1506980	around sort of the longer term arc of this
1506980	1510780	of not just how it is that the data can be used
1510780	1513260	within the existing political institutional structures
1513260	1517860	that we already have, city governments, state governments,
1517860	1520140	country governments, UN, whatever,
1520140	1524140	but the ways in which that at a certain scale
1524140	1528340	and at a certain point that it becomes a qualitatively,
1528340	1533340	it constitutes and enables qualitatively different forms
1534300	1537900	of governance per se that could not have existed otherwise.
1537900	1540700	And that not only demand,
1540700	1544860	but indeed already constitute other institutional forms
1544860	1545860	in the first place.
1545860	1550860	And it should be clear while I'm interested in the former,
1552780	1556540	how would it, with my servers going live scenario,
1556540	1558660	my longer term interest is in the latter.
1558660	1562020	My longer term interest is in how planetary scale
1562020	1566780	computation as a whole constitutes the basis
1566780	1570140	by which it becomes possible, perhaps for the first time
1571740	1575300	for an always already planetary scale human society
1576980	1581540	to be able to produce reliable technical abstractions
1581540	1586060	about its own processes at a scale commensurate
1586060	1587700	with those processes itself,
1587700	1589940	which is to say planetary scale,
1589940	1592820	that would allow for a reorganization
1592820	1597820	of some of the fundamentals of a economic, political
1598820	1602820	and ecological circumstance.
1602820	1605260	That is where I try to link this question
1605260	1606500	of planetary scale compilation
1606500	1609500	to some of the questions of planetarity per se
1609500	1612420	that animates the work of people like Spivak or Mbembe
1612420	1615060	and where they have an emphasis on literacy,
1615060	1616860	which in my mind is a bit more numeracy.
1618020	1623020	The bigger question of how it is that it's possible
1623820	1628820	for collective reason to be made to manifest itself.
1629620	1634180	How is it possible for society to compose itself?
1634180	1636580	And I think one of the things we've seen in the pandemic
1636580	1640820	in the West, the calamity of how the West has dealt
1640820	1645180	with the pandemic is a dramatic example
1645180	1650180	of how much the West is now unable to compose itself,
1650180	1655180	unable for a society to organize itself in a kind of way.
1655980	1659780	Certainly the United States and UK and Italy
1659780	1664780	and Germany are some of the more tragic examples of this.
1666740	1669140	But this is the real question
1669140	1672780	of how can a society sense itself
1673740	1675900	so that it knows what's going on?
1675900	1678380	How can it model itself in different ways
1678380	1681540	so that it can produce multiple and different conceptions
1681540	1684100	of its own collective image?
1684980	1687820	How can it simulate its possible futures
1687820	1691620	so that it understands what its possible capacities are?
1691620	1694060	And then how can these models of the future
1694060	1697060	recursively act back upon that society
1697060	1699900	so that it is able to manifest this capacity
1699900	1702500	for self-composition and collective reason?
1703780	1705340	That's what data governance is for.
1705340	1706700	That's what data governance is, I think,
1706700	1707860	to be in the long-term.
1709500	1713020	Fantastic. Benjamin, I would like to leave some time
1713020	1714540	for the students to ask questions,
1714540	1717540	but there is one closing question
1717540	1719340	I'd like to ask all of my guests.
1719340	1721580	And that is, if you think about the future,
1721580	1723180	what makes you joyful?
1727940	1730380	I'll just give a simple answer.
1734300	1736500	My son, my 12-year-old son,
1736500	1738660	I have more the idea of thinking about
1740100	1744020	just the process of watching him understand
1744020	1747300	more and more of how the world works around him
1747300	1750260	and seeing his interest and frustration
1750260	1751100	in the rest of this.
1751100	1756100	And so, probably the ability to think about
1757420	1759740	the world that he will grow up in
1759740	1761580	and the world that he will sort of go through
1761580	1763300	and just sort of think about it on that arc,
1763300	1767260	it kind of gives you, there's just a sense of,
1767260	1770900	there's a sense of the stakes of what's at stake,
1772060	1773540	what's at stake for the future
1774620	1777420	and where, sort of, to mean.
1777420	1780820	So, I mean, that's, I mean, it's a simple, stupid answer,
1780820	1782220	but it's really, you know, like the most,
1782220	1784860	that kind of like immediately honest one.
1785860	1787460	You know, more philosophically,
1787460	1789740	it kind of depends on what we mean by the future.
1789740	1791820	You know, there's a, we have a problem
1791820	1792940	of thinking about the future
1792940	1795580	in terms of the scale of human lifespans,
1797540	1801460	but, you know, the environments and ecologies
1801460	1804420	in which we live operate on a different kind of scale.
1804420	1807300	But, I don't know, there's more specific things,
1807300	1808660	but I'll just sort of leave it,
1808660	1810460	I'll kind of leave it at that, maybe.
1811460	1812300	Fantastic.
1812300	1814100	Benjamin, thank you so much for your time
1814100	1816780	and thanks a lot for being part of Future Histories.
1816780	1817620	My pleasure.
1817620	1818900	Thank you for inviting me.
1824620	1825940	Thank you so much for listening.
1825940	1828340	This has been the interview with Benjamin Breton
1828340	1830860	that I did in the context of my guest lecture
1830860	1833540	at the Goldsmiths College in London.
1833540	1836340	Thanks a lot to Mattia for inviting me
1836340	1841340	and thanks a thousand times to Benjamin for taking part.
1841500	1844180	I could not have imagined a better transition
1844180	1847940	from 2020 into 21 than having Benjamin Breton
1847940	1851020	as a guest in the last episode of 2020
1851020	1854540	and then the second part as a start for this year,
1854540	1857020	so I absolutely love it.
1857020	1860220	You will now hear the discussion that took place afterwards
1860220	1863260	and since we didn't have any consent from the students
1863260	1868260	in terms of releasing their questions as the original audio,
1868460	1872460	I will simply restate them in order to avoid any problems
1872460	1874740	in terms of privacy.
1874740	1877100	The first question comes from Mattia,
1877100	1879620	so this one I won't have to restate,
1879620	1881500	but then afterwards I will do so.
1881500	1882940	Please enjoy.
1882940	1887940	Perhaps I can ask one question that made all together
1888700	1890940	what has been said in such detail.
1893900	1897820	You presented very poignantly
1897860	1902180	the problem of not thinking technology, politics,
1902180	1905180	and subjectivity in the classic.
1905180	1906820	I absolutely agree it is paramount
1906820	1908980	that we look at these issues.
1908980	1910620	You did say something at some point
1910620	1912580	that seemed to me to go against the grain
1912580	1913900	of the rest of what you were saying
1913900	1916580	and probably just the way I heard it,
1916580	1919500	but I think it's important to expand on it.
1919500	1923420	At some point you said that your best guess
1923420	1928420	or your look forward was that the superstructure
1928740	1931620	would prevail over the base structure
1931620	1935540	in terms of where agency and gravity are located.
1935540	1936620	No, no, no, no, no, no.
1936620	1939460	The other way that I was arguing,
1939460	1942060	just on the point of cause and effect,
1942060	1946300	I was suggesting that if we want to ask the question
1946300	1948580	in the totally over reductive way
1948580	1949860	or if I want to answer the question
1949860	1951460	in this very over reductive way
1951540	1955220	of whether or not the culture causes infrastructure,
1955220	1957460	infrastructure causes culture,
1957460	1960660	and where we should invest our time,
1960660	1965220	I would argue I'm on team base causes infrastructure,
1965220	1966300	base causes superstructure,
1966300	1967460	base causes superstructure, right,
1967460	1970900	so that the geotechnology causes geoculture
1970900	1974060	was more where I was trying to come down on that.
1974060	1976500	The first student question is,
1976500	1978900	since you were talking about pricing the future,
1978900	1981140	I was interested in how that applies
1981140	1984540	to Shojana Zuboff's surveillance capitalism approach
1984540	1987820	and how pricing the future could impact individuals
1987820	1990460	and the kind of ethical implications of that.
1991940	1994260	Right, so you're right.
1994260	1997100	I think it's certainly correct
1997100	2000700	that this question of pricing the future
2000700	2004780	is something that already exists.
2004780	2006540	It's not something that would be,
2006860	2011860	it's already part of the way in which our economies work.
2013540	2015340	Our economies in many respects are,
2015340	2017340	whether that's the stock market
2017340	2021580	or pricing the future attention of an individual user
2021580	2022980	or something like that,
2022980	2026980	that pricing the future is not something
2026980	2029940	that would need to be introduced ex nihilo
2029940	2031580	or invented from tabula rasa.
2031580	2034540	It's actually already part of the system.
2035220	2039980	And then what I'm suggesting then is that the recognition
2039980	2043020	of this as a strategy and the recognition of this
2043020	2045900	as something that we have already built a degree
2045900	2048260	of sophistication and capability with
2048260	2051140	is something that should not be overlooked
2051140	2055940	if the goal of the deployment of that capacity
2055940	2057900	is for something other than predicting
2057900	2059540	whether or not a user is,
2060060	2065060	the purpose of this is for rectifying the pathologies
2065340	2068100	identified as part of the capless pricing problem
2068100	2071540	as opposed to predicting whether or not a user
2071540	2075140	is likely to look at this particular cat video
2075140	2076860	or that particular cat video,
2077740	2081420	that the relevancy of this technical capacity
2081420	2084820	is being suppressed by the stupidity
2084820	2086660	of the way in which we are using
2086660	2088620	planetary scale computation.
2089500	2090980	To underscore the point,
2092580	2096220	one of the differences I have with Zuboff on this point is,
2096220	2099300	whereas I think for Zuboff, the individual,
2099300	2102100	the privacy and sovereignty of the individual
2102100	2105540	as the core unit of planetary scale computation
2105540	2108020	is not only left unquestioned,
2108020	2111820	it's in fact re-fortified as the basis of something
2111820	2114460	that needs to be re-privatized,
2114460	2117300	that needs to be re-individuated,
2117300	2120340	that needs to be further individuated
2120340	2124260	from the supervisory manipulative molestation
2124260	2125460	from the platforms.
2128980	2132260	I think deeper and probably more fundamental critique
2132260	2133940	of the way planetary scale computation works
2133940	2138940	is that this unit of the self-sovereign private
2139300	2142300	and privatized individual as the space unit
2142300	2145340	is itself a kind of original sin
2145340	2147660	for how we have organized planetary scale computation.
2147660	2152100	And there is no solution, no kind of social dilemma,
2153780	2155340	restructuring our privacy,
2155340	2158660	re-fortifying our anonymity in relationship to one another
2158660	2159940	in relation to the system
2159940	2162580	that will ultimately solve that problem.
2162580	2166780	I think in many ways it's actually re-fortifying that problem
2166780	2168580	by re-conquering this idea.
2168580	2172580	So saying the same thing in a few different ways,
2172580	2177580	but the more fundamental point of the predictive capacity,
2178700	2180460	the kind of preemptive logic,
2181580	2183940	the pricing of preemption,
2183940	2187380	even within planetary scale computation
2187380	2188260	is something that exists
2188260	2190460	both in terms of something we might admire,
2190460	2192220	as in climate science,
2192220	2195380	where we are preemptively simulating the future
2195380	2197020	through scenarios,
2197020	2198780	and something we might not admire
2198780	2200660	in terms of the preemptive simulation
2200660	2203620	of what individual users might click on.
2203620	2204460	But you're correct
2204460	2207300	that this capacity for preemption already exists.
2207300	2209540	The next student question is,
2209540	2211060	picking up on your last point
2211060	2212700	of predictive, prescriptive,
2212700	2214980	and projective models of governance,
2214980	2217100	I was curious how well you think humans
2217100	2218580	are even able to determine
2218580	2221940	how well computers or algorithms are modeling.
2221940	2224540	So when we move into global computation,
2224540	2226780	or we've already been in global computation,
2226780	2228420	how well we are actually able
2228420	2231260	to evaluate models going forward.
2231260	2233780	Taking chess or Go as an example,
2233780	2237020	which are comparatively extremely simple systems,
2237020	2239500	but we already struggle to evaluate
2239500	2241420	how well computers model them.
2241420	2244100	They play a lot of moves that we think look wrong,
2244100	2247140	and only turn out to be effective much later on,
2247140	2249820	or much further down the road at the end of the game.
2249820	2251860	So I'm wondering from our perspective,
2251860	2253780	how well we are able to evaluate
2253780	2256180	how good the models actually are.
2257140	2260740	Yeah, it's a really important question,
2260740	2262460	and one that is doesn't have a,
2262460	2266140	one that gets more complicated and more interesting
2266140	2271140	the more you continue to ask it with greater specificity.
2273180	2274260	So thank you for that.
2274260	2279260	I think it has a bit of a question around,
2281100	2283180	if we keep this differentiation as I proposed
2283180	2285980	between descriptive, predictive, and projective models,
2286820	2289420	we might have different ways of answering that.
2289420	2291980	If that is a descriptive model,
2291980	2294180	the function of which has the ability,
2294180	2297180	is supposed to be a kind of reductive,
2297180	2300380	a reductive approximation of a mind-independent reality,
2300380	2302100	like heliocentrism or something,
2302100	2304500	at least we have the experimental method
2304500	2306620	to try to test the model over and over again,
2306620	2308380	and to try to find out,
2308380	2311500	to try to test the descriptive capacity of the model
2311500	2313580	through its predictive capacity.
2313580	2316980	That is, if this model is true,
2316980	2318500	then it should be able to predict
2318500	2321820	what is going to happen under experimental conditions,
2321820	2322860	X, Y, or Z.
2323780	2325180	And if under those conditions,
2325180	2326580	it's not able to predict it,
2326580	2329260	then we realize that its description might be a bit wrong.
2329260	2331660	And so, you know, science marches forward
2331660	2336420	through that kind of testing capacity.
2337300	2339460	The projective models are ones
2339460	2341780	that are a little bit more difficult,
2341780	2343140	but it's also interesting to speak,
2343140	2345580	since we're talking about temporality of models,
2345580	2346900	you know, one of the interesting things
2346900	2349460	about climate models is the way in which
2349460	2352860	the future is validated against the past.
2353860	2356140	And what I mean by that is this,
2356140	2357500	the ways in which,
2357500	2359340	and I'm sure you're probably aware of that,
2359340	2360780	but I'll just mention the point
2360780	2363140	in the context of this question,
2363140	2365260	the way in which we have some degree of confidence
2365260	2367660	in why it is that we think that the world
2367660	2370580	will look a certain way in 2040 or 2050,
2371420	2374860	given whatever ecological variables
2374860	2377740	we wish to emphasize,
2377740	2380780	is because you test that model against past data.
2380780	2382380	And so, for example, you'll take,
2382380	2383420	here's the model,
2383420	2386180	what we think is gonna happen between 2020 and 2050
2386180	2389060	in that 30-year arc based on these variables.
2389060	2391060	Let's take that model and try to predict
2391060	2394460	what would happen between 1820 and 1850
2395340	2397260	based on what that model should tell us
2397260	2399660	what would likely happen.
2399660	2403060	And then you go back and look at what did happen in 1850.
2403060	2405980	And if the prediction turned out to be true,
2405980	2407500	if the prediction of the future
2407500	2409780	turns out to be able to predict the past,
2409780	2411820	then you have a degree of confidence
2411820	2416140	in the way in which it would work.
2416140	2417820	Now, your question, though,
2417820	2420340	about the kind of the patterns within this,
2420340	2422300	and I think a lot of it has to do with
2422300	2423980	the way in which models allow us
2423980	2428500	to deduce and abstract patterns.
2428500	2429700	And as I've said a few times,
2429700	2432460	this capacity for technical abstraction
2432460	2434300	of collective technical abstraction
2434300	2437740	is one of the important epistemological functions
2437740	2439460	of planetary scale computation.
2439460	2441460	And I'll just emphasize the point here.
2442580	2444940	There is, in many ways,
2444940	2447660	the arguments I'm making have as much to do
2447660	2449220	with the way in which the technologies
2449220	2450620	function instrumentally.
2450620	2452700	That is, what are we able to do with them?
2452700	2454820	But equally importantly, if not more,
2454820	2457220	is the epistemological function of the technologies.
2457220	2459660	How is it that through using of these technologies,
2459660	2461060	we're able to know things
2461060	2463500	that we wouldn't have been able to know otherwise?
2463500	2464340	And in many cases,
2464340	2465780	it's the epistemological function
2465780	2467820	of planetary scale computation that's most important,
2467820	2470700	that's more important in the long run, I think.
2470700	2473020	But your examples of AlphaGo and the chess
2473020	2475060	and the rest of this bring up an important point,
2475060	2478580	and that is, in theory,
2478580	2480980	the function of something like an AI
2480980	2485380	would be that it is able to see patterns in the world
2485380	2486620	and patterns in the data
2486660	2489060	that we would not be able to intuit on our own.
2489060	2491700	Otherwise, why would we bother building them?
2491700	2494780	That it's able to see something we can't see.
2496940	2501140	But what happens when it seems to see something
2501140	2505460	that seems so weird and unlikely
2505460	2510460	that we're not sure whether or not it's stupid or ingenious?
2510540	2512180	We don't know whether or not
2512180	2516540	there's obviously a deep error in our presumptions
2517460	2518940	and we've produced a machine that's incapable
2518940	2522020	of producing nothing but stupid noise,
2522020	2524180	or we've produced this genius machine
2524180	2525260	that's able to see patterns
2525260	2527700	that we never would have seen otherwise
2527700	2530220	and cause and effect relationships between dynamics
2530220	2534580	that we've overlooked for our entire evolutionary career.
2534580	2535740	How would we know?
2536620	2540180	How would we know whether a totally unlikely pattern
2540180	2545180	is trivial or fantastically important?
2546180	2551100	And someone needs to invent a name for this within AI,
2551100	2554060	I think, where the AI finds a pattern
2554060	2556860	that we don't recognize as being logical
2556860	2560220	and yet we have to, in essence, take this,
2560220	2565220	we have to decide in a way to decide to believe the pattern
2565980	2568220	or decide not to believe it in a way.
2569420	2573060	And this is again part of the epistemological complexity
2573060	2573900	of these technologies.
2574060	2576380	The example that you gave of AlphaGo
2576380	2577940	is the key one here,
2577940	2579940	is the one that everyone refers to
2579940	2581460	in relationship to this phenomenon,
2581460	2583820	is that, and for those that,
2583820	2587100	the computer made this move that at the time,
2588140	2589460	early in the game,
2589460	2593740	move 33, I think, of the game against Lee Sedol,
2593740	2598340	that everyone thought, oh my God, the machine, it's broken.
2598340	2599300	The AI is broken.
2599300	2601860	This is very embarrassing for Google.
2601860	2603660	Right in the middle of game three,
2604420	2605740	their computer went nuts
2605740	2608540	and placed a stone way off in the middle of nowhere
2608540	2613420	and, oh shit, this Google stock's gonna go down,
2613420	2614420	everything's horrible.
2614420	2616100	And then, lo and behold,
2616100	2618740	over a period of the rest of the game,
2618740	2621140	the whole game arcs towards this one stone
2621140	2624060	in such a way that it turned out to be ingenious
2624060	2626220	and as the Sedol, the Go player said,
2626220	2628340	no human ever would have made that move.
2629220	2633020	And it was also seen example of the ways in which
2634580	2637380	it was something that we could take as optimistic,
2637380	2638460	at least in this regard,
2638460	2643460	that part of the problem of reinforcement learning-based AIs
2643500	2648500	and, indeed, using big data models of the past
2649340	2651620	in order to simulate the future
2651620	2653940	is that you run the risk of, in essence,
2653940	2657100	just replicating pre-existing patterns
2657100	2659940	and presuming that pre-existing patterns
2659940	2662460	will be continuous into the future
2662460	2665220	in ways that, in essence, make it so.
2665220	2668220	You're enforcing the possibility
2668220	2671740	that pre-existing patterns would be the future patterns
2671740	2673500	by, in essence, predicting it
2673500	2675140	and then acting on those predictions.
2675140	2678580	And so some of the people who do serious work
2678580	2679940	around AI bias,
2679940	2682260	there's a lot of un-serious work around AI bias too.
2682260	2684660	People who do serious work around AI bias,
2684660	2686500	a lot of the work is based on this question
2686500	2687740	that you have previous patterns
2687740	2689900	and that making predictions and policies
2690020	2692460	and the previous patterns will enforce this,
2692460	2696140	which is a real and serious general problem
2697820	2701220	about the ways in which previous models replicate themselves.
2701220	2703580	What it showed with the AlphaGo thing
2703580	2708220	was at least the possibility that, no, novelty is possible,
2708220	2710340	that there is some way in which,
2711180	2713380	even through the reinforcement learning methods
2713380	2715700	of the built AlphaGo,
2715700	2718500	that in this production and its conceptualization
2718500	2722140	and its prediction and its sort of stochastic perspective,
2722140	2726540	prediction of what the right move would be.
2726540	2728340	And in this case, the right move would be part
2728340	2729940	of what we're calling a projective model,
2729940	2732380	a normative model, not a descriptive predictive,
2732380	2734660	but a normative model of what the right move would be,
2734660	2736420	that it could come up with something
2736420	2740020	that we would never have thought of itself.
2740020	2744340	That it was an example that AI is capable of being
2744340	2747300	a kind of epistemic machine
2747300	2752140	that's capable of producing ideas, producing novelty,
2752140	2755500	producing patterns we wouldn't have been able to see.
2755500	2761420	And in that sense, I take the weird alienation
2761420	2763220	we may have had from the logic of that move
2763220	2769020	as very optimistic, as very, very good news in this kind of regard.
2769020	2774220	But again, your question about how do we validate the model
2774220	2775980	and how do we not only validate the model,
2775980	2777780	whether it's come up with something stupid,
2777780	2782100	but how do we ensure that even the validity of past models,
2782100	2785580	how do we outsource size ourselves from this position
2785580	2790740	where the previous models are simply replicating themselves,
2790740	2793580	becoming recursive in the bad sense,
2793580	2799220	becoming a kind of echo effect where we're using all of these systems
2799220	2803060	as simply a way to enforce the condition
2803100	2806540	by which the future is just an echo of the past.
2806540	2809540	This is also a way in which our relationship to these models
2809540	2814180	must be seriously interrogated.
2814180	2817260	The other side of this is, so you could think of it in this way,
2817260	2819380	one, how do you use these models in such a way
2819380	2823500	that you can act upon their implications recursively,
2823500	2826340	which is what we want to do with climate change models,
2826340	2831340	but also how do you ensure that these models continue to accelerate
2831340	2835540	the space-based search function by which they're able to identify
2835540	2841140	and look for and produce novelty, produce innovation,
2841140	2844460	produce something that hasn't happened before?
2844460	2850380	And I think a lot of the philosophy of computation
2850380	2854900	of the next several decades will be based upon that conflict
2854940	2860180	between modulating recursion
2860180	2865820	and modulating face-based search and novelty production.
2865820	2869300	So the last student question was asked with a strong British accent,
2869300	2871860	and I hope I managed to capture the essence.
2871860	2876780	The question brings up Andrew Geim and how he used very off-the-charts methods
2876780	2882020	and ideas in his so-called Friday experiments when discovering graphene.
2882020	2885860	In relation to that, AI seems very methodical and logical,
2885860	2891580	and so there's the question of how AI could incorporate these acts of randomness,
2891580	2897540	and also when it does so, how it knows when it found anything of value.
2897540	2900460	Yeah, I mean, it's the same thing with the Friday experiments,
2900460	2904140	is that many of them, the value of them is uncertain,
2904140	2908540	where it may be that it's not as though...
2908580	2915540	It's not as you can expect that through some sort of randomization process
2915540	2920500	that by definition, some kind of fitness,
2920500	2923100	some sort of process will necessarily hold.
2923100	2926700	It's the same kind of dynamic of mutation and evolution, I suppose, in that regard.
2926700	2930660	Most mutations are useless.
2930660	2933100	But that's probably the same for the AI, too,
2933100	2937420	that you're expecting them to every time come up with this is probably inaccurate.
2937420	2941140	But I should say that there's a whole other lecture to describe about the ways...
2941140	2946700	I think that also going forward, this term AI will hopefully
2946700	2949500	sort of fork into a much more specific terminology,
2949500	2953620	that when we're talking about the kinds of...
2953620	2956460	The things that different kinds of AI are good for,
2956460	2961860	where reinforcement learning versus other kinds of techniques,
2961860	2965460	Judea Pearl and other people, and Gary Marcus are trying to bring back
2965500	2968660	a more symbolic modeling type of structures here as well.
2968660	2973060	That AI is lots of different technologies, and AI is lots of different techniques,
2973060	2978380	and AI is built upon its sensing capacity as much of its calculative capacity,
2978380	2984020	that the question of how can we guarantee AI is heading in one direction in terms of that,
2984020	2994180	I think it will be able to ask the question with a greater deal of specificity and context.
2994220	2999020	So, and I don't know, I probably would not agree with the idea that in general,
2999020	3011460	AI is just a kind of brute force rationalization as its only capacity and its core capacity.
3011460	3015260	But at the same time, I might suggest that there's something quite amazing
3015260	3018020	about brute force rationalization in its own sense,
3018020	3025100	and that it may be that many of the most interesting forms of mind-bending,
3025100	3032340	pattern-finding abstraction that we learn from AI is from its brute force rationality,
3032340	3040340	that we shouldn't assume that rationality and creativity are somehow the opposite of one another.
3041220	3051820	In many cases, they're quite at home, and that many of the ways in which we kind of lapse into,
3051820	3060380	on the human side of the ledger, lapse into convention and clich and stereotype and muddy thinking
3060420	3070620	and sort of replicating the known is because of a reliance on sort of arbitrary,
3070620	3079100	irrational processes of semiotic symbolization, that in many cases the fact that we're constantly
3079100	3086500	repeating ourselves is more to do with culture than it has to do with math.
3086780	3091900	It may be that rationality does provide a certain kind of escape route that we shouldn't overlook.
3091900	3101420	There was a question about Ted Chiang. People are probably most familiar with Ted Chiang,
3101420	3108660	he's the author of the movie Arrival was based upon. Anyone who enjoyed that movie,
3108660	3113260	I would strongly suggest reading the short story, it's called The Story of Your Life,
3113260	3124580	which is a really fascinating story. It's based around this idea of artificial linguistics,
3124580	3129860	and linguistics. It's a short story that you kind of need to know a little bit about linguistics
3129860	3133900	theory in order to make your way through it, or if you make your way through the story,
3133900	3139540	you will have learned quite a bit about linguistics theory by reading the story.
3139540	3148700	But in terms of things like, there's a lot of interest of late, of course, in things like GPT-3
3148700	3157340	and other ways in which the algorithmic production of different kinds of language as a predictive
3157340	3163100	model, language as structuring model of here as well. I think if we want to go deeper on this
3163100	3168700	question of where it is that the technologies of thought and the technologies of inscription,
3168740	3173180	technologies of modeling, technologies of description, the basis of inscription and
3173180	3177740	ontology in relationship to some of these kinds of dynamics, the relation between our own kind
3177740	3184660	of cognitive prospection, the ways in which our models of the world, the Bayesian prediction
3184660	3190900	functions of our models of the world are the basis of our own neuroscience, and how that gets
3190900	3197980	inscribed into our capacities for signification and communication through language. This field
3197980	3204540	of artificial linguistics is one that would be certainly a rich area for anyone to spend some
3204540	3208700	time with. Thank you very much. It has been extremely interesting. Oh, thank you. Thanks
3208700	3219900	for the invitation. Thanks a lot, Benjamin. That was our show for today. Thanks a lot for listening.
3219900	3225180	If you want to support future histories, you can do so on Patreon, or you can just simply tell a
3225180	3230300	friend that you heard of the show and that he or she might like it as well.
3230940	3233580	Have a good time and hear you in two weeks.
