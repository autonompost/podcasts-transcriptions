start	end	text
0	5720	Herzlich Willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft.
5720	10720	Mein Name ist Jan Groß und ich freue mich sehr, heute Adrian Daupp begrüßen zu dürfen.
10720	16720	Adrian ist Professor für vergleichende Literatur und Germanistik an der Stanford-Universität,
16720	19520	also im Herzen des Silicon Valley.
19520	24760	Er betreibt den Podcast The Feminist Present und ist zudem ein unbriebiger Autor.
24760	30760	Ganz frisch erschienen bei Surkamp ist sein Buch, was das Valley Denken nennt.
30760	37760	Bevor es losgeht, darf ich ganz herzlich Vainö in der Gemeinschaft der Future Histories Patroninnen und Patronen begrüßen.
37760	39760	Vielen Dank für deine Unterstützung.
39760	43760	Viel Freude bei der heutigen Folge Future Histories mit Adrian Daupp.
49760	51760	Herzlich Willkommen, Adrian.
51760	52760	Vielen Dank.
52760	59760	Adrian, du setzt dich in deinem Buch mit geistesgeschichtlichen Ursprüngen der im Silicon Valley vorherrschenden Ideologien auseinander.
59760	63760	Gleich zu Beginn des Buchs machst du dabei eine wichtige Einschränkung
63760	66760	und ich finde, wir sollten diese auch unserem heutigen Gespräch vorausschicken.
66760	74760	Deine Untersuchungen zu den vorherrschenden Idealisierungen, Mythen und Narrativen des Tech-Sektors bezieht sich auf die, und ich zitiere hier,
74760	80760	sehr sichtbaren GründerInnen, Finanziers und MeinungsführerInnen der Branche.
80760	86760	Dein Buch erhebt also bewusst nicht den Anspruch auf Vollständigkeit und ich möchte an dieser Stelle ergänzend vielleicht auf das Buch
86760	91760	Voices from the Valley von Meurer Weigl und Ben Tarnow hinweisen, das kürzlich erschienen ist,
91760	94760	das quasi einen komplimentären Zugang zu deinem wählt.
94760	100760	Warum hast du dich für diese Linse entschieden, die bei dir ja auch eine kritische ist, und was bringt sie zutage?
100760	105760	Naja, einerseits, weil ich eben als Geisteswissenschaftler an dieses Thema ran wollte.
105760	114760	Das heißt, ich habe mich mit einer kulturellen Formation beschäftigen wollen und die existiert eben primär um diese Firmengründer,
114760	120760	um den Medien- und Politikkult, der um diese Medien im Positiven wie auch im Negativen gemacht wird.
120760	127760	Also für jeden Elon Musk gibt es einen Mark Zuckerberg, der uns eher als Negativfigur dient.
127760	132760	Aber die sind eigentlich im Grunde genommen fast literarische Figuren.
133760	138760	Das sind Figuren, denen mit den Mitteln der Kulturwissenschaft relativ gut beizukommen ist.
138760	146760	Die Frage, wie man die Voices from the Valley, die Meurer und Ben in ihrem Buch eingefangen haben,
146760	150760	wirklich nachweisen würde, das ist ja bei ihnen eher so eine Oral History.
150760	153760	Ich glaube, das lässt sich auch ganz toll machen.
153760	161760	Da müsste man aber 10.000 Fragebögen verschicken und da müsste ich noch einen Dotteltitel in Soziologie drauf.
161760	164760	Darauf legen und gucken, ob Theodor Adorno noch abkömmlich ist.
164760	169760	Und dann ginge das auch. Ich finde, das ist eine sehr spannende, sehr spannende Idee.
169760	176760	Mir ging es aber eben wirklich mehr um die Art, wie wir das Valley mit diesen Figuren,
176760	182760	mit diesen Gründerfiguren, diesen Dortliederfiguren zusammen konstruieren.
182760	188760	Also das Feld, das sich sozusagen ergibt, aus dem Interesse einer Weltöffentlichkeit,
189760	195760	die irgendwie davon ausgeht, nicht ganz unbegründeterweise, aber davon ausgeht,
195760	199760	dass im Silicon Valley sozusagen die Geschichte der Zukunft geschrieben wird.
199760	205760	Nicht in Shenzhen, nicht in Hyderabad, sondern in Silicon Valley.
205760	214760	Und dann eben jenen im Valley, weil sie Geld brauchen, weil sonst ihr Businessmodell nicht funktioniert,
215760	224760	weil sie denken, dass die Welt an ihrer Weisheit genesen kann, da mitmachen und die sich dem anbieten.
224760	228760	Und es gibt auch Firmengründer im Valley, die sowas nicht tun.
228760	232760	Die bewusst Interviews nur geben, wenn es um ihren Business geht und sagen,
232760	236760	ja so haben wir das gemacht, bitte kaufen Sie unsere Aktien ungefähr.
236760	239760	Aber das ist eben nicht Elon Musk, das ist nicht Mark Zuckerberg.
239760	246760	Die werden nicht eingeladen, um Reden an Unis zu halten und würden das wahrscheinlich auch nicht tun.
246760	252760	Es geht also um einen Komplex, der sich konstituiert durch das Interesse an diesen Unternehmen
252760	259760	und das diesen Unternehmen eine Wichtigkeit beimisst für die Art und Weise,
259760	264760	in der wir alle leben oder leben werden und umgekehrt den Kräften im Valley,
264760	267760	denen daran gelegen ist, so verstanden zu werden.
270760	276760	Und einer der zentralen Mythen, die da florieren und auch lange schon kursieren,
276760	279760	der dreht sich um die Disruption.
279760	285760	Du schreibst dazu, paradoxerweise ist die Disruption letzten Endes also etwas wie Neuheit für Menschen,
285760	287760	die sich vor genuin Neuem fürchten.
287760	292760	Eine Revolution für Menschen, die sich von der Revolution keinen Vorteil erwarten dürften.
292760	295760	Das ist eine sehr wichtige Feststellung, finde ich.
295760	299760	Vielleicht kannst du uns ein wenig die Genese dieses Konzepts der Disruption näherbringen
299760	302760	und warum es sich hierbei eben nicht um eine Revolution handelt.
302760	310760	Die Disruption speist sich ganz stark aus Joseph Schumpeters Begriff der kreativen,
310760	314760	der schöpferischen Zerstörung, sorry auf Deutsch, schöpferischen Zerstörung.
316760	321760	Und der wiederum bezieht sich auf Karl Marx und Friedrich Engels im kommunistischen Manifest.
321760	330760	Und seine Theorie war seinerzeit dazu angelegt, zu erklären, warum Teile ihrer Kapitalismuskritik absolut zutreffen,
330760	335760	warum es aber trotzdem wahrscheinlich nicht zu einer Revolution kommen wird.
335760	347760	Das heißt, im Grunde genommen war die Schöpferische Zerstörung eine Art Sublimierung der Revolution
347760	350760	in den Vollzug des Kapitalismus selber.
350760	357760	Und das hat sich in den letzten 80 Jahren gewandelt, dadurch, dass Schumpeter das annahm,
357760	364760	dass dadurch sozusagen, dass durch die Tatsache, dass der Kapitalismus immer dabei ist,
364760	370760	immer schon alles kaputt zu machen, immer schon alle Konstanten zu negieren,
370760	378760	dass das irgendwie die Menschen dazu führen würde, etwas außerhalb des Kapitalismus zu suchen und sich zu wünschen.
378760	384760	Und er nahm an und er fand das, soweit ich ihn verstehe, gar nicht mal positiv,
384760	388760	aber er meinte, das macht eine Art Staatssozialismus relativ unausweichlich.
388760	395760	Das ist in den letzten 80 Jahren verloren gegangen und Disruption ist derzeit eher, wie ich es im Buch beschreibe,
395760	397760	eine Theorie C des Hyperkapitalismus.
397760	405760	Das heißt, sie ist sozusagen, sie beglaubigt den Kapitalismus noch, anstatt dass sie ihm sozusagen seine Grenzen aufzeigt.
405760	414760	Und insofern ist das, und sie ist sozusagen das Scharnier geworden durch das ganz bestimmte Branchen,
414760	419760	das war nicht ursprünglich die Tech-Industrie, das war ursprünglich die Finanzindustrie,
419760	422760	aber jetzt mittlerweile vor allem die Technologieindustrie,
422760	429760	anderen Wirtschaftszweigen ihre Logik als gesamtgesellschaftliche Logik überstülpen können.
430760	439760	Wenn wir kommen können und wir krempeln dein Geschäftsmodell innerhalb von zwei Jahren so um, dass du Bankrott gehst,
439760	444760	dann zeigt das doch eigentlich, dass du es nicht verdient hattest zu überleben.
444760	457760	Das ist das Fatale an diesem Diskurs, weil er im Grunde genommen, ich meine, was wurde denn nicht schon alles disrupted?
457760	464760	Und es gibt, das will ich sofort dazu sagen, es gibt Momente, in denen Disruption sehr wohl beschreibt, was vor sich geht,
464760	473760	auch genau beschreibt und, sag ich mal, relativ und auch, sag ich mal, einen Prozess beschreibt,
473760	478760	von dem wir alle sagen können, der ist gesellschaftlich wahrscheinlich sogar wünschenswert.
478760	485760	Das Problem ist aber, dass es eben als, als Sie sagen, öffne dich für so ungefähr alles jetzt verwendet wird.
485760	493760	Ja, was heißt das, wenn man eine Branche wie, was weiß ich, die Grundschule disrupted?
493760	498760	Also ich meine, in Deutschland ist man noch nicht ganz so weit, aber in den USA hört man schon so Sachen.
498760	504760	Oder Trump disrupted den Staat, in dem er eben komplett inkompetent ist.
504760	507760	Also na gut, das ist keine Disruption mehr, das ist Destruction.
507760	512760	Und Schumpeter war sehr, sehr bewusst, dass das eine eben nicht das andere ist.
512760	518760	Aber es ist eben mittlerweile richtig eine Art, eine Spielart, mit der mit der Unterschiede,
518760	522760	soziale Unterschiede nivelliert werden können und einfach gesagt werden können kann.
522760	531760	Jede Art Neuordnung ist an und für sich gut und an und für sich legitimer als das, was sie neu ordnet.
531760	538760	Weil das, was disrupted werden kann, es irgendwie halt schon verdient hat.
538760	543760	Wobei ja bestimmte Sachen dann eigentlich durchwegs unangetastet bleiben.
543760	548760	Also das, so hatte ich jetzt das bei dir auch verstanden, dass im Grunde ja auf der einen Seite eben,
548760	553760	so wie du es jetzt auch als Beispiel genannt hast, sich also dieses Konzept hergenommen wird, um zu legitimieren,
553760	557760	dass man in ganz viele Bereiche auch hineingeht, in denen es eigentlich nicht adäquat wird.
557760	564760	Aber gleichzeitig ist ja zum Beispiel alles, wo es jetzt zum Beispiel darum ginge, sich vom Profitmotiv zu entfernen.
564760	568760	Das ist ja davon dann irgendwie aus dem Vorgehalten, scheint mir.
568760	575760	Genau. Also wir haben gerade in Kalifornien eine lange und wirklich fürchterliche Wahlkampagne
575760	578760	über diese Proposition 22 über uns ergehen lassen müssen.
578760	587760	Das war der Staat Kalifornien hatte sich, hatte entschieden, dass Leute, die für Uber und Lift fahren,
587760	590760	als Belegschaft behandelt werden müssen.
590760	594760	Nicht als Vollzeitbeschäftigte, aber auch zumindest als Teilzeitbeschäftigte.
594760	601760	Und dass denen somit gewisse Versicherungen und so weiter zustehen.
601760	609760	Und dagegen haben sich die Unternehmen verwehrt aus dem ganz einfachen Grunde,
609760	614760	dass sie wahrscheinlich bankrott gehen würden, wenn sie ihre Fahrer nach diesem Prinzip bezahlen würden.
615760	621760	Und haben stattdessen 200 Millionen Dollar ausgegeben, um eine Proposition, also einen Volksentscheid zu erwirken,
621760	634760	der auch tatsächlich durchgekommen ist, der eben besagt, dass die Fahrer für Uber und Lift von diesem Gesetz ausgenommen sind.
634760	637760	Also so haben die sich sozusagen über die Runde gerettet.
638760	649760	Aber wie sie das gemacht haben, es ging immer darum, wir wollen unseren Fahrern mehr Flexibilität und mehr Autorität zubilligen.
649760	655760	Wie kann es der böse Staat wagen, sich da einzumischen und das ist halt alles so altmodisch und so weiter.
655760	660760	Und es wurde nie offen, natürlich haben sie es nicht offen gesagt, aber es war erstaunlich,
660760	669760	wie viel Nonsense die eigentlich generieren konnten, um sozusagen nichts sagen zu müssen.
669760	674760	Unsere Profitmargen hängen davon ab, dass diese Menschen unterbezahlt werden.
674760	677760	Wir müssen sie weiter unterbezahlen dürfen, sonst gibt es uns nicht mehr.
677760	682760	Und das kam sogar zu Spaß, wir müssten dann unsere Operation woanders hin verlegen.
682760	689760	Ja klar, weil bei fairer Bezahlung das System sehr schnell kollabiert.
689760	694760	Und das ist für mich eben so ein Moment, wo Disruption sich eben sehr stark,
694760	703760	sie lässt die Mächtigen, die Mächtigen werden mächtiger oder bleiben genau gleichmächtig,
703760	708760	das Geld fließt genau so wie es vorher floss, aber alle tun so,
708760	714760	als seien die alten Kapitalismusformen irgendwie ausgehebelt oder umformiert worden.
714760	720760	Also es gibt dann bei jedem so einem Startup dann einen Artikel, der irgendwie beschreiben will,
720760	726760	wie jetzt angeblich dieses oder jenes Metier komplett revolutioniert wird
726760	730760	und dass eben häufig der Middleman dann wegfällt und so weiter.
730760	734760	Aber im Grunde genommen handelt es sich immer um eine Art Sales Pitch,
734760	740760	um eine Art Publicity, die eben kaschieren soll, dass im Grunde genommen
740760	744760	die alten Machtgefüge relativ konstant bleiben werden,
744760	751760	aber dass eben jetzt eine neue Schicht von Bossen reich werden wird.
751760	756760	Und dass vor allem häufig ja nicht mal die Bosse, Uber oder Lyft, sondern häufig die Geldgeber,
756760	761760	häufig dieselben Investoren, die früher in die kleineren Unternehmen investiert hätten,
761760	765760	aber dass die jetzt eben genauso so reich werden und dass keiner sich mit dem Taxifahren
765760	769760	eine goldene Nase verdient, haben sie früher auch nicht, werden sie heute auch nicht.
769760	775760	Wer reich wird, ist Uber. Oder wer reich wird, sind die Uber Investoren.
775760	783760	Und wenn es denn also so ist, dass die Disruption letzten Endes etwas wie Neuheit ist für Menschen,
783760	788760	die sich vor dem genuin Neuen fürchten, dann schließt sich da eigentlich die Frage an,
788760	793760	wie würde eine tatsächliche Neuerung denn aussehen, also welche Kategorien müsste man bereit sein,
793760	798760	in Frage zu stellen, um wirklich zu einer genuinen Neuerung zu kommen?
798760	801760	Ich glaube, du hast es vorhin schon angesprochen, das Profitmotiv wäre,
801760	803760	das stünde für mich an allererster Stelle nicht.
803760	808760	Es gibt Formen, also Wikipedia wäre eine Sache, die hat wirklich, das ist wirklich eine Disruption gewesen,
808760	815760	aber das ist wirklich etwas, wo sehr wenig, wo ja wirklich kaum jemand Profit daraus schlägt
815760	833760	und wo wirklich wir etwas aufgebaut haben, das genuin neu ist, aber genuin und genuin anders funktioniert als herkömmliche Lexika.
833760	838760	Das heißt nicht, dass Wikipedia keine Probleme hat oder dass man nicht vielleicht auch manchmal Experten ranlassen sollte,
838760	844760	statt dass Tante Erna da irgendwie an ihren Lieblingseinträgen schraubt.
844760	850760	Aber es heißt doch, dass das Modell an sich wirklich das leistet, was es erstmal verspricht.
850760	859760	Und da gibt es viele Beispiele und ich glaube, es gibt viele Ansätze, gerade auch an den Universitäten,
859760	868760	gerade auch was Open Access angeht und so weiter, auch im Verlagswesen gibt es wirklich tolle Ideen.
868760	876760	Und das sind die Ideen, wo man allen Beteiligten anmerkt, dass sie ganz erschrocken darüber nachdenken,
876760	882760	ja, aber wie überleben wir denn dann? Das sind wirklich die, die nämlich ein Risiko auf sich, indem sie das machen.
882760	889760	Das, was ich interessant finde bei all dem Risikokapital, das hier rumschwappt in San Francisco, immer noch, muss man sagen, trotz Covid,
890760	899760	dass das eigentlich die falsche Bezeichnung dafür ist. So wahnsinnig viele riskieren diese Menschen gar nicht.
899760	905760	Die geben hundert Wetten ab und sind sich ziemlich sicher, dass zwei oder drei von denen das große Los sind.
905760	912760	Ich meine, klar, das ist ein gewisses Risiko, aber es ist ein Risiko, dass wenn du oder ich das Geld hätten,
912760	915760	wir sicherlich auch gerne auf uns stehen würden. Das ist die Frage, wie viel Geld der Mensch hat.
916760	921760	Und ich glaube aber, es gibt eben andere Ansätze, wo Menschen wirklich genuin was riskieren.
921760	929760	Und es ist eben auffällig, dass gesellschaftlich oder was die Politik angeht, wenn deutsche Politiker
929760	937760	oder auch österreichische Politiker nach Silicon Valley kommen, gehen sie zu Google, gehen sie nach Stanford,
937760	946760	gehen sie, schauen sie möglicherweise bei Uber vorbei. Das ist da, wo die die Zukunft verorten.
946760	950760	Und das ist eine Wahl, das ist eine Entscheidung. Man könnte es auch anders machen.
950760	956760	Man könnte auch bei irgendwelchen komischen Hacker-Kollektiven vorbeischauen, gucken, wie macht ihr das denn eigentlich?
956760	967760	Aber nein, was wir uns als Gallionsfigur für das 21. Jahrhundert auserkoren haben, ist das Megastartup,
967760	978760	dessen Risiko eigentlich Makulatur ist, dessen Disruption eigentlich nur eine Neuordnung des Bestehenden,
978760	988760	eine Neuordnung des bestehenden Machtbefüges ist und deren Zukunft, würde ich mal sagen,
988760	994760	ins Dystopische, wenn man sie wirklich zu Ende denkt, ins Dystopische bis hin zum Neofeudalistischen geht,
994760	999760	was manche dieser Gründer auch offen aussprechen. Und dann muss man einfach fragen,
999760	1009760	was macht dann ein Forschungsminister bei Google, anstatt sich mit irgendwelchen Hackern in einem Café zu treffen?
1009760	1021760	Es gibt da ganz tolle Ansätze. Das Problem ist, dass man die Aufmerksamkeitsökonomie Silicon Valleys nennen könnte,
1021760	1026760	die das Augenmerk immer auf die anderen lenkt.
1026760	1033760	Du beschreibst in deinem Buch auch diese eigentümliche Mischung des Silicon Valleys aus Lokalismus und extrem geschlossenem
1033760	1041760	und auch sehr homogenem Umfeld auf der einen Seite und gleichzeitig aber einem Gestus des Universalismus auf der anderen Seite.
1041760	1047760	Ich habe einen Begriffsvorschlag dafür, nämlich provenzieller Universalismus, musste ich sofort denken, das würde passen.
1047760	1050760	Was ist das für eine Melange, die du da beschreibst?
1050760	1057760	Ein Beispiel, das ich im Buch nicht bringe, das habe ich vor Jahren mal in einem Text in der NZZ gebracht.
1057760	1067760	Das war für mich der Moment, das muss 2018 zur Wahl gewesen sein, bin ich in ein kleines kalifornisches Städtchen.
1067760	1074760	Ungefähr 80.000 Einwohner im Central Valley, vornehmlich von mexikanischen Amerikanern bewohnt.
1075760	1081760	Es war eine ganz andere Welt vom Bay Area, nur 200 Kilometer weg oder 300 Kilometer weg, aber total anders.
1081760	1084760	Und dann kam Lunch und dann habe ich gedacht, wie mache ich das jetzt?
1084760	1087760	Und dann habe ich Yelp angestellt und es war faszinierend.
1087760	1094760	Yelp hat unglaublich viel rezensiert worden, aber eben von der Art Mensch, die Yelp benutzt.
1094760	1102760	Das heißt, ich konnte vor einer Tacerea stehen, wo ich danach auch gegessen habe, das war fantastisch und die kam bei Yelp nicht vor.
1102760	1109760	Und daneben war eine andere Tacerea, die hatte nur zwei Sterne, weil irgendjemand das Gefühl hatte, dass eine Maus durchgelaufen ist.
1109760	1115760	Was in einer Tacerea häufig hervorkommt, ist halt so. Das Essen ist oben, das ist egal.
1115760	1124760	Aber es war eindeutig, es war unglaublich proppenvoll in der Tacerea, die laut Yelp nicht existierte.
1124760	1131760	Und dann gab es so eine etwas bourgeois angelegte Tacerea um die Ecke und die hatte irgendwie 5000 Rezensionen auf Yelp.
1131760	1134760	Das fand ich dann doch auch interessant.
1134760	1146760	Dann habe ich angefangen, mich durch meine Bay Area Apps, die also im Bay Area geschaffen werden, aber die angeblich eine Geografie der ganzen Welt mir zur Verfügung stellen sollten.
1146760	1148760	Das war 2018, es kann sein, dass jetzt mittlerweile etwas geändert hat.
1148760	1152760	Ich habe damals Uber angemacht, Lyft gab es damals dort noch nicht.
1152760	1160760	Und es gab vier Autos, was natürlich in so einer Gegend gar nicht wenig ist und sie waren alle Toyota Prius.
1160760	1164760	Also alle Hybridfahrzeuge, was in San Francisco jeder fuhr damals.
1164760	1170760	Mittlerweile ist es auf Elektroauto umgestellt, aber das war damals das Auto im Bay Area.
1170760	1177760	Aber dort sah ich erst mal gar keins. Das waren Trucks, das waren sehr, sehr alte amerikanische Modelle, viele Chevys und so weiter.
1177760	1184760	Viele Sachen, die eben auch, sage ich mal, für eine Fahrt auf den Acker passen würden.
1184760	1187760	Kein Prius. Aber sämtliche Lifts waren Prius.
1187760	1191760	Und das hat damit natürlich zu tun, dass erstens die Kundschaft das erwartet,
1191760	1197760	und zweitens, dass man für den Prius, glaube ich, irgendwie kriegt man eine Zulage von Uber.
1197760	1201760	Oder kann man das von Uber sich leasen lassen, irgendwie sowas.
1201760	1205760	Es hieß also, und das habe ich dann mit allen Apps gemacht, und das wiederholte sich immer,
1205760	1210760	dass sozusagen diese Apps so taten, als würden sie eine Geografie wiedergeben.
1210760	1217760	Eine genuin lokale Geografie. Aber im Grunde genommen in Wahrheit die Geografie,
1217760	1227760	die Lebenswelt der Programmierer dieser Apps, dieser doch ziemlich verschiedenen Gegend, einfach überstöten.
1227760	1233760	Und das habe ich damit gemeint, dass einerseits die Fragen, wie diese Apps funktionieren,
1233760	1236760	eindeutig einer ganz spezifischen Lebenswelt entnommen werden.
1236760	1240760	Einer relativ privilegierten Lebenswelt, aber auch einfach einer lokalen Lebenswelt.
1240760	1243760	Eine Lebenswelt, die nicht so irre groß ist.
1243760	1251760	7 Millionen Menschen, 6 Counties, ich weiß jetzt nicht wie viele Square Miles, aber nicht so irre viele.
1251760	1258760	Und das eben aber doch so mit dem Verständnis angetreten wird, dass das doch für alles jetzt funktionieren wird.
1258760	1263760	Jeder, der mal versucht hat, durch eine mittelalterliche Stadt mit Google Maps zu fahren, hat das auch schon erlebt.
1263760	1270760	Dass Google Maps eindeutig sich entschieden hat, als Straße zu werten, was lokal als Straße gewertet wird.
1270760	1276760	Und das ist auch so eine Sache, wo einfach einem Bewohner des Bay Area eben nicht einfallen würde,
1276760	1279760	dass in mittelalterlichen Städten eine Straße sehr wohl existieren kann.
1279760	1285760	Dass man sie aber mit einem Auto wirklich nicht befahren sollte, wenn man es vermeiden kann.
1285760	1292760	Also das sind so Sachen, wo man einfach merkt, es sind nicht nur so lokale Produktionen diese Apps.
1292760	1295760	Sondern sie kommen auch aus einem ganz bestimmten Milieu.
1295760	1307760	Und dieses Milieu hat, sage ich mal, wenig Einbildungskraft, was lokale Besonderheiten angeht.
1307760	1311760	Das heißt, diese Menschen rekrutieren sich aus einer sehr bestimmten Schicht.
1311760	1316760	Aus sehr bestimmten Unis, aus sehr bestimmten Regionen.
1317760	1322760	Und dadurch werden gewisse Aspekte gar nicht sichtbar.
1322760	1330760	Ich hatte einmal ein Gespräch, um die Gedanken abzuschließen, bei einer Party mit einem Freund, der bei Uber arbeitete.
1330760	1336760	Und der mir sagte, dass Uber sehr viel besser sei als die Taxiunternehmen.
1336760	1342760	Weil viele Taxiunternehmen natürlich in Gebiete mit hoher schwarzer Bevölkerung prinzipiell nicht hinfahren.
1342760	1344760	Das stimmt auch, da hatte er recht.
1344760	1347760	Und er sagte, Uber hat das eben ausgeschaltet.
1347760	1350760	Was nicht stimmte, aber das wusste er damals nicht.
1350760	1352760	Es gibt Indizien, dass die es genauso machen.
1352760	1358760	Aber dann habe ich ihn gefragt, jeder kann eben unseren Service benutzen.
1358760	1362760	Und dann sagte ich, was ist denn mit jemandem, der keine Kreditkarte hat oder kein Smartphone?
1362760	1364760	Und dann sagte er, oh.
1364760	1370760	Und dann dachte ich, Moment, du arbeitest seit zwei Jahren bei dieser Firma.
1370760	1375760	Und du hast noch keinen Gedanken darauf verschwendet, dass es Menschen gibt in dieser Stadt, die keine Kreditkarte haben.
1375760	1377760	Und die kein Smartphone haben.
1377760	1379760	Und dann sprichst du ständig von allen.
1379760	1381760	Das ist für alle da. Uber ist für alle da.
1381760	1383760	Das ist doch ein Universales.
1383760	1386760	In seiner Welt hatte einfach jeder Kreditkarte und Smartphone.
1386760	1388760	Die Vorstellung, das hört man häufig.
1388760	1390760	Everyone's got a Smartphone.
1390760	1392760	No, not everyone has a Smartphone.
1392760	1399760	Das sind so die Momente, wo die Grenzen ihrer Welt, sehr schnell die Grenzen unserer Möglichkeiten werden.
1399760	1401760	Wo wir plötzlich merken, oh, wir sind damit nicht gemeint.
1401760	1409760	Nicht weil ihr irgendwie das Böse gemeint habt, sondern wenn ihr genuin nicht kapiert habt, dass es Menschen gibt, die nicht so sind wie ihr.
1409760	1420760	Und tatsächlich ist ja die Uni, an der du arbeitest, Stanford, durchaus aktiv beteiligt an der Fabrikation dieser sozio-technischen Imaginationen des Silicon Valley.
1420760	1423760	Vielleicht können wir da noch ein bisschen genauer eintauchen.
1423760	1430760	Also worin besteht der, sagen wir, der Anteil von Stanford an diesem Prozess des Bounds?
1430760	1435760	Und mich würde auch interessieren, ob du einen Wandel feststellen kannst.
1435760	1443760	Ich kann mich erinnern, in deinem Buch, da nimmst du einmal auch Bezug auf das Buch von Fred Turner, From Counterculture to Cyberculture.
1443760	1450760	Und wenn ich mich richtig erinnere, grenzt du das aber ein bisschen ab und stellst fest, okay, die Generation, die der Fred Turner damals beschreibt,
1450760	1457760	und das war 2006, glaube ich, das Buch, das ist schon noch irgendwie eine andere Generation als die, die du jetzt dort antrittst.
1457760	1461760	Was macht da den Unterschied aus und was ist die Rolle von Stanford insgesamt in dem Ganzen?
1461760	1470760	Ja, also wie der Titel von Freds Buch hier schon besagt, und das lege ich allen Zuhörern ans Herz, ein wirklich tolles, ein wirklich tolles Buch.
1470760	1479760	Ja, also Freds Buch bezieht sich, wie der Titel ja sagt, auf das Nachleben der Gegenkultur in den Tech-Unternehmen.
1479760	1487760	Und das stimmt tatsächlich, dass die Kollegen bei mir in der Informatik waren bis vor kurzem noch, einige sind es immer noch,
1487760	1497760	im Grunde genommen Hippies, die Computer benutzt haben, um sich Gedanken zu machen über Medien, Bewusstsein, die Gesellschaft.
1497760	1501760	Bei die waren Computer sozusagen eine Spielart der Gegenkultur.
1501760	1507760	Das waren natürlich auch diejenigen, die häufig nicht in die Unternehmen gegangen sind, sondern stattdessen sich eben für den Campus entschieden haben,
1507760	1513760	was natürlich auch noch mal eine Art Präselektion war, das heißt, die sind natürlich nicht repräsentativ.
1513760	1521760	Aber ich denke eben, dass diese Kollegen immer mehr verzweifelt sind, ich zitiere auch einen Kollegen, der wirklich daran verzweifelt ist und Stanford verlassen hat,
1521760	1531760	weil er immer mehr, was er The Get Rich Quick Brigade genannt hat, also diejenigen, die einfach für diese Industrie eben ein ganz starkes,
1531760	1541760	ganz stark mit dem Profit-Motiv verbunden war und die im Grunde genommen in seine Kurse kamen, um zu lernen, wie man das macht.
1541760	1546760	Und das ist für diese Kollegen war das eine wirklich große Enttäuschung.
1547760	1558760	Und viele von ihnen haben den rasanten Anstieg an Informatik-Studenten an Stanford eher als persönliche Katastrophe wahrgenommen, als Triumph.
1558760	1563760	Das ist mehr wie ein Zauberlehrling. Für die Geister, die sie riefen, werden sie nicht los.
1563760	1569760	Also es ist, sie machen einerseits ihre Sache halt so gut, dass man um die nicht herumkommt.
1569760	1577760	Umgekehrt heißt es, dass sich immer mehr Studenten herumschlagen müssen, von denen immer weniger sich wirklich genuin für die Fragen interessieren,
1577760	1585760	die die überhaupt erst in die Informatik getrieben haben und immer mehr sich für den Schnickschnack drum herum interessieren,
1585760	1589760	der meinen Kollegen dem Empfinden nach eher peinlich ist, um ganz ehrlich zu sein.
1589760	1594760	Das ist das Erbe der Gegenkultur doch eher Verhalten, würde ich sagen.
1594760	1598760	Und das ist schon ein sehr wichtiger generationeller Einschnitt.
1598760	1606760	Ich will in dem Buch zeigen, dass es natürlich schon, also Turner ist nicht, Turner's Narrativ ist jetzt nicht komplett abgelöst.
1606760	1614760	Es gibt es noch, die lebt weiter, aber so direkt, wie man noch 1995 wahrscheinlich diese Linie hätte ziehen können,
1614760	1621760	auf jeden Fall 2006 noch, als Fred das Buch schrieb, würde ich sagen, das geht so nicht mehr.
1621760	1629760	Also da ist das Erbe doch, sage ich mal, verhaltener oder einfach angereichert durch andere Einflüsse.
1629760	1641760	Allerdings würde ich sagen, diese Generation mag jetzt, das zeigt sich ganz, ganz behutsam.
1641760	1646760	Ich stelle das als Vermutung, als Vermuten der Diagnose an.
1647760	1651760	Es kann sein, dass ich mir in zwei Jahren nochmal anhöre und sage, ach Gott, du Naivling.
1651760	1656760	Aber das ist so mein Gefühl, dass sich das Blatt wieder wendet.
1656760	1665760	Also mein Kollege Eric Roberts, den ich in dem Buch auch zitiere, der Informatiker in Stanford war jetzt am Reed College in Portland, Oregon.
1665760	1673760	Der sagte eben, uns hat es hart erwischt, dass wir 2008 die Einzigen waren, dass die Technologie die Einzige war,
1673760	1679760	die nicht abgekratzt ist während der Finanzkrise. Und dann kamen eben diese Get Rich Quick Typen.
1679760	1686760	Und ich habe das auch beobachtet, genau das, was er da gesehen hat, habe ich auch bei meinen Studenten beobachtet.
1686760	1691760	Auch das Elterndruck gemacht haben, das Komilitonendruck gemacht haben.
1691760	1697760	Dass jemand sagt, was machst du denn mit dem Englisch-Major? Willst du da nur Burgerflippen gehen oder sowas?
1697760	1702760	Also wirklich hartes Zeugs. Das ändert sich jetzt wieder, habe ich den Eindruck.
1702760	1709760	Und zwar nicht, aber nicht in der Hinsicht, dass plötzlich Leute Hippies da in den Vorlesungen sitzen, sondern dass Menschen da sitzen,
1709760	1714760	die begriffen haben, die sozusagen den Kapitalismus voll mit an Bord genommen haben und sagen,
1714760	1722760	okay, wir werden ausgebildet, um Arbeiter zu werden in einem Konzern. Und wir treten da auf als Belegschaft.
1722760	1727760	Und das heißt, wir verstehen sehr wohl, dass wir streiken können, dass wir klagen können,
1727760	1733760	dass es Bürgerrechte gibt, die wir haben, die wir einklagen können, dass es Antidiskriminierungsgesetze gibt,
1733760	1737760	die, wenn sie missachtet werden, wir eine Pflicht haben, anzuzeigen.
1737760	1745760	Also dass die den Kapitalismus, den Silicon Valley in den letzten zwölf Jahren einerseits absolut gemacht hat,
1745760	1753760	hypostatisiert hat, aber andererseits eben immer weggewischt hat und gesagt, nein, nein, nein, wir sind kein Unternehmen, wir sind eine Familie.
1753760	1757760	Nein, nein, nein, wir müssen ja keinen Profit machen, wir verändern ja die Welt.
1757760	1763760	Diesen Bullshit lassen sie denen nicht mehr durchgehen, sagen, ja, wenn Kapitalismus dann aber, wenn A dann auch B.
1763760	1768760	Wenn Kapitalismus für die Investoren gilt, dann gilt es auch für die Belegschaft.
1768760	1777760	Und das heißt, wir bleiben weg, wenn ihr anfängt mit Erdogan irgendwelche Geschäfte von wegen IP-Tracking aufzunehmen.
1777760	1792760	Das heißt, wenn ihr die Cafeteria-Arbeiter, wenn ihr die Leute, die uns den Lunch vorsetzen, wenn ihr die nicht ausreichend bezahlt, dann streiken wir Programmierer auch.
1792760	1795760	Und so klingen meine Studenten jetzt.
1795760	1804760	Also es kann sein, dass Fred eine Generation beschrieben hat, ich jetzt die nächste beschreibe, im Moment ihre Ablösung.
1804760	1808760	Es kann wirklich sein, dass wir in zwei Jahren, dass ich ein ganz neues Buch schreiben müsste.
1808760	1811760	Ich glaube es nicht ganz, ich glaube nicht ganz daran.
1811760	1814760	Ich glaube, das Kapital findet immer einen Weg.
1814760	1827760	Aber auf jeden Fall die Art Geläubigkeit, die mich zuerst dazu gebracht hat, dieses Buch zu schreiben und die mich sehr beängstigt hat, muss ich sagen.
1827760	1834760	Das war so 2012, 13, 14, also die Ideen, die in dieses Buch dann einflossen zum ersten Mal für mich wichtig wurden.
1834760	1841760	Die, glaube ich, sind nicht mehr so dominant, wie sie einmal waren.
1841760	1847760	Es gibt sie noch, ich habe noch ganz viele Unterhaltungen mit Studenten, die so klingen, aber ich habe viel mehr mit den anderen.
1847760	1852760	Und die Rückmeldungen auf die englische Fassung des Buchs von Studenten ist genau in die Richtung.
1852760	1855760	Ich will in die Tech-Industrie einsteigen.
1855760	1857760	Wie mache ich das ethisch?
1857760	1858760	Wie kann ich sicherstellen?
1858760	1864760	Was für Fragen soll ich denn da stellen, damit ich sicherstellen kann, dass die auch auf ihre Belegschaft hören?
1864760	1871760	Mit wem soll ich reden und zu schauen, dass LGBT und das People of Color da willkommen sind?
1871760	1874760	Und ich muss sagen, weiß ich nicht, aber es ist eine tolle Frage.
1874760	1876760	Und es ist eine richtige Frage.
1876760	1880760	Wenn du da so einsteigst, dann wird das Unternehmen auch schon dadurch besser.
1880760	1885760	Dass jemand sagt, ja, hör mal, so funktioniert die App, aber wo ich herkomme, gar nicht.
1885760	1887760	Es wird auch das Produkt besser machen.
1887760	1894760	Aber es wird auch vor allem diese Firmen, es wird diese toxische Monokultur sehr schnell verändern, glaube ich.
1894760	1907760	Du schreibst dann auch in deinem Buch, dass der Tech-Sektor, wie wir ihn heute kennen, entstanden ist, als ein unhinterfragtes Wertesystem auf große Mengen Geld traf, die keine andere Antwortmöglichkeit fanden.
1907760	1912760	Und du hast jetzt schon mehrmals auch das Kapital und im Speziellen eben das Risikokapital angesprochen.
1912760	1919760	Welche Rolle spielt denn dieses Risikokapital in der Gestaltung der Technologien, die uns alle ja umgeben?
1919760	1931760	Eine enorme Rolle, denn viele der genuin interessanten Ideen, die Silicon Valley in den zwölf Jahren, die ich hier gelebt habe, generiert hat, sind ja nie zu Markt gekommen.
1931760	1939760	Weil die Frage ja nicht ist, wird das die Welt verändern, sondern wird es unsere Investoren reich machen?
1939760	1955760	Und sag ich mal, weil der Anreiz einen Mythos um sich selber und um das eigene Unternehmen zu stricken, anstatt einfach sich hinzusetzen und ein Produkt zu schaffen, natürlich da am wichtigsten ist, wo Risikokapital bedient werden muss.
1955760	1967760	Das heißt, die mediale Zumüllung, die wir alle erfahren durch Menschen wie Elon Musk und so weiter, das ist ein Stil des Thought Leadership, das sozusagen ohne Risikokapital gar nicht zu denken wäre.
1967760	1974760	Denn eigentlich spielen die ja nicht, du und ich sind kollateral im Publikum dafür.
1974760	1977760	Das eigentliche Publikum sind die Kapitalgeber.
1977760	1982760	Wenn wir uns für Elon Musk irgendwie interessieren, dann interessieren sich auch die Kapitalgeber für ihn.
1982760	2010760	Und das ist glaube ich äußerst wichtig, dass dieser Mythos, den diese Unternehmen um sich gestrickt haben, ganz stark damit einhergeht, dass sie einerseits eben von den Ideen und den Hobbys fast, den Grillen der Kapitalgeber abhängen, aber dass sie andererseits eben fast nie Geld verdienen.
2010760	2017760	Das hat diese sehr interessante, ich habe das vorhin die Aufmerksamkeitökonomie genannt, das ist glaube ich kein schlechtes Wort dafür.
2017760	2024760	Dass es wichtig ist, sozusagen alle mit Silicon Valley-Stories zuzuspammen, damit eben das Geld weiterfließt.
2024760	2037760	WeWork ist ein ziemlich gutes Beispiel dafür, wo der Mythos eben dazu da war, ich sage es jetzt mal brutal, zu kaschieren, dass das eigentlich ein Vermieter war, der kein Geld verdient hat.
2037760	2042760	Was man als Vermieter in dieser Lage erstmal schaffen muss.
2042760	2045760	Das ist gar nicht so einfach, als Vermieter Geld zu verlieren.
2045760	2056760	WeWork hat es spektakulär geschafft, aber hat eben sozusagen dann den Jargon und den Persönlichkeitskult von Unternehmen wie Apple oder Google kopiert,
2056760	2066760	um eben sozusagen eine Runway, eine Startbahn zu erzeugen, die sozusagen es allen ermöglicht, ist in Ordnung, wenn die ein paar Milliarden verbraten.
2066760	2071760	Das wird ja am Ende dann total disruptive und toll und dann kriegen wir alle unser Geld zurück.
2071760	2082760	Das scheint jetzt eher ein Pustekuchen zu sein, aber gut, das ist, da will ich jetzt kein, das Wort Schadenfreude will ich jetzt nicht bedienen.
2082760	2095760	Aber es ist auffällig eben, dass das Risikokapital eigentlich ganz stark nicht nur die Industrie selber geprägt hat, sondern eben auch unsere Wahrnehmung dieser Unternehmen.
2095760	2109760	Und hinzu kommt aber eben auch, dass das Risikokapital, also ich will jetzt nicht sagen, dass das Risikokapital sozusagen der Bad Guy ist in meinem Buch.
2109760	2124760	An Schurken hat das, es hat viele Schurken, sage ich mal, aber es ist schon eine besonders fragwürdige Instanz in Silicon Valley.
2124760	2131760	Ich gebe drei Beispiele. Erstens ist Risikokapital ein Riesengrund, warum diese Industrie so homogen ist.
2131760	2147760	Es gibt Versuche von Kapitalgebern und von Denkern, könnte man zum Beispiel Ellen Pow nennen, die bei kleiner Perkins ausgestiegen ist vor ein paar Jahren, ziemlich spektakulär.
2147760	2158760	Die versuchen eben Finanzstrukturen aufzubauen, die es nicht weißen und nicht männlichen Founders ermöglichen sollen, an Risikokapital zu kommen.
2158760	2169760	Das ist derzeit sehr, sehr schwierig. Viele dieser Risikokapitalgeber sind die Gründer von vor 20 Jahren oder vor 10 Jahren, 15 Jahren nicht, also Peter Thiel, Sam Altman und so weiter.
2169760	2190760	Das reproduziert sich immer selber. Das sind häufig Stanford-Absolventen oder Harvard-Absolventen, die weiter Geld an weiße männliche Stanford- und Harvard-Absolventen schaufeln, damit die irgendwie eine neue App schaffen können, die es revolutionieren soll, wie wir Katzenbilder verteilen oder sowas.
2190760	2209760	Das ist das Erste. Die Homogenität in Silicon Valley ist teilweise, oder wer hier gewinnt und wer hier verliert, ist ganz stark abhängig von der Ethnie, vom Geschlecht, vom Habitus, vom Sozialstatus, von der Uni, die man besucht hat und so weiter.
2209760	2214760	Und daran sind ganz maßgeblich die Kapitalgeber schuld.
2214760	2233760	Zweitens ist diese Art Risikobereitschaft, die eigentlich eine Art Hasenfüßigkeit ist, das heißt eine, die so tut, die den Gestus eines Risikos zwar liebt, andererseits aber doch relativ scheu vor Genuim Neuen ist, wie wir es vorhin gesagt haben, ist auch häufig ein Artefakt dieser Kapitalgeber.
2233760	2247760	Das sind Milliardäre, die Milliardäre bleiben wollen. Die haben keinen Anreiz, etwas zu machen. Ich weiß noch nicht, wie das Geld verdienen soll, aber wäre das nicht toll, wenn alle sauberes Wasser bekommen würden.
2247760	2257760	Das ist nicht interessant. Wenn irgendjemand in dein Haus kommt und die Wäsche für dich wäscht und dann weniger bezahlt bekommt, als wenn er das jetzt machen würde, dann gehören sie alle hin.
2257760	2266760	Das ist die Art Revolution, die sie sich vorstellen können. Jeder Gründer im Valley muss sich fragen lassen, wie viel Revolution sich machen lässt, wenn eine Revolution von Milliardären finanziert wird.
2266760	2277760	Das ist eben, was bei diesen Kapitalgebern, bei den angel Investors und bei den Venture Capital Funds eben immer die Frage ist.
2277760	2290760	Und dann drittens, würde ich dazu sagen, sind diese Menschen ganz maßgeblich an dem Mythos der Meritocracy beteiligt im Silicon Valley.
2290760	2303760	Das heißt, das sind häufig Menschen, die, um es ganz ehrlich zu sagen, einmal riesig Glück hatten. Die sind nach Monte Carlo gefahren, haben alles auf 38 Schwarz gesetzt und dann kam 38 Schwarz. Super! Fantastisch!
2303760	2318760	Und jetzt sind sie Milliardäre. Toll! Und jetzt als Geldgeber gehen sie davon aus, dass diese eine Wette eigentlich doch ein Indiz sei, dass sie absolut brillant sind, dass sie die absoluten Übergenies sind.
2318760	2347760	Das ist eben der Punkt. Diese Kapitalgeber verkaufen Glück als Verdienst und umgekehrt verkaufen Unglück, verkaufen es nicht geschafft zu haben, sowohl unter Programmierern als auch unter denen, die für Uber fahren oder für DoorDash Pizzen austragen, als im Grunde genommen ebenso moralisch gedeckt.
2347760	2370760	Die haben irgendwas falsch gemacht. Die waren nicht disruptive genug. Die waren nicht aktiv genug. Aber die basale Wahrheit, dass sie eben nicht auf 38 Schwarz gesetzt haben, dass sie nicht Glück gehabt haben, dass sie vielleicht auch nicht das Geld hatten nach Monte Carlo zu fahren, das kann in diesem Ökosystem nicht zur Sprache kommen und es wird radikal ausgeblendet.
2370760	2387760	Also ich würde sagen, dass in diesen drei Punkten sind die Risikoinvestoren wirklich sehr verantwortlich, stark verantwortlich, nicht absolut verantwortlich, aber stark verantwortlich für das toxische Umfeld, das viele dieser Unternehmen geschaffen haben.
2388760	2405760	Sehr spannend, ja. Also es gibt ja verschiedene Moves, die sagen, die Tech-Industrie darauf hat, dass die von die jetzt Beschriebenen mit dem Risikokapital sind sicher unter den Einflussreicheren.
2405760	2424760	Ein anderer unglaublich geschickter Move, muss man sagen, ist der, dass sie es geschafft haben, so zu tun, als seien Social Media Plattformen quasi neutrale Infrastruktur und sollten deshalb nicht für die durch sie vertriebenen Inhalte verantwortlich gemacht werden.
2424760	2432760	Damit es einmal erwähnt ist, was ist der Communication Decency Act und wieso gibt es die behauptete Neutralität der Plattform eben nicht?
2432760	2445760	Ja, also das ist die berühmte Section 230 des Communication Decency Act, die eben sagen soll, die einerseits, also ich habe mehrere Kollegen, die sich damit von der juristischen Seite beschäftigen und die sagen, das hat natürlich schon seine Begründung.
2445760	2468760	Die Überlegung ist die, dass Twitter für einen Inhalt natürlich nicht redaktionell gerade stehen kann, einfach auch aus der reinen Masse der Tweets heraus, wie jetzt, sage ich mal, der San Francisco Chronicle für einen Text, den er selber angefordert, bezahlt, gesetzt und in Druck gegeben hat.
2468760	2472760	Also es hat im Grunde genommen eine relativ logische Grundlage.
2472760	2479760	Wozu es aber geführt hat, ist eben, dass sich diese Plattformen eben komplett neutral geben können, ohne es wirklich zu sein.
2479760	2484760	Ich meine, diese Kritiken stammen nicht von mir, das ist nicht, das kann man bei anderen viel besser nachlesen.
2484760	2493760	Aber das Problem ist einerseits eben, dass für sowohl Twitter als auch für Facebook Engagement das Wichtigste ist.
2494760	2508760	Das heißt, da das im Grunde genommen Unternehmen sind, die per Werbung getragen werden, ist jemand, ist ein Twitter User, der aufhört zu doom scrollen, wie man heute sagt, ein schlechter User, jemand, der sich von Facebook auslockt, um eine Zeitung zu lesen, ist ein schlechter Facebook User.
2508760	2516760	Und das heißt, dass die immer den Content priorisieren, der die stärkste emotionale Wirkung auslösen.
2516760	2528760	Das heißt, dass eine falsche Meldung über Flüchtlinge, die hunderttausendmal geteilt wird von jedem rassistischen Onkel, der sich von Facebook auslockt, ein schlechter User ist.
2528760	2557760	Das heißt, dass eine falsche Meldung über Flüchtlinge, die hunderttausendmal geteilt wird von jedem rassistischen Onkel in ganz Mitteleuropa, für die viel, viel wertvoller ist als ein Interview mit sechs Geflüchteten über ihre Erfahrungen, mit schönen Bildern und mit einem sehr melancholischen oder nachdenklichen Fazit am Schluss.
2557760	2562760	Das wird zwar auch geteilt werden, aber ist nicht so schnell konsumierbar.
2562760	2573760	Es hat keinen offensichtlichen, hat einen komplizierteren emotionalen Pitch und ist deswegen eben dann vom Engagement her kleiner.
2573760	2587760	Das heißt, die sind im Grunde genommen dazu ausgelegt, darauf ausgelegt, eine ständige Aufregeökonomie zu betreiben.
2587760	2594760	Wir kennen das ja alle. Man schaltet Twitter an und der Puls rast nach drei Minuten.
2594760	2599760	Das spricht dieser Toilet, wie alle sagen.
2599760	2615760	Was ich in dem Buch, was das ver.li.denken nennt, neu dazu beitrage, es kann sein, dass jemand anderes das schon gesagt hat, in dem Fall entschuldige ich mich, aber das war sozusagen für mich ein Gedanke, den ich noch nicht gelesen hatte,
2615760	2625760	war eben, dass die Leute wie Jack Dorsey, der Gründer und derzeitige CEO von Twitter, derzeit mit Rauschebart im Kongress zu beobachten,
2625760	2637760	dass die sich gerne auf so einen alten Topos zurückziehen, nämlich die Enttäuschung, dass wir die schönen Tools, die sie uns geschaffen haben, missbrauchen.
2637760	2647760	Wenn wir nur die Schönheit dieses Mediums erkennen könnten, dann wäre alles besser.
2647760	2653760	Das ist für mich ein ganz fataler Topos.
2653760	2660760	Enttäuschung mit den Kommunikationsmedien ist ein äußerst konservativer Move.
2660760	2667760	Nicht nur auf der konservativen Seite muss man sagen, es ist ein relativ Wohlfeil einerseits.
2667760	2680760	Es ist andererseits eine Art Pauschalisierung, also wenn man im deutschen Feuilleton liest, auf Twitter war zu hören, dann merkt man gleich, aha, da werden jetzt die Schmuddelkinder sozusagen in ihre Ecke gestellt.
2680760	2689760	Ich halte diese Art Enttäuschung, man kann beides sagen.
2689760	2693760	Einerseits ist viel von Twitter ziemlich scheiße.
2693760	2699760	Andererseits finde ich Enttäuschung über Twitter ostentative, Enttäuschung über die sozialen Medien genauso scheiße.
2699760	2706760	Das sind imperfekte Kommunikationsplattformen, ebenso wie alle unsere anderen Kommunikationsplattformen.
2706760	2711760	Und da haben wir, tragen wir eine Mitschuld dran und da sollten wir uns das besser machen.
2711760	2718760	Aber ganz, ganz stark trägt Jack Dorsey eine Mitschuld daran und der muss seine Plattform ändern.
2718760	2720760	Und das fängt ja jetzt an.
2720760	2726760	Also nach vier Jahren Trump werden diese Tweets endlich mal als Fehlinformation markiert.
2726760	2734760	Dass sie das nicht gewagt haben, wer der Präsident ist, wird immer ein Makel auf diesem Unternehmen sein.
2734760	2739760	Aber es zeigt ja doch, dass sie sich das schon überlegt haben.
2739760	2741760	Die hatten diese Strategie.
2741760	2750760	Und dieses kleine Informationszeichen unter diesen Tweets oder dieses kleine Do you want to see this content und so weiter
2750760	2759760	ist im Grunde genommen ein Armutszeugnis für Twitter, weil es sagt, so transparent wie wir uns geben, sind wir halt nicht.
2759760	2763760	Machtstrukturen beeinflussen halt doch, was hier passiert.
2763760	2765760	Wir sind nicht alle gleich.
2765760	2771760	Auf einer abstrakten Ebene sind ich und Donald Trump genauso Twitterer, aber eben doch nicht.
2771760	2778760	Ich habe etwas unfreundliches bei Faschos getweetet und durfte dafür 48 Stunden von Twitter weg.
2778760	2783760	Wurde blockiert, weil mich natürlich irgendwie ein, nach dem Netz-DG, irgendjemand in Deutschland,
2783760	2786760	ich habe den Fehler gemacht, das auf Deutsch zu tweeten, nehme ich an.
2786760	2797760	Aber umgekehrt durfte Trump ja unmögliches verbreiten und alle möglichen Guidelines verletzen und durfte trotzdem weitermachen.
2797760	2806760	Also insofern hat Twitter sozusagen seine eigene, ist seinem eigenen Anspruch, eine Art Forum zu sein, nie gerecht geworden.
2806760	2813760	Er hat es nie wirklich ernst genommen, dieses Versprechen von dem und hat andererseits doch dann immer den Enttäuschten markiert.
2813760	2825760	Wenn ihr nur bessere Twitter-User wäret, dann gäbe es nicht so viele white nationalists auf Twitter.
2825760	2827760	Nein, nein, nein.
2827760	2837760	Die Art, die dieses Unternehmen Geld verdient, das Geschäftsmodell ist darauf ausgelegt, dass es genau so etwas hier gibt.
2837760	2844760	Und dass das damit muss Jack Dorsey leben. Und wenn er das nicht kann, dann soll das ändern.
2844760	2850760	Und letztlich muss man sagen, speist sich ja diese Enttäuschung eigentlich auch nur aus der vorhergegangenen Überhöhung, würde ich sagen, oder?
2850760	2853760	Also ohne die ist das Ganze letztlich auch nicht denkbar.
2853760	2862760	Und wir sind jetzt schon sehr nah an einem anderen Thema, was du in deinem Buch ansprichst, was mir auch große Freude gemacht hat beim Lesen, muss ich sagen.
2862760	2864760	Und zwar geht es da um Trolle.
2864760	2869760	Das fand ich wirklich überaus interessant oder ein guter Abschnitt in deinem Buch.
2869760	2877760	Und im Grunde so, wenn ich das richtig verstehe, sagst du eigentlich, dass der Troll eigentlich die Violine spielt, wie sie gespielt werden soll.
2877760	2878760	Genau.
2878760	2882760	Vielleicht kannst du das ein bisschen beschreiben. Was ist die Logik des Trollens?
2882760	2887760	Also für mich war, es gibt natürlich ganz viele verschiedene Arten des Trollens.
2887760	2891760	Es gibt auch welche, die ich sehr, sehr lustig finde, muss ich zugeben, oder die ich sehr kreativ finde.
2892760	2897760	Ich selber habe manchmal, wir sind ja alle irgendwie Trolle, die Vorstellung, dass es den Troll als Typen gibt.
2897760	2900760	Also es ist eine Bandbreite.
2900760	2911760	Aber eine sehr wichtige, eine sehr wichtige Art des Trollens finde ich eben die Art Intervention, von der gar nicht klar ist, was sie eigentlich für eine Art Kommunikation sein soll.
2912760	2919760	Der Reply Guide zum Beispiel, der irgendwas beifügt, das irgendwie gar nicht zur Sache tut.
2919760	2924760	Und wenn du ihn darauf hinweist, dann sagst du, ja, da bin ich halt missverstanden worden.
2924760	2931760	Aber sich nie die Frage stellt, die z.B. Jacques Deux, die sich auch nicht stellt.
2931760	2934760	Nämlich, wozu sollte das denn jetzt gut sein?
2934760	2937760	Was war meine Kommunikation, sondern wozu sollte sie dienen?
2937760	2940760	Was wäre eine gute Antwort darauf gewesen?
2940760	2944760	Und das ist für mich eine Essenz, eine Art des Trollens.
2944760	2951760	Es gibt andere Arten, das will ich gar nicht in Abrede stellen, aber ich glaube, ein Großteil des Trollens lässt sich darauf reduzieren,
2951760	2958760	dass im Grunde genommen eine Kommunikation hergestellt wird, nur um enttäuscht zu werden.
2958760	2961760	Ich wollte ja nur eine Frage stellen.
2961760	2964760	Ich wollte ja nur sagen, dass ich das so nicht beobachtet habe.
2964760	2972760	Ich wollte ja nur bitten, dass Sie, eine Person of Color, mir Belege bringen dafür, dass Sie rassistisch behandelt worden sind.
2972760	2974760	Just asking questions.
2974760	2982760	Wie das aussehen sollte, dass so ein Beweis gar nicht existiert, wird sozusagen, stillschweigend, vorausgesetzt, aber auch verschluckt.
2982760	2986760	Das heißt, der Troll ist im Grunde genommen absolut enttäuschbar.
2986760	2988760	Er ist immer schon enttäuscht.
2988760	2990760	Egal, was zurückkommt, er wird erstmal ganz enttäuscht sein.
2990760	2992760	Ich habe das ab so ernst gemeint.
2992760	2994760	Ich habe das so nett gefragt.
2994760	2998760	Und dann kommen Sie so mit Ihrer Cancel Culture.
2998760	3000760	Mein Gott, wie können Sie nur?
3000760	3002760	Das ist der Troll. Das ist der Jesus des Troll.
3002760	3008760	Und das ist genau, wie du gesagt hast, das ist eigentlich keine Perversion der sozialen Netzwerke.
3008760	3012760	Der Troll spielt die Orgel genauso, wie sie gebaut ist.
3012760	3014760	Er drückt alle Tasten.
3014760	3018760	Er nutzt die Kürze aus.
3018760	3022760	Er ist persönlich getroffen, wenn es für ihn gut ist.
3022760	3024760	Und er ist absolut unpersönlich.
3024760	3026760	Der Geist der Maschine, wenn es gut für ihn ist.
3026760	3030760	Das Beispiel, das ich bringe, ist die Journalistin Sarah Jong.
3030760	3040760	Die vor Jahren sich von einem Nazitroll hat dazu verführen lassen, seine Logik sozusagen auf Weiße anzuwenden.
3040760	3042760	In einem sehr lustigen Twitter-Thread.
3042760	3050760	Der aber eben einfach gezeigt hat, was wäre, wenn ich eure Tweets auf Weiße Personen beziehen würde.
3050760	3058760	Und dann wurde sie von den New York Times als Editorial Writer angeheuert.
3058760	3062760	Also sozusagen als Leitartikelautorin angeheuert.
3062760	3066760	Und dann kam die Trolle mit ihren alten Tweets.
3066760	3068760	Aus dem Kontext gerissen natürlich.
3068760	3070760	Jedes Mal, wenn sie irgendwas tweetet, kommen die.
3070760	3078760	Was ich faszinierend fand, ich hab mal ungefähr 28 Stunden mit ihrem Twitter verbracht, wie schnell das kam.
3078760	3080760	Und wie automatisch.
3080760	3082760	Und wie eigentlich sachunbezogen.
3082760	3086760	Und ich hab irgendwann gemerkt, das ist fast wie der umgekehrte Touring-Test.
3086760	3095760	Ich konnte nicht sagen, ob das Menschen waren, die einfach obsessiv sich einen Alert zurechtgelegt haben, wenn Sarah Jong twittert.
3095760	3097760	Oder ob das tatsächlich automatisiert ist.
3098760	3101760	Und in dem Moment ist es ja eigentlich auch egal.
3101760	3103760	Es kam aufs selbe raus.
3103760	3105760	Und das war für mich so der Moment.
3105760	3117760	Ja, das sind Menschen, die sozusagen den Spammer und den obsessiven Nerd sozusagen in eines führen.
3117760	3131760	Und das ist so der Moment, in dem sie eigentlich, ja, sich mit der Struktur dieses, mit der Hitze, wie McLuhan sagen würde, dieses Mediums identisch machen.
3131760	3139760	Das ist der Moment, in dem sie sagen, ich benutze dieses Ding jetzt genau so, wie Twitter es von mir will.
3139760	3151760	Viel Engagement, viel Emotionalität, viel Aggro, sag ich mal.
3151760	3154760	Aber dann auch Ewiges hin und her.
3154760	3163760	Also ein Troll ist ja dadurch, auf häufiger Kennzeichnung, dass es gibt die Möglichkeit, einen zu trollen, indem man einfach einen Satz zurückschreibt.
3163760	3165760	Delete your account.
3165760	3167760	Das ist eine Art, das ist eine beliebte Art des Trollens.
3167760	3169760	Was ich auch sehr lustig finde.
3169760	3172760	Aber der Punkt ist, dass man nicht zurückschreibt.
3172760	3182760	Aber viele dieser Trolle, indem sie dann so tun, als sei ihre erste Intervention tatsächlich eine Kommunikationsakt gewesen, schreiben dann zurück, ja, warum antworten sie mir nicht?
3182760	3183760	Warum debattieren sie mich nicht?
3183760	3187760	Warum fürchten sie sich vor mir?
3187760	3191760	Allein schon daran, die generieren einfach unglaublich viele Tweets.
3191760	3194760	Die sind also eigentlich die perfekten Twitter User.
3194760	3197760	Die sind genau die User, die sich Jack Dorsey wünscht.
3197760	3202760	Und das ist eben im Grunde genommen die Wahrheit, vor der er sich zu verstecken sucht.
3202760	3209760	Dass diese Menschen nicht diese Form ad absurdum führen, sondern dass sie im Grunde genommen seine Jünger sind.
3209760	3218760	Dass sie sich seinen Konstrukt angeschaut haben und gesagt haben, ich habe mich entschieden, kein Rebell zu sein.
3218760	3220760	Ich bin jetzt der Todesstern.
3220760	3222760	Jack Dorsey hat mir einen schönen Todesstern gebaut.
3222760	3224760	Das benutze ich jetzt mal.
3224760	3233760	Und das ist, glaube ich, da ist der Trolle der Virtuose von Twitter.
3233760	3238760	Das ist aber etwas, was sich Twitter selber nicht eingestehen wird.
3238760	3248760	Und was ich total gut fand, war, du hast dann auch in diesem Abschnitt zur Kommunikation, hast du diesen Mechanismus, den du jetzt gerade in Bezug auf die Online-Trolle beschreibst,
3248760	3254760	nämlich dass man so tut, als hätte man eigentlich die Hand ausgestreckt in einem kommunikativen Akt,
3254760	3264760	aber eigentlich in Wirklichkeit überhaupt gar nicht eine Antwort, eine produktive Antwort oder einen Diskurs gesucht hat, sondern im Grunde nur die Enttäuschung gesucht hat.
3264760	3278760	Diesen Mechanismus, den beschreibst du dann auch ganz schön an einem Real-World-Beispiel und zwar dem des Autors dieses Google-internen Memos, mir ist jetzt der Name entfallen.
3278760	3281760	James Damore, ich glaube, so spricht sich das aus, ja.
3281760	3291760	James Damore, aha, ja, weil das fand ich nämlich auch sehr aufschlussreich, weil ich das Gefühl habe, dass das nämlich so ein Diskursvollzug ist oder eben kein Diskursvollzug letztlich,
3291760	3302760	die Antäuschung eines Diskurses, wenn man so will, dass das etwas ist, was man jetzt immer wieder auch einfach in vielen verschiedensten gerade politischen Kontexten eigentlich auch wiederfindet.
3302760	3310760	Und dass das aber eigentlich eine sehr perfide Move ist eben. Vielleicht kannst du das nochmal kurz beschreiben, wie das da ablief.
3310760	3328760	Ja, genau, es ist, als James Damore eben diese Google-Memo schrieb und danach relativ schnell dann auch von Google eben rausgeschmissen wurde, war das jetzt so eine perfekte Opfergeschichte für eben konservative Kreise.
3328760	3335760	Und der Gestus war immer, ja, ich stelle ja nur ein paar Fragen.
3335760	3338760	Kannst du kurz sagen, welche Fragen er da gemeint hat?
3338760	3349760	Ja, das ist gar nicht, das ist gar nicht mal so klar. Er hat das nie, er hat das nie, also es schien so, dass er sagen wollte, Google hat, der eigentliche Titel der Memo war Google's Ideological Echo Chamber.
3349760	3354760	Also im Grunde genommen hat er gesagt, es gibt zu viele Linke bei Google und konservative Fragen dürfen nicht gestellt werden.
3354760	3371760	Aber es war eine Reaktion auf ein Diversity Training, also auf die Frage, wie man mit, wie man in einem Arbeitsplatz funktioniert, in dem es halt Menschen gibt, die anders sind, die nicht weiße Männer sind.
3371760	3386760	Die Memo hat also ziemlich klar eben sagen wollen, ich so, es ist ein Problem, dass Google keinen Platz macht für Menschen, die sagen, dass Frauen und People of Color bei Google nichts zu suchen haben.
3386760	3393760	Und genauso wurde es auch aufgenommen. Und genauso wurde das, so hat Google das auch verstanden und hat gesagt, das geht nicht.
3394760	3408760	Du kannst nicht ein Drittel unserer Belegschaft sagen, dass sie ihre IQ und ihre, was weiß ich, Schädelmessungen nahelegen, dass sie hier nur als Fehler sind und dass sie eigentlich rausschliegen sollten.
3408760	3417760	Das ist mit unserer Firmenkultur nicht vereinbar. Aber das wurde dann eben als unmögliche Zensur ausgelegt.
3417760	3424760	Aber Teil dessen war eben, dass eben gesagt wurde, er habe ja nur Fragen gestellt. Er habe ja nur ein bisschen Research zitiert.
3424760	3434760	Dass das ein Research war von Menschen, die eindeutig Rassenkunde im Sinne des Dritten Reiches betreiben, wurde sozusagen erst mal geflissentlich beiseite gelassen.
3434760	3437760	Er hat ja nur wissenschaftliche Texte zitiert.
3438760	3446760	Ja, das Wichtige daran ist eben, dass es sozusagen vorfabriziert war für diese Art Enttäuschung.
3446760	3453760	Wie enttäuschend, dass Silicon Valley so sich für diese Ideen verschließt, dass es diese Ideen nicht mehr ernst nimmt.
3453760	3464760	Aber die Frage war eben, wie hätte das denn ausgesehen? Wie sieht das denn aus, wenn eine schwarze Frau, die als Programmiererin bei Google tätig ist, eine Debatte führt mit James Damore?
3464760	3471760	Ja, ich sollte hier beschäftigt sein dürfen. Was ist das für eine Debatte? Wer würde denn da hingehen?
3471760	3480760	Was für eine Debatte wird denn da gesucht? Du sollst nicht sein, ist keine interessante Debattenvorgabe.
3480760	3491760	Das ist ziemlich perverse. Aber weil eben die Reaktion das eigentliche Thema wurde, konnte das sozusagen geflissentlich übersehen werden.
3491760	3501760	Das ist ganz ähnlich wie das Sprachspiel der politischen Korrektheit in Deutschland oder in deutschsprachigen Medien.
3501760	3509760	Wo immer die Reaktion, die neue Intoleranz zum Thema gemacht wird und die Frage, was sollte das denn anderes eigentlich bewirken?
3509760	3513760	War das nicht genau die Reaktion, die du eigentlich wolltest?
3513760	3528760	Was war die andere Reaktion, die die ausgeblieben ist angeblich, die du intendiert hattest, die du dir vorgestellt hast in dem Moment, als du Dieter Nuhr deinen hoch komischen Text vorgelesen hast über Alisaster sowas.
3528760	3538760	Was hattest du dir vorgestellt, was da jemand sagt? Was war die Erwartung, die so brutalst enttäuscht wurde?
3538760	3547760	Und ich glaube, diese Leute können das nicht beantworten, einfach weil sie diese Reaktion natürlich vorher gesehen haben und sie es auf diese Reaktion auch angelegt hatten.
3547760	3557760	Und das ist ja auch gut, kann man sagen, das macht die bei gewissen Menschen sehr beliebt. Ich denke mal an, die verdienen sich damit eine goldene Nase. Warum würde man das sonst machen?
3557760	3571760	Okay, das Problem ist, wenn wir das als Gesellschaft, als genuine Kommunikation und die Reaktion von anderen als genuine Kommunikationsverweigerung wahrnehmen,
3571760	3581760	wenn wir sagen, sind wir jetzt schon so weit, dass sich in Deutschland Menschen nicht dazu herablassen, ihre eigene Existenz zu debattieren.
3581760	3596760	Wie intolerant von ihnen, dass sie sagen, dass sie sich mit der Position, ihr gehört alle abgeschoben, nicht auseinandersetzen wollen, nur weil sie halt einen deutschen Pass haben und so weiter.
3596760	3607760	Also das ist für mich das Fatale. Wenn das in einem gewissen Sektor des Internets sowas gut sieht, klar, es ist geschenkt.
3607760	3615760	Dass gewisse Menschen das ausschlachten, ja, Scheiße ist aber so. Free Country.
3615760	3628760	Dass aber das dann irgendwie gesamtgesellschaftlich so reflektiert wird, als würden unsere Kommunikationskanäle irgendwie schlechter funktionieren als früher, halte ich für entfahrend.
3628760	3635760	Das halte ich eben für genau denselben Fehler, den Jack Dorsey macht. Das ist der Fehler häufig vieler Deutscher, nicht alle, aber vieler.
3635760	3643760	Und ich denke, das ist eben diese Art heereenttäuschung, die nie wirklich sagen kann, in was sie denn jetzt eigentlich enttäuscht wurde.
3643760	3652760	Was ihr genuines Angebot war, das angeblich so gemein ausgeschlagen wurde.
3652760	3656760	Absolut, also da kann ich nur aus ganzem Herzen zustimmen, muss ich sagen.
3656760	3661760	Wir haben jetzt über Disruptoren, über Risikokapital und jetzt zuletzt über Trolle gesprochen.
3661760	3668760	Und du hattest es eigentlich vorhin auch schon im Grunde auf eine Art beantwortet oder angesprochen.
3668760	3674760	Zumindest ist, du hast auf der einen Seite diesen Generationswechsel beschrieben in Richtung Get Rich Fast Orientierung.
3674760	3678760	Aber du hast auch schon angedeutet, es gibt natürlich auch die andere Seite.
3678760	3692760	Das ist nicht, das ist kein ganzes Bild, diese Get Rich Fast Orientierung, sondern es gibt eben auch viele Menschen, die immer noch in die Tech-Branche strömen, mit ganz anderer Orientierung, mit durchaus einer idealistischen Orientierung.
3692760	3698760	Vielleicht können wir quasi gegen Ende nochmal diese optimistische Rampe nehmen.
3698760	3704760	Wo siehst du sie denn hinstreben, diese Idealistinnen und Idealisten, die in die Tech-Branche gehen?
3704760	3710760	Ja, also ich muss zugeben, unter meinen jüngeren Studenten habe ich nicht das Gefühl, dass sie sehr idealistisch sind.
3710760	3714760	Sie sind realistisch, sie verlangen das Unmögliche.
3714760	3721760	Also sie sagen, wenn wir wirklich genuin Neues in dieser Wirtschaftszweigerzeugung, dann lass uns das auch machen.
3721760	3729760	Also sozusagen, sie lassen sich nicht mehr mit Versprechungen abspeisen, sondern sie stellen einfach Fragen.
3730760	3741760	Es ist der Idealismus einer guten Gewerkschaft, die sagen soll, wir können doch alle davon leben, das muss doch irgendwie möglich sein.
3741760	3749760	Oder es muss doch möglich sein, Geld zu verdienen in dieser Gesellschaft, ohne dass andere Menschen in absolute Armut versinken.
3749760	3757760	Das kann man für einen Idealismus halten, aber das halte ich für einen sehr realistischen Optimismus.
3757760	3773760	Es ist wirklich eine sehr, es ist einfach eine Unwilligkeit, gewisse Aussparungen, gewisse Abstraktionen so hinzunehmen und einfach nachzufragen.
3773760	3780760	Und ich glaube, da hilft es sehr, dass viele dieser Unternehmen, da muss man ihnen wirklich auch einfach credit where credit is due,
3780760	3786760	dass sie doch eindeutig versuchen, nicht mehr ganz so monokulturell zu funktionieren.
3786760	3791760	Dass es ihnen wichtig ist, dass da Menschen am Tisch sitzen, die andere Erfahrungen mitbringen.
3791760	3799760	Dass sie häufiger eben doch, auch jetzt gerade während der Trump-Jahre, immer wieder gesagt haben, das sind unsere Werte.
3799760	3811760	Und da ist es uns scheißegal, ob das jetzt uns zum Nachteil gereicht mit den White Supremacists im Weißen Haus.
3811760	3815760	Und das sind für mich alles sehr, sehr positive Signale.
3816760	3829760	Ich glaube, dass das utopische, also eine Art der Utopie, die ich nicht habe vorhersagen können, als ich 2015 mit der Arbeit an diesem Buch angefangen habe,
3829760	3835760	die mich immer wieder überrascht hat, ist der Utopismus so zu sein wie alle anderen.
3835760	3845760	Es ist eine Branche, unter vielen sein könnte, die ihre Segnungen hat und birgt, aber umgekehrt eben auch einfach nur mit Wasser kocht.
3845760	3853760	In dem letzten Kapitel des Buchs geht es um das Scheitern und darum, dass eigentlich Silicon Valley das Scheitern unmöglich gemacht hat.
3853760	3861760	Was einerseits natürlich eine wunderschöne Vorstellung ist, aber andererseits eben doch unglaublich mit der Machtpolitik in Silicon Valley zu tun hat
3861760	3864760	und damit, wer man ist und wo man herkommt und wie jung man ist.
3864760	3873760	Und in den Recherchen für den Artikel, auf dem dieses Kapitel basiert, habe ich ein Gespräch geführt mit einem Firmengründer,
3873760	3881760	dessen Firma einmal das ganz große neue Ding sein sollte und dann irgendwann nach drei Jahren haben die entdeckt, daraus wird nichts.
3881760	3887760	Und dann war die Frage, ja, sollen wir unsere Willigschaft rausschmeißen und einfach neues Risikokapital für das nächste Ding einsammeln?
3888760	3895760	Und stattdessen haben die zwei Gründer gesagt, du, was ist denn, wenn wir das ist, was wir hier haben, ist eigentlich ein schönes Mittelstandsunternehmen.
3895760	3907760	20 Belegschaften, irgendwie 20, 25 Leute. Wir können unsere Sekretärinnen gut bezahlen, wir können die Empfangsdame gut bezahlen, alles toll.
3907760	3915760	Wir machen unsere Sache gut, unsere Kunden mögen unser Produkt, wachsen werden wir nicht mehr, aber das ist auch in Ordnung.
3915760	3921760	Und er sagt, das Verrückte ist, das ist für Silicon Valley, für unsere Geldgeber war das ein Scheitern.
3921760	3928760	Aber wir haben sie überzeugen können, dass wir das machen wollen, wir haben uns freigekauft und seitdem, ich verdiene nicht viel, aber ich verdiene genug.
3928760	3938760	Und wir kommen zur Arbeit, wir arbeiten nicht zu viel, wir beuten uns gegenseitig und uns selber nicht mehr aus, wir können alt werden, wir können gut alt werden in diesem Betrieb.
3938760	3946760	Und diese Utopie, wir sind wie eine Automechaniker-Werkschaft im Grunde genommen, aber eben für Software, das ist sowas von schön.
3946760	3960760	Und ich glaube, das ist ein bisschen die Utopie meiner Studenten, dass sie sagen, ich gehe dahin, das ist auch nicht anders, als würde ich im Werk arbeiten oder in der Werft.
3960760	3972760	Ich komme als Arbeiter dahin und ich stelle etwas her, was gesamtwirtschaftlich natürlich wichtig ist und Impulse geben kann, was ein Wirtschaftszweig mächtig und groß machen kann.
3972760	3982760	Das kann ja auch was Schönes sein, aber ich bin eben ein Arbeitnehmer und das heißt, ich muss einklagen, dass dieses Unternehmen mit dem Klima gut umgeht,
3982760	3988760	dass es mit der ganzen Belegschaft umgeht, dass nicht nur ich gut behandelt werde, sondern auch andere Arbeiter gut behandelt werden.
3988760	4001760	Und wenn nicht, dann habe ich meine Mechanismen, dann kann ich streiken, dann kann ich mir woanders hingehen und so weiter und so weiter.
4001760	4014760	Also es gibt verschiedene Arten des Tech-Utopismus, aber den, der mich sozusagen überrascht hat, den, den ich nicht vorhergesagt habe, ist eine Art Sparflammen-Utopismus,
4014760	4023760	dass bei diesen überzogenen Zukunftserwartungen, die diese Industrie habituell uns weckt, es manchmal unglaublich utopisch sein kann.
4024760	4036760	Nein, seien wir doch mal normal, seien wir doch, orientieren wir uns doch daran, was andere gemacht haben.
4036760	4052760	Also ein wunderschöner Moment, auch dank der Kollegen Moira Weigel und Ben Tarnow, die vorhin schon erwähnt wurden, war ein Penner ganz am Anfang der Trump-Jahre.
4052760	4066760	Tech against Trump. Und das war wirklich, das waren lauter Leute von Facebook und so weiter und Google, aber nicht jetzt obere Etage, aber doch Programmierer und ganz viele Gewerkschafter.
4066760	4074760	Und der Grundtenor des Abends war nicht, dass die Technologisten uns mal wieder die Welt erklären.
4074760	4079760	Wie können wir Twitter dazu bringen, was weiß ich? Nein, die waren da, um von den Gewerkschaftern zu lernen.
4079760	4085760	Wie macht ihr das? Wir wollen unsere Belegschaft, wir sind eine Belegschaft, wir begreifen das jetzt. Wir wollen nicht mehr Teil des Problems sein.
4085760	4092760	Wie habt ihr das gemacht? Wie organisiert man eine Ölraffinerie? Wie kann ich das beim Facebook Campus machen?
4092760	4107760	Das hat mich unglaublich bewegt. Das fand ich wunderschön. Einfach die Vorstellung, dass der Exzeptionalismus dieser Branche,
4107760	4119760	der selbst den Reichsten in dieser Branche häufig zum Nachteil gereicht hat, selbst vielen, die es geschafft haben in dieser Branche zum Nachteil gereicht hat, dass dieses Ausnahmedenken ausgehebelt wurde.
4119760	4130760	Wir können lernen von Typen in Overalls, die die Schiffe zusammenschrauben oder die Ölpipelines verlegen. Die können uns erklären, wie man sowas macht.
4130760	4140760	Und das fand ich ganz, ganz toll. Und das ist so ein bisschen die Hoffnung, die unerwartete Hoffnung, die mich beschlichen hat im Schreiben dieses Buches.
4140760	4147760	Total interessant, muss ich sagen. Das höre ich mit absolut gemischten Gefühlen, muss ich sagen.
4147760	4164760	Auf der einen Seite ist es natürlich total ein super erster Schritt und ganz großartig nämlich auch, dass ja gerade die Tech-Worker sich im Grunde auch als eine Art von Schlüsselindustrie mit all der Macht, die damit einhergeht, empfinden lernen.
4164760	4172760	Und diese Macht dann auch bewusst einsetzen, um ihre Arbeiterinnenrechte dann eben einzufordern. Das ist ja fantastisch und da bin ich natürlich absolut dafür.
4172760	4186760	Gleichzeitig ist natürlich quasi das Weinen der Auge ist dann eigentlich entsteht dadurch, dass das auch was darüber aussagt, wie weit wir eigentlich weg waren von dem Ganzen.
4186760	4197760	Also wenn schon so eine ganz milde Sozialdemokratie, also normale Sozialdemokratie, also irgendwie eine Absicherung angestellt sein und irgendwie gewisse Rechte haben.
4197760	4205760	Wenn das schon quasi die Hero-Utopie ist, dann sagt das natürlich auch sehr viel aus, von woher man gestartet ist im Grunde.
4205760	4212760	Und ich würde ja ganz klar dafür votieren, dass wir das als einen Zwischenschritt sehen sollten und weit darüber hinaus schießen.
4212760	4215760	Aber auf jeden Fall total spannend, muss ich sagen.
4215760	4222760	Ja, da stimme ich auch ganz mit dir überein. Das ist immer ein Zeichen, wie in welch dunklen Zeiten wir leben.
4223760	4234760	Das ist jetzt eigentlich mein Stichwort zu der letzten Frage, die ich am Ende eines jeden Podcasts stelle, nämlich wenn du dir Zukunft vorstellst, was stimmt dich freudig?
4234760	4249760	Naja, also schon gerade wenn es was die Technologie betrifft, die Vorstellungen, was diese doch unglaublich beeindruckenden Technologien einmal leisten könnten,
4249760	4257760	wenn sie nicht im Dienst von ein paar Risikokapitalisten wären, stimmt mich schon sehr, sehr.
4258760	4263760	Ich meine, der Weg dahin ist steinig und lang und es kann auch ganz, ganz anders kommen.
4263760	4271760	Aber ich denke, wenn es so käme, das wäre schon irgendwie unglaublich und wäre schon irgendwie inspirierend.
4274760	4281760	Ich denke auch, dass, was mich auch hoffnungsvoll stimmt, sind einfach junge Menschen.
4281760	4289760	Ich meine, ich habe dieses Buch in Dialog mit jungen Menschen geschrieben und habe eben gemerkt, dass junge Menschen keine, das weiß man ja, aber es sind keine Konstante.
4289760	4302760	Und dass diese Generation eben, das ist in den USA die Generation, die unter Barack Obama eben Kinder waren, mit Bernie Sanders erwachsen wurden und die jetzt eben ins Arbeitsleben kommen.
4302760	4312760	Das ist die Generation, die unter Hunderttausenden Dollar von Schulden jetzt schon echt, Mitte 20.
4312760	4331760	Und das ist die Generation, die Covid dazu benutzt hat, ihr Verständnis von gesellschaftlich Verantwortlichem Handeln nochmal zu explizieren und gegen die Unverantwortlichkeit der Babyboomer ehrlich gesagt zu verteidigen.
4331760	4342760	Um es mal ganz runter raus zu sagen. Ich kann, ich will nicht zu hoffnungsvoll sein, aber es ist für mich schwer vorstellbar, dass es eine Generation ist, mit der sich nicht, die nicht viel erreichen kann.
4342760	4356760	Die haben viel durchgemacht, aber sie haben, es sind ihm glaube ich Impulse eingeimpft worden, die es ihnen ermöglichen, was vorige Generationen nicht vermocht haben.
4356760	4365760	Also wenn ich Hoffnung brauche, dann gehe ich in meine Seminarräume, was ich jetzt in einer Stunde auch nochmal tun werde.
4365760	4374760	Für ein Seminar, das heißt der Faschismus nach dem Faschismus. Und da sitzen ganz viele Leute, die dann irgendwann bei Twitter arbeiten werden und bei Facebook und so weiter und so weiter.
4374760	4380760	Und die Fragen, die die stellen, die geben mir die allergrößte Hoffnung für die Zukunft.
4380760	4392760	Das sind junge Menschen, die sich für das Klima verantwortlich fühlen, die sich für ihre Mitmenschen verantwortlich fühlen, die sich für den Kapitalismus verantwortlich fühlen, was der anrichtet.
4392760	4397760	Auf eine Art und Weise, die ich selbst vor sechs Jahren, acht Jahren bei meinen Ständen festgestellt habe.
4397760	4410760	Und die bei allem Zynismus, den sie sich wirklich verdient haben, doch eindeutig dafür plädieren, es noch einmal darauf ankommen zu lassen und zu gucken, was geht.
4410760	4412760	Und das gibt mir ganz enorme Hoffnung.
4412760	4416760	Wunderbar. Großartig. Vielen Dank für das Gespräch.
4416760	4417760	Danke Jan.
4422760	4424760	Das war Future Histories für heute.
4424760	4426760	Vielen Dank fürs Zuhören.
4426760	4432760	Show-Notizen und vieles mehr findet ihr auf www.futurehistories.today.
4432760	4437760	Diskutiert mit auf Twitter unter dem Hashtag Future Histories oder auf Reddit.
4437760	4441760	Lasst mich wissen, was ihr zu dem Ganzen denkt und wie euch diese Folge hier gefallen hat.
4441760	4445760	Unbedingt gut bewerten auf allen Podcast-Plattformen, die ihr nutzt.
4445760	4453760	Für unsere Patreon-Unterstützerinnen und Unterstützer gibt es auf www.patreon.com schrägstrich Future Histories vieles an Zusatzmaterial.
4453760	4458760	Da könnt ihr also auch vorbeischauen. Bis zum nächsten Mal. Ich freue mich.
