start	end	text
0	4960	Herzlich willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von
4960	11120	Zukunft. Mein Name ist Jan Groß und ich freue mich sehr, heute Robert Seifert begrüßen zu dürfen.
11120	17460	Er ist Professor für Soziologie an der Christian-Albrechts-Universität zu Kiel und arbeitet unter
17460	23880	anderem an einer Theorie algorithmischer Sozialität. Gemeinsam mit Jonathan Robert hat er den
23880	30720	Sammelband Algorithmus Kulturen herausgebracht, den man als Open Access Publikation bei Transkript
30720	38080	finden kann. Und Full Disclosure, Robert betreut meine Doktorarbeit, was mich sehr freut. Ich habe
38080	42160	diese Folge hier ein wenig vorproduziert, weshalb ich jetzt auch gar nicht großartig
42160	48440	irgendwelche Danksagungen einbauen kann, was ich natürlich sonst immer sehr gerne mache und wünsche
48440	54680	euch deswegen einfach viel Freude bei der heutigen Episode mit Robert Seifert zu algorithmischer
54680	68240	Sozialität. Herzlich willkommen, Robert. Hallo, Jan. Fangen wir mit der Definitionsfrage an. Was
68240	74080	sind Algorithmen und inwiefern unterscheidet sich vielleicht dein Zugang zu dieser Frage von anderen?
74080	78040	Wogegen kennst du dich vielleicht auch ab? Ja, Algorithmen, das ist natürlich immer eine
78040	84480	sehr schwierige Frage, weil es dafür ganz unterschiedliche Definitionen gibt. Vor allem
84480	90640	gibt es eben auch unterschiedliche Definitionen in den Sozialwissenschaften oder in der Soziologie.
90640	97440	Ich habe mir da ein ganz spezifisches Verständnis angeeignet oder übernommen,
97440	103240	eine Definition, also dass man Algorithmen als relational und prozessual versteht,
103360	109440	diese doppelte Charakteristik ist mir wichtig und das kann man vielleicht am besten verstehen,
109440	114520	wenn man das mal versucht, mit anderen gängigen Definitionen von Algorithmen in eine Beziehung zu
114520	122440	setzen. Also häufig werden Algorithmen definiert als formale Handlungsanweisungen oder als die
122440	129880	Gesamtheit von Regeln von Input und Output, also der Verarbeitung von Input und Output oder als
129880	135640	eine Art Symboltabelle, eine klassische Analogie ist auch immer das Rezept. Also das Rezept sagt
135640	142800	sozusagen genau, was man in welchen Schritten tun, machen soll, wie sie kramen, Zutaten,
142800	149200	in welchen Zeitraum und so weiter und so fort. Und das hat eigentlich zwei Implikationen oder
149200	156120	das hat zwei Voraussetzungen, solche Definitionen. Einerseits wird davon die Hardware von der
156120	160080	Software getrennt, also man sagt eben der Algorithmus ist sozusagen eine formale
160080	164880	Handlungsanweisung, die mit einer Software dann zum Beispiel in ein Programm in Gang gesetzt wird
164880	171160	und man trennt eben die Handlungsanweisung dadurch auch von der Implementierung. Also
171160	175720	die Implementierung des Algorithmus muss dann nochmal durch einen anderen Prozess
175720	180800	vonstatten gehen und für mich ist eben wichtig, dass diese Definition des Algorithmus selbst
180800	184560	schon prozessual ist, dass er sozusagen diese Implementierung selbst schon enthält. Das wäre
184560	193320	sozusagen wichtig, das sind selbst Prozesse. Der Techniksoziologe Roger Häusling sagt,
193320	198560	dass Daten die Produkte von Relationierungen sind und das finde ich eigentlich insofern eine ganz
198560	203120	gute Definition, weil man eben sagen kann, dass Algorithmen eben genau diese Relationierungsprozesse
203120	208960	sind. Also die Algorithmen relationieren Daten und produzieren sie oder co-produzieren sie dabei.
208960	212960	Das heißt, insofern geht eben die Definition des formalen Rezepts ein bisschen an der Realität
213080	220120	vorbei, weil das eben der Algorithm und der Ablauf dieses Prozesses selbst ist. Schreiben sozusagen
220120	225200	Temporalität und Zeitlichkeit in die soziale Welt ein. So kennen wir sie als Soziologen ja auch die
225200	231440	Algorithmen. Wenn wir sie jetzt nicht computerseitig uns anschauen, wie sie geschrieben sind, im Alltag
231440	235760	begegnet man Algorithmen in erster Linie auch durch eine sehr spezifische Zeitlichkeit,
235960	246280	indem sie eben unsere Handlungen mit strukturieren. Bei Shintaro Miyazaki, so ein Medienwissenschaftler,
246280	252320	hat einen sehr schönen Begriff dafür, dass die sich entfalten müssen und sich in Zeit verkörpern.
252320	258120	Das finde ich eine sehr gute Beschreibung dafür. Wie gesagt, also nicht nur ein formales Schema,
258120	265320	ein real ablaufender Prozess und man würde eben sogar sagen, es handelt sich genau genommen um
265320	270720	eine Art Maschine, nicht eine algorithmische Maschine. Diese Definition wiederum ist jetzt
270720	278120	inspiriert von einem Computerwissenschaftler Juri Gurevich, der eben zugleich noch darauf
278120	282640	hinweist, dass diejenigen, die Algorithmen von ihrer Implementierung trennen wollen,
282640	286920	die also sagen Algorithmen und Computerprogramme oder Codes sind verschiedene Dinge, dass die
286920	291800	eben den Begriff der Implementierung für Dinge verwenden, die selber Algorithmen sind. Also die
291800	299120	Implementierung selbst ist eigentlich wieder ein algorithmischer Prozess und das wäre sozusagen,
299120	304200	wenn ich das mal versuchen würde, so knapp zusammenzufassen, einerseits die Spezifik meines
304200	310200	Algorithmusverständnis herauszuarbeiten, aber auch eben da eine Unterscheidung vorzunehmen von dem,
310200	315680	was andere, die zentrale Unterscheidung, wie gesagt, besteht darin, dass glaube ich der Begriff des
315680	321000	Rezeptes extrem irreführend ist, weil das so tatsächlich aus einer technisch-soziologischen
321000	326320	Perspektive eigentlich überhaupt nicht, auf diese Art und Weise Algorithmen eigentlich nicht begegnen.
326320	332520	Und wir kommen später dann auch noch zu ganz konkreten Beispielen, anhand derer, finde ich,
332520	337600	man das wirklich sehr schön auch sehen kann, inwiefern dieses relationale Verständnis von
337600	343920	Algorithmen eigentlich auch nachvollziehbar ist. Bevor wir dahin kommen, interessiert mich aber
343920	348920	noch ein bisschen eine Beschreibung der Ausgangslage, denn du gehst von einer umfassenden,
348920	353760	im Grunde sogar allumfassenden, Zitat, algorithmischen Transformation der Gesellschaft,
353760	361120	Zitat Ende, aus und schreibst da, nochmal zitiert, es gibt keinen Weltzugang und keine
361120	367680	soziale Beziehung, keine sozialen Beziehungen, in denen keine algorithmischen Elemente
367680	373320	eingebunden sind, Zitat Ende. Worum handelt es sich bei dieser algorithmischen Transformation
373320	378280	der Gesellschaft und was bedeutet sie für den Versuch eines Verstehens der Gesellschaften?
378280	384720	Also das ist natürlich eine Formulierung, die gerichtet ist sozusagen von einem Soziologen
384720	390280	an die Soziologie. Das ist einerseits sozusagen ein Gesellschaftsbefund, nicht die Gesellschaftsanalyse
390280	395360	und zugleich aber eben auch eine Herausforderung für die Soziologie, insbesondere die soziologische
395360	402200	Theorie. Dass man eben sagt, die Zentralen für die Intersoziologie, auch wenn es natürlich
402200	406080	mit der Techniksoziologie und den Science and Technology Studies und Medienwissenschaften
406080	412320	natürlich viele oder Mediensoziologie viele spezielle oder Formen der Soziologie gibt,
412320	416480	die sich mit der Auseinandersetzung mit Dingen und Medien beschäftigen, ist eben doch, kann man schon
416480	422080	sagen, die Mainstreamsoziologie beschäftigt mit der Interaktion in der Beziehung von menschlichen
422080	426880	Wesen. Das ist tatsächlich eben so, wenn Sie das jetzt studieren oder den Einführungspunkt
426880	434080	zur Soziologie nehmen, ist eine soziale Beziehung eben Menschen zwischen Menschen. Vielleicht kann
434080	441680	man auch, wenn man Beziehungen thematisiert oder sich dazu anschaut, wie die Soziologie sich
441680	445840	dazu positioniert, kann man vielleicht noch einen Kommunikationsbegriff finden, der das vielleicht
445840	450640	noch abstrakter macht und sich nicht allein auf menschliche Interaktion bezieht, aber die sind
450640	456640	dann meistens eben so abstrakt, dass es dann eigentlich keinen Unterschied mehr macht, wer
456640	460120	sozusagen mit wem kommuniziert. Das können dann Systeme und Menschen und alles Mögliche
460160	466080	miteinander sein. Und wenn man das dann sozusagen so verallgemeinert und sagt, die soziale Beziehung
466080	470680	ist jede Form von Kommunikation, dann kommt man natürlich zu dem nicht sehr überraschenden
470680	475720	Befund, dass wir eigentlich immer schon in einer digitalen Gesellschaft gelebt haben. Das liegt da
475720	481960	einfach sozusagen an dem theoretischen Zuschnitt. Aber nicht, wie gesagt, der dominante
481960	487400	soziologische Zugang, das kann man, mein Lieblings, wenn ich das in der Lehre mache, nehme ich immer
487400	492920	Wikipedia Seite zur Soziologie heraus, steht eben dann auf der ersten Zeile, ist die Wissenschaft
492920	498720	von Menschen und den sozialen Beziehungen. Das steht da ganz selbstverständlich. Und jetzt ist
498720	504480	eben der Befund, dass wenn man sich das anschaut, schon seit einigen Jahren eigentlich davon keine
504480	509600	Rede mehr sein kann, dass das sozusagen der dominante Weltzugang ist, sondern der dominante
509600	516560	Zugang ist eben über technische Dinge oder mit technischen Dingen, dass man sagen kann, die
516560	521200	Face-to-Face, die reine menschliche Interaktion ist sozusagen fast schon ein Spezialfein geworden,
521200	525440	umso mehr jetzt in der ganzen pandemischen Situation, denn auch wir sitzen ja jetzt im
525440	529760	Studio nicht uns gegenüber, sondern auch wir sind hochgradig algorithmisch vermittelt.
529760	537000	Insofern hat uns das sozusagen jetzt diese pandemische Situation das noch stärker sozusagen
537000	542720	transparent gemacht, wie weit wir vermittelt sind und das einerseits sozusagen diese digitale
542720	545960	Vermittlung, aber eben auf der anderen Seite, was du angesprochen hast, diese Frage der
545960	552280	algorithmischen Sozialität, dass es eben nicht allein irgendwie einfach nur technische Gerätschaften
552280	556440	sind, die uns miteinander verbinden, wie eine Wippe oder eine Schaukel oder irgend sowas,
556440	562840	sondern dass es eben immer Techniken sind, die mit algorithmischen Prozessen uns in Verbindung
562840	569480	miteinander setzen. Also ein Beispiel, immer wenn man mit älteren Menschen spricht, heißt es dann
569520	574360	immer, früher konnte man einfach mal bei jemandem vorbeiklingen und klingeln, kommst du runter oder
574360	579120	nicht, machen wir was. Mittlerweile ist das sozusagen völlig undenkbar, dass ich bei jemandem
579120	585400	vor der Tür stehe. Es ist halt immer irgendwie verabredet über Messenger-Apps oder E-Mails oder
585400	590720	wie auch immer. Man sieht halt sozusagen, dass zwischen diese zwischenmenschlichen Beziehungen
590720	597360	eigentlich in fast jeder Form, wie wir uns begegnen, eigentlich algorithmische Prozesse
597360	604040	dazwischengeschaltet sind. Dass es möglicherweise von der Partnersure bis zur Orientierung im Raum,
604040	609720	Landkarten oder jetzt diese Situation hier sich dem Podcast anzuhören oder hinziehen zu produzieren,
609720	616280	alles hochgradig algorithmische Prozesse sind, die ohne das gar nicht erklärbar sind und insofern
616280	621680	eben nicht die Herausforderung an der Soziologie, diesen Interaktions- oder Beziehungsbegriff da
621680	626760	umzustellen. Und da ist jetzt die algorithmische Sozialität eben der Versuch, dem Umstand gerecht
626760	632280	zu werden, dass jede Form der Beziehung in erster Linie über algorithmische Systeme läuft.
632280	640640	Und allgemein bekannter, würde ich sagen, ist ja der Begriff der digitalen Transformation. Du schreibst
640640	644760	eben von der algorithmischen Transformation. Ich erinnere mich da an einen Paper von dir,
644760	649600	wo du zu Beginn eben auch eine Unterscheidung einführst zwischen Digitalisierung 1.0 und
649600	654920	Digitalisierung 2.0. Das scheint mir so ein bisschen in eine ähnliche Richtung zu gehen. Also es ist
654920	659040	schon so zu verstehen, dass du das untereinander auch nochmal unterscheiden würdest, die Frage
659040	662960	der digitalen Transformation und die Frage der algorithmischen Transformation. Genau,
662960	666840	das ist natürlich eine Unterscheidung, die heute von manchen natürlich gemacht wird,
666840	673320	häufig nicht gemacht wird, dass man, wenn man alt genug ist, eigentlich den Digitalisierungsbegriff
673320	679960	nochmal von Begriff der 90er, 2000er Jahre hielt, dann ist der verschwunden. Und seit einigen Jahren
680240	685720	ist er wieder als sozusagen der heißeste Begriff wieder aufgetaucht. Was eigentlich überraschend ist,
685720	688960	dass sozusagen so ein Revival so schnell wieder auftaucht, eine Mode jetzt nicht,
688960	693960	dass er keine 40, 50 Jahre gedauert, sondern der kommt irgendwie nach 20 Jahren wieder raus und
693960	700760	alles ist sozusagen digital. Und da ist jetzt der Versuch, die Unterscheidung hier zu machen,
700760	707880	dass man sagt, Digitalisierung 1.0 ist eben tatsächlich unterschieden von Digitalisierung 2.0,
707920	711760	ganz einfach gesagt durch den Grad der Verallgemeinerung. Dass man eben sagen kann,
711760	717040	in den 90ern, Anfang 2000er Jahre war, wie unsere ehemalige Bundeskanzlerin gesagt hatte,
717040	722760	das Internet tatsächlich noch Neuland. Das war für sie natürlich viel länger Neuland als für andere,
722760	726320	aber da ist es eben tatsächlich eben eine Nischenkultur, da gibt es auch in der Soziologie
726320	731400	oder in Sozialwissenschaften dann auch sozusagen spezielle Soziologien, Internet-Studies,
731400	740200	Software-Studies, die sich sozusagen in irgendwelche Expertennischen einarbeiten und dort die
740200	747480	verwunderlichsten Dinge an die Gesellschaft hervorbringen und davon berichten. Und mittlerweile,
747480	751400	und das ist der Unterschied zur Digitalisierung 2.0, würde ich sagen, hat es einen Grad der
751400	758400	Verallgemeinerung und Verselbstständigung und Selbstverständlichung gefunden, dass man da eben
758440	762600	nicht mehr von einer Nischen- und einer Expertenkultur sprechen kann, sondern das betrifft eben,
762600	766760	wie gesagt, alle. Das, was ich jetzt versucht habe, mit der algorithmischen Sozialität zu
766760	771280	beschreiben, also dass man jetzt sagen kann, in der Digitalisierung 2.0 ist der Punkt erreicht,
771280	777720	wo es eben keine Experten, sondern eine Alltagskultur ist. Was natürlich Konsequenzen hat,
777720	783000	weil was auch viel übersehen wird, weil eben in der Digitalisierung 1.0 in erster Linie
783560	789840	Innenexperten sich damit beschäftigt haben, die einen ganz anderen, ja auch vielleicht technikaffineren,
789840	795920	technisch alphabitisierten Zugang zu den Technologien hatten, wo ich als Soziologe heute sagen würde,
795920	800680	heutzutage ist der Zugang ganz anders, der ist eher implizit. Meistens Leute wissen überhaupt nicht,
800680	806080	wie Algorithmen funktionieren und wie die Technik funktioniert und trotzdem funktionieren und
806080	811280	benutzen sie es richtig. Aber das heißt natürlich, dass eine solche Analyse an diesen beiden Fällen
811280	817200	ganz anders untersuchen muss. Ich kann jetzt nicht so tun, als seien wir alle Softwareingenieure und
817200	821600	daran scheint mir auch das Problem der Aufforderung derjenigen zu sein, die sagen, wir sollten jetzt
821600	826440	alle schon in der Schule Programm schreiben lernen. Das geht eigentlich an der Realität vorbei,
826440	832320	weil das faktisch einfach mit Alltagsgegenständen nie der Fall ist. Die kennt man nie und ein
832320	837520	Phänomen der Veralltäglichung und Selbstständigung besteht immer auch darin, dass man es eben benutzt
837520	842280	wie ein Toaster. Man weiß zwar, wie er angeht, aber sonst interessiert einen auch dazu nicht
842280	847160	sonderlich viel mehr. Und das wäre jetzt nochmal das Argument einerseits, sozusagen analytisch die
847160	852440	beiden zeitlich-historisch zu trennen und zweitens analytisch darauf hinzuweisen, dass man dafür eine
852440	857600	ganz andere Form der soziologischen Untersuchung braucht, weil es eben eine Veralltäglichung ist
857600	863000	und einen anderen Rezipienten und Konsumenten voraussetzt als den noch in der früheren
863000	870600	Phase der Digitalisierung 1.0. Also das würde jetzt ja diese Differenzierung zwischen Digitalisierung
870600	876920	1.0 und Digitalisierung 2.0 nachvollziehbar machen. Inwiefern steht das in Zusammenhang mit diesen
876920	883520	beiden Begriffsparen von algorithmischer Transformation und digitaler Transformation? Gibt es da sozusagen
883520	888960	auch noch eine differenziertere Unterscheidung, was unter dem einen zu verstehen ist und was unter dem
888960	896360	anderen? Das ist eine gute Frage. Also da würde ich bei digitaler Transformation eben schon eher auch
896360	903920	noch an Frage einer vernetzten Gesellschaft denken. Also die Frage der Vernetzung, der Frage der
903920	910200	Kommunikation. Der Vernetzungsbegriff bezieht sich sozusagen nicht notwendigerweise auf die Art und
910200	915600	Weise, wie man in den Netzen prozessiert, sondern der bezieht sich in erster Linie darauf, auf diese
915600	921280	Idee der Weltgesellschaft, dass man sozusagen an allen Formen, an allen Enden miteinander kommunizieren
921280	926960	kann. Und da habe ich den Eindruck, dass der Begriff der digitalen Transformation auch häufig so
926960	932880	verwendet wird. Aber es ist natürlich auch klar, dass mit Digitalisierung auch gemeint ist, häufig
932880	937960	das, was ich sozusagen algorithmische Sozialität beschreibe. Dass man eben bestimmte Apps entwickelt,
937960	943720	die mir erlauben, bestimmte Dinge zu tun. Aber ich würde sagen, dass digitale Transformation sich
943720	949800	sozusagen noch auf noch anderes bezieht. Das heißt, ich mache ja auch die Unterscheidung
949800	955120	zwischen Infrastrukturen und Systemen. Das heißt nicht nur ich, das machen relativ viele. Und eben
955120	959880	digitalen oder algorithmischen Systemen. Und die gesamte digitale Transformation umfasst natürlich
959880	965960	auch den kompletten gesellschaftlichen Umbau der Infrastrukturen. Also Einbau von Kabeln und
965960	973440	Sensoren. Und das ist sozusagen eine massive gesellschaftliche Transformation. Wobei sich
973720	981760	dagegen sich diese algorithmische Sozialität eben eher um die Art und Weise des Prozesses,
981760	986920	sozusagen des Lebensprozesses bezieht. Wie wir miteinander in Verbindung treten. Einfach,
986920	992600	dass man auch sagen kann, dass bestimmte algorithmische Systeme, Apps oder was auch
992600	1000560	immer eine gewisse Zeitlichkeit einschreiben. Das ist ja immer ein Navigationsgerät. Ich würde
1000560	1005160	schon sagen, dass das Phänomen, das da dransteht, immer die Navigationsgerät, wie viel Zeit es bis
1005160	1010240	zu Ziel ist, die Art und Weise des Fahrerlebens schon grundlegend ändert. Nicht, dass da da steht
1010240	1016120	nach dreieinhalb Stunden bis zur Ankunft. Das ist, glaube ich, schon eine ganz andere Form. Das
1016120	1021880	kennen wir aber in anderen Formen auch der Arbeit mit Apps oder mit Software. Dass da immer eine
1021880	1028400	bestimmte Zeitlichkeit implementiert ist. Nicht, dass wir, wenn wir jetzt Messenger-Apps benutzen,
1028400	1035680	wir eine bestimmte Erwartung haben, wie lange jemand eine Nachricht schreibt. Das wird häufig
1035680	1039800	gebrochen, wenn man mit älteren Leuten oder Leuten kommuniziert, die sich damit nicht auskennen.
1039800	1043480	Dann kann man beobachten, wie der andere oder die andere schreibt und schreibt und schreibt und die
1043480	1048120	Nachricht wird nicht fertig. Und dann gibt es irgendwie einen Punkt, wo diese Erwartung sozusagen,
1048120	1055960	was man als normale Antwortzeitraum hinnehmen würde, durchbrachen würde. Ähnlich kennen wir das ja
1055960	1060160	auch bei E-Mails. Das hat auch sozusagen die Zeitlichkeit, wie wir miteinander interagieren,
1060160	1067280	vollständig verändert. Eine E-Mail nach 14 Tagen zu beantworten, kann man machen, aber es eben auch
1067280	1074720	dann meistens fällt auf. Also insofern wäre das vielleicht noch mal der Unterschied zur digitalen
1074720	1078400	und transformativen algorithmischen Sozialität. Das ist bei der algorithmischen Sozialität eben
1078400	1085160	wirklich um diese Form, Art und Weise der prozessualen Führung des Lebens auch geht.
1085160	1089360	Aber da kommen wir vielleicht noch darauf, dass man das eben jetzt nicht, das muss man vielleicht
1089360	1093560	schon warnen sozusagen, wieder sagen, nicht notwendigerweise nur kritisch versteht und sagt,
1093560	1100160	wir werden von den algorithmischen Maschinen diszipliniert und auf Linie gebracht. Das ist
1100160	1105200	damit eigentlich nicht gemeint, sondern eher erstmal ganz analytisch der Umstand, dass es so
1105200	1110120	eine Art von Interaktion zwischen individuellen, menschlichen Individuen, algorithmischen Systemen
1110120	1117400	als dominantes Beziehungssystem gibt. Du hast jetzt schon ganz selbstverständlich immer mal
1117400	1122640	wieder eben dieses Begriff par algorithmische Sozialität auch verwendet. Ich hatte ja zuvor
1122640	1131840	noch heranbahnend von algorithmischer Transformation gesprochen, aber es ist, glaube ich, trotzdem
1131840	1136880	jetzt eben dann vielleicht noch mal sinnvoll, sich eben diesen Ausdruck ein bisschen genauer
1136960	1142440	anzugucken oder was du darunter verstehst unter algorithmischer Sozialität. Es gibt da also
1142440	1148200	andere Beziehungen, die es in den Blick zu nehmen gilt. Das hattest du jetzt schon beschrieben,
1148200	1154040	Beziehungen, die auch in dieser Form eben vor der digitalen Transformation der Gesellschaften eben
1154040	1159160	auch noch nicht existiert haben in dieser Form. Und du fasst es eben dann unter den Begriff der
1159160	1166720	algorithmischen Sozialität zusammen. Was sind das für Beziehungen, die da eben neu auftreten,
1166720	1171760	die durch eine algorithmische Sozialität beschrieben werden können? Was haben wir
1171760	1176520	uns darunter vorzustellen? Ja, wie gesagt, das habe ich vielleicht jetzt schon ein bisschen
1176520	1182800	zusammen gemischt. Also es geht in erster Linie auch um diese Art von grundlegender Beziehung.
1183440	1189640	Das geht auch auf den Anfangspunkt zurück, dass wir mit jeder Art der sozusagen
1189640	1198080	Alltagsorientierung mit Algorithmen, ja, dass wir damit operieren. Also das geht ja sogar so weit,
1198080	1206920	dass wir sagen würden, wenn ich jetzt entnetzen will und Digital Detox betreiben will, brauche
1206920	1212000	ich da wahrscheinlich auch ein Navigationsgerät, was mich zum Kampf fährt. Ich also auch dieser
1212000	1216680	Ausstieg ist sozusagen wieder über solche Orientierungen und Zeitlichkeitsphänomene
1216680	1223280	vermittelt. Und nicht diese Zeitlichkeit ist mir dabei relativ wichtig. Also die Frage,
1223280	1229160	was ich jetzt schon beschrieben habe, eben einerseits, dass wir, das kann man sich eben
1229160	1234160	hier nochmal deutlich klar machen, der Unterschied zwischen Algorithmus und Rezept, ein Navigationsgerät
1234160	1238600	ist eben nicht allein nur ein Rezept. Da kann man natürlich sagen, da steht sozusagen, jetzt fahren
1238600	1242560	sie rechts und danach 300 Metern fahren sie wieder links und danach fahren sie wieder links
1242560	1245640	und dann fahren sie wieder rechts. Das wäre sozusagen, das könnte man aufschreiben, dann
1245640	1250080	könnte ich mir das durchlesen, dann könnte ich da sozusagen danach folgen. Aber wir wissen eben aus
1250080	1256880	der eigenen Erfahrung, dass das Navigationsgerät eben ganz anders funktioniert, weil das eben
1256880	1264920	permanent uns begleitet, das Gerät und uns sozusagen in gewisser Weise auch antreibt oder
1265040	1271520	zurückhält, bestimmte Dinge zu tun. Oder wenn wir noch weitere Assistenzsysteme in Beziehung setzen,
1271520	1274840	eben vielleicht auch sagt, dass wir immer mal eine Pause machen sollen und so weiter und so fort nicht.
1274840	1279160	Aber beim Messenger, das hatte ich beschrieben, dieses Phänomen der Zeitlichkeit, aber auch bei
1279160	1288120	sozialen Medien ist es eben auch so, wir reden häufig davon, dass es eben darauf ankommt, mit
1288120	1296520	besonders aufmerksam reichens reichen Bildern oder Posts sozusagen Aufmerksamkeit zu generieren,
1296520	1300320	auf welchen Medien auch immer, Instagram vielleicht mit Bildern, Twitter muss es halt
1300320	1304280	besonders witzige Tweets sein. Also das ist sozusagen mit sozialen Medien sehr unterschiedlich,
1304280	1309320	aber es kommt nicht nur sozusagen darauf an, was man und wie man es postet, sondern eben auch in
1309320	1316720	welcher Zeitlichkeit. Also dass man das bei diesen sozialen Medien eben auch berücksichtigt, dass
1316720	1322480	man das mit einer relativ großen Regelmäßigkeit macht. Und wenn man jetzt wenig postet, dann wird
1322480	1327640	der nächste Post, den man nach zwei Wochen postet, auch entsprechend runtergerankt. Und auch hier haben
1327640	1331760	wir diese Zeitlichkeit, die ich vorhin bei den E-Mails oder Messenger beschrieben habe, eine
1331760	1337440	bestimmte erwartbare Zeit überschritten ist, dann wird man sozusagen taucht das nicht mehr in der
1337440	1341920	Aufmerksamkeit auf, ist auch nicht mehr in der Aufmerksamkeit der eigenen Person auf, weil man
1341920	1347120	sagt, das ist eine E-Mail, da war vor 14 Tagen, das ist jetzt nicht mehr relevant. Oder eben der
1347120	1354000	Algorithmus sagt, das, was Sie jetzt hier posten, ist nicht mehr aufmerksamkeitsrelevant, weil du als
1354000	1359280	Person viel zu selten. Was machst du nicht? Also diese Zeitlichkeit, diese Spezifische findet
1359280	1365480	man eben da. Und das ist mit dem Begriff der Sozialität eben gemeint, nicht dieser Doppelbegriff
1365480	1370240	Relationalität, also Beziehungen nicht nur zu Menschen, sondern auch zu Dingen und Prozesse,
1370240	1375080	das heißt, die Form der Art und Weise, wie man in eine Beziehung miteinander dreht,
1375080	1382560	ist hochgradig von algorithmischen Prozessen mitgeprägt und umgekehrt. Da nochmal anzuschließen an
1382560	1386880	dem vorhergehenden Kommentar, prägt man diese Prozesse eben auch mit, nicht? Also das ist
1386880	1391440	sozusagen auch eine Wechselseitigkeit und nicht nur eine einseitige, determinierende, bestimmte
1391440	1400960	Beziehung. Ein Aspekt oder ein Teil dessen, was du als algorithmische Sozialität beschreibst,
1400960	1406440	sind eben verschiedene Formen der Beziehung. Und das sind eben nicht immer nur Formen zwischen
1406440	1415800	Menschen und Algorithmen, sondern es gibt da eben verschiedenste Interaktionen, die durch diese
1416640	1421200	algorithmische Sozialität mit in den Blick kommen können. Und das sind eben auch unter anderem
1421200	1426200	interalgorithmische Beziehungen. Also es geht eben nicht nur darum, damit jetzt beschreibbar zu machen,
1426200	1434840	dass all unsere gemeinten Menschen leben und unser Handeln von Algorithmen, sagen, auch betroffen
1434840	1441200	und mitbestimmt und co-produziert sind, sondern es gibt eben auch andere Beziehungen, die damit in
1441200	1445760	den Blick geraten, unter anderem eben auch interalgorithmische Beziehungen. Interessant
1445760	1450080	fände ich vielleicht noch, dass du das einmal kurz skizzierst, was das für Formen der Beziehungen
1450080	1454680	sind und wie man sich denen vielleicht auch nähert. Der Begriff stammt eigentlich von
1454680	1464560	Karin Knut-Zetina und Donald McKenzie, die das im Zusammenhang der Finanzmarktsozialogie erforscht
1464560	1469520	haben. Und vor allem bei Donald McKenzie kann man eben schön sehen, also der hat sozusagen diesen
1469520	1475880	Begriff von Goffman der Interaktion jetzt diese Herausforderung angenommen und hat gesagt, wenn
1475880	1480800	das stimmt, dass wir nicht mehr wie bei Goffman dominant mit menschlichen Interaktionsbeziehungen
1480800	1486920	zu tun haben, sondern auch mit Interaktionen, mit technischen Dingen, mit Algorithmen, dann muss man
1486920	1491280	sich überlegen, ob wir vielleicht sogar so weit gehen könnten, eben die Beziehungen zwischen
1491280	1495480	Algorithmen, das was du gerade beschrieben hast, selbst als eine Form des Sozialen, als Gegenstand
1495480	1501200	der Sozialen der Soziologie zu betrachten. Er bejaht das, versucht das und das Argument ist hier, da
1501200	1507640	geht es um den Hochfrequenzhandel, dass wenn man sich anschaut, wie geht es um Order-Bücher,
1507640	1514400	Auftragsbücher in elektronischen Börsenplätzen, dass wie da Aufträge gestellt werden, wie die
1514400	1521320	verkauft und gekauft werden, dass die eben hochgradig Ergebnisse politischer Entscheidungen sind,
1521320	1529240	hochgradig sozial vermittelt sind. Also schon die Frage, ob ich Preisbruchteile von einem Dollar
1529240	1536880	oder von zehn Cent festlege, ist eine politische Entscheidung, eine soziale Norm und das materialisiert
1536880	1543280	sich dann sozusagen in diesen Handelsalgorithmen, die dann eben entscheiden, ob jetzt der Verkauf
1543280	1548320	noch relevant ist oder eben dann sagen, hier wird an dem Börsenplatz nur in Bruchteilen von zehn
1548320	1553960	Cent gehandelt, da kann ich sozusagen diesen drei Cent Gewinn gar nicht materialisieren,
1553960	1560920	weil das auf dem Börsenplatz eben nicht strukturell möglich ist. In diesen Art von Beispielen zeigt
1560920	1567160	Mackenzie, dass das sozusagen auch jede Form der algorithmischen Interaktivität oder was eben als
1567160	1572960	algorithmische Interaktivität bezeichnet, eben generell als auch eine soziale Beziehung beschrieben
1572960	1579720	werden kann, weil sie eben soziale Normen hat, Erwartungen eingeschrieben sind. Auch die Frage,
1579720	1587280	wenn man sich anschaut, wie Aufträge in den Auftragsbüchern sortiert werden, gibt es da
1587280	1593000	Warteschlangen und diese Warteschlangen erinnern eben an all das, was wir sonst im normalen Leben an
1593000	1598560	Warteschlangen auch so kennen und wir kennen dort auch Marktmanipulationsstrategien, wo man
1598560	1603320	versucht, die Warteschlange auszutricksen, wo man sich vorzudrängelt, wo Hochfrequenzhändler
1603320	1608480	bestimmte Strategien entwickeln, um sozusagen in eine bessere Position im Auftragsbuch zu kommen,
1608480	1617440	dass ihre Aufträge eben dann schneller behandelt werden. Das ist jetzt eine Perspektive, die vor
1617440	1622480	allen Dingen eben in den Science and Technology Studies sehr prominent ist, also diese Form der
1622480	1627520	Einschreibung der sozialen oder selbst die digitalen Technologien eben so weit zu gehen,
1627680	1632960	zu sagen, das sind jetzt nicht einfach nur Technologien, sondern selbst das Signal des
1632960	1639400	WLAN Router Routers ist eben ein sozialer Tatbestand. Das ist natürlich eine Provokation,
1639400	1645880	aber ich finde das auch an den Beispielen, wie Mackenzie das deutlich macht, schon sehr illustrativ,
1645880	1650280	weil er eben wirklich zeigen kann, wie all diese Dinge gar nicht entstehen würden. Die sind nicht
1650280	1654840	einfach nur sozusagen ein Ergebnis einer technischen Evolution, wie uns manche Technik-Freaks
1654840	1658960	immer einreden wollen, dass das sozusagen aus sich selbst sich heraus gebiert, sondern das sind
1658960	1665480	hochgradig pfadabhängige Entwicklungen, die auch das Ergebnisse von sozialer und politischen
1665480	1670240	Entscheidungen sind. Genau das ist ja vielleicht ein Beispiel dafür, wenn man diese interalgorithmischen
1670240	1676800	Beziehungen vielleicht illustrieren könnte. Ja, das würde ich auch ja sofort unterschreiben.
1676800	1683680	Interessanterweise ist es für dich dann aber trotzdem sind die subjektalgorithmischen Beziehungen,
1683840	1687600	eben nicht die interalgorithmischen Beziehungen, sondern die subjektalgorithmischen Beziehungen
1687600	1695240	für dich eigentlich dann zentral, wenn es um die algorithmische Sozialität geht. Also das ist da
1695240	1701880	doch in deinem Paper recht stark rübergekommen, dass das ist das, was dich am allermeisten interessiert.
1701880	1709240	Und was ich auch in diesem Zusammenhang interessant fand, war, dass du da eine Abfolge von
1709320	1715000	Wechselbeziehungen beschreibst, die eben also Prozesse, die diese Wechselbeziehungen eben
1715000	1722440	darstellen in der subjektalgorithmischen Beziehung. Und das beginnt mit einer algorithmischen
1722440	1727120	Mustererkennung, dann zweitens der Versuch einer behavioristischen Verhaltenssteuerung,
1727120	1734920	dann drittens ein vernarkulares Erkennen und viertens dann digitale Praktiken,
1734920	1741440	die wiederum das Material für dann eine erneute algorithmische Mustererkennung bilden. Also diese
1742360	1748080	Abfolge von Prozessen fand ich interessant. Vielleicht wäre es hilfreich, den Zuhörerinnen
1748080	1756320	das an einem Beispiel einmal zu erläutern. Und im Anschluss würde mich dann interessieren, ob diese
1756320	1764480	Prozessabfolge für dich bei allen Formen von subjektalgorithmischen Beziehungen so gegeben
1764480	1769800	sind. Weil ich mich zum Beispiel gefragt habe, ob der Schritt des Versuchs einer behavioristischen
1769800	1775800	Verhaltenssteuerung, ob der zum Beispiel zwingend vorkommen muss, weil das ist ja eine sehr spezifische
1775800	1785600	Form des Versuches der Verhaltenslenkung, eine bestimmte Rationalität, die da eingeschrieben ist.
1785600	1793520	Und auf eine Art fragt man sich ja, ob das zwingend an Algorithmus als Formen gebunden sein muss. Ich
1793520	1800120	würde eher intuitiv jetzt sagen, nein, hoffentlich nicht. Das geht sozusagen schon mit der letzten
1800120	1807400	Frage anzufangen auf das, was man eben soziale Algorithmen nennen kann. Also ich würde jetzt
1807400	1811320	gar nicht sagen, das sind notwendigerweise maschinell lernende Algorithmen, die in der
1811320	1816440	Lage sind, Feedback zu verarbeiten, sondern es geht hier wirklich um soziale Algorithmen,
1816440	1824360	die sozusagen in irgendeiner Art und Weise das Verhalten des männlichen Akteurs in der Lage sind
1824360	1830840	zu verarbeiten. Also nochmal das Navigationsgerät beobachtet einen, wenn man sich verfährt oder
1830840	1835480	nicht folgt, wird neu ausgerechnet und wird sozusagen eine neue Route vorgeschlagen. Kann
1835480	1841160	man jetzt natürlich begriffsanalytisch fragen, ob es sich streng genommen dabei bei einer
1841160	1848120	Verhaltenssteuerung handelt. Aber ich würde schon sagen, dass eben das Navigationsgerät,
1848120	1854520	das hat natürlich jetzt relativ geringe Möglichkeiten Anreize zu schaffen oder die
1854520	1859040	Leute zu disziplinieren oder zu strafen, aber ich denke schon, dass der Vorschlag selbst,
1859040	1863520	den das Navigationsgerät macht, eben zu sagen, jetzt hier links und rechts, wieder rechts,
1863520	1870880	dass das schon auch Elemente einer Verhaltenssteuerung involviert, würde ich schon
1870920	1881280	denken. Die erste Frage war genau dieser Kreislauf. Der Impuls dahinter ist der, der Theorie, zwei
1881280	1888240	Fallen zu entkommen. Die eine Falle ist das, was man jetzt oft mit Interviews mit Ingenieuren und
1888240	1893880	Computerwissenschaftlern spricht, eben diese Vorstellung, das ist ein Werkzeug, das ist eine
1893880	1898240	Technik wie alles andere auch, das macht, ich programmiere das, hier der Algorithmus und letztlich
1898240	1903280	mache da genau das, was ich da reinschreibe. Das sind Produkte menschlichen Intentionen und die
1903280	1908880	setzen sich da um und dann kann ich dann eben sehen, das hört man häufig, das hört man auch
1908880	1914440	sogar noch von Börsenhändlern, wo man, wenn man jetzt da ethnographisch beobachtet, sagen kann,
1914440	1918960	dass das mit Sicherheit nicht der Fall ist, weil die hochgradig auch von den Algorithmen gesteuert
1918960	1927560	werden in ihrem Verhalten. Aber nicht, das ist sozusagen ein Aspekt und der andere Aspekt ist
1927560	1930200	natürlich das, was man aus der kritischen Soziologie oder der kritischen Theorie kennt,
1930200	1934680	die natürlich immer sofort den Begriff der Disziplinierung und Steuerung kennt, das kennen
1934680	1939040	wir auch aus der populären Literatur, da brauchen wir wahrscheinlich jetzt nicht in dem Medium hier
1939040	1945200	länger darauf eingehen, das habt ihr wahrscheinlich schon in anderen Formen diskutiert. Also die
1945200	1950320	Vorstellung nicht, dass wir sozusagen von den sozialen Medien oder was auch immer wieder alle
1950320	1957280	sozusagen gesteuert sind. Also die beiden Extreme, das zu entgehen und da ist diese Idee eben dieses
1957280	1963400	Algorithmischen oder diese Objektsubjektiven oder Subjektalgorithmischen Beziehungen,
1963400	1969200	die auf der einen Seite dem Umstand gerecht wird, dass es natürlich Versuche der Verhaltenssteuerung
1969200	1975680	gibt, also ich war selbst angefangen bei Navigationsgeräten oder eben Banalität immer
1975680	1980600	wieder Amazon, sie haben das gekauft, also wollen sie auch das kaufen, kennen wir ja mittlerweile
1980600	1987960	schon und jetzt ist das umgekehrte Argument, dass wir eben das wahrnehmen und das hatte ich am
1987960	1993280	Anfang gesagt, das kennzeichnende Digitalisierung 2.0 ist eben, dass wir nicht technikaffin sind
1993280	1998080	und auch nicht technikalphabetisiert, das heißt wir wissen nicht, warum die Entscheidungen
1998080	2001520	zustande kommen, wie sie zustande kommen, das hat verschiedene Gründe, weil wir wie gesagt
2001520	2006880	entweder vielleicht nicht alphabetisiert sind technologisch oder andersrum, weil eben viele
2006920	2011560	Unternehmen auch ein Interesse daran haben, das intransparent zu halten, wie die Algorithmen zu
2011560	2018640	ihren Entscheidungen kommen, aber nichtsdestotrotz ist es eben tatsächlich so, dass wir irgendwie aus
2018640	2024840	diesem Verhalten einen Sinn für uns machen und das ist mit dem Begriff des vernackularen Wissens
2024840	2032320	beschrieben, das heißt, dass wir implizit irgendwie, wenn wir damit umgehen, ein Verständnis
2032320	2039760	dafür entwickeln, wie die Dinge funktionieren und hier ist es eben wichtig, nicht den Fehler zu
2039760	2045920	machen, eine Korrespondenz zu vermuten, also dass man sagt, das könnte man jetzt dieses implizite
2045920	2050280	Wissen explizit machen, dann wäre ich Computerwissenschaftler, also das wäre jetzt
2050280	2054640	die Falle, dieses implizite Wissen, deswegen nenne ich es eben vernackulares Wissen und nicht
2054640	2061520	implizites Wissen, weil es eben eine eigenständige Form, eine Volkssprache, sozusagen eine
2061520	2065920	eigenständige Sprache oder Kultur ist des Umgangs, für uns zum Beispiel ist bei
2065920	2071280	etwa der Hashtag, der sozusagen durch die NutzerInnen erfunden wurde, das ist wieder
2071280	2074680	eine Plattform eingeschrieben, noch hat das irgendjemand mal vorgesehen, hat jemand mal
2074680	2080440	angefangen, hat das benutzt und es hat sich halt durchgesetzt, das heißt, da wurde nichts
2080440	2087680	verstanden, da wurde auch nichts irgendwie, ja, kein Code offen gelegt oder keine Schulung
2087720	2092320	durchgeführt, das hat sich eben sozusagen so entwickelt und egal wie wir jetzt damit
2092320	2099520	umgehen, jede Form, auch den sozialen Medien entwickeln wir vernäckulare Form des Wissens
2099520	2105160	darüber, wie gesagt wichtig ist eben, dass die eigentlich überhaupt nicht mit den eigentlichen
2105160	2110840	Intentionen oder Absichten dieser Technologie viel zu tun haben müssen und dann kommen
2110840	2117160	wir zum Begriff der digitalen Praktik, weil natürlich Wissen diese Wisseneffekte hat,
2117160	2122560	man macht dann wieder irgendwas damit und jetzt muss eben dieses System entweder, indem
2122560	2128160	es jetzt sozusagen aktualisiert wird von Programmieren oder weil es selbst durch machinelle
2128160	2132080	Lernprozesse vielleicht versucht sich wieder darauf einzustellen, wieder darauf reagieren
2132080	2136160	und wird da wieder irgendwie was versuchen zu erkennen und das dann wieder einen neuen
2136160	2142600	Input geben und das Interessante ist sozusagen an diesen Subjekt-Algorithmienbeziehungen,
2142600	2147120	dass sie eben mit hochgradigen Prozessen sozusagen des wechselseitigen Nicht-Verstehens
2147120	2152520	zu tun haben, das würde ich sozusagen auch immer den Leuten sozusagen entgegenhalten,
2152520	2159280	die die Algorithmen sozusagen vermuten, dass die irgendwas aushecken, dass die eben tatsächlich
2159280	2165400	und das ist mit der Begriff der behavioristischen Modelle schon relativ wichtig, weil diese
2165400	2170920	Vermutung, dass sich sozusagen in den digitalen Systemen Gesellschaft nur einfach ausdifferenziert
2171000	2177880	glaube ich relativ naiv ist, weil eben diese Systeme ja nicht differenzierungstheoretisch
2177880	2181920	oder systemtheoretisch komplex gedacht sind, sondern die auf den einfachsten behavioristischen
2181920	2188040	Modellen beruhen und wenn ich das als Soziolog sage, dass ich diese behavioristischen Modelle
2188040	2193120	in der Soziologie als eine unangemessene Beschreibung der gesellschaftlichen Wirklichkeit ansehe,
2193120	2198480	kann ich ja jetzt nicht mich umgekehrt hinstellen und sagen, jetzt sind sie aber als Algorithmen
2198480	2201000	auf der Welt und jetzt sind sie auf einmal richtig, das ist natürlich nicht der Fall.
2201000	2206000	Fakt ist aber dennoch natürlich, dass die uns irgendwie auf eine Art und Weise beeinflussen.
2206000	2213400	Also irgendwas macht das mit uns und dann muss man jetzt empirisch herausfinden, was das mit uns
2213400	2217920	macht und interessanter ist eben die Frage nicht, wie die Menschen dann darauf reagieren, welche
2217920	2223440	neue Formen des vernachlässigen Wissens sie entwickeln und wie sie dann darauf wieder sozusagen
2223440	2230000	sich wechselseitig irritieren. Ja, also ich muss sagen, mir leuchtet das eh auch total ein. Ich
2230000	2237000	glaube, was ich mich gefragt habe, war halt vor allem, ob diese spezifische Abfolge von Prozessen
2237000	2244000	als Wechselbeziehungen, die eben diese Formen des Versuchs behavioristischer Verhaltenssteuerung
2244000	2253000	mit eingeschrieben hat, ob das nur ein Subset ist der Subjekt algorithmischen Beziehungen oder
2253000	2258760	ob sich das auf alle Subjekt algorithmischen Beziehungen so umlegen lässt. Das war, glaube
2258760	2262760	ich, so ein bisschen das, was hast du denn? Du hast ja vielleicht eine Vermutung, wo es nicht passt.
2262760	2268840	Ja, meine Intuition wäre halt, dass nicht jede Form von Subjekt algorithmischer Beziehung diese
2268840	2276040	diese Form von behavioristischer Intentionalität sozusagen irgendwie eingeschrieben hat. Was wäre
2276040	2283400	ein Beispiel? Da müsste ich jetzt nachdenken. Ich glaube, also so ein konkretes Beispiel hätte
2283400	2291920	ich jetzt nicht sofort. Klar, man kann natürlich immer sagen, man könnte jetzt schon dieses
2291920	2296600	Beispiel des Navigationsgerätes hinnehmen und schon sozusagen das bestreiten, dass das was mit
2296600	2300280	einer Verhaltenssteuerung zu tun hat. Man kann natürlich immer sagen, eigentlich ist das nur
2300280	2308520	eine Form der Beschreibung, sozusagen ein coded space, wo irgendwie eine Art von Prozessualität
2308520	2313840	eingeschrieben ist. Und das, was ich auf jeden Fall sozusagen umständlich zugestehen würde,
2313840	2318440	ist, dass das natürlich graduell extrem unterschiedlich ist. Also, dass es natürlich
2318440	2324560	Formen gibt, wo wir uns viel mehr bereit sind, darauf einzulassen oder auch gar keine andere Wahl
2324560	2330680	haben, sozusagen auf diese Verhaltenssteuerung und das vielleicht eher hinnehmen. Und in anderen
2330680	2339200	wurde das halt vielleicht eher weniger. So ist, also man muss vielleicht diese Wechselseitigkeit
2339200	2344600	kann man vielleicht auch als wechselseitige Beziehung unterschiedlicher Intensität bezeichnen,
2344600	2350360	nicht die auch graduell unterschiedlich sind. Also ein Beispiel ist immer jetzt bei der empirischen
2350360	2357920	Forschung zum Hochfrequenzhandel, dass man eben schon sehr unterscheiden kann, wie sehr man sich
2357920	2364520	bereit ist, von algorithmischen Prozessen zu streuen zu lassen. Das hat eben sehr mit der
2364520	2370920	Subjektivierungsform auch zu tun. Also wenn ich sozusagen sehr der Vorstellung eines sozusagen
2370920	2377000	autonomen, selbstermächtigten, reflexiven, rationalen Ichs folge, dann tendiere ich,
2377320	2381920	eher dazu zu sagen, der Algorithmus ist ein Werkzeug, der das macht, was ich will. Wenn ich
2381920	2388960	sozusagen eher kooperativ bin, dann bin ich auch eher bereit, mich vielleicht von Prozessen einfach
2388960	2394600	mal anregen zu lassen, die ich jetzt nicht notwendigerweise verstehe. Das ist feldspezifisch,
2394600	2402280	glaube ich, auch noch unterschiedlich. Also insofern man das wahrscheinlich jetzt beim Spiel viel
2402280	2409160	eher bereit ist, sozusagen diese Transgression des Subjekts einzugehen, Immersion, Immersions in
2409160	2414760	der Kunst und im Spiel nicht. Dort, wo es ernst wird, dann nicht. Bei dem Kapitalismus, da ist es
2414760	2420920	dann alles ganz, ganz furchtbar. Nini, ich hatte mich ja wirklich gefragt, ob es nicht einfach auch
2420920	2427720	Kontexte gibt, in denen eben nicht nur ich als Subjekt, willentlicher da mich hineinbegebe,
2427720	2433320	sondern Kontexte gibt, in denen Algorithmen per se gar nicht aufbauen auf eine Rationalität,
2433320	2439480	die als eine solche behavioristische Verhaltenssteuerung korrekt geframt wäre.
2439480	2446200	Das war quasi das. Aber nachdem ihr ohnehin sozusagen ein Beispiel jetzt nicht sofort in
2446200	2456160	den Kopf springt, gehen wir einfach weiter, würde ich sagen. Also diese verschiedenen Prozesse und
2456200	2463080	Wechselbeziehungen, die lassen sich, finde ich, sehr schön an einem Beispiel verständlich machen,
2463080	2472600	das du aufzeigst und zwar anhand des autonomen Fahrens bzw. eigentlich des assistierten Fahrens.
2472600	2479960	Vielleicht kannst du uns anhand dessen einmal kurz erläutern, wie denn diese Subjekt-Algorithmus-
2479960	2486560	Beziehungen vonstatten gehen und wie sie auch durch die Perspektive einer algorithmischen
2486560	2493400	Sozialität eigentlich besonders gut in den Blick genommen werden können und dabei dann vielleicht
2493400	2497080	auch nochmal diesen Unterschied klarmachen zwischen autonomem Fahren und assistierten
2497080	2502880	Fahren, weil wir haben oft autonomes Fahren schon gehört und viele nehmen das natürlich
2502880	2509800	einfach als gegeben voraus, dass das jetzt dann bald ins Haus steht, aber dem scheint ja nicht
2509800	2515800	wirklich so zu sein. Genau, das ist sozusagen auch eine Beobachtung gewesen, die mir dann
2515800	2520360	relativ schnell bei dem Phänomen des autonomen bzw. assistierten oder auch vernetzten Fahrens
2520360	2527240	aufgefallen ist, dass da eben sehr viele Dinge durcheinander kommen. Einerseits strategisch,
2527240	2530600	von denen diejenigen, die solche Systeme produzieren, das kennen wir ja, die versuchen
2530600	2535960	sozusagen immer natürlich auch ihre Technologie als viel fähiger zu verkaufen, als sie tatsächlich
2536440	2542000	ist. Elon Musk ist da ja sozusagen das Paradebeispiel dafür, Sachen zu behaupten, die
2542000	2547120	faktisch eben nicht umgesetzt sind. Das kann man kritisieren, aber da würde man sagen, gut,
2547120	2553960	das ist eben DNA-Geschäft. Viel problematischer ist es eben tatsächlich auch bei der Analyse im
2553960	2560600	Journalismus, aber auch in der Sozialwissenschaft, dass man diese Begriffe nicht sauber trennt. Es
2560600	2564600	gibt so einen Lieblingsartikel in der FAZ, den Namen jetzt des Autos habe ich vergessen, da heißt
2564600	2570320	es eben, es gibt sozusagen eine Road-Driver-Kamera, die die Augenbewegungen des Fahrers oder der
2570320	2577920	Fahrerin beobachtet und dadurch den Zitat, das autonome Fahren sicherer machen will. Diese Kamera
2577920	2583680	dient dazu, die Person sozusagen dafür zu warnen, wenn sie in den Sekundenschlaf einschläft, also
2583680	2588600	wie sie einschläft, gibt es ein Signal, wacht man auf. Und wenn man diesen Satz jetzt liest,
2588600	2596680	fragt man sich natürlich schon, warum muss ein autonomes Fahrzeug die Wachheit des Fahrers oder
2596680	2602840	der Fahrerin überwachen, wenn es doch heißt, dass diese autonomen Fahrzeuge uns irgendwann mal selbst
2602840	2607480	fahren sollen. Und wieso ist das eine Entwicklung, eine Technologie auf dem Weg hin zum autonomen
2607480	2613400	Fahren? Es scheint doch eigentlich eine Entwicklung auf dem Weg zu etwas ganz anderem zu sein, nämlich
2613400	2622000	nicht zum autonomen Fahren, sondern eben zu einem viel stärkeren Vernetzung von Fahrzeug und Fahrerin.
2622000	2626440	Das ist sozusagen die Beobachtung, dass hier also zwei Dinge durcheinander geworfen werden,
2626440	2631840	dass also autonomes Fahren eigentlich in erster Linie nur als ein imaginäres existiert, also
2631840	2637520	ein imaginäres Versprechen der Produzenten oder eben auch in einer unreflektierten Übernahme von
2637520	2641720	Journalisten oder sozialwissenschaftlichen Analysen. Und auf der anderen Seite, das assistierte Fahren
2642040	2649400	tatsächlich eine Praktik ist bzw. eben auch eine Politik. Eine Politik insofern, als man ja
2649400	2654600	kürzlich lesen konnte, dass verschiedene Assistenzsysteme seit Anfang dieses Jahres in
2654600	2661440	der Europäischen Union verpflichtend in jedem verkauften Fahrzeug einzubauen sind. Da kann man
2661440	2666080	eben tatsächlich sehen, dass es nicht nur ein imaginäres ist, eine Imagination oder eine Fantasie,
2666080	2671120	sondern es ist eben tatsächlich, kann man als Technologie jetzt sagen, die hat sich auf dem
2671120	2675440	Markt verbreitet und ist insofern auch für die Soziologie eben interessant, weil natürlich die
2675440	2681600	Individualmobilität, ob man das jetzt gut findet oder nicht, eines der weit verbreitesten Phänomene
2681600	2686280	oder Gesellschaftsphänomene sind. Da kann man jetzt sehen, dass diese Umsetzung der Assistenzsysteme
2686280	2693000	natürlich wichtig sind. Und wenn man sich das anschaut, stellt man eben fest, dass diese
2693000	2700560	Assistenzsysteme eigentlich alle dazu dienen, die Aufmerksamkeit des Fahrers oder der Fahrerin auf
2700560	2705240	den Verkehr und das auf Fahrzeug zu lenken. Ablenkungsassistenten, Einschlafwarnungen,
2705240	2712760	alle solche Formen dienen nicht dazu, dass das Auto besser fährt, sondern Spurhalteassistenten,
2712760	2722160	Notbremsassistenten, alles solche Sachen dienen letztlich nur dazu, den Fahrenden nicht davon
2722160	2725760	abzuhalten, dass sie einschlafen oder aus dem Fenster gucken oder sie mit ihren Nachbarn
2725760	2729640	unterhalten. Und da sieht man eben, das sind ganz verschiedene, nochmal um den Begriff der
2729640	2733040	algorithmischen Sozialität oder auch der Beziehung zurückzukommen, das sind eben ganz andere
2733040	2736680	Beziehungsformen. Und jetzt wäre der Vorschlag zu sagen, mit dem Begriff der algorithmischen
2736680	2741640	Sozialität bekommt man dieses Phänomen in den Griff, weil man eben sehen kann, dass hier diese
2741640	2748960	Beziehung zwischen Fahrzeug und Fahrerin immer weiter intensiviert wird auf der visuellen Ebene,
2749200	2757160	also die Überwachung der Augen, nicht der Lied, ob man einschläft oder eben ob man von der Bahn
2757160	2763840	abkommt. Und da finde ich eben dieser relationale Begriff der algorithmischen Sozialität analytisch
2763840	2770640	viel hilfreicher, weil er eben nicht zu diesen Verwirrungen führt, dass wir irgendwie von autonomen
2770640	2776600	Fahrzeugen ständigen reden, die weder sozusagen entwickelt sind noch marktfähig sind. Und diese
2776640	2782360	ganze Rede auch sozusagen dazu führt, dass wir faktisch überhaupt nicht erkennen, mit welcher
2782360	2787640	gesellschaftlichen Veränderung wir es eigentlich zu tun haben. Dass die gesellschaftliche, relevante
2787640	2794560	gesellschaftliche Veränderung nicht darin besteht, autonome Fahrzeuge zu haben, die uns es erlauben,
2794560	2799320	irgendwann einfach mal ein Buch zu lesen im Auto, sondern die eher dazu führen werden,
2799320	2804600	dass wir mit dem Auto, mit dem Fahrzeug noch auf eine viel intensivere Art und Weise verschmolzen
2804600	2811040	werden als je zuvor. Also eine Intensivierung, eine Vertiefung der Mensch-Maschine-Beziehung,
2811040	2816960	würde man eben sagen. Und das wäre jetzt sozusagen das Argument, dass man das nur erkennt, wenn man
2816960	2821560	eben erstens diese beiden Phänomene unterscheidet. Das eine ist ein imaginäres, das eine ist eine
2821560	2826520	tatsächliche empirische umgesetzte Praktik oder die Technologie. Und zweitens brauche ich dafür
2826520	2831800	eben eine Theorie, die das überhaupt beschreiben kann. Und dafür wäre dann der Vorschlag, dass ich
2831800	2836360	jetzt hier mit dieser algorithmischen Sozialität gleich in die Bresche springen kann.
2836360	2841760	Diesen Prozess, den du eben gerade skizziert hast, den fasst du dann auch als Ironie der
2841760	2848480	Assistenz bzw. Dialektik der Assistenz zusammen. Und was ich total interessant fand, und das kam
2848480	2852440	dir eigentlich doch auch in der Art und Weise, wie du das beschrieben hast, ganz gut durch,
2852440	2856840	ist, dass es am Ende eigentlich in einer gesteigerten Disziplinierung des Subjekts
2856840	2862640	auch mit untermünden kann. Und zwar nämlich genau eigentlich diametral entgegengesetzt zu dem,
2862640	2868720	was als Verkaufssprech dann eigentlich eben angefahren wird, nämlich ein Autonomieversprechen.
2868720	2875360	Was wiederum interessant ist, weil ja da dann eigentlich man auf eine Art von doppelter
2875360	2881680	Idealisierung der Autonomie stößt. Es ist ja kein Zufall, dass Elon Musk quasi die Person ist,
2881680	2888320	die in diesem ja in diesem Move quasi federführend ist, denn der ist ja bekanntermaßen
2888320	2895000	ein Libertärer, der sozusagen die Idee des autonomen Individuums quasi ganz besonders
2895000	2901960	hoch hält. Und das fand ich auch total spannend, dass da ja dann auf der einen Seite eigentlich dem
2901960	2908040	Fahrzeug quasi eine Autonomie zugesprochen wird, die nicht eingelöst wird, weil das Fahrzeug ja
2908040	2912800	am Ende dann eben nicht autonom Fahrt ist, sondern nur eben quasi assistiert immer noch
2912800	2917680	von einem Menschen gesteuert wird. Und natürlich dann eigentlich im Verkaufssprech wiederum ja auch
2917680	2925360	dem der Fahrerin und dem dem Fahrer quasi eigentlich eine Idee von Autonomie irgendwie
2925360	2933400	ja vorgehalten wird oder nicht vorgehalten, eine Art von Autonomie versprochen wird. Insofern
2933400	2938000	ist, dass sie quasi während der Fahrt sozusagen sich zurücklehnen kann und eben was lesen,
2938000	2943000	schlafen, was auch immer. Und beides wird eigentlich eben nicht eingehalten, aber trotzdem
2943000	2949520	mit der Idee der der Autonomie verkauft. Das fand ich irgendwie ganz ganz spannend und das dann am
2949520	2954640	Ende als Pointe, die wiederum durch die Theorie algorithmischer Sozialität dann in den Blick
2954640	2959480	kommt als Pointe, eigentlich auch noch als Sahnehäubchen oben draufgesetzt wird, dass im
2959480	2963880	Grunde das in der Form von gesteigerte Disziplinierung der Subjekte dann würde das,
2963880	2971440	fand ich eigentlich als Gesamtbild ganz ganz anschaulich und ironisch eigentlich. Deswegen
2971440	2978280	war Ironie der Assistenz auch ziemlich treffender Begriff fand ich muss ich sagen. Ja das würde man
2978280	2983960	jetzt überhaupt nicht, also gerade wenn man jetzt jetzt aus Deutschland kommt, kennen wir ja das
2983960	2990640	Phänomen, dass der oder die Deutsche gern mit manuell schaltenden Fahrzeugen fährt. Also
2990640	2996320	Deutschland ist ja das einzige Land, wo es kaum automatische Schalter gibt, weil eben alle sozusagen
2996320	3003080	kleine Versionen von Michael Schumacher sind. Und ausgehend von dieser Beobachtung würde man
3003080	3008320	natürlich sagen, es gibt eine bestimmte Widerständigkeit gegen die Vorstellung
3008320	3012240	autonomer Fahrzeuge. Wenn ich jetzt schon nicht bereit bin eine automatische Gangschaltung zu
3012240	3016320	abzitieren, dann würde ich natürlich vermuten, dass ich auch gegen die Vorstellung autonomer
3016320	3021720	Fahrzeuge bin. Und gerade in den USA lässt sich halt genau das gegenteilige Phänomen beobachten,
3021720	3028280	wie du es schon beschrieben hast, dass da eben die Vorstellung des freien unregulierten Individuens,
3028280	3034200	also unreguliert nicht vor Gesellschaft sozusagen, sich gespiegelt wird in das Fahrzeug. Nicht,
3034200	3041520	dass man dort aktive Lobbyarbeit betreibt, dass diese Fahrzeuge nicht vernetzt sein sollen. Also
3041600	3047160	dass man jetzt sagen würde als Regulierungsbehörde, wir setzen jetzt voraus, dass zum Beispiel die
3047160	3051680	Fahrzeuge miteinander vernetzt sind, dass sie erkennen können, wenn vorne einer abbremst,
3051680	3055360	kann der hinten schon abbremsen, kommen sie nicht zu Auffahrunfällen, wäre ja technisch
3055360	3062640	eigentlich liegt auf der Hand. Das wird sozusagen aktiv unterminiert, weil man eben dadurch für
3062640	3067840	seinen Eingriff in die Freiheit des Individuums befürchtet, was in dem Moment sich sozusagen
3067840	3072640	als Fahrzeug reinkarniert hat. Eine ziemlich verrückte Wandlung, die man jetzt wirklich gar
3072640	3076560	nicht erwarten würde. Genau, und das Ergebnis ist dann, das kann man ja auf YouTube und überall
3076560	3081440	beobachten, diese Videos, wo irgendwelche Leute in Tesla sitzen und schlafen, die also sozusagen
3081440	3085920	auf dieses Versprechen von Maske reingefallen sind. Das heißt, dieses Assistenzsystem ja auch
3085920	3090640	glaube ich Autopilot. Also das wird das sozusagen so verkauft. Das heißt, die fahrenden Kaufen
3090640	3095920	glauben das eben, dass das so ist, nutzen das dann, kommen es dann eben zu entsprechenden Unfällen.
3095920	3103120	Das wäre sozusagen eben diese Ironie der Assistenz. Gibt es einige Untersuchungen,
3103120	3108400	die sagen eben mittlerweile sind diese Assistenzsysteme die größten Quellen von
3108400	3113520	Verkehrsunfällen. Nicht mehr Alkohol oder irgend sowas, sondern diese Ablenkung durch
3113520	3118000	Assistenzsysteme oder einfach, indem man die Assistenzsysteme überschätzt oder indem man sie
3118000	3122600	unterschätzt oder indem man abgelenkt wird, wenn man nicht versteht, nicht wenn man überlastet ist,
3122600	3125840	man demietet sich vielleicht ein Auto oder jemand ist in entsprechendes Alter erreicht,
3125840	3129800	versteht nicht so schnell, was diese ganzen Displays alles machen, guckt da drauf und
3129800	3134040	sozusagen kommt es zu Unfällen. Das wäre sozusagen die Ironie der Assistenz, nicht das
3134040	3139120	sozusagen jetzt durch Systeme, die eigentlich das Fahren leichter machen sollen, die eigentlich
3139120	3145800	das verschlimmern. Und die Dialektik der Assistenz besteht eben dann darin, dass man jetzt
3145800	3151760	Assistenzsysteme einbaut, die genau das wieder verhindern sollen. Also Ablenkung verhindern
3151760	3155960	sollen, dass ich jetzt eben nicht vor den Assistenzsystemen abgelenkt werde, wird durch
3155960	3163040	erweiterte Assistenzsysteme verhindert. Das ist eine schon sehr verrückte Entwicklung und hat,
3163040	3169720	glaube ich, in erster Linie damit zu tun, was ich vorhin angesprochen habe, dass man systematisch
3169720	3175520	sozusagen diesen Verkaufsversprechen, dass es sich um autonome Fahrzeuge handelt, systematisch auf
3175640	3181680	Leim gegangen ist. Das ist sozusagen niemand oder es gab natürlich immer Leute, die gewarnt haben
3181680	3186880	und das wissen nun, aber dass man auch in den zentralen Medien überhaupt nicht versteht, mit
3186880	3192560	welchen Entwicklungen wir zu tun haben, dass jedes Assistenzsystem eigentlich eine Vertiefung der
3192560	3200400	Beziehung ist und keine Entlastung in dem Sinne. Aber ich muss das immer ein bisschen beholen,
3200400	3203080	weil unsere Diskussion jetzt in eine weiche Richtung geht, weil ich eben gerade diese
3203240	3209520	Disziplinierungsperspektive entkommen will, ist das eben auch eine Disziplinierung des Fahrzeugs.
3209520	3215640	Das Fahrzeug wird ja jetzt auch gezwungen, ständig aufzupassen, was der Fahrer macht oder die
3215640	3220800	Fahrerin. Es ist auch eine Subjektivierung des Fahrzeugs gleichzeitig, was jetzt auf einmal sehr
3220800	3227200	menschlich wird oder zumindest für menschliche Schwächen sich sensibilisieren muss. Da sitzt jetzt
3227200	3231920	ein Mensch drin, der überschätzt sich, der wird abgelenkt, der tentidiert dazu auch einzuschlafen.
3232080	3238120	Also haben wir es auch einerseits mit einer wechselseitigen Assistenz, könnte man sagen,
3238120	3243160	zu tun. Also ich assistiere dem Fahrzeug, das Fahrzeug assistiert mir. Umgekehrt ist das aber
3243160	3248160	eben auch eine doppelseitige Disziplinierung, insofern als das autonome Fahrzeug ja auch Autonomie
3248160	3255040	verliert. Es wird immer mehr abhängig davon, dass da jemand drin sitzt und auch das Richtige tut und
3255040	3261600	die richtigen Knöpfe drückt. Damit haben wir jetzt im Grunde eigentlich einen Weg, der derzeit
3261600	3268840	beschritten wird, beschrieben. Also diese Abfolge von eigentlich Ironie der Assistenz und dann
3268840	3275760	Dialektik der Assistenz, dass man also eben in dem Fall mit dem Versprechen der Autonomie
3275760	3282360	nicht autonome Systeme einbaut, die dann wiederum von den Menschen falsch verstanden werden oder
3282360	3288640	für bare Münze falsch verstanden werden als autonome Systeme. Daraufhin ihr Verhalten darauf
3288640	3293880	ausrichten, als wären sie wirklich autonom, was wiederum Dysfunktionalitäten erzeugt,
3293880	3299680	weshalb man eben die Dialektik der Assistenz wieder neu erweiterte Assistenzsysteme einbauen
3299680	3307680	muss, die das wiederum versuchen zu adressieren. Das ist sozusagen der eine Strang, der wirklich
3307680	3312400	gelebte Realität ist, muss man da auch jetzt hinzu sagen, weil wie Roberto ja eben gesagt hast,
3312400	3318880	das ist jetzt auch quasi schon in die Politik eingegangen. Das ist sozusagen mal der eine Zugang,
3318880	3327920	der derzeit auch absolut so praktiziert wird und ein anderer Zugang auf dieses Problem in
3327920	3334200	Anführungsstrichen der störenden Subjekte oder der sozusagen in dem Fall dysfunktional agierenden
3334200	3341960	Subjekte einzugehen, den beschreibst du als Prinzip des Ausschlusses der eigentlich der
3341960	3348160	menschlichen Subjekte. Ja, und also mich hat das sehr stark erinnert an einen Vortag, den ich
3348160	3354360	mal gesehen habe von Benjamin Bretton, in dem er eine Zukunft beschreibt, in der menschliche
3354360	3361560	AutofahrerInnen als ignorant-individualistische Bedrohungsfaktoren beschreibt, die entgegen jeder
3361560	3368320	empirischen Fakten lagen, darauf beharren, ein freiheitliches Verkehrsrisiko darstellen zu dürfen.
3368320	3375440	Ja, und Bretton nimmt da dann halt relativ klar Stellung für ein umfassendes, kollektiv
3375440	3381320	vernetztes, nicht-menschliches Fahren. Ja, also das ist eben das, was du dann wiederum in deinem
3381320	3390360	Text mit Verweis auf einen Konzern namens Waymo, der wohl eben auch versucht, autonome Systeme,
3390360	3397000	also Systeme autonome Fahrens beziehungsweise erweitert assistierenden Fahrens zu entwickeln.
3397000	3404320	Mit Verweis auf diesen Konzern gehst du eben auch auf diese Variante ein, denn eben auch Waymo
3404320	3410280	beschreibt, dass im Grunde sagen, in ihrer Perspektive der Mensch eigentlich das größte
3410280	3419160	Problem ist, denn der Mensch, der ist eben nicht so regelkonform, wie es die programmierten Autos
3419160	3425800	eben sind, und denen fällt es wiederum unglaublich schwer, auf dieses Abweichen von der Regel wiederum
3425800	3431960	einzugehen, weswegen dann wiederum die Schlussfolgerung von Waymo ist, man müsse doch eigentlich dann
3431960	3439480	dafür sorgen, dass dieser Störfaktor nicht mehr partizipiert am Verkehr, am Straßenverkehr und
3439480	3447480	erst dann könne sozusagen ein Maß an Sicherheit erzeugt werden, dass irgendwie der Sache gerecht
3447480	3452520	wäre, vielleicht kannst du das uns ein bisschen näher bringen, diesen Zugang des Ausschlusses und
3452520	3458560	auch was das bedeutet. Die Ausgangslage ist natürlich wieder wie vorhin, also sozusagen die
3458560	3464400	völlige Verwirrung, was autonomes Fahren tatsächlich in seiner Umsetzung bedeutet, dass wir eben
3464400	3471360	angefixt sind, Lucy Satchman nennt das sozusagen die Privilegierung der Maschine, also wir schauen
3471360	3476240	uns an Möglichkeiten und Grenzen, Big Data und maschinelles Lernen und autonomes Fahren, aber
3476240	3482640	dass das natürlich eigentlich immer nur in Interaktionsbeziehungen auftaucht und als
3482640	3489400	Technologie völlig uninteressant ist oder nicht sehr aufschlussreich ist, wird halt übersehen und
3489400	3496200	das sind sozusagen jetzt, kommen diese Unternehmen, stellen halt fest in ihren Analysen, also bestimmte
3496200	3502280	Abläufe können wir das Fahrzeug sozusagen semi-autonom durch die Stadt führen, aber dann gibt es Leute,
3502280	3507920	die laufen dabei rot über die Ampel und zum Schluss fahren die Autos sozusagen super vorsichtig im
3507920	3512160	Schritttempo durch die Stadt, die menschlichen Fahrerinnen, die dahinter sind, verlieren den
3512160	3517240	Nervenfang an zu hupen und es kam sozusagen auch zu Gewaltausbrüchen gegen diese Testfahrzeuge,
3517240	3524640	einfach weil man hier ist und das ist eigentlich das, wo ich auch mit diesem ganzen Gemengelage der
3524640	3529000	algorithmischen Sozialität hinweisen will, dass das Problem, das größte Problem eigentlich nicht
3529040	3533360	die technische Umsetzung des autonomen Fahrers ist, sondern eben eigentlich die
3533360	3541240	Subjekt-algorithmische Beziehung, nicht dass man es schafft, Fahrzeuge und menschliche Personen
3541240	3548720	in Beziehung zu setzen und ähnlich, ich habe das mal auf einer Industriekonferenz mal jemanden,
3548720	3553920	so ein Ingenieur, gefragt, die sozusagen ihre Präsentation machen, da ist ja dann das autonome
3553920	3560640	Fahrer immer in fünf Jahren umgesetzt in diesen Präsentationen und dann habe ich eben mal gefragt,
3560640	3565880	wie das jetzt eigentlich man sich das als Soziologe vorstellen soll, dass wir eben auf der einen Seite
3565880	3572000	als Soziologe in dem Wissen, dass Menschen eben Normenbrecher sind, sich eben nicht an Normen
3572000	3580400	halten oder eben dazu tendieren, die Normen immer ein bisschen zu schieben und eben ein Algorithmus,
3580480	3585040	das halt nicht kann, eine Höchstgeschwindigkeit ist halt eine Höchstgeschwindigkeit, die kann man
3585040	3589520	jetzt zwar irgendwie manuell diskretionär überschreiben, aber dazu braucht es auch wieder
3589520	3596400	einen menschlichen Fahrer, das Fahrzeug wird das nicht können und ist eben die Frage, wie können
3596400	3603440	Regelfolger und Regelbrecher zusammenleben? Das läuft, hat ja Ingenieur dann auch zugegeben,
3603440	3610640	dass das eigentlich faktisch empirisch nur geht, indem man die Menschen das Fahren verbietet,
3610640	3617720	also das, was du auch geschrieben hast, indem man sie aus dem Verkehr ausschließt. Wir kennen das
3617720	3622840	und daran zeigt sich auch in gewisser Weile die Banalität des gesamten Phänomens. Wir kennen
3622840	3628200	das ja auch von anderen autonomen Fahrzeugen, nämlich zum Beispiel so Zubringer-Shuttle am
3628200	3632280	Flughafen, die sozusagen autonomig verankert werden. Was man da beobachten kann, ist genau das
3632320	3638680	Phänomen, das wird halt in hochgradig isolierten Umwelten findet das statt, da gehen Türen zu,
3638680	3644400	gehen Türen auf, es gibt eine Schiene, auf der das langfährt, das sind sozusagen hochgradig
3644400	3650000	künstliche Umwelten und auch man sieht man jetzt bei dem autonomen Fahren, die angeblich in diese
3650000	3654360	Alltagswelt gebracht werden soll, das ist ja Anspruch, dass das autonome Fahrzeug eigentlich
3654360	3660520	faktisch überall fahren kann auf dem Mond, dass das eben eigentlich nur zufangs funktioniert,
3660520	3667000	wenn man die eben umweltextrem artificiell zurichtet, also entweder vollpackt mit Sensoren,
3667000	3673440	dass die Fahrzeuge eben wissen, wo sie sind und eben auch eine massive Ausschluss von Menschen.
3673440	3681480	Und da gab es jetzt verschiedene Testgelände, verschiedene Städte haben eben Experimente zu
3681480	3686840	technischen Fahrzeugen gemacht und da gab es eben dann auch diese Phänomene, dass dann faktisch die
3686840	3690920	gesamte Innenstadt für Menschen abgesperrt ist, nicht? Da haben wir dann sozusagen Zäune an der
3690920	3697840	Straße, es gibt Schranken beim Fußgängerüberweg, da sieht man also genau das Umgesetz, dass sozusagen
3697840	3704320	der Regelbrecher Mensch aus diesem Phänomen ausgeschlossen ist und es ist ganz offensichtlich,
3704320	3709560	dass es entweder darauf hinaus läuft, den Menschen auszuschließen, wie sozusagen beim
3709560	3716680	Flughafenzubringer, beim Shuttle oder dass es in einer Art von intensivierter Beziehung bedarf,
3716800	3723960	wo man dann aktiv sagen kann, so kennt man das jetzt nicht auch, wenn man sich mal ein neues Auto mit
3723960	3731080	so Assistenzsystemen mal fährt und man hat diese Abstandsassistenten und man merkt das sozusagen,
3731080	3736720	man fährt jetzt auf der Überholspur und der Abstandsassistent hält sozusagen diese Mindestabstand ein
3736720	3742600	und nachdem das vierte oder fünfte Auto in den Sicherheitsabstand gefahren ist, hat man dann auch
3742600	3746840	keinen Spaß mehr an diesem Assistenzsystem und wird dann entweder eben diese Distanz verringern,
3746840	3753160	also eigentlich den vorgeschriebenen Sicherheitsabstand unterschreiten oder man wird die
3753160	3757600	Geschwindigkeit rosseln müssen und irgendwie heranfahren. Das ist jetzt eben nochmal sozusagen ein
3757600	3764200	Zeichen dafür oder ein Symptom dafür, dass man eben sagen kann, die wahrscheinlichere Form als
3764200	3768320	Soziologe, würde ich sagen, ist eine Form von Interaktion, dass man komplette Städte und die
3768320	3773520	gesamte komplette Fahrindustrie oder Infrastruktur von Menschen absperrt, kann ich mir faktisch
3773520	3779360	eigentlich nicht vorstellen. Insofern eben nochmal eben das Plädoyer, dass man das mit einer
3779360	3785160	Beziehungsanalyse eigentlich aufschlüsseln muss, diese Transformation, die sich da vor uns in
3785160	3790040	Augen abspielt. Oder auf eine Art finde ich ist ja oder vielleicht verstehe ich das noch falsch,
3790040	3795880	das würde mich jetzt interessieren. Auf eine Art klang das ja jetzt so, als ob durch die
3795880	3802160	Differenzierung von autonomem Fahren oder dem eben in Anführungsstrichen falschen Versprechen,
3802160	3808200	von autonomem Fahren und dem anderen Paradigma, nämlich dem vernetzten, koordinierten Fahren,
3808200	3813960	dass da eigentlich schon auch zwei unterschiedliche Paradigmen sich so ein bisschen aufzeigen. Oder
3813960	3820400	also das ist das vielleicht dann auch eine Form des Verständnisses von subjektalgorithmischen
3820400	3827560	Beziehungen und Beziehungshaftigkeit eigentlich da so ein bisschen drin versteckt liegt oder ein
3827560	3832400	Versprechen vielleicht auch eine Möglichkeit, eine Chance drin liegt. Wenn man also weder das
3832400	3840240	menschliche Subjekt komplett ausschließen will, noch eigentlich einem falschen Versprechen totaler
3840240	3847320	Autonomie folgen, das dann in einer gesteigerten gegenseitigen Disziplinierung von sowohl in dem
3847320	3852080	Fall dem Auto als auch dem Menschen mündet, was gäbe es da vielleicht noch für einen anderen Weg,
3852080	3861960	mit dieser grundsätzlichen Problematik von subjektalgorithmischen Beziehungen umzugehen.
3861960	3871040	Und auf eine Art hatte ich das Gefühl, dass die Form des vernetzten koordinierten Fahrens
3871040	3876400	eigentlich da auch schon versucht zu sagen, einem anderen Paradigma zu folgen,
3876400	3881840	das eben dann nicht auch in dieser Falle der falschen Autonomie tappt und infolgedessen dann
3881840	3887560	eben auch andere Lösungsvorschläge anstrebt. Aber wie hätten wir uns die vorzustellen? Wie
3887560	3891680	kann man sich das vielleicht anhand des Beispiels des autonomen Fahrens dann auch ein bisschen
3891680	3896040	veranschaulichen, wie quasi diese Beziehung anders gedacht werden kann?
3896040	3902680	Nein, das gibt es natürlich alles. Das sind auch eigentlich, könnte man jetzt nochmal den
3902680	3908160	Begriff der Algorithmuskulturen schreiben, es sind eben verschiedene Algorithmuskulturen. Das ist
3908160	3911880	jetzt vielleicht ein bisschen eine steile These, aber ich habe eigentlich auch ehrlich gesagt ein
3911880	3919160	bisschen die Vermutung, dass das ein Grund ist, warum wir viel von dem autonomen Fahren aus den USA
3919160	3930960	hören. Vamo, Musk, Tesla und eigentlich aus Europa gar nicht so sehr. Das, was ich mal sozusagen als
3930960	3935440	explorative Studie auch untersucht habe in Düsseldorf zum vernetzten Fahren, hieß eben
3935440	3940400	vernetztes Fahren, und das hatte eigentlich einen ganz anderen Zuschnitt. Das ist also nicht das
3940400	3946600	Interessesprojekt von technolibratären Individualisten und Millionärin, sondern das
3946600	3950960	ist ein Projekt einer Stadt. Eine Stadt hat natürlich eine ganz andere Form, ein ganz anderes
3950960	3955520	Problem. Eine Stadt hat ja überhaupt gar kein Interesse daran, dass das Auto und Fahrzeug an den
3955520	3962000	Umfährt. Die Stadt hat Interesse daran, dass der Verkehr effizient geregelt wird, dass die
3962000	3966920	Emissionen gesteuert werden, dass das Parkplatzproblem gelöst werde und dieses vernetzte Fahren in
3966920	3972040	Düsseldorf zielte eben genau darauf ab. Das sind ganz andere Problemarisierungen, die damit betrieben
3972040	3977000	werden. Wie kann man verhindern, dass in dem Tunnel es zu Auffahrunfällen, wie kann man den
3977000	3982240	Sperren, wenn es ein Feuerunfall ist, Verkehrsleitssysteme, nicht, da ist sozusagen die
3982240	3987880	Frage des vernetzten Fahrens immer eine Frage der Kooperation und Kooperationsprobleme. Also würde
3987880	3995480	man sagen, wenn eine Stadt sowas betreibt, dann wird sie dieses Phänomen ganz anders angehen, als
3995480	4001880	wenn ein sozusagen irgendwie ein Egomane das betreibt, der am liebsten mit seinem Auto gleich
4001880	4007200	noch zum Mond fahren würde, wenn es möglich wäre. Also das unterscheidet sich sozusagen schon.
4007200	4011640	Interessant war bei dieser explorativen Studie in Düsseldorf eben auch, dass die eigentlich
4011760	4020080	im Grunde eine Infrastruktur gebaut haben. Also wir bauen Sensoren, Kameras, Bluetooth-Schnittstellen,
4020080	4024840	bieten wir ein in der Stadt, in der Teststrecke und jetzt bieten wir das Privatunternehmen an,
4024840	4030520	das zu nutzen. Das Einzige, was richtig gut funktioniert hat, ist sozusagen der öffentliche
4030520	4037080	Nahverkehr, also die Busse. Dass man jetzt sagt, kann die Busfahrer damit optimieren. Das System
4037080	4041520	findet jetzt heraus, dass in 30 Sekunden davon erholt wird, kann der Busfahrer auch ein bisschen
4041520	4045600	länger in der Haltestelle warten und stellen und solche Sachen. Aber man hat dann versucht,
4045600	4049880	auch Privatunternehmen fort und so einzubinden und eigentlich hat man festgestellt, dass viele
4049880	4054000	von diesen Unternehmen überhaupt kein Interesse haben, weil sie eben ihre Technologien, die sehr
4054000	4058640	so sehr auf Individualverkehr abgestellt sind, mit diesen Infrastrukturen eigentlich überhaupt
4058640	4062440	nichts anfangen können oder einfach auch gar nicht daran interessiert sind. Die sind eben daran
4062440	4070320	interessiert, Individualfahrzeuge herzubauen und dadurch ist diese gesamte Ausrichtung der Technologie
4070320	4077960	ganz anders orientiert, als wenn ich sagen würde, ich versuche ein Phänomen zu bauen,
4077960	4083320	wo wir ein gesellschaftliches Problem lösen und nicht nur ein individuelles. Also insofern ist es
4083320	4088720	auch empirisch jetzt schon so, dass man eben ganz verschiedene, man kann eben vernetztes Fahren,
4088720	4094680	ist eigentlich wieder ein anderes Phänomen. Also man kann ja sagen, Assistenzsysteme oder assistiertes
4094680	4099760	Fahren kann auch vernetzt sein, wenn die Fahrzeuge eben miteinander vernetzt sind und sich beobachten
4099840	4105840	miteinander kommunizieren, aber vernetztes Fahren kann auch viel ganz anders gemeint sein. Also das
4105840	4111680	ist eben wirklich um eine Funktion des Gemeinschaftslebens, des gemeinsamen Zusammenlebens
4111680	4116560	geht. Man sagt, wie kann ich das jetzt so gestalten, dass wir alle einen Bus benutzen können, ohne jetzt
4116560	4120640	sozusagen ständig irgendwie zu spät zu sein und dann lieber doch wieder das eigene Auto nehmen,
4120640	4127000	solche Sachen. Das ist ja wirklich ein ganz großartiger Ausblick, finde ich, der sich jetzt
4127000	4134760	da bietet aus der Analyse der algorithmischen Sozialität heraus eigentlich zu einem Plädoyer
4134760	4142120	für kooperative Algorithmuskulturen. Das ist ja eigentlich wirklich schön und schließt auch super
4142120	4148720	an an meine letzte Frage, die da ist. Wenn du dir Zukunft vorstellst, was stimmt dich freudig?
4148720	4157640	Das ist immer eine schwierige Frage. Also wie gesagt, solche Sachen, solche Phänomene,
4157640	4161440	wie wir sie jetzt gerade zum Schluss geschrieben haben von Kooperation, sind natürlich viel
4161440	4168920	spannender. Ob das jetzt sozusagen eine Zukunftsentwicklung ist, kann ich schwer absehen.
4168920	4178280	Ich bin da ehrlich gesagt als Soziologe auch ein bisschen emotionslos. Sowohl was hoffnungsvolle
4178280	4186360	Zukunftsszenarien als auch Dystopien betrifft. Ich bin da mehr sozusagen an den tatsächlichen
4186360	4193760	Veränderungen, die man konkret beobachten kann, interessiert. Und da glaube ich schon, dass man,
4193760	4198480	das versuche ich auch sozusagen in diesem Konzept der algorithmischen Sozialität zu
4198480	4205520	berücksichtigen, dass das eben keine festgelegte Sache ist. Also da sind extrem viele Unbestimmtheiten
4205840	4219400	drin in dem Prozess. Ich dekonstruiere jetzt vielleicht eine Frage zu sehr, dass ich eigentlich eher
4219400	4225320	Interesse habe oder finde, dass wir eine größere Sensibilität entwickeln sollten für die Momente
4225320	4232120	der Transformation oder das Werten, in dem wir uns gerade befinden, weil wir eben sehr dazu tendieren,
4232120	4237760	die aktuellen Entwicklungen entgegweder von der Ausgehen von der Vergangenheit zu denken oder eben
4237760	4243600	irgendwelche kritischen Befürchtungen gleich mal von der Vergangenheit wieder in die Zukunft klappen.
4243600	4250760	Insofern, da bin ich wahrscheinlich dann auch wieder zu sehr Deleuzianer, finde ich diese
4250760	4255600	Fokussierung auf die Zukunft vielleicht eher problematisch und würde eher sagen, was wir
4255600	4262040	eigentlich sehr selten können, ist zu verstehen, dass in den Momenten, in denen wir leben,
4262040	4267880	was da eigentlich für Momente möglich sind, Transformationsmomente eigentlich drinstecken,
4267880	4274000	weil wir möglicherweise eben immer schon sozusagen in Zukunftshoffnungen und Zukunfts- oder
4274000	4280440	Vergangenheitsbefürchtungen leben. Also, weil ich die Frage vielleicht ein bisschen umdrehe,
4280440	4287280	dass ich immer sozusagen auf diese Transformation im aktuellen Moment eigentlich, das stimmt mich
4287280	4292920	sozusagen immer wieder freudig, weil ich glaube, dass man, egal was sozusagen passiert, es nie
4292920	4299680	vollständig bestimmt ist, wie es weitergeht. Das kann, was jetzt freudig ist, damit auch natürlich
4299680	4303920	schlecht gewählt, weil es kann auch immer alles viel schlimmer kommen als es eh schon ist, aber es
4303920	4310560	kann auch eben noch wieder besser kommen. Das ist jetzt so eine sehr unbefriedigende sowohl
4310560	4316320	als auch Antwort, das tut mir jetzt leid. Finde ich überhaupt nicht. Ich finde, das ist, das beharrt
4316320	4322560	ja einfach vehement auf der Offenheit, die in jeder Gegenwart auch gegeben ist. Das finde ich
4322560	4326000	eigentlich ganz großartig und mich persönlich stimmt das auch freudig. Insofern kann ich das
4326000	4331320	total verstehen als eine Antwort. Ja, ganz super. Und danke dir ganz herzlich für dieses Gespräch.
4331640	4336840	Ja, danke dir, dass ich hier sein durfte. Und ja, ich genieße das immer sehr, den Podcast,
4336840	4343040	und werde weiter zuhören, neben was hier in Zukunft noch kommt. Das freut mich. Bis dahin, ciao.
4348040	4355080	Das war Future Histories für heute. Vielen Dank fürs Zuhören, Show-Notizen und vieles mehr findet
4355080	4361960	ihr auf www.futurehistories.today. Diskutiert mit auf Twitter unter dem Hashtag Future Histories
4361960	4368280	oder im eigenen Subreddit. Ihr könnt Future Histories nicht nur auf allen großen Podcast-Plattformen
4368280	4374960	hören und abonnieren, sondern auch auf YouTube, wo ihr neben den Episoden dann auch Kurzvideos
4374960	4382240	zu Kernbegriffen einzelner Episoden findet. Schreibt mir gerne unter jan at futurehistories.today. Ich
4382240	4387760	freue mich immer sehr über interessante Rückmeldungen und Hinweise. Wenn ihr Future
4387760	4394000	Histories unterstützen wollt, dann könnt ihr das auf patreon.com schrägstrich Future Histories oder
4394000	4399760	auch via Spende auf unserer Homepage. Future Histories ist eine Produktion von MetaLapses
4399760	4405800	zu finden auf meta-lapses.net. Bis zum nächsten Mal. Ich freue mich.
