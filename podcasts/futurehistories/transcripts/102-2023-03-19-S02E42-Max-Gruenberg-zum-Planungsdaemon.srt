1
00:00:00,000 --> 00:00:06,000
Herzlich willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft.

2
00:00:06,000 --> 00:00:11,000
Mein Name ist Jan Groß und ich freue mich sehr, heute Max Grünberg begrüßen zu dürfen.

3
00:00:11,000 --> 00:00:15,000
Ich habe Max am Anfang des Gesprächs gebeten, sich kurz vorzustellen.

4
00:00:15,000 --> 00:00:18,000
Daher werde ich da jetzt nicht zu viele Worte zu verlieren.

5
00:00:18,000 --> 00:00:22,000
Ich schätze Max jedenfalls sehr als Stimme in der Planungsdebatte.

6
00:00:22,000 --> 00:00:27,000
Und nachdem er es in der Vorstellung nicht erwähnt, möchte ich zumindest mal darauf hinweisen,

7
00:00:27,000 --> 00:00:31,000
dass Max auch Mitgründer von DEFRACT ist.

8
00:00:31,000 --> 00:00:37,000
Das ist ein kollektiv organisierter Raum in den ehemaligen Räumen des Merbe-Verlags in Berlin Schöneberg.

9
00:00:37,000 --> 00:00:40,000
Und da passieren ganz viele spannende Sachen.

10
00:00:40,000 --> 00:00:44,000
Und ich kann euch nur sehr empfehlen, mal auf der Homepage vorbei zu schauen.

11
00:00:44,000 --> 00:00:47,000
Den Link, den findet ihr in den Show Notes.

12
00:00:47,000 --> 00:00:54,000
Das Gespräch mit Max, das habe ich am Rande des Workshops The Algorithmic Road to Socialism aufgezeichnet,

13
00:00:54,000 --> 00:00:58,000
der im Juni 2022 in Kiel stattgefunden hat.

14
00:00:58,000 --> 00:01:03,000
Und ich möchte Marlon lieber ganz herzlich danken für die Organisation dieses Workshops.

15
00:01:03,000 --> 00:01:08,000
Es war wirklich ausgezeichnet und es hat mich sehr gefreut, dass ich dabei sein durfte.

16
00:01:08,000 --> 00:01:15,000
Ich freue mich ebenfalls sehr, dass die Folge mit Max jetzt hier direkt nach der Episode mit Antoinette Rouvois erscheinen kann.

17
00:01:15,000 --> 00:01:23,000
Denn Antoinette, die setzt sich ja sehr intensiv und kritisch mit der Frage algorithmischer Governmentalität auseinander.

18
00:01:23,000 --> 00:01:28,000
Das macht es also umso spannender jetzt im Anschluss an die Episode mit Antoinette.

19
00:01:28,000 --> 00:01:36,000
Versuche zu diskutieren, algorithmische Technologien in Form alternativer Techniknutzung für die Planungsdebatte nutzbar zu machen.

20
00:01:36,000 --> 00:01:42,000
Da besteht also ein interessantes Spannungsverhältnis, könnte man sagen, zwischen diesen beiden Episoden.

21
00:01:42,000 --> 00:01:45,000
Und ich kann euch nur empfehlen, sie im Tandem zu hören.

22
00:01:45,000 --> 00:01:52,000
Bevor es jetzt losgeht, dann möchte ich noch Scott ganz herzlich als Patron von Future Histories begrüßen

23
00:01:52,000 --> 00:01:58,000
und Karl, Lukas, Carmen, Wilfried und Fabian für ihre Spenden danken.

24
00:01:58,000 --> 00:02:05,000
Und jetzt viel Freude mit der heutigen Folge Future Histories mit Max Grünberg zum Planungsdemon.

25
00:02:10,000 --> 00:02:15,000
Herzlich willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft.

26
00:02:15,000 --> 00:02:19,000
Ich freue mich sehr, heute Max Grünberg begrüßen zu dürfen.

27
00:02:19,000 --> 00:02:23,000
Max, ich habe jetzt keine einleitenden Worte vorbereitet.

28
00:02:23,000 --> 00:02:25,000
Vielleicht magst du dich selbst kurz vorstellen.

29
00:02:25,000 --> 00:02:27,000
Vielen Dank für die Einladung.

30
00:02:27,000 --> 00:02:33,000
Mein Name ist Max Grünberg und ich bin wissenschaftlicher Mitarbeiter an der Universität Kassel,

31
00:02:33,000 --> 00:02:43,000
wo ich promoviere zur Rolle von Algorithmen in der Verwirklichung einer möglichen postkapitalistischen Wirtschaftsweise.

32
00:02:43,000 --> 00:02:46,000
Und ich freue mich hier zu sein.

33
00:02:46,000 --> 00:02:49,000
Ich muss sagen, ich habe den Paper wirklich sehr genossen, Max.

34
00:02:49,000 --> 00:02:53,000
Das ist allen wirklich wärmstens ans Herz zu legen.

35
00:02:53,000 --> 00:02:56,000
Und mir hat besonders gut gefallen, dass du im Grunde versuchst,

36
00:02:56,000 --> 00:03:02,000
einen Brückenschlag zu erschaffen zwischen unterschiedlichen Positionen innerhalb der Planungsdebatte.

37
00:03:02,000 --> 00:03:03,000
Vielleicht fangen wir da mal mit an.

38
00:03:03,000 --> 00:03:07,000
Was sind das für Pole, die du da aufspannst und was zeichnet sie aus?

39
00:03:07,000 --> 00:03:09,000
Was sind vielleicht auch ihre Schwächen?

40
00:03:09,000 --> 00:03:14,000
Vielleicht hole ich da ein bisschen weiter aus, wenn ich darf.

41
00:03:14,000 --> 00:03:20,000
Wir fangen erstmal mit der Vision an oder mit dem Projekt, das vor uns steht,

42
00:03:20,000 --> 00:03:30,000
in der Überwindung eines Wirtschaftssystems, das eklatante Mängel hat, ist unstabil, unökologisch, ungerecht.

43
00:03:30,000 --> 00:03:37,000
Und die Frage, wie wir eine Welt schaffen können, in dem einfach der Platz für Menschen gegeben ist in der Form.

44
00:03:37,000 --> 00:03:45,000
Und in der Frage sozusagen, wie so eine kommunistische Zukunft aussehen kann.

45
00:03:45,000 --> 00:03:47,000
Ich denke, da gibt es erstmal eine philosophische Frage,

46
00:03:47,000 --> 00:03:53,000
das sozusagen aus den Lehren der Vergangenheit des autoritären Kommunismus,

47
00:03:53,000 --> 00:03:58,000
des real existierenden Kommunismus vor allem in der Sowjetunion erstmal auf einer philosophischen Basis

48
00:03:58,000 --> 00:04:03,000
mein Verständnis einer kommunistischen oder sozialistischen Gesellschaft

49
00:04:03,000 --> 00:04:07,000
vor allen Dingen eine Versöhnung von Freiheit und Gleichheit ist.

50
00:04:07,000 --> 00:04:14,000
Und in dem Sinne, der Kapitalismus vor allen Dingen die Gleichheit zugunsten der Freiheit geopfert hat

51
00:04:14,000 --> 00:04:22,000
und im real existierenden Kommunismus eben die Gleichheit zumindest offiziell großgeschrieben wurde,

52
00:04:22,000 --> 00:04:25,000
praktisch sah das dann natürlich auch anders aus.

53
00:04:25,000 --> 00:04:32,000
Und in diesem Sinne, wirklich eines libertären Kommunismus, gehe ich der Frage nach, wie das umgesetzt werden kann.

54
00:04:32,000 --> 00:04:34,000
Und da vielleicht noch mal konkreter die Ziele.

55
00:04:34,000 --> 00:04:43,000
Es ist vor allen Dingen auch erst mal auf einer materiellen Basis das Ziel einer sozialistischen Produktionsweise

56
00:04:43,000 --> 00:04:47,000
wirklich den Lebensstandard aller breiten Bevölkerungsmasse anzuheben.

57
00:04:47,000 --> 00:04:57,000
Also gleichzeitig gibt es da auch gewisse Tendenzen, wie beispielsweise in Büchern von Aaron Bistani

58
00:04:57,000 --> 00:05:04,000
die Idee von irgendwie einer sehr konsumeristischen Vorstellung von einem Kommunismus,

59
00:05:04,000 --> 00:05:11,000
der Fully Automated Luxury Communism genannt wird.

60
00:05:11,000 --> 00:05:19,000
Und das aber sehr stark eben mit einer Idee von Nachhaltigkeit und einem Planeten,

61
00:05:19,000 --> 00:05:25,000
der wirklich an die Grenze der Machbarkeit gestoßen wird.

62
00:05:25,000 --> 00:05:31,000
Und da vor allen Dingen sozusagen mit metabolistischen Limits man konfrontiert ist

63
00:05:31,000 --> 00:05:36,000
und die Tragfähigkeit des Planeten einfach mit einbezogen werden muss.

64
00:05:36,000 --> 00:05:40,000
Also eine extravistische Logik irgendwie neu gedacht werden muss.

65
00:05:40,000 --> 00:05:42,000
Und das ist so ein Spannungsfeld.

66
00:05:42,000 --> 00:05:50,000
Auf der anderen Seite hat man natürlich auch die Frage von demokratischer Teilhabe einerseits, vor allen Dingen in Planungsprozessen.

67
00:05:50,000 --> 00:05:59,000
Und auf der anderen Seite auch die Frage einer Überwindung oder zumindest Minimierung der Entfremdung der Arbeit selbst.

68
00:05:59,000 --> 00:06:10,000
Und diese Effizienz-Fragen wirklich die Konsumgüter in dem Maße bereitzustellen, wie sie heute produziert werden,

69
00:06:10,000 --> 00:06:17,000
aber gleichzeitig auch Arbeitsverhältnisse zu verbessern, das ist auf jeden Fall ein Spannungsverhältnis, das überall da ist.

70
00:06:17,000 --> 00:06:25,000
Und die Frage ist natürlich, welche Stoßrichtung gibt es heute, um diese Ziele zu verwirklichen in der Debatte?

71
00:06:25,000 --> 00:06:31,000
Und da würde ich sagen, ist traditionell nach dem Zusammenbruch der Sowjetunion in den 90er Jahren

72
00:06:31,000 --> 00:06:37,000
der Marktsozialismus in der öffentlichen Diskussion übrig geblieben.

73
00:06:37,000 --> 00:06:46,000
Und heute die Leute, die mit dem Podcast vertraut sind, wissen sicherlich, dass die Planungsdebatte wieder angeheizt wird.

74
00:06:46,000 --> 00:06:55,000
Und in dieser Planungsdebatte, würde ich sagen, gibt es zwei Pole, wie letztendlich diese Ziele hergestellt werden oder Planung verwirklicht werden soll.

75
00:06:55,000 --> 00:07:05,000
Und das, würde ich sagen, ist auf der einen Seite ein partizipativer Pol oder eine Stoßrichtung, die auch ins Extrem geführt werden kann.

76
00:07:05,000 --> 00:07:17,000
Also es gibt im Englischen diese Redeweise, die, glaube ich, Oscar Wilde zugesprochen wird, dass der Sozialismus zu viele Abende braucht,

77
00:07:17,000 --> 00:07:22,000
weil also eine nie endende Meeting des Plenums andauernd läuft.

78
00:07:22,000 --> 00:07:30,000
Und auf der anderen Seite gibt es einen durch, vor allen Dingen populär geworden durch dieses Buch,

79
00:07:30,000 --> 00:07:39,000
The People Republic of Walmart von Lee Phillips und Michael Rosowski,

80
00:07:39,000 --> 00:07:49,000
in dem einfach die internen Planungsmechanismen von Unternehmen wie Amazon als Beweis dargestellt werden, dass sowas wie Planung funktioniert

81
00:07:49,000 --> 00:08:02,000
und da vor allen Dingen algorithmische Gubermentalität oder eine Entscheidungsfindung mit der Hilfe von Algorithmen vorgestellt wird.

82
00:08:02,000 --> 00:08:11,000
Und das findet sich dann vor allen Dingen auch bei Autoren wie Paul Cockshott und Ellen Cottrell oder Philipp Dabrich,

83
00:08:11,000 --> 00:08:18,000
die vor allen Dingen sich um die Optimierungsprozesse konzentrieren.

84
00:08:18,000 --> 00:08:28,000
Und diese Aushandlung von diesen beiden Polen, da würde ich meine eigene Forschung auch drin verorten, vor allen Dingen in der Vermittlung

85
00:08:28,000 --> 00:08:36,000
und zwischen diesen beiden Polen, weil ich denke, in beiden Extremen funktioniert es nicht.

86
00:08:36,000 --> 00:08:44,000
Also wir haben in der Idee des Plans, vielleicht jetzt kann ich noch weiter ausholen, wenn ich darf,

87
00:08:44,000 --> 00:08:48,000
eine Art Geburtsfehler, würde ich sagen.

88
00:08:48,000 --> 00:09:02,000
Der, wenn wir zurückgehen wirklich zur Stunde Null des modernen Sozialismus um 1800 drum und was Marx die Patriarchen des Sozialismus genannt hat,

89
00:09:02,000 --> 00:09:16,000
also die kanonisierten Väter, Gründungsväter des europäischen Sozialismus, Charles Fourier ist einer, Robert Owen und Henri de Saint-Simon ist der Letzte.

90
00:09:16,000 --> 00:09:21,000
Mit Saint-Simon wurden letztendlich zwei Ideen eingeführt.

91
00:09:21,000 --> 00:09:31,000
Der eine ist der Industrialismus, also eine Befürwortung der modernen Industrie, der moderne, der Wissenschaft, das was Engels und Marx sehr an ihm geschätzt haben.

92
00:09:31,000 --> 00:09:43,000
Und auf der anderen Seite ist die planhafte Verwirklichung der Wirtschaft entgegen eines blinden und anarchischen Markttreibens.

93
00:09:43,000 --> 00:09:52,000
Und gleichzeitig hat man einen positiven, könnte man meritokratischen Moment sagen, im Negativen eine absolute Technokratie.

94
00:09:52,000 --> 00:10:01,000
Das sozusagen Saint-Simon, der der Intelligenz der Gesellschaft die Planung anvertrauen wollte.

95
00:10:01,000 --> 00:10:13,000
Und da hat man sozusagen von Beginn an diesen Punkt, dass die fähigsten Leute dazu in die Position kommen sollen, um die Entscheidungen über die gesamte Gesellschaft zu führen.

96
00:10:13,000 --> 00:10:23,000
Und gleichzeitig muss man sagen, haben auch Bildungsprogramme und so weiter da eine Rolle gespielt, dass sozusagen der Talent Pool erweitert werden soll.

97
00:10:23,000 --> 00:10:30,000
Aber trotzdem wurde knallhart entschieden in seinem Sinne, wer am Ende die Geschicke der Gesellschaft lenkt.

98
00:10:30,000 --> 00:10:39,000
Und diesen Geist, würde ich sagen, mit dem hat die Planwirtschaft oder die Idee der Planwirtschaft immer zu kämpfen.

99
00:10:39,000 --> 00:10:51,000
Also den auszuspuken und wird besonders auf die Spitze getrieben, würde ich sagen, wenn Algorithmen ins Spiel kommen.

100
00:10:51,000 --> 00:11:07,000
Die zumindest verheißen quasi übermenschliche Fähigkeiten, seerische Fähigkeiten, aber auch Optimierungsprozesse und so weiter, die sozusagen Resultate ermöglichen,

101
00:11:07,000 --> 00:11:19,000
die eventuell im verbalen Aushandlung in der Form nicht möglich sind, so sozusagen die These, die da in den Raum gestellt wird.

102
00:11:19,000 --> 00:11:31,000
Und auf der anderen Seite natürlich ist die Frage, will man das? Will man in so einer Gesellschaft leben?

103
00:11:31,000 --> 00:11:44,000
Es hat auch ein unbehagliches Gefühl, der Maschinengeist, die Geschicke der Welt anzuvertrauen.

104
00:11:44,000 --> 00:11:58,000
Und mit diesen Fragen müssen wir uns trotzdem auseinandersetzen, ob wir überhaupt im Blick auf den planetaren Kollaps diese Produktivkräfte ausschlagen können in so einem Projekt.

105
00:11:58,000 --> 00:12:06,000
Und da, würde ich sagen, ist sozusagen meine eigene Forschung verortet in der Aushandlung von diesen Fragen.

106
00:12:06,000 --> 00:12:16,000
Und vor allen Dingen auch wirklich genau darauf zu schauen, was für Folgen vielleicht daraus entstehen können, für Risiken für die Gesellschaft.

107
00:12:16,000 --> 00:12:26,000
Also da habe ich jetzt ganz viele Fragen natürlich zu dieser wirklich spannenden und auffaltenden Antwort.

108
00:12:26,000 --> 00:12:38,000
Ich glaube, wir verschieben mal die Nachfragen in Bezug auf die verschiedenen Pole, die du jetzt gezeichnet hattest, etwas nach hinten und gehen einfach doch nochmal direkt jetzt zu dieser Frage des Vorausschauens,

109
00:12:38,000 --> 00:12:50,000
zu dieser Frage des Forecasting, das du eben im Grunde jetzt dann auch nutzbar machen willst als eine algorithmische Guvernmentalität und die du im Grunde dann auch vorschlägst,

110
00:12:50,000 --> 00:12:57,000
als eine Technologie, die in der Lage sein könnte, diesen Brückenschlag zwischen den beiden Polen zu vollziehen.

111
00:12:57,000 --> 00:13:00,000
Vielleicht kannst du da ein bisschen genauer darauf eingehen.

112
00:13:00,000 --> 00:13:02,000
Was ist es genau, was du vorschlägst?

113
00:13:02,000 --> 00:13:10,000
Und wie kann eben auch diese Gefahr, die du ja auch ein bisschen angedeutet hattest, dass diese Prädiktion in eine Präskription umschlägt?

114
00:13:10,000 --> 00:13:19,000
Wie kann das vielleicht auch adressiert werden in einer Form, die eben dann eine vielleicht auch alternative Art der Techniknutzung möglich macht?

115
00:13:19,000 --> 00:13:30,000
Ja, vielleicht vorweg noch als Kommentar. Ich weiß ja, dass die Zuhörer wahrscheinlich mit der Planungsdebatte etwas vertraut sind.

116
00:13:30,000 --> 00:13:41,000
Aber trotzdem glaube ich, ein bisschen Kontext hilft da schon, um nochmal auf den Planungsprozess selbst zu schauen.

117
00:13:41,000 --> 00:13:52,000
Und in der klassischen sozialistischen Kalkulationsdebatte ging es vor allen Dingen um Fragen von Optimierung.

118
00:13:52,000 --> 00:14:05,000
Das heißt, die Frage, welche Preise braucht es, um Markträumung zu erfolgen, um generelles Equilibrium zu realisieren.

119
00:14:05,000 --> 00:14:10,000
Also Schattenpreise wurde das auch genannt. Das ist dann eher so die marktsozialistische Variante.

120
00:14:10,000 --> 00:14:17,000
Und auf der anderen Seite gibt es die Optimierungsalgorithmen, lineare Programmierungen.

121
00:14:17,000 --> 00:14:29,000
Aber es gibt auch sehr viele andere Ansätze da. Und die Frage, das sind wirklich, was statische Effizienz genannt werden kann.

122
00:14:29,000 --> 00:14:41,000
Also diese Fragen haben keinen Blick auf Dynamik. Die Frage, wenn neue Produkte sozusagen jetzt in diesen Markt integriert werden,

123
00:14:41,000 --> 00:14:58,000
was muss anders, also muss alles wieder neu arrangiert werden. Und die Frage der Vorhersage oder des Forecastings im Englischen ist eben mehr mit diesen dynamischen Prozessen befasst.

124
00:14:58,000 --> 00:15:06,000
Und die gleichzeitig hat, das muss man auch unterscheiden, gibt es einen qualitativen Anteil und einen quantitativen Anteil.

125
00:15:06,000 --> 00:15:15,000
Und beim qualitativen Anteil ist die Frage, was wollen wir überhaupt auf der Ebene der Konsumgüter.

126
00:15:15,000 --> 00:15:19,000
Und ich denke, da muss man auch ganz viele Ebenen vielleicht unterscheiden.

127
00:15:20,000 --> 00:15:32,000
Also für den Privatkonsum, für den kollektiven Konsum, irgendwie Infrastruktur und so weiter oder Konsumgüter für Zuhause, Essen, Kleidung, Technik und so weiter.

128
00:15:32,000 --> 00:15:42,000
Und ich würde sagen, dass auf dieser qualitativen Seite, was wir wollen, Algorithmen uns sehr wenig helfen können.

129
00:15:43,000 --> 00:16:01,000
Und es wird aber auf der quantitativen Seite sie doch eine särische Fähigkeit vielleicht mitbringen, die in einer sozialistischen Wirtschaft, meiner Meinung nach, die wir nicht ausschlagen sollten.

130
00:16:01,000 --> 00:16:16,000
Und die Frage, wie diese Technologie eingehegt werden kann, da werde ich vielleicht ein bisschen später drüber reden, noch was zu sagen und erstmal noch mal zu diesen Algorithmen selbst kommen.

131
00:16:16,000 --> 00:16:22,000
Aber ein gutes Beispiel ist vielleicht der Stromverbrauch.

132
00:16:22,000 --> 00:16:39,000
Heutzutage im Kapitalismus selbst gibt es ja, die Stadtwerke oder auch für ganz Deutschland werden Prognosen hergestellt, um den Stromverbrauch zu antizipieren in der Zukunft.

133
00:16:39,000 --> 00:16:47,000
Und für morgen, für abends und je nachdem werden Kraftwerke hochgefahren, gebaut, abgerissen und so weiter.

134
00:16:47,000 --> 00:16:53,000
Atomausstieg, Kohleausstieg, diese ganzen Fragen sind aber dann qualitativ.

135
00:16:53,000 --> 00:17:04,000
Also das auf der einen Seite wird ein bestimmter Zahlenwert ermittelt, heutzutage sehr stark mit Algorithmen, da sind keine Menschen daran beteiligt.

136
00:17:04,000 --> 00:17:20,000
Und auf der anderen Seite stehen wir dann vor Fragen, wie wollen wir diese Quantitäten füllen und ob es mit Kohle, mit Nuklearenergie, mit Solar, Wind, Erneuerbaren und so weiter gemacht wird, ist eine Frage, da können uns Algorithmen nicht weiterhelfen.

137
00:17:20,000 --> 00:17:31,000
Das sind politische Prozesse, die meiner Überzeugung nach auch vom Grund auf in Bottom-Up-Prozessen irgendwie eruiert werden müssen.

138
00:17:31,000 --> 00:17:45,000
Und die quantitative Bestimmung zeigt sich aber dann nochmal besonders in der Ermittlung von Konsumbütern selbst.

139
00:17:45,000 --> 00:17:53,000
Also wirklich im Privaten die Frage, wie viel von X brauche ich nächstes Jahr?

140
00:17:53,000 --> 00:18:10,000
Und da ist mir persönlich in der Planungsliteratur, bin ich irritiert über so die Vorstellung gestoßen, die sehr verbreitet scheinbar ist in sozialistischen Kreisen,

141
00:18:10,000 --> 00:18:26,000
dass der Kommunismus oder der Sozialismus als Produktionsweise vor allen Dingen, da ist der Terminus eine Produktion ex ante, ist also gemeinschaftliche Produktion ex ante.

142
00:18:26,000 --> 00:18:41,000
Und ex ante ist lateinisch für vor dem Ereignis. Und das Ereignis ist, die Produktion und die gemeinschaftliche sinnhafte Produktion bewusst eben das produziert werden soll, was die Menschen wollen.

143
00:18:41,000 --> 00:18:57,000
Und ich würde sagen, da ist schon mal in erster Linie ein leichter Denkfehler drin, weil es ist die auch selbst, wenn man die Menschen fragt, was sie denn wollen, ist es eine Antizipation von zukünftigen Bedürfnissen.

144
00:18:57,000 --> 00:19:15,000
Also auch die Konsumenten selbst müssten Vorhersagen machen. Es ist nicht, weil die Bedürfnisse selbst meist ein immanentes Gefühl ist, dass das kurz vor dem Konsum irgendwie auftaucht, jetzt will ich das oder so.

145
00:19:15,000 --> 00:19:35,000
Und sonst bleibt uns eigentlich nur die Vorhersage. Und in dieser Beschreibung einer gemeinschaftlichen Produktion ex ante ist mir in der Literatur, der Planungsliteratur, aber auch der weiteren sozialistischen Literatur, bin ich einer Irritation begegnet,

146
00:19:35,000 --> 00:19:57,000
dass letztendlich der Grundthenus geboren aus so einem partizipativen Ideal der Selbstbestimmung der Konsumenten letztendlich, die Vorstellung gewachsen ist, dass die Menschen selbst sagen, was sie brauchen, was sie wollen in der Zukunft.

147
00:19:57,000 --> 00:20:15,000
Und auf der Grundlage sozusagen die komplette Wirtschaft ausgerichtet ist. Also das sozusagen, die im Vergleich zur profitorientierten kapitalistischen Wirtschaft eben eine Wirtschaft ins Leben gerufen wird, die auf Gebrauchswerte ausgerichtet ist.

148
00:20:15,000 --> 00:20:31,000
Also das Erfüllen von menschlichen Bedürfnissen. Und diese müssen ja irgendwie erfasst werden. Und in der Literatur, in der Planungsliteratur werden diese Bedürfnisse als gegeben verstanden.

149
00:20:31,000 --> 00:20:47,000
Und da wurden vor allem von der, auch bei dir im Podcast ja schon war, von Robin Hannell und Michael Albert in ihrem Paragon-Modell wurde die Idee das erste Mal, also da wurde das wirklich konkret von Wunschlisten eingeführt.

150
00:20:47,000 --> 00:21:11,000
Das heißt Konsumenten, die sind bei denen nochmal anders, also es sind nicht individuelle Wunschlisten, sondern sind, ich glaube ich jetzt nicht abvergessen, wie genau es organisiert ist, aber man hat auf der sowas wie keine Kernfamilie, sondern irgendwie kleine Kollektive, die dann ihre Wunschlisten zusammentragen, was sie denn brauchen.

151
00:21:12,000 --> 00:21:24,000
Und das wird dann nochmal auf höher Ebene abgesegnet, ob das denn auch im Rahmen ist. Und dann wird es weitergeleitet, um irgendwie das abzugleichen, was die Produktion denn hergeben kann.

152
00:21:24,000 --> 00:21:37,000
Und vor einigen Jahren, das ist dann besonders populär geworden durch das Essay Digital Socialism von Evgeny Morozov, der hat diesen Vorschlag ein bisschen aus der Versenkung geholt.

153
00:21:37,000 --> 00:22:06,000
Der Vorschlag von Daniel Iseras, der ja auch hier in dem Podcast schon prominente Position hatte, die Idee von auch so, ich glaube er nennt das Individual Need Profiles, die eben durch einen Katalog sich scrollen, in dem alle Gebrauchswerte aufgelistet werden und man dann für die nächste Produktionsperiode eine Orderliste anstellt.

154
00:22:07,000 --> 00:22:22,000
Und diesen Gedanken, den ich erstmal von sich aus begrüße, die Idee der Partizipation finde ich allerdings äußerst fragwürdig, ob das wirklich so machbar ist.

155
00:22:22,000 --> 00:22:41,000
Einerseits aufgrund der reinen Quantität von Konsumgütern, die es letztendlich gibt. Wir haben heute Amazon führt rund 500 Millionen Produkte und sicherlich werden in der zukünftigen Gesellschaft viele von diesen unnötigen Produkten rausfallen.

156
00:22:41,000 --> 00:22:51,000
Aber wir werden im hohen sechsstelligen bis siebenstelligen Bereich eine Liste haben, durch die sich die Konsumenten dann durchscrollen müssen.

157
00:22:51,000 --> 00:23:04,000
Und es ist für mich interessant, wie sozusagen dieses partizipative Ideal hier in der gemeinschaftlich geteilten Agonie sozusagen kollabiert, diese Listen auszufüllen.

158
00:23:04,000 --> 00:23:16,000
Ob Partizipation nicht wirklich anders gedacht werden kann und da bin ich sehr bei Leibman, der mir gesagt hat, Partizipation ist etwas, das optimiert werden muss und nicht maximiert werden.

159
00:23:16,000 --> 00:23:24,000
Und ich sage jetzt vielleicht nochmal ein bisschen detailreicher, warum das so problematisch ist.

160
00:23:24,000 --> 00:23:43,000
Also wir haben einerseits diese Liste, die rein Mengen und was sozusagen die Autoren vorschlagen, um Komplexitätsreduktion zu betreiben, ist, dass man sozusagen die Liste aus dem letzten Jahr oder der letzten Produktionsperiode,

161
00:23:43,000 --> 00:23:51,000
bei Cyrus ist es auch überhaupt nicht klar, von welchen Zeitintervallen wir da reden. Das hat er in seinem Buch meines Wissens nicht abgesteckt.

162
00:23:51,000 --> 00:24:00,000
Und die Frage ist sozusagen, deren Lösung die Komplexität zu reduzieren, dass man sagt, man fängt mit der Liste vom letzten Jahr an.

163
00:24:00,000 --> 00:24:18,000
Und in gewissen Bereichen könnte das sozusagen funktionieren, aber wenn man sich wirklich vorstellt, dass sehr, sehr viele Konsumprodukte einfach nicht jährlich gekauft werden, man denkt an Waschmaschinen und so weiter.

164
00:24:18,000 --> 00:24:39,000
Und diese Vorstellung, dass man einfach das vom letzten Jahr an benutzt und als Grundlage steht und da so ein bisschen dran dreht, halte ich, also es ist in der Wettervorhersage wäre das ungefähr zu sagen, das Wetter morgen wird so wie heute, aber ein bisschen anders.

165
00:24:39,000 --> 00:24:50,000
Ja, und also das ist im Forecasting nennt sich das ein naiver Forecast. Das ist wirklich die einfachste oder einfachste Form der Vorhersage.

166
00:24:50,000 --> 00:24:59,000
Und ich würde behaupten, dass wir heute andere Mittel haben, um das vorherzusagen und vielleicht noch da nachgeschoben.

167
00:24:59,000 --> 00:25:10,000
Also ich würde jedem einfach, wenn sie einen Amazon-Account oder so haben, einfach mal reinzuschauen und schauen, hätte ich dieses Produkt vor einem Jahr bestellt.

168
00:25:10,000 --> 00:25:22,000
Und ich glaube also bei mir persönlich, ich hätte das nicht gemacht. Also das ist sozusagen die Frage, habe ich die Kapazitäten dazu überhaupt?

169
00:25:22,000 --> 00:25:47,000
Ja, und ich würde sagen, dass diese Autoren als Grundlage so einen sozialistischen Homo economicus nehmen, der, wenn er von den Fesseln des Kapitalismus befreit ist, in der Lage ist, endlich das auszudrücken und zu fordern, was irgendwie die eigentlichen Bedürfnisse sind.

170
00:25:47,000 --> 00:26:01,000
Aber ich würde behaupten, die Menschen sind sich überhaupt nicht bewusst über ihre zukünftigen Bedürfnisse. Und viele Menschen haben sicherlich mich eingeschlossen, vielleicht habe ich da einen kleinen Bias, haben gar kein Interesse, diese Listen auszufüllen.

171
00:26:01,000 --> 00:26:14,000
Sondern ich würde von einer funktionierenden Produktionsweise erwarten, dass die Produkte in einem Maß vorrätig sind, der dem Bedürfnis der Menschen wirklich entspricht.

172
00:26:14,000 --> 00:26:24,000
Und die Frage, wie Partizipation dann reinkommt, ist letztendlich über den Konsum selbst.

173
00:26:24,000 --> 00:26:39,000
Das ist eine letztendlich würden diese Konsummärkte oder Märkte für Konsumbieter, egal ob es monetär oder so Logiken weiter gibt, könnten ja erfasst werden.

174
00:26:39,000 --> 00:26:50,000
Und man könnte den eigenen Konsum auch als Abstimmung oder als Votum für ein bestimmtes Produkt verstehen.

175
00:26:50,000 --> 00:27:14,000
Das ist natürlich wie der Ex-Post passiert. Aber ich finde, diese Unterscheidung von Ex-Ante und Ex-Post ist nicht sonderlich hilfreich, weil auch in einer Planwirtschaft, die über solche Listen funktionieren würde, hätte man den gleichen Prozess, dass man mit Vorhersagen anfängt.

176
00:27:14,000 --> 00:27:28,000
Man würde die Waren produzieren und dann später schauen in der Konsumtion, ob diese Vorhersagen validiert werden, ob sie richtig waren oder falsch werden, und auf der Grundlage natürlich Änderungen vornehmen.

177
00:27:28,000 --> 00:27:48,000
Und ich glaube, dieser Feedbackprozess, den man ja ganz kubernetesch ganz gut als Feedbackprozess bezeichnen kann, der natürlich nie so linear ist, sondern auch während der Produktion sicherlich Angleichungen vorgenommen werden müssen, weil sich irgendwas ändert und parallel konsumiert und produziert wird und vorhergesagt wird,

178
00:27:48,000 --> 00:28:15,000
also es ist wesentlich dynamischer und iterativer als so ein klare, lineare, aufeinanderfolgender Prozess. Und da auch letztendlich Mitbestimmungsrecht in dem Sinne gibt, weil du als Konsument mit dem Kauf oder der Auswahl eines Produktes letztendlich dich dafür entscheidest.

179
00:28:15,000 --> 00:28:43,000
Natürlich muss man sagen, ist es in gewisser Weise begrenzt durch die Auswahl, die es gibt. Deswegen ist dieser Voting-Mechanismus im Kapitalismus auch dysfunktional, würde ich sagen, weil man eine Produktpalette hat, die auf Profitoptimierung ausgerichtet ist und nicht auf Gebrauchswerte,

180
00:28:43,000 --> 00:28:51,000
also die geplante Obsoleszenz und solche Sachen, dass das eingeschrieben ist in Produkte und man oft auch gar keine andere Wahlmöglichkeit hat.

181
00:28:51,000 --> 00:29:20,000
Und die in sozialistischen Konsummärkten sozusagen auch durch sowas wie Einkommensgleichheit eine gewisse Gerechtigkeit hergestellt wird, die in kapitalistischen Märkten nicht gibt, wo eben durch die Lohndifferenzen und Einkommensdifferenzen eben manche Menschen wesentlich mehr zu sagen haben,

182
00:29:20,000 --> 00:29:25,000
wie die, welche Produkte hergestellt werden sollen.

183
00:29:25,000 --> 00:29:52,000
Gut, da gibt es jetzt auch dieses Mal extrem viel zu sagen zu. Vielleicht hake ich einfach mal als erstes bei dem letzten Punkt ein, den du jetzt gebracht hast, weil im Grunde fragt man sich doch dann, ob nicht das eine wie das andere im Grunde dann in die Falle tappt, dass es eben die Individuen auf ihre Rolle als Konsumentinnen und Konsumenten reduziert, weil das würden sie ja dann im einen wie im anderen tun.

184
00:29:52,000 --> 00:30:16,000
Also du hattest jetzt zuletzt gesagt, wenn wir sozusagen nicht voting by our feet, aber voting by our consumption power sozusagen, wenn das quasi dann der Mechanismus ist, auf den es am Ende hinausläuft, dann ist das doch im Grunde eine ähnliche Spiegelung des sozialistischen Homo economicus, den du finde ich richtigerweise kritisierst bei den anderen Modellen.

185
00:30:16,000 --> 00:30:25,000
Eine ähnliche Spiegelung oder eine Spiegelung, die das Individuum dann ähnlich konzeptionalisiert als eben diese laufende Wishlist, wenn man so will.

186
00:30:25,000 --> 00:30:47,000
Und das wäre ja was, was ich bei Seros zum Beispiel auch als Kritikpunkt total nachvollziehen würde, dass im Grunde dort eben die Konzeption ist, dass wir alle als individualistische Order-Lists adressiert werden und dadurch sich akkumulativ sozusagen dann im Grunde die Wirtschaft zusammensetzen würde.

187
00:30:47,000 --> 00:31:14,000
Und dass das entscheidende Element, was daran aber fehlt, nicht unbedingt die Frage ist, inwiefern andere Mechanismen das noch perfekter machen könnten, weil das wäre ja die Logik zu sagen, wir gehen jetzt zusammen zu einem algorithmischen Forecasting, sondern das entscheidende Element, was daran fehlt, wäre ja im Grunde Formen der ja auch Politisierung dieser Formation von Wünschen.

188
00:31:14,000 --> 00:31:25,000
Weil das wäre sozusagen, finde ich, dann eigentlich quasi der dritte Weg, in Anführungsstrichen, dass eigentlich die Formierung der Wünsche an sich schon prozessual gedacht wird und auch kollektiv gedacht wird.

189
00:31:25,000 --> 00:31:38,000
Und das ist natürlich dann die Frage, worauf bezieht sich das? Also auf jetzt individuelle Letztkonsumensachen oder sowas, kaufe ich jetzt ein Wasser oder so, das müssen wir beide nicht miteinander abstimmen, so kann ich aber kaufen.

190
00:31:38,000 --> 00:31:55,000
Aber ich glaube, da stellt sich halt dann wieder die Frage, okay, in Bezug auf welche Elemente sind welche Zugänge eigentlich zielführend und wo ist welche Methodik vielleicht auch defizitär und wie könnte sie angereichert werden?

191
00:31:55,000 --> 00:32:09,000
Und das bringt mich eigentlich zu einer Grundeinschätzung in Bezug auf dein Paper und deine Position und auf welche Punkte du da, finde ich, richtigerweise hinweist, weil ich nämlich am Ende eigentlich immer das Gefühl hatte,

192
00:32:09,000 --> 00:32:23,000
Du empfindest die Widersprüche viel stärker als ich bei Paracon zum Beispiel. Ja, das ist ja durchaus, das wäre eigentlich das Paradebeispiel, an dem ein sowohl als auch im Grunde sich darstellt.

193
00:32:23,000 --> 00:32:33,000
Weil bei Paracon ist ja diese parametrische Herangehensweise gibt, die sich in der Rat, in der Ratio zwischen Social Cost und Social Benefit darstellt.

194
00:32:33,000 --> 00:32:42,000
Das ist ja sozusagen so ein Parameter, quasi der, wenn man so will, in Anführungsstrichen Effizienz innerhalb des Worker Councils, anhand dessen er gemessen wird.

195
00:32:42,000 --> 00:32:52,000
Und das wäre durchaus zum einen automatisierbar oder in algorithmische Formen der Gewöhnementalität einspeisbar und so weiter.

196
00:32:52,000 --> 00:33:01,000
Also da hätte ich eigentlich eher das Gefühl, es gibt ganz viel Raum für Synthetisierung zwischen den verschiedenen Positionen, was du ja im Grunde auch anstrebst.

197
00:33:01,000 --> 00:33:17,000
Und die Zugänge, die du kritisierst, also zum Beispiel ein Beispiel von Seros jetzt mit dem General Catalog, die finde ich, sind eigentlich aufgelegt dafür, im Grunde durch die Dinge angereichert zu werden, die du ins Spiel bringst.

198
00:33:17,000 --> 00:33:33,000
Beziehungsweise ist es eben bei mir schon so gewesen, dass ich von vornherein sowieso davon ausgegangen wäre, dass in etwas wie dem General Catalog natürlich dann auch Technologien des Forecastings eingesetzt werden, um Vorschläge zu machen.

199
00:33:33,000 --> 00:33:48,000
Und wie weit man dann welche Zugänge für einen bestimmten Bereich wählt und welche Zugänge für einen anderen, das ist dann sozusagen die Frage der Nuansierung oder der Kombination der verschiedenen Logiken.

200
00:33:48,000 --> 00:34:06,000
Aber zumindest für mich hat es sich eigentlich nie so dargestellt, als gäbe es wirklich oder zumindest bei den interessanteren Zugängen nicht entweder sowieso schon diese Kombination, wie zum Beispiel bei David Leibmans Modell, der das ja auch dezidiert immer so sagt, dass es das zu fusionieren gelte.

201
00:34:06,000 --> 00:34:21,000
Oder als eine Form von, weiß ich nicht, theoretischer Affordanz. Das heißt, das ist irgendwie ein Punkt, wo logischerweise eigentlich dann diese Technologien, die du ja auch nutzbar machen willst, dann im Grunde eingeführt werden sollten.

202
00:34:21,000 --> 00:34:26,000
Das ist jetzt nicht wirklich eine Frage, das ist eher so ein Gefühl quasi zu dem Ganzen.

203
00:34:26,000 --> 00:34:37,000
Vielleicht zwei Kommentare dazu. Ich denke, es braucht weiterhin, also ich würde auch sagen, in vielen Bereichen sind die Widersprüche gar nicht so groß.

204
00:34:37,000 --> 00:34:42,000
Und ich denke, wie ich dich jetzt richtig verstanden habe, zwei Punkte vielleicht.

205
00:34:42,000 --> 00:35:01,000
Das eine ist die kollektive Arbeit an Wünschen zu hinterfragen. Also heutzutage, dass viele Bedürfnisse vielleicht sich auch ändern, durch das es keine Werbung mehr gibt, gar kein Anreiz zur Produktion, sich sehr viel verschieben wird.

206
00:35:01,000 --> 00:35:11,000
Und auf der anderen Seite, was ich eben in deinem Kommentar so ein bisschen rausgehört habe, auch die Frage einer Involvierung des Konsumenten in Produktionsprozesse.

207
00:35:11,000 --> 00:35:19,000
Dass da irgendwie auch sowas wie qualitative Kanäle vielleicht gibt, um Produktion und Konsumption ein bisschen weiter zu verschränken.

208
00:35:19,000 --> 00:35:33,000
Aber gleichzeitig sind wir auch in einer, also denke ich, werden wir auch weiterhin in einer arbeitsteiligen Gesellschaft leben werden, auch nach einer Überwindung des Kapitalismus.

209
00:35:33,000 --> 00:35:39,000
Aber gleichzeitig ist die Involvierung in gewisser Weise begrenzt.

210
00:35:39,000 --> 00:35:48,000
Also wir können nicht überall die Konsumenten sozusagen involvieren, also nicht alle, vielleicht Repräsentanten.

211
00:35:48,000 --> 00:35:57,000
Das gibt es ja gerade bei Pat Levin und so weiter, ist das sehr präsent, dass dann in den Produktionseinheiten Repräsentanten von Konsumenten sind.

212
00:35:57,000 --> 00:36:04,000
Das hat man ja heutzutage auch im Kapitalismus sogar, dass es dann so Patientenverbände und so weiter gibt.

213
00:36:04,000 --> 00:36:12,000
Also da ist überhaupt kein Streitpunkt drüber.

214
00:36:12,000 --> 00:36:18,000
Und es sollte sicherlich auch sowas wie qualitative Feedback-Kanäle geben.

215
00:36:18,000 --> 00:36:29,000
Es ist auch wieder vielleicht ein blödes Beispiel, das im Kapitalismus schwer missbraucht wird, weil es auch wieder einen monetären Anreiz gibt.

216
00:36:29,000 --> 00:36:37,000
Das Produkt-Rating auf Seiten wie Amazon mit fünf Sternen und dann kann man noch einen Kommentar und so weiter machen,

217
00:36:37,000 --> 00:36:46,000
das sozusagen auch qualitative Informationen generieren würde über die Beschaffenheit von irgendwelchen Produkten, ob es gut ankommt und so weiter.

218
00:36:46,000 --> 00:36:54,000
Und im Kapitalismus ist natürlich absolut dysfunktional, weil man diese Likes und so weiter einfach kaufen kann.

219
00:36:55,000 --> 00:37:01,000
Da müsste dann irgendwas überlegt werden, ob man das in irgendeiner Weise, also IP gebunden kann man es nicht machen,

220
00:37:01,000 --> 00:37:14,000
dass man irgendwie halbwegs anonymisiert, irgendwelche Profile hat und das dann pseudo-anonym oder sonst wie, um sowas herzustellen.

221
00:37:14,000 --> 00:37:22,000
Aber ich will trotzdem darauf festhalten, dass, also nochmal den Punkt vielleicht starkmachend ist,

222
00:37:22,000 --> 00:37:31,000
mir vor allen Dingen um die quantitative Bestimmung von der Frage, wie viel iPhones oder sonst welche Güter braucht man.

223
00:37:31,000 --> 00:37:41,000
Und da eben in den letzten Jahren besonders die Fähigkeiten zugenommen haben,

224
00:37:41,000 --> 00:37:48,000
dass über bestimmte statistische Methoden oder Machine Learning solche Vorhersagen zu verfeinern.

225
00:37:48,000 --> 00:37:56,000
Und da muss man trotzdem auch festhalten, heutzutage im Supply Chain Management und so weiter gibt es immer noch,

226
00:37:56,000 --> 00:38:08,000
es nennt sich Subjective Overrides, dass selbst wenn irgendwelche Modelle Vorhersagen über den Konsumbedarf herstellen,

227
00:38:08,000 --> 00:38:17,000
dass die trotzdem weiterhin verhandelt werden mit Wissen, Domainwissen, das vielleicht wichtige Informationen hat,

228
00:38:17,000 --> 00:38:23,000
wie beispielsweise ein Corona Lockdown oder so, der nicht im Modell wirklich vorhanden ist.

229
00:38:23,000 --> 00:38:29,000
Und extern sozusagen, es nennt sich dann sogenannten Broken-Leg-Scenarios,

230
00:38:29,000 --> 00:38:37,000
wo es geht auf ein Gedankenexperiment zurück, dass irgendwie das Broken-Leg-Scenario ist ein Professor,

231
00:38:37,000 --> 00:38:47,000
der mit einer 90% Wahrscheinlichkeit, also in der Bayesian Wahrscheinlichkeitstheorie verankert,

232
00:38:47,000 --> 00:38:53,000
mit einer 90% Wahrscheinlichkeit ins Kino geht, aber sich das Bein bricht und die Frage ist,

233
00:38:53,000 --> 00:38:58,000
wird er am Donnerstag wieder ins Kino gehen? Und da ist die Wahrscheinlichkeit sicherlich nicht 90%,

234
00:38:58,000 --> 00:39:02,000
auch wenn er die letzten zehn Jahre immer ordentlich ins Kino gegangen ist.

235
00:39:02,000 --> 00:39:14,000
Und diese Informationen sind oft außerhalb von solchen statistischen Modellen und müssen dann von eben den Planern irgendwie integriert werden.

236
00:39:14,000 --> 00:39:18,000
Und dann ist auch die Frage, auf welcher Ebene laufen diese Vorhersagen ab?

237
00:39:18,000 --> 00:39:27,000
Und da ist die Unterscheidung des heutzutageigen Kapitalismus, werden die Vorhersagen einzig und allein auf der Ebene des Unternehmens geführt.

238
00:39:27,000 --> 00:39:34,000
Da hat man die Teilung zwischen dem Management, die die Pläne machten, den Arbeitern, die sie ausführen,

239
00:39:34,000 --> 00:39:40,000
und die Konsumenten kommen da eigentlich relativ wenig vor.

240
00:39:41,000 --> 00:39:49,000
Man hat natürlich auch wieder die Daten von früher, man hat vielleicht Vorbestellungen in vielen Betrieben,

241
00:39:49,000 --> 00:39:57,000
gerade wenn es also nicht um Konsumgüter geht, sondern intermediäre Güter, da läuft ja sehr viel auch mit Vorbestellungen,

242
00:39:57,000 --> 00:40:08,000
sowas wird es auch weiterhin geben, denke ich, dass darüber auch Informationen generiert werden, die in statistische Modelle integriert werden.

243
00:40:08,000 --> 00:40:15,000
Das nennt sich dann Konsens-Forecasting, dass man mehrere Arten vielleicht hat und die zusammen aggregiert,

244
00:40:15,000 --> 00:40:22,000
mehrere Arten Vorhersagen zu machen, qualitative, quantitative Daten irgendwie heranzieht,

245
00:40:22,000 --> 00:40:28,000
subjektive Methoden eben mit solchen objektiven Methoden zusammenbringt.

246
00:40:28,000 --> 00:40:36,000
Und da versuchen sollte, die bestmögliche Zukunft auch zu errechnen.

247
00:40:36,000 --> 00:40:45,000
Und die Frage ist natürlich da, also das Gute ist, man kann die Methoden vergleichen,

248
00:40:45,000 --> 00:40:53,000
aber das Gemeine an der Sache ist auch, dass jedes Modell, egal wie gut es ist, irgendwann auch zusammenbricht.

249
00:40:53,000 --> 00:41:01,000
Und man kann ein Modell, das über Jahre sehr gute Ergebnisse gebracht hat, kann im nächsten Modell auseinanderbrechen.

250
00:41:01,000 --> 00:41:12,000
Mit dieser Ungewissheit müssen wir leben. Und gleichzeitig kann man heutzutage sehr gut, es läuft auch,

251
00:41:12,000 --> 00:41:23,000
also durch solche Wettbewerbsseiten wie Kaggle, wo Data Scientists einfach bestimmte Datensätze beispielsweise zur Verfügung gestellt bekommen

252
00:41:23,000 --> 00:41:31,000
und auf deren Grundlage Vorhersagen machen und da natürlich vor allen Dingen statistische Methoden, Machine Learning usw. verwenden,

253
00:41:31,000 --> 00:41:42,000
um diesen Wettbewerb zu gewinnen. Und sowas könnte ich mir auch sehr gut vorstellen in zukünftigen sozialistischen Gesellschaft,

254
00:41:42,000 --> 00:41:51,000
dass da wieder so ein Wettbewerb der Methoden, die Datensätze können ja frei zugänglich gemacht werden.

255
00:41:51,000 --> 00:42:02,000
Und der große Vorteil einer gemeinschaftlichen Produktion vor allen Dingen ist, dass die ganzen Informationssilos, die es heutzutage gibt,

256
00:42:02,000 --> 00:42:12,000
zwischen verschiedenen im Wettbewerb stehenden Unternehmen wirklich offengelegt, der Gemeinschaft zur Verfügung gestellt werden können

257
00:42:12,000 --> 00:42:21,000
und nutzbar gemacht werden können. Und das ist sowas, was Marx die Anarchie der Produktion genannt hat, dass eigentlich niemand weiß,

258
00:42:21,000 --> 00:42:29,000
was der andere macht und was wirklich gebraucht wird und wer wieviel von was produziert und das natürlich aufgehoben wird.

259
00:42:29,000 --> 00:42:37,000
Und dieser Datenpool, der dadurch entsteht, der schreit gerade so nach Interpretation.

260
00:42:37,000 --> 00:42:49,000
Und die Frage ist, welche Modelle ist es sozusagen der einzelne menschliche Konsumentenkopf, der diese Daten interpretiert?

261
00:42:49,000 --> 00:42:59,000
Oder ist es die Alchemie der künstlichen Intelligenz, die das für uns macht? Und das hat natürlich wieder auch was Unbehagliches,

262
00:42:59,000 --> 00:43:11,000
weil vor allen Dingen die Deep Learning Modelle eine Funktionsweise haben, die nicht einsichtbar ist.

263
00:43:11,000 --> 00:43:21,000
Also das wird als Black Box Algorithmus beschrieben. Du kannst nicht sagen, wieso dieser Algorithmus einen bestimmten Output produziert hat.

264
00:43:21,000 --> 00:43:30,000
Das ist natürlich, da sind wir wieder im Unbehagen, dass wir die Frage, wir haben diese wirkmächtigen Algorithmen,

265
00:43:30,000 --> 00:43:42,000
aber können wir solche doch vielleicht wichtigen Entscheidungen denen wirklich anvertrauen? Und ich denke, automatisieren wird man das auf keinen Fall.

266
00:43:42,000 --> 00:43:59,000
Das müsste immer ein Mensch als Monitor irgendwie im Hintergrund sein, der das einhegt oder bestimmte vielleicht Institutionen, die dann ins Leben gerufen werden müssen.

267
00:43:59,000 --> 00:44:08,000
Irgendwelche Forecasting Boards, die sich zusammensetzen, auch wieder aus Arbeiterinnen, aus irgendwelchen Produktionseinheiten,

268
00:44:08,000 --> 00:44:21,000
vielleicht sektoral organisiert oder auch bestimmte Konsumenten oder Repräsentanten aus Regierungen, wenn es sowas gibt, sowas wie Parteien oder so.

269
00:44:21,000 --> 00:44:33,000
Also das muss auf jeden Fall weitergedacht werden. Aber die Wirkmacht, die zeigt sich vor allen Dingen heute bei Unternehmen wie Amazon.

270
00:44:33,000 --> 00:44:38,000
Und da sind wir wieder bei der Rückfindung zu diesem Buch, People Republic of Walmart.

271
00:44:38,000 --> 00:44:45,000
Später haben die Autoren gesagt, sie hätten es People Republic of Amazon nennen sollen, weil sie angefangen haben, das Buch zu schreiben.

272
00:44:45,000 --> 00:44:54,000
War Amazon eben noch nicht das Unternehmen, das es heute ist, das vor allen Dingen, wenn man die Geschichte anschaut,

273
00:44:54,000 --> 00:45:03,000
der als Online-Buchhandel angefangen hat, dann irgendwie zu diesem Everything Store geworden ist, der alles verkauft und irgendwann das auch nicht genug war.

274
00:45:03,000 --> 00:45:19,000
Und Jeff Bezos in seiner napoleonischen Ambition gesagt hat, okay, die gesamte Wirtschaft soll auf meiner Plattform laufen und mit sozusagen irgendwann die internen Planungsprozesse

275
00:45:19,000 --> 00:45:29,000
und die Infrastruktur zum Produkt gemacht hat mit Amazon Web Service, das heute mit Abstand der profitabelste Teil dieses Unternehmens ist

276
00:45:29,000 --> 00:45:42,000
und gleichzeitig auch einen Forecasting-Algorithmus auch für das Unternehmen selbst aus der eigenen Forschung entwickelt hat,

277
00:45:42,000 --> 00:45:50,000
der wirklich ein einziges Modell für diese ganzen 500 Millionen Zeitreihen hat.

278
00:45:50,000 --> 00:46:02,000
Also die 500 Millionen Produkte, die eben Verkäufe pro Zeiteinheit abgebildet werden und da für diese ganzen Produkte Vorhersagen macht.

279
00:46:02,000 --> 00:46:17,000
Und der große Vorteil, die diese Deep Learning-Algorithmen haben, ist eben, dass einerseits diese interrelationalen Beziehungen zwischen Produkten sehr gut abgebildet werden können,

280
00:46:17,000 --> 00:46:26,000
dass früher das statistische Vorhersagen immer ein Modell pro Zeitreihe war.

281
00:46:26,000 --> 00:46:35,000
Also du hast ein Modell gehabt, das bestimmte Daten interpretiert hat, die aber unabhängig alle zueinander war, wenn man mehrere Produkte hat.

282
00:46:35,000 --> 00:46:41,000
Und jetzt hat man diese Interdependenzen, die sehr gut in diesen Modellen abgebildet werden können.

283
00:46:41,000 --> 00:46:46,000
Und auf der anderen Seite kannst du noch viel mehr Daten in dein Modell integrieren.

284
00:46:46,000 --> 00:46:57,000
Du kannst Metadaten, wenn du Promotionen machst und so weiter, die früher sehr schwer modellierbar waren, kannst du mit in deine Vorhersagen einarbeiten.

285
00:46:57,000 --> 00:47:04,000
Es kann auch, wenn man das noch weiterdenkt, hungern diese Modelle nach immer mehr Information.

286
00:47:04,000 --> 00:47:09,000
Und dann ist man natürlich auch in der Position zu fragen, wie viel will man bereitstellen?

287
00:47:09,000 --> 00:47:17,000
Wie viel sind wir als Gesellschaft bereit, unsere Google anfragen oder die Suchmaschine der Zukunft?

288
00:47:17,000 --> 00:47:24,000
Wollen wir das? Ist das wirklich anonymisierbar? Sollten wir die Daten nutzbar machen?

289
00:47:24,000 --> 00:47:31,000
Und ja, solche Fragen stehen natürlich im Raum, aber sollten diskutiert werden.

290
00:47:31,000 --> 00:47:38,000
Ja, unbedingt. Und ich finde auch, dass es eben sozusagen dann ein Punkt, bei dem es einfach anzusetzen gilt,

291
00:47:38,000 --> 00:47:47,000
weil es natürlich schon so ist, dass du vorschlägst, dass wir uns da einer bestimmten Logik bedienen,

292
00:47:47,000 --> 00:47:56,000
die Antoinette Revoy mal als Algorithmic Governmentality bezeichnet hat und die sich unter anderem auch dadurch auszeichnet,

293
00:47:56,000 --> 00:48:06,000
dass im Grunde Zukunft nicht eben nur projiziert, also vorhergesagt werden, basierend auf vergangenen Events,

294
00:48:06,000 --> 00:48:12,000
sondern dass dadurch, dass diese Vorhersagen dann auch als, im Grunde, wenn man will,

295
00:48:12,000 --> 00:48:17,000
nicht nur epistemische, sondern auch politische Player eigentlich in die Agenda treten,

296
00:48:17,000 --> 00:48:22,000
dass man dadurch dann eben eigentlich im Grunde auch Zukunft mit produziert.

297
00:48:22,000 --> 00:48:25,000
Und dass das sozusagen nicht voneinander getrennt gedacht werden kann.

298
00:48:25,000 --> 00:48:34,000
Und dass in der Art und Weise, wie du das jetzt zeichnest, eben durchaus halt immer mal wieder, finde ich,

299
00:48:34,000 --> 00:48:40,000
so ein bisschen dieser Beigeschmack halt mitkommt. Zum einen natürlich, wohin führt das, wenn man es extrapoliert?

300
00:48:40,000 --> 00:48:47,000
Das war jetzt der letzte Punkt, den du angesprochen hast. Aber auch, inwiefern tappt man sozusagen in die Falle,

301
00:48:47,000 --> 00:48:53,000
dass da eigentlich eine Maximierung der Befriedigung von Consumer-Wünschen sozusagen verabsolutiert wird

302
00:48:53,000 --> 00:49:04,000
und im Grunde eigentlich man Gefahr läuft, in die Falle zu tappen, im Grunde den Kapitalismus in seinem eigenen Spiel out zu performen.

303
00:49:04,000 --> 00:49:16,000
Und dass das aber ja eigentlich einer grundlegenderen Logik des Kommunismus, wenn man jetzt einfach mal das setzt,

304
00:49:16,000 --> 00:49:27,000
bis zu einem gewissen Grad zuwidergeht, als dass da dann sozusagen im Grunde nicht zu genüge, sage ich mal,

305
00:49:27,000 --> 00:49:36,000
diese Bedürfnisse eigentlich kontextualisiert werden als weit über reine Konsumwünsche hinausgehend.

306
00:49:36,000 --> 00:49:44,000
Und inwiefern dann durch eine Adressierung via Algorithmic Governmentality eigentlich mal wieder in diese Isolation,

307
00:49:44,000 --> 00:49:50,000
nämlich Isolation des Individuums gegriffen als Konsumentin hineintappt.

308
00:49:50,000 --> 00:50:01,000
Also auf der einen Seite diese Gefahr, dass es sozusagen eine Fahrtabhängigkeit generiert in Richtung Abhängigkeit von Technologien,

309
00:50:01,000 --> 00:50:07,000
die eigentlich dann perspektivisch weit über das hinausgehen, wofür du jetzt vielleicht intendierst sie einzusetzen.

310
00:50:07,000 --> 00:50:15,000
Und auf der anderen Seite eben eine sehr spezifische Form der Adressierung und dadurch auch Produktion des Individuums als Konsumentin.

311
00:50:15,000 --> 00:50:23,000
Diese beiden Felder sind so ein bisschen was, was glaube ich einfach immer aufkommt, wenn vorgeschlagen wird,

312
00:50:23,000 --> 00:50:26,000
diese Technologien in einer Art und Weise zu nutzen, wie du es jetzt auch vorschlägst.

313
00:50:26,000 --> 00:50:31,000
Was wiederum auf meiner Seite jetzt gar nicht heißen soll, dass ich irgendwie dagegen wäre, das zu tun.

314
00:50:31,000 --> 00:50:34,000
Aber ich glaube, es muss adressiert werden.

315
00:50:34,000 --> 00:50:39,000
Ich finde, du hast ja auch schon so ein, zwei Sachen angedeutet, wie man damit umgehen kann.

316
00:50:39,000 --> 00:50:43,000
Aber vielleicht greifen wir das doch nochmal als ein eigenes Themenfeld,

317
00:50:43,000 --> 00:50:48,000
zusammengenommen vielleicht auch mit der Privacy-Frage, weil die da definitiv auch reinspielt.

318
00:50:48,000 --> 00:50:53,000
Wie ich es verstehe, zumindest zwei Fragen.

319
00:50:53,000 --> 00:50:58,000
Ich fange vielleicht erst mal mit der Frage, die so ein bisschen als Unterton ausgehört,

320
00:50:58,000 --> 00:51:02,000
oder die Frage nach so einem Konsumismus, also so ein blinder Konsumismus,

321
00:51:02,000 --> 00:51:12,000
einen Hedonismus, den wir die Sinnlehre der heutigen Existenz einfach mit materiellen Gütern zu füllen.

322
00:51:12,000 --> 00:51:22,000
So ein Verdacht, dass das sich wiederholen könnte, habe ich jetzt in deiner Frage ein bisschen rausgehört.

323
00:51:22,000 --> 00:51:31,000
Und da auch, du wirst dann bestimmt gleich wieder schmunzeln, vielleicht zwei Extreme aufzumachen.

324
00:51:31,000 --> 00:51:38,000
Auf der einen Seite haben wir das, den Status Quo, und auf der anderen Seite irgendwie einen radikalen Asketismus,

325
00:51:38,000 --> 00:51:46,000
das bescheidene Leben, Low-Tech, wenig Konsum, wenig Transport, wenig Reisen und so weiter vielleicht aufzumachen.

326
00:51:47,000 --> 00:51:56,000
Und es ist vorhersehbar, aber ich strebe da vielleicht die Mitte von beiden vielleicht an,

327
00:51:56,000 --> 00:52:06,000
dass ich sage, ich verstehe nicht ganz, warum, ich kann den Weg, würde ich sagen, nicht ganz mitgehen,

328
00:52:06,000 --> 00:52:14,000
den Konsum in der Weise zu problematisieren. Ich denke, es gibt ein Bedürfnis, ein gutes,

329
00:52:14,000 --> 00:52:19,000
ich habe jetzt hier meinen Computer vor mir, ein gutes Betriebssystem vor mir zu haben,

330
00:52:19,000 --> 00:52:25,000
das mit der Software und Hardware wunderbar abgestimmt ist, das meine Arbeitsfähigkeit erleichtert.

331
00:52:25,000 --> 00:52:32,000
Ich finde, das ist ein Gebrauchswert, der ein bestimmtes Bedürfnis für mich erfüllt,

332
00:52:32,000 --> 00:52:38,000
das ich auch im Kommunismus so haben will. Die Frage ist, brauche ich jedes Jahr einen neuen?

333
00:52:38,000 --> 00:52:44,000
Ja, da ist für mich die Frage, also persönlich, das mache ich auch im Kapitalismus schon nicht,

334
00:52:44,000 --> 00:52:50,000
dass ich irgendwie jedes Jahr mein Geld vielleicht gar nicht für, aber auch wenn ich es hätte,

335
00:52:50,000 --> 00:52:54,000
fände ich es verschwenderisch. Also es ist vielleicht etwas, was persönlich ist.

336
00:52:54,000 --> 00:53:05,000
Und da ist dann natürlich die Sache auch ohne Werbung, ohne Produkte, die auch nach bestimmten Jahren,

337
00:53:05,000 --> 00:53:10,000
man hat vielleicht das subjektive Gefühl, die Frage ist, ob es wirklich so ist,

338
00:53:10,000 --> 00:53:16,000
dass dann das Smartphone auf einmal schlechtere Bilder macht oder langsamer wird.

339
00:53:16,000 --> 00:53:24,000
Also es steht ja im Raum, dass die Vorwürfe zumindest, dass Unternehmen wie Apple das runterdrehen

340
00:53:24,000 --> 00:53:30,000
und die Leistungsfähigkeit, um dann wirklich das subjektive Empfinden bei dem Konsumenten hervorzurufen,

341
00:53:30,000 --> 00:53:35,000
ich brauche was Neues, es taugt nichts mehr, es ist so langsam, es macht so schlechte Fotos und so weiter.

342
00:53:35,000 --> 00:53:43,000
Und sowas existiert ja nicht. Also da gibt es nicht den Anreiz dafür, weil wir kosteneffizient,

343
00:53:43,000 --> 00:53:50,000
also es wird dann auch ein modulares Bauen von solchen Konsumgütern geben, dass sie leicht reparierbar sind,

344
00:53:50,000 --> 00:53:59,000
ja dieser Wahnsinn, dass die Akkus verklebt sind und so weiter, dass man also so dieses Right to Repair,

345
00:53:59,000 --> 00:54:06,000
was heute unheimlich wichtig ist, das wird ja das Leitprinzip einer kommunistischen Produktion.

346
00:54:06,000 --> 00:54:13,000
Deswegen sind Produkte dann so ausgelegt, dass sie im besten Fall ein Leben lang halten.

347
00:54:13,000 --> 00:54:19,000
Bei vielen ist es sicherlich technisch nicht möglich, aber fast fashion und so weiter.

348
00:54:19,000 --> 00:54:26,000
Ich kaufe mir Hosen bei einer Untergruppe von H&M bei Koss und die gehen ein Jahr später kaputt.

349
00:54:26,000 --> 00:54:35,000
Und das ist, weil der Garn so hergestellt ist, dass es notwendig wird, wieder Neues zu kaufen.

350
00:54:35,000 --> 00:54:42,000
Und gleichzeitig, also die Frage von dir nach dem Individuum und dem Selbstverständnis,

351
00:54:42,000 --> 00:54:50,000
ich sehe auch heute meinen Konsum, natürlich könnte man moralisch besser konsumieren,

352
00:54:50,000 --> 00:54:56,000
weniger fliegen, weniger reisen und so weiter, in der Ernährung irgendwie schrauben,

353
00:54:56,000 --> 00:55:06,000
aber ich sehe da natürlich auch einen Wandel, was irgendwie im Mainstream heutzutage an Konsumkultur herrscht

354
00:55:06,000 --> 00:55:15,000
und auch forciert wird von Medien, von Bildern, mit denen man ausgesetzt ist.

355
00:55:15,000 --> 00:55:29,000
Aber ich sehe das vielleicht ein bisschen anders, also den Konsumenten an sich sehe ich nicht so kritisch in seiner Rolle als Konsumenten.

356
00:55:29,000 --> 00:55:40,000
Also ich sehe nicht die Notwendigkeit, also ich frage mich vor allen Dingen, auf was du vielleicht, vielleicht könntest du das nochmal weiter ausführen,

357
00:55:40,000 --> 00:55:49,000
was der Konsument und die Konsumentin anders machen sollte im Kommunismus.

358
00:55:49,000 --> 00:55:54,000
Ja, also vielleicht gehe ich einfach in eine andere Route, weil es geht überhaupt nicht darum zu sagen,

359
00:55:54,000 --> 00:56:03,000
es wäre problematisch, dass man auch Konsument ist oder dass man auch mal, weiß ich, dass man irgendwas Schönes, Gutes, Neues haben will oder so.

360
00:56:03,000 --> 00:56:16,000
Es ist eher auf einer grundsätzlichen Ebene, wo du ja sozusagen vorschlägst, wir haben diesen Planungsdemon, nennst du es ja dann an einem bestimmten Punkt,

361
00:56:16,000 --> 00:56:29,000
der im Grunde deiner Meinung nach effizienter darin sein wird, die tatsächlichen Bedürfnisse der Menschen vorauszusagen, als wir es in der Lage sein könnten, sie zu kommunizieren.

362
00:56:29,000 --> 00:56:37,000
Das ist ja sozusagen eigentlich die Grundaussage, wenn man so will, das erinnert mich übrigens auch an Alex Pentland und seine Social Physics,

363
00:56:37,000 --> 00:56:45,000
die ich nur indirekt über Anna Verena Nostov und Felix Maschewski kennengelernt habe und immer mal wieder reinlesen wollte.

364
00:56:45,000 --> 00:56:50,000
Und auch an den libertären Paternalismus ein bisschen in dieser Positionierung.

365
00:56:50,000 --> 00:57:00,000
Beim libertären Paternalismus ist es ja dann eben der Behavioral Economist, der besser weiß, wie wir uns denn zu verhalten hätten, als wir es denn selber wissen.

366
00:57:00,000 --> 00:57:14,000
Das heißt, es gibt dort quasi eine bestimmte, in dem Fall bei dir oder bei diesem Planningdemon ist es ja so eine Reproduktion der Vergangenheit als Zukunft.

367
00:57:14,000 --> 00:57:29,000
Und das ist eine bestimmte Logik sozusagen, die dem inne wohnt, die Fragen aufwirft in Bezug auf welche, also zum einen wie kommen Veränderungen ins System

368
00:57:29,000 --> 00:57:41,000
und wie weit kann das Fenster dessen sein, was sich verändern kann, wenn Zukunft aus extrapolierter Vergangenheit hergestellt wird.

369
00:57:41,000 --> 00:57:52,000
Also das sind sozusagen wie beim Bowling gibt es ja diese, für Kinder kann man dann rechts und links diese Dinge hochfahren, damit die Bowlingkugel da nicht runterfällt und auf jeden Fall immer die Bahn entlang fährt.

370
00:57:52,000 --> 00:57:54,000
Das ist vielleicht ein Bild.

371
00:57:54,000 --> 00:58:04,000
Also es gibt sozusagen einfach durch diese extrapolierte Vergangenheit eine ganz klare Einhegung der Zukunft, würde ich sagen.

372
00:58:05,000 --> 00:58:14,000
Und das ist sozusagen ein Kern dessen, was sozusagen als algorithmische Governmentalität ja auch kritisiert wird.

373
00:58:14,000 --> 00:58:18,000
Und ich bin mir jetzt nicht so ganz sicher.

374
00:58:18,000 --> 00:58:31,000
Also ich will überhaupt nicht jetzt so klingen, als ob ich das grundsätzlich problematisch fände, Technologien der Prädiktion auch im Consumerbereich einzusetzen, würde ich gar nicht sagen.

375
00:58:32,000 --> 00:58:38,000
Es ist eher so, dass ich mich frage, was bedeutet das?

376
00:58:38,000 --> 00:58:47,000
Was bedeutet diese Einhegung der Zukunft durch die extrapolierte Vergangenheit in Bezug auf einen solchen Planning Demon, den du vorschlägst?

377
00:58:47,000 --> 00:59:00,000
Und das ist gar nicht sozusagen eine ausgedachte, also ein ausformuliertes Ich glaube, das ist dann so und so, sondern das ist sozusagen eine Frage in Bezug auf diese spezifische Logik,

378
00:59:00,000 --> 00:59:07,000
der Herangehensweise an das Problem und was man sich damit einkauft sozusagen, vielleicht so.

379
00:59:07,000 --> 00:59:17,000
Ja, du hast den Dämonen gerade als Figur eingeführt, vielleicht für den Hörer und die Hörerin.

380
00:59:17,000 --> 00:59:19,000
Ein paar Worte dazu erst mal.

381
00:59:19,000 --> 00:59:35,000
Das ist eine Figur, die ja schon lange durch die Welt spukt, nicht mit dem böshaften Dämonen aus der Bibel und dem Christentum zu verwechseln oder aus anderen Religionen,

382
00:59:35,000 --> 00:59:47,000
sondern es hat eher ein, also das Dämonium taucht bei Sokrates als innere Stimme beispielsweise auf, der ihn davon abhält, falsche Entscheidungen zu treffen.

383
00:59:47,000 --> 00:59:55,000
Dann haben wir in der Physik taucht er als in den Gedankenexperimenten auf, berühmt vielleicht der Laplace Dämon,

384
00:59:55,000 --> 01:00:02,000
der den Stand eines Systems erfasst und auf der Grundlage sozusagen perfekt die Zukunft vorher sieht.

385
01:00:02,000 --> 01:00:11,000
Aber dieser Dämon auch mit diesen Algorithmen niemals realisiert werden kann.

386
01:00:11,000 --> 01:00:13,000
Vielleicht erst mal das.

387
01:00:13,000 --> 01:00:18,000
Also die Zukunft wird immer ungewiss sein und unbestimmt.

388
01:00:18,000 --> 01:00:31,000
Und der Dämon aber vor allen Dingen im Rahmen von Computern auftaucht als damals in der Zeit des Mainframes.

389
01:00:31,000 --> 01:00:37,000
Das erste Mal hatte man das Problem, dass sozusagen verschiedene Terminals auf einen Mainframe zugegriffen hatten.

390
01:00:37,000 --> 01:00:49,000
Und da muss es dann eine koordinative Instanz geben, das sozusagen im Hintergrund nicht auf den Terminals sichtbar abläuft, um diese Koordination zu bewerkstelligen.

391
01:00:49,000 --> 01:01:06,000
Heutzutage taucht es wahrscheinlich am prominentesten im Internet, also das HTTP, das Hypertext Transfer Protocol, als Protokoll zwischen Servern und Klienten.

392
01:01:06,000 --> 01:01:10,000
Und da sozusagen den Verkehr von Informationen regelt.

393
01:01:10,000 --> 01:01:22,000
Und der Dämon auch ein Prozess ist, ein Service, der im Hintergrund im Server sozusagen lauscht und auf Anforderungen sozusagen reagiert.

394
01:01:22,000 --> 01:01:24,000
Und das gibt es auch sozusagen in anderen Betriebssystemen.

395
01:01:24,000 --> 01:01:38,000
Aber die Figur ist einfach, dass etwas nicht direkter Zugriff sozusagen auf der Benutzeroberfläche, sondern im Hintergrund lauert.

396
01:01:38,000 --> 01:01:40,000
Und da kommen wir gleich nochmal drauf.

397
01:01:40,000 --> 01:02:02,000
Aber ich beantworte erst nochmal die Frage zu dieser Eigenlogik, auf die du angespielt hast, die sicherlich ein reales Problem oder eine reale Wirklichkeit erschafft.

398
01:02:02,000 --> 01:02:20,000
Und es ist auch eine Ironie, dass sozusagen die Position von solchen eher zu den Algorithmen strebenden Planern etwas wiederholt, was sich bei Hayek auch zu finden ist,

399
01:02:20,000 --> 01:02:27,000
der den Markt ja selbst als etwas Übermenschliches, Übernatürliches, also die Transzendenz.

400
01:02:27,000 --> 01:02:31,000
Und auf einmal taucht der Algorithmus wieder auf.

401
01:02:31,000 --> 01:02:39,000
Und die Frage ist, agiert er auch so hinter dem Rücken der Produzentin und der Konsumentin?

402
01:02:39,000 --> 01:02:59,000
Oder schafft es nicht am Ende doch etwas, was irgendwie das größere Glück erfüllt, weil die materialen Grundlagen doch besser abgebildet sind, als die Menschen wissen?

403
01:02:59,000 --> 01:03:08,000
Und ich hake da jetzt noch oder mache noch einen Gedanken hinterher, man muss es wirklich als permanent iterativen Prozess verstehen.

404
01:03:08,000 --> 01:03:20,000
Und das ist beispielsweise auch wieder der Vergleich zu Wettervorhersage, weil aus der Meteorologie diese ganzen statistischen Ideen eigentlich stammen.

405
01:03:20,000 --> 01:03:35,000
Wenn man in das 19. Jahrhundert schaut, die Statistik in großen Teilen auch aus der Meteorologie dann auf die Gesellschaft als Körper zustößt.

406
01:03:35,000 --> 01:03:48,000
Und in der Meteorologie, wir haben ja überall Datenpunkte, Wetterstationen, während Covid auch interessant, weil die ganzen Flugzeuge nicht geflogen sind, die Wettervorhersagen schlechter geworden sind.

407
01:03:48,000 --> 01:04:03,000
Aber das Interessante ist da, dass ja permanent Modelle entworfen werden und früher oder später werden sie widerlegt von dem, was sich einstellt.

408
01:04:03,000 --> 01:04:15,000
Und es wird einfach wieder Neues gemacht, also ein permanent iterativer Prozess, an dem ja, wenn wir jetzt auf die Konsumentinnen und den Konsum wieder schauen, die Menschen teilhaben.

409
01:04:15,000 --> 01:04:26,000
Durch die Verwirklichung, durch das Feedback an Daten, das sie generieren, ja permanent die Ausrichtung von diesen Zukunften sich verändert.

410
01:04:26,000 --> 01:04:39,000
Und natürlich hat man einen sehr großen Teil der Interpretation, die ausgelagert ist, die automatisiert teilweise ist, aber der Mensch liefert eben die Daten immer noch.

411
01:04:39,000 --> 01:04:49,000
Und viele Menschen würden sagen, das ist ein Grad an Unfreiheit, den ich nicht aushalte.

412
01:04:49,000 --> 01:05:06,000
Aber für mich ist das eine sehr abstrakte, rationale Position vielleicht, würde ich sagen, am Ende, wenn es dazu führt, dass 5 Prozent weniger Abfälle in Supermärkten, 10 Prozent weniger weggeschmissen werden muss.

413
01:05:06,000 --> 01:05:26,000
Wenn das dazu führt, dann habe ich nichts dagegen. Wenn das nicht so ist und andere Methoden besser sind, dann habe ich kein Problem, einen anderen Weg zu gehen und also ganz im Sinne der Wissenschaft oder ein Wettbewerb der Ideen, mich da in eine andere Richtung zu bewegen.

414
01:05:26,000 --> 01:05:36,000
Aber die Wissenschaft ist relativ klar, dass diese Methoden in den letzten Jahren beachtliche Fortschritte gemacht haben.

415
01:05:36,000 --> 01:05:48,000
Leider ist es so, dass diese ganzen Effizienzgewinne einfach dann in Mehrkonsum umkippen.

416
01:05:48,000 --> 01:06:14,000
Also jetzt sind die Alex Pentland-Vibes natürlich peak. Jetzt sind sie ganz stark, weil natürlich, dass die Argumentationslinie auch ist, die er vorbringt, dass im Grunde unsere äußerlich produzierten Datenpunkte im Grunde mehr über uns aussagen, als wir das in der bewussten Selbstanalyse irgendwie kommunizieren könnten.

417
01:06:14,000 --> 01:06:40,000
Und letztlich machst du ja jetzt gerade das Argument, dass diese, ich sage jetzt einfach mal polemisch, Unterwerfung, obwohl ich eigentlich gar nicht unbedingt das so extrem jetzt sehen würde, aber dass diese Unterwerfung unter diese Logik dieser Technologie oder eben auch dieser Technologie der Prädiktion, dass diese Unterwerfung gerechtfertigt wird dadurch, dass es einen Effizienzgewinn gibt.

418
01:06:40,000 --> 01:07:07,000
Und das ist, glaube ich, ein bisschen problematisch, weil also natürlich man sich ja auch fragen könnte, okay, geht es darum, also geht es darum, sozusagen diese, diesen Effizienzgewinn zu verabsolutieren und deswegen sozusagen leider in Anführungsstrichen bestimmte Freiheiten, wenn man so will, irgendwie abzuschreiben.

419
01:07:07,000 --> 01:07:20,000
Ja, also ist das eine Argumentationslogik, der wir eigentlich folgen wollen? Und ich glaube, die Antwort darauf würde am Ende dann sein mal ja, mal nein. Also in bestimmten Fällen halte ich das auch komplett unproblematisch.

420
01:07:20,000 --> 01:07:39,000
Also hat es dir die Energie angesprochen, so eh super, wenn jetzt irgendwie der Energieverbrauch gemessen wird und dann kann quasi ein aggregierter Zustand irgendwie vorausgesagt werden für die nächsten Monate oder so was, der dann dazu führt, dass die Energieproduzentinnen irgendwie weniger Überschuss haben oder so was.

421
01:07:39,000 --> 01:07:57,000
Dann ist das ja super. In anderen Bereichen ist natürlich genau diese Argumentationslinie, die du jetzt vorgebracht hast, höchst problematisch, ohne dass ich jetzt wieder in andere Extrem kippen wollen würde und sozusagen das ultimativ autonome selbstbestimmte Subjekte an dem gegenüber stark machen zu wollen.

422
01:07:57,000 --> 01:08:08,000
Aber ich glaube, umso mehr schreit das Ganze eigentlich danach, eine sehr, sehr genaue Fall Fall zu Fall Begutachtung irgendwie walten zu lassen.

423
01:08:08,000 --> 01:08:20,000
Und ein Ding, was mich da interessieren würde, wäre, du sprichst jetzt viel über Konsumgüter, wo das in vielen Teilen, würde ich mal sagen, einfach auch wirklich unproblematisch ist.

424
01:08:20,000 --> 01:08:26,000
Eben ob ich jetzt also da vorausgesagt wird, wie viel Milch ich produziere, mir eigentlich schnuppe sozusagen.

425
01:08:26,000 --> 01:08:38,000
Dann hast du zum Teil jetzt auch schon intermediäre Güter angesprochen, die eben nicht eigentlich jetzt nur den Konsum Konsumermarkt betreffen, sondern im Gegenteil sagen Produzentinnenmarkt.

426
01:08:38,000 --> 01:08:41,000
Wie weit würdest du da gehen?

427
01:08:41,000 --> 01:08:49,000
Also nochmal höhere Level wären ja dann Fragen von gesamtgesellschaftlichen Investitionsentscheidungen und so.

428
01:08:49,000 --> 01:08:55,000
Also wie wie funktioniert das da bei dir, dass du sagen, diese Abwägungen machst?

429
01:08:55,000 --> 01:09:02,000
Wo macht das Sinn? Wo macht es keinen Sinn mehr? Wo sind welche Gefahren involviert, die noch gerechtfertigt sind oder auch nicht?

430
01:09:02,000 --> 01:09:08,000
Also was gibt es da irgendwie so eine Orientierung in dir in deinem Zugang?

431
01:09:08,000 --> 01:09:20,000
Als erstes fällt mir gerade ein Zitat von Marx zu dem ersten Teil von deiner Frage über, dass ich letztens nochmal in Grundrisse gestolpert bin,

432
01:09:20,000 --> 01:09:30,000
der irgendwie dieses Spannungsverhältnis zwischen Autonomie des Individuums und Notwendigkeit globaler Koordination irgendwie so ein bisschen aufmacht.

433
01:09:31,000 --> 01:09:34,000
Das Gleiche hat Marx in Grundrisse geschrieben.

434
01:09:34,000 --> 01:09:48,000
Freie Individualität gegründet auf die universelle Entwicklung der Individuen und die Unterordnung ihrer gemeinschaftlichen gesellschaftlichen Produktivität als ihres gesellschaftlichen Vermögens ist die dritte Stufe.

435
01:09:48,000 --> 01:09:54,000
Und die dritte Stufe ist hier gemeint der Kommunismus nach dem Feudalismus und dem Kapitalismus sozusagen.

436
01:09:54,000 --> 01:10:03,000
Und das finde ich ganz schön, wie diese ganzen Diskussionen da schon irgendwie so enthalten ist.

437
01:10:03,000 --> 01:10:16,000
Das läuft jetzt Gefahr, quasi den Planning Demon mit dem, was Marx jetzt hier als eine Unterordnung unter auch gesamtgesellschaftliche Interessen bezeichnet, gleichzusetzen.

438
01:10:16,000 --> 01:10:21,000
Das eine ist ja nicht automatisch das andere. Das wäre nur sozusagen eine spontane Anmerkung, sage ich.

439
01:10:21,000 --> 01:10:32,000
Ja, und zu deiner Frage, wann oder wo diese Algorithmen zur Anwendung kommen sollten.

440
01:10:32,000 --> 01:10:47,000
Natürlich, ich bin nicht so naiv zu sagen, wir blind machen das und lassen dieses Modell laufen und gucken dann auf das Ergebnis und danach wird irgendwie die gesamte Produktion ausgerichtet.

441
01:10:47,000 --> 01:11:08,000
Dennoch würde ich sagen, ist eine nach Gebrauchswerten ausgerichtete Gesellschaft, würde ich sagen, gibt es letztendlich eine gewisse notwendige Instanz aus der Richtung der Konsumenten heraus.

442
01:11:08,000 --> 01:11:21,000
Also dass die Determination von Konsumgütern letztendlich auch rückwirkt auf eine bestimmte Bestimmung, wie viel von irgendwelchen Produkten in der Produktion gebraucht wird.

443
01:11:21,000 --> 01:11:28,000
Also wenn ich sage, wir wollen eine bestimmte Anzahl von Getreide, hat das auch eine Auswirkung darauf, wie viele Traktoren man vielleicht braucht.

444
01:11:28,000 --> 01:11:46,000
Und das Wichtige, das ist mir sehr oft auch in der Debatte oder in der Kritik an Positionen wie Paul Cockshott und Philipp Dabrich, die sicherlich auch wieder kritikwürdig sind,

445
01:11:46,000 --> 01:12:02,000
auf der Seite, okay, kann die Information wirklich überhaupt erfassen und wollen wir das in der Weise automatisieren und nicht in Verhandlungsprozesse zwischen Produktionseinheiten und so weiter delegieren.

446
01:12:02,000 --> 01:12:18,000
Das ist sicherlich kritikwürdig, aber trotzdem wichtig für mich ist an dieser Stelle festzuhalten, dass man diese lineare Programmierung und Optimierungsprozesse bottom-up denken kann.

447
01:12:18,000 --> 01:12:39,000
Also es ist eben nicht die Gosplan, wie früher in der Sowjetunion, von oben bestimmte Produktionsmethoden vorgegeben werden, sondern die Produktionsmethoden selbst werden auf der Ebene der Produktionseinheiten, der Unternehmen, wie auch immer wir sie nennen wollen, gemacht.

448
01:12:39,000 --> 01:12:56,000
Und was diese Optimierungsalgorithmen letztendlich machen, ist eine quantitative Determination, was dann technische Koeffizienten oder Inputs, also eine Bestimmung, die da stattfindet.

449
01:12:56,000 --> 01:13:17,000
Das ist auch höchst problematisch, die Frage, inwieweit passt die gesamte Wirtschaft in eine Matrix. Das hat man ja in diesen Modellen, wo man dann aber Milliarden Variablen hat und ein bestimmtes, das nennt sich dann eine Produktionsfunktion, wo man sagt, mit diesen Inputs bekomme ich diesen Output.

450
01:13:17,000 --> 01:13:39,000
Und die Idee ist dann, dass jede Produktionsgruppe irgendwie diese Produktionsfunktion erstellt, in diesem Verhältnis von diesen Inputs, die benötigt, um diesen Output zu produzieren und dann vielleicht auch eine maximale Kapazität angeben, was sie denn leisten sind, an Output auch zu produzieren.

451
01:13:39,000 --> 01:13:53,000
Und was dann diese Optimierungsalgorithmen machen, ist letztendlich eine quantitative Determination davon, wieviel letztendlich die einzelnen Gruppen bekommen.

452
01:13:53,000 --> 01:14:10,000
Und das ist, in der gesamten Planungsliteratur hat man ja immer so ein bestimmtes initiales Planziel, das dann durch Optimierung, und da ist sozusagen, das wird durch Vorhersagen definiert.

453
01:14:10,000 --> 01:14:27,000
Teilweise natürlich auch, wenn wir über eine Infrastrukturprojekte denken, da helfen uns Algorithmen jetzt nicht, weil da gibt es ja überhaupt keine Daten, Zeitreihen, und wenn wir eine Schule bauen, da helfen die uns nicht weiter.

454
01:14:27,000 --> 01:14:45,000
Aber man hat bei dieser quantitativen Determination schon so eine Rückbindung am letztendlich, was beim Verbraucher ankommt, und letztendlich gibt es eine Unterordnung vielleicht.

455
01:14:45,000 --> 01:14:58,000
Und da ist also sozusagen wieder der zweite Teil in diesem Marx-Zitat der Produktion unter die Bedürfnisse, die letztendlich entstehen bei Konsumenten.

456
01:14:58,000 --> 01:15:05,000
Weil wenn keine Bedürfnisse bestehen, dann gibt es gesellschaftlich keinen Sinn, warum irgendwas weiter produziert werden sollte.

457
01:15:05,000 --> 01:15:20,000
Und deswegen, denke ich, leitet sich so ein bisschen der Bedarf an diesen intermediären Gütern letztendlich auch in zweiter Instanz sozusagen ab aus dem Bedarf, der an Konsumgütern besteht.

458
01:15:20,000 --> 01:15:24,000
Also da gibt es ein Abhängigkeitsverhältnis.

459
01:15:25,000 --> 01:15:31,000
Da fällt mir jetzt eine ganz andere Frage ein, oder eigentlich nicht ganz anders, aber die eigentlich auch unbedingt gestellt gehört.

460
01:15:31,000 --> 01:15:37,000
Und da jetzt eigentlich anschließend, da bin ich jetzt drauf gekommen, weil du eben Kokscha Kotrel nochmal erwähnt hattest.

461
01:15:37,000 --> 01:15:52,000
Wie ist denn das, wenn jetzt dann der Planning Demon sozusagen einen optimal plan oder near to optimal oder as good as it gets, oder wie auch immer man es nennen will, auf jeden Fall better as human plan erstellt hat.

462
01:15:53,000 --> 01:15:57,000
Wie wird das dann geregelt, dass der auch so ausgeführt wird?

463
01:15:57,000 --> 01:16:07,000
Weil das ist nämlich zum Beispiel was, möchte ich nur anfügen, weil du sozusagen ja sehr kritisch dich in Bezug auf Paracon und auch von Serres das Modell geäußert hast.

464
01:16:07,000 --> 01:16:21,000
Da ist es ja zumindest mal ein Vorteil, dass irgendwie die Arbeiterinnenräte jetzt zum Beispiel in diesem General Catalog auch sozusagen auf dieser Seite dann eine gewisse Autonomie herrscht.

465
01:16:21,000 --> 01:16:29,000
Weil die ja quasi ihr Angebot wiederum auch im General Catalog posten und das sozusagen sich ja dann an dieser Schnittstelle quasi finden kann.

466
01:16:29,000 --> 01:16:42,000
Und dadurch dann eben auch nicht diese Situation erzeugt wird, wo es quasi einen absichtlich polemisch perfect plan gibt, der dann aber irgendwie durch Zwangsmechanismen sozusagen ausagiert werden muss.

467
01:16:42,000 --> 01:16:47,000
Weil das ja dann schon auch eine problematische Situation ist, die man damit dann erzeugt eigentlich.

468
01:16:47,000 --> 01:16:57,000
Sicher, also es ist letztendlich eine politische Frage, wie man damit umgeht, also mit solchen Anweisungen.

469
01:16:57,000 --> 01:17:13,000
Und ich würde sagen, gerade der Vorteil, den solche algorithmischen Frameworks bieten im Gegensatz zu eher Partizipativen, also noch stärker.

470
01:17:13,000 --> 01:17:16,000
Also es ist nochmal, vielleicht mache ich den Punkt nochmal stark.

471
01:17:16,000 --> 01:17:23,000
Es gibt auch zwischen diesen Optimierungsprozessen, sollte es immer horizontale Verbindungen zwischen den Produktionseinheiten geben.

472
01:17:23,000 --> 01:17:28,000
Es wird sehen, okay, hier gibt es gerade einen Bottleneck für diesen bestimmten Input.

473
01:17:28,000 --> 01:17:40,000
Vielleicht sollten wir uns mit anderen Unternehmen in diesem Sektor koordinieren, dass wir vielleicht auf was anderes, eine Alternative umsteigen und das einfach die direkte Kommunikation auch verlangt.

474
01:17:40,000 --> 01:17:54,000
Und Verhandlung auch, sicher. Aber der große Vorteil ist, dass diese, also da sind vor allem die Arbeit, vielleicht auch ein möglicher Gast von Thomas Herlin,

475
01:17:54,000 --> 01:18:07,000
ein schwedischer Computerwissenschaftler, der mit Dave Zaccaria auch dabei ist, einfach neue Optimierungsalgorithmen für Planung zu entwickeln.

476
01:18:07,000 --> 01:18:12,000
Der einfach, die unheimlich schnell laufen.

477
01:18:12,000 --> 01:18:36,000
Er hat einen Blog und hat da auch das zur Verfügung gestellt, dass mit einer Toy-Economie mit 23 Milliarden Variablen dieser Algorithmus auf einem relativ kleinen, im Vergleich zum Supercomputer in ein paar Stunden laufen könnte.

478
01:18:36,000 --> 01:18:53,000
Das heißt, man kann diese Optimierungsalgorithmen, könnte man permanent laufen und in Interaktion und auf eben die real existierenden Zustände in der Wirtschaft angleichen.

479
01:18:53,000 --> 01:19:06,000
Und das ist dann zum Beispiel, du hast das Beispiel eben genannt, was macht sozusagen der Optimierungsalgorithmus, wenn irgendeine Produktionsgruppe streikt oder so.

480
01:19:06,000 --> 01:19:14,000
Diese Information muss natürlich erfasst werden, dass da irgendwas, irgendwelche Outputs nicht geliefert werden, dass es da zum Engpass kommt.

481
01:19:14,000 --> 01:19:19,000
Aber das kann sehr schnell auch so die eingespeist werden.

482
01:19:19,000 --> 01:19:36,000
Und da denke ich, hat man dieses Informationsproblem, das man in der Sowjetunion hatte, heutzutage nicht so stark, weil die Outputs und Inputs, also Lieferungen und Ablieferungen und Zulieferungen, ja schon gesellschaftlich irgendwie erfasst sind.

483
01:19:36,000 --> 01:19:44,000
Also wenn eine Produktionsgruppe irgendein intermediäres Gut zu einer anderen Produktionsgruppe schickt, ist das ja erfasst.

484
01:19:44,000 --> 01:19:50,000
Und das kann man ja auf Datenbanken zentral erfassen, die Produktströme.

485
01:19:50,000 --> 01:20:02,000
Und diese Fehlinformation würde wesentlich schneller gesellschaftlich erfasst, weil die Informationstechnologien das einfach ermöglichen.

486
01:20:03,000 --> 01:20:10,000
Und ich würde sagen, gerade der Vorteil ist, also die Antwort ist natürlich, dann muss der Plan geändert werden.

487
01:20:10,000 --> 01:20:34,000
Und das ist, denke ich, also gerade der große Vorteil, dass diese, so ein algorithmisches Framework wesentlich dynamischer ist als vielleicht Paracon, wo wieder die ja komplette Zweige vielleicht in Nachverhandlung gehen müssen und ihre Preise angleichen.

488
01:20:34,000 --> 01:20:53,000
Also das dann ja entlang der Supply Chain und auch wirklich, also das hat dann ja schwer vorhersehbar, vom Punkt der einzelnen Produktion hat es Schockwellen, kann das ja wirklich durch die ganze Wirtschaft treiben.

489
01:20:53,000 --> 01:21:11,000
Beispielsweise, also während der Corona-Pandemie hatten wir Engpässe in Schiffcontainern, die irgendwo im Mittleren Westen in der USA gestrandet sind und das zu riesigen logistischen Problemen geführt hat, das wieder zu entwirren.

490
01:21:11,000 --> 01:21:22,000
Also da sind wir heute noch dran, dass irgendwie diesen Zustand vor Corona herzustellen, weil es einfach unheimlich schwierig ist, das den Anreiz zu schaffen.

491
01:21:22,000 --> 01:21:40,000
Also zum einen habe ich das Gefühl, du hast meine Frage nicht beantwortet, weil ja eigentlich die Frage auch war, inwiefern sozusagen dieses Top-Down-Element, das durch einen in Anführungsstrichen perfekten Plan, der dann von den Menschen aus agiert werden muss, entsteht.

492
01:21:40,000 --> 01:21:56,000
Also diese Konstellation, in der es diesen Plan gibt, der eben sozusagen errechnet worden ist oder vorhergesagt worden ist, dass der dann sozusagen durch Mittel von Zwang im Grunde von den Menschen aus agiert werden muss, das ist eigentlich ein großer Punkt, glaube ich.

493
01:21:56,000 --> 01:22:11,000
Weil eigentlich ist ja interessant wäre, Konstellationen zu erzeugen, in denen eben beide Elemente eine Teilautonomie haben, wo also die Produzentinnen und Produzenten und die Konsumentinnen und Konsumenten sozusagen in einer Teilautonomie sich gegenseitig begegnen.

494
01:22:11,000 --> 01:22:22,000
Und wäre dann nicht eigentlich eine anschließende Frage, dass eben so etwas wie eine Optimierung in Richtung von Konsensualisierung vielleicht am Ende besser wäre.

495
01:22:22,000 --> 01:22:40,000
Und das würde eventuell dann auch inkludieren, eine Form der Partizipation und zwar nicht, weil gesagt wird, dass es dann am Ende effizienter wäre im klassischen Sinne, sondern weil die Tatsache, dass man dieses Element der Partizipation eingeführt hat, eine höhere Konsensualisierung der Systematik erzeugt.

496
01:22:40,000 --> 01:22:51,000
Und wer weiß, vielleicht durch diese höhere Konsensualisierung am Ende dann doch auch wieder ein Resultat entsteht, das vielleicht besser ist als das, das beginnt mit der Effizienz.

497
01:22:52,000 --> 01:23:12,000
Ja, ich wiederhol vielleicht nochmal oder mach das nochmal schärfer, dass das Argument, dass die Produktionseinheiten, also da, wo wirklich die Sachen hergestellt werden, auch in so Modellen von Paul Cockshott, bei ihm vielleicht weniger.

498
01:23:12,000 --> 01:23:20,000
Also ich glaube, er hat so eine Tendenz, dass sehr viel auf höhere Ebene entschieden werden sollte.

499
01:23:20,000 --> 01:23:44,000
Gleichzeitig ist es, also von einer logischen Perspektive, wie man diese Algorithmen nutzen könnte, kann man das auch wirklich von der absoluten Autonomie eines, der Produktionsanhalt aus denken, die selbstverwaltet ist, die vor allen Dingen, die ein gewisses Grad an Zwang vielleicht haben sollte, was produziert werden.

500
01:23:44,000 --> 01:23:57,000
Also es sollte jetzt nicht sein, dass das irgendwie ein Schraubenhersteller, ein kollektiv geführte Schraubenfabrik sagt, wir wollen jetzt Prozessoren machen oder so.

501
01:23:57,000 --> 01:24:14,000
Und da irgendwie so ein bisschen Mitbestimmungsrecht der Gesellschaft auch sein sollte, dass so ein Schwenk vielleicht mehr Koordination mit anderen braucht und dann auch vielleicht das Zentrum, die die Peripherie überstimmen sollte.

502
01:24:14,000 --> 01:24:31,000
Aber im Rahmen, in dem man sich bewegt, man sagt irgendwie, du bist ein Textilhersteller und in dem Rahmen ein sehr hoher Freiheitsgrad auch sein kann, was an neuen Produkten auf den Markt kommt.

503
01:24:31,000 --> 01:24:39,000
Das ist den sozusagen freigestellt und vor allen Dingen auch, was für Inputs dafür gewählt werden.

504
01:24:39,000 --> 01:24:48,000
Also die Produktionsmethode eigentlich in der Hand der Produzenten wirklich liegt.

505
01:24:48,000 --> 01:25:00,000
Aber die Frage, wie viel von diesen Inputs die Produzentinnen dann am Ende bekommen, das ist sozusagen, das wird in diesem Prozess der Optimierung herausgestellt.

506
01:25:00,000 --> 01:25:11,000
Dann haben natürlich auch wieder die Produzentin einen gewissen Grad von Freiheit, auf dieses Ergebnis zu reagieren, indem sie vielleicht Änderungen vornehmen.

507
01:25:11,000 --> 01:25:27,000
Die sehen, hier haben wir einen Überschuss von vielleicht einem anderen Garn oder so oder einem anderen Plastik für unsere Schuhe und können da eben selbstbestimmt Veränderungen durchführen.

508
01:25:27,000 --> 01:25:40,000
Deswegen, ich finde, das ist auch wenn, ich denke, das ist sehr leicht, wenn man irgendwie Paul Cockshott liest, das irgendwie so als sehr zentralistisches Modell zu sehen.

509
01:25:40,000 --> 01:25:52,000
Aber man kann eben diese Optimierungsprozesse auch radikal bottom up und vor allen Dingen iterativ, das dann permanent in verschiedenen auf diese Ergebnisse reagiert wird.

510
01:25:52,000 --> 01:26:04,000
Und das braucht dann eben auch diese horizontalen Verbindungen zu anderen Produzentinnen und eben vielleicht Zulieferern oder Kunden, dass das auch abgestimmt wird.

511
01:26:04,000 --> 01:26:26,000
Aber diese Prozesse sollten und müssen auch weiter auslaufen, weil da hat der, es wird sicherlich auch sozusagen eine qualitative Verhandlung, dass es dann, wenn beispielsweise noch Autobauer geben sollte, ja irgendwie auch mit den Zulieferern von den Reifen das ein bisschen abgestimmt werden sollte.

512
01:26:26,000 --> 01:26:44,000
Und diese Prozesse können dann aber eben integriert werden und das ist natürlich ein fragwürdig und ein Riesenaufwand, inwieweit auch diese Klassifizierungsarbeit von Produkten und so weiter, die Kennzeichnung, wie wird das dann wirklich gemacht?

513
01:26:44,000 --> 01:27:03,000
Und also eine Produktionsfunktion ist ja auch unheimlich fragwürdig, ist ja nicht nur, wie ich sage, ich brauche so und so viel irgendwie einen Reifen, eine Stoßstange und so weiter, sondern es hängen ja auch die kompletten Sachen, die in der Fabrik vielleicht noch verwendet werden.

514
01:27:03,000 --> 01:27:11,000
Also das Druckerpapier und das Telefon und so weiter, wie werden die in diese Produktionsfunktionen eingefügt?

515
01:27:11,000 --> 01:27:29,000
Ja, das ist hoch fragwürdig, ob das überhaupt passieren kann, aber das Wichtige ist einfach und deswegen denke ich sind auch so, also das in der Computerwissenschaft, die Komplexität von Algorithmen betrifft,

516
01:27:29,000 --> 01:27:42,000
Ausschlag geben, dass es einen Algorithmen braucht, der nicht die optimale Lösung bietet, sondern einfach 99%, weil eh permanent die Pläne über Bord geschmissen werden.

517
01:27:42,000 --> 01:27:51,000
Wir leben in einer dynamischen Welt, wie du richtig gesagt hast, auch Machine Learning Algorithmen konnten nicht vorhersagen, dass Toilettenpapier gefragt werden wird.

518
01:27:52,000 --> 01:28:08,000
Und die Frage ist, wie kann irgendwie in interativen Prozessen das permanent verschränkt werden, also diese qualitativen Planungsprozessen mit Vorhersagealgorithmen und auch Optimierungsalgorithmen?

519
01:28:08,000 --> 01:28:17,000
Und ja, also es bleibt spannend und sonst soll ich noch was zu Parikon sagen?

520
01:28:17,000 --> 01:28:32,000
Na, ich glaube, das gibt mir einfach was, war eh nicht so wichtig, aber nur jetzt, um nochmal nachgefragt zu haben, wie würden jetzt eben, weil du sozusagen beim Cockshot-Modell eben herausgestellt hast, dass das auch grundsätzlich bottom abgedacht werden könnte,

521
01:28:32,000 --> 01:28:42,000
wenngleich eben bei Cockshott es tendenziell ja nicht so konzeptionalisiert ist, aber wie würden dort sozusagen neue Unternehmen in die Welt kommen?

522
01:28:42,000 --> 01:28:53,000
Ist das dann auch ein Self-Assignment oder, weil zumindest so wie ich es bisher verstanden hatte, war eben schon ein starkes Top-Down-Element im Cockshottischen Modell,

523
01:28:53,000 --> 01:29:04,000
dass sozusagen am Ende eben natürlich es schon einen Diktat gibt, so okay, hier brauchen wir aber jetzt das, hier brauchen wir jetzt aber jenes, hier brauchen wir jetzt dieses so.

524
01:29:04,000 --> 01:29:12,000
Und das ist dann nochmal eine andere Frage als die Verwaltung bestehender Produktionsmittel zum Beispiel.

525
01:29:12,000 --> 01:29:27,000
Sehr wichtige Frage. Also und das würde ich sagen, also dieser dynamische Aspekt der Wirtschaft, das würde ich sagen, da ist ein wenig untertheoretisiert bei dem Modell von Paul Cockshott.

526
01:29:27,000 --> 01:29:40,000
Aber gleichzeitig, da fällt, also ich weiß, dass Aron Beneneff da an irgendwie so Investmentprotokollen arbeitet und versucht, das auszuformulieren.

527
01:29:40,000 --> 01:29:59,000
Hier ein anderer, das ist in Historical Materialism glaube ich Ende des Jahres erschienen von Maxi Nieto, ein spanischer Theoretiker, der eben die Frage eines sozialistischen Unternehmertums,

528
01:29:59,000 --> 01:30:15,000
also Entrepreneurism in den Raum gestellt hat und da letztendlich die Frage von, ja, was er dann Investmentrate nennt und die Frage, also sozusagen, das ist auch interessant,

529
01:30:15,000 --> 01:30:34,000
dass auf dieser Makroebene sich alle Modelle eigentlich einig sind, dass irgendwie zu Beginn muss irgendwie klargestellt werden, wie viel sollen wir für Privatgüter, also von unseren Ressourcen sollen wir für Privatgüter zur Verfügung stellen,

530
01:30:34,000 --> 01:30:49,000
wie viel soll in kollektive Güter wie Infrastruktur, Bildung, Krankenhäuser und so weiter zur Verfügung gestellt werden, wie viel soll für die Forschung vorgesehen werden und wie viel soll auch für Investment.

531
01:30:49,000 --> 01:31:17,000
Und die Vergabe von diesen Ressourcen kann dann letztendlich entweder an bereits bestehende Gruppen delegiert werden oder die andere Möglichkeit ist, dass entweder durch irgendwelche demokratischen Prozesse die Gelder vergeben werden oder auch sowas wie Crowdfunding oder so.

532
01:31:17,000 --> 01:31:37,000
Das ist denke ich ein großer Vorteil wieder, also die Kapazitäten, die Kreativität, die in vielen Menschen schlummert heutzutage, die nicht das Kapital haben, um sich selbstständig zu machen, um ihre Idee zu realisieren, in irgendeiner Form den Raum zu geben, eine gute Möglichkeit.

533
01:31:37,000 --> 01:31:54,000
Und da ist auch wieder die Frage, wie werden Konsumenten eingebunden, dass solche Menschen, da könnte es dann irgendwelche, also das ist jetzt wieder sehr detailliert, finde ich, es ist wichtig natürlich, aber es ist ein reiner Utopismus jetzt, sich vorzustellen, wie das genau funktioniert.

534
01:31:54,000 --> 01:32:22,000
Aber es könnte irgendwie die Möglichkeit geben, dass die medial ausgerüstet werden, wie es heute auch gemacht wird, dass ein Werbevideo, jetzt hat man dann die Werbung vielleicht wieder drin, also den Konsumismus, aber vielleicht den konnte man ihm auch gar nicht ganz und vielleicht ist es auch gar nicht so schlecht, zur Verfügung gestellt wird und sie einfach sagen, ich will hier dieses neue Haushaltsprodukt machen.

535
01:32:22,000 --> 01:32:49,000
Ich finde, es ist eine gute Idee und wenn genug Menschen, Konsumenten das eben wollen, dann wird die Person mit den nötigen Produktionsmitteln ausgestattet oder man könnte auch, also ich müsste an, vor kurzem gerade war eine Diskussion auf Twitter, ob es noch Restaurants im Sozialismus geben wird und die Frage, oder ob es dann irgendwie Kantinen werden, auch auf der Vollkontrolle,

536
01:32:52,000 --> 01:33:21,000
man könnte dann nachbarschaftlich entschieden werden, dass da Räumlichkeiten sind und jemand will irgendwie Pizzeria aufmachen und dann wird es eher lokal auf der Ebene entschieden und die nötigen Mittel werden der Person zur Verfügung gestellt und dann aber auch wieder, würde ich sagen, knallhart einer Marktlogik unterworfen, wenn am Ende niemand diese Pizzen essen will, dann wird dieser Person auch die Produktionsmittel entzogen.

537
01:33:22,000 --> 01:33:27,000
Oder zumindest vielleicht, bevor das gemacht wird, vielleicht Hilfe angeboten, nochmal einen Kochkurs oder so.

538
01:33:28,000 --> 01:33:40,000
Wir haben jetzt hier schon ziemlich viel abgedeckt, denke ich, aber einen letzten Bereich wollen wir noch adressieren. Wir waren gestern in einem Workshop, wir sind hier gerade in Kiel und waren beim Workshop Algorithmic Road to Socialism?

539
01:33:40,000 --> 01:33:48,000
Dort sind wir auch getroffen auf Christina Kratorp und ich fand das sehr interessant und wertvoll, was sie da auch eingebracht hat.

540
01:33:49,000 --> 01:34:07,000
Sie selbst arbeitet auch als Systemingenieurin mit Machine Learning Technologien und die hat eigentlich einen ziemlich spannenden Punkt gemacht, nämlich eigentlich die Frage, wie groß denn eigentlich der tatsächliche, wenn man so will, Netto-Nutzen von solchen Technologien eigentlich denn ist.

541
01:34:07,000 --> 01:34:24,000
Weil, und das hat sie dann sehr schön aufgeführt, da eigentlich ein Haufen an nicht deklarierter Arbeit auch hineinfließt und oft eben nicht nur Arbeit, sondern einfach ganz manifeste Ausbeutungsverhältnisse, die eben auch unbezahlt sind zum Teil.

542
01:34:24,000 --> 01:34:34,000
Also da geht es natürlich um Fragen von Kehrarbeit, da geht es aber auch um Dinge wie eben extrem unterbezahlte Clickwork und und so weiter und so fort.

543
01:34:34,000 --> 01:34:41,000
Also es gibt sozusagen eigentlich unausgesprochene Kosten, die da entstehen im Rahmen der Nutzung dieser Technologien.

544
01:34:41,000 --> 01:34:57,000
Und es gibt auch etwas, was wiederum Robert Seifert eigentlich ähnlich beschrieben hat in seiner Theorie algorithmischer Sozialität als eine Ironie der Assistenz oder auch eine Dialektik der Assistenz, in der man eigentlich Systeme erschafft.

545
01:34:57,000 --> 01:35:09,000
Und dann, um diese Systeme irgendwie handhabbar zu machen, sich Assistenzsysteme erschafft, die mit den Problemen der zuvor erschafften Systeme dann umgehen müssen.

546
01:35:09,000 --> 01:35:14,000
Dann entstehen wieder neue und man muss eine Assistenz der Assistenz erschaffen und so weiter und so fort.

547
01:35:14,000 --> 01:35:23,000
Und am Ende ist eben dann ein großes Fragezeichen in Bezug auf die Frage, ob denn der Nutzen der Nutzung dieser Technologien wirklich so groß war.

548
01:35:23,000 --> 01:35:28,000
Und die Christina war gestern eigentlich schon ziemlich eindeutig in Bezug auf ihr Resümee.

549
01:35:28,000 --> 01:35:36,000
Also hat sich da eigentlich ziemlich klar ausgesprochen gegen Automatisierung via Machine Learning und so weiter.

550
01:35:37,000 --> 01:35:44,000
Und das natürlich dann aus dem Munde einer Person, die tatsächlich mit diesen Systemen arbeitet, ist umso spannender.

551
01:35:44,000 --> 01:35:53,000
Was heißt das jetzt in Bezug auf den kleinen Demon, weil das natürlich in unmittelbarer Verhältnis dazu steht?

552
01:35:53,000 --> 01:35:57,000
Ja, also es hat mir auch sehr gut gefallen.

553
01:35:57,000 --> 01:36:06,000
Es ist hilfreich, auch da vielleicht zwischen verschiedenen Problemen vielleicht, also zu verschiedenen Vorhersageproblemen zu unterscheiden.

554
01:36:06,000 --> 01:36:13,000
Der eine Fall, den sie vor allen Dingen, also mit dem sie befasst ist, sind Klassifikationsprobleme.

555
01:36:13,000 --> 01:36:25,000
Das ist das klassische Clickwork, der die Datensätze überhaupt, also die Labels bereitstellt, um diese Machine Learning Algorithmen zu trainieren.

556
01:36:25,000 --> 01:36:28,000
Die müssen ja gelabelt sein.

557
01:36:28,000 --> 01:36:32,000
Der Datensatz, das ist eine Katze.

558
01:36:33,000 --> 01:36:43,000
Und was der Algorithmus letztendlich macht, dass ihm sozusagen in dem Trainingsprozess diese Trainingsdatensätze zur Verfügung gesetzt werden.

559
01:36:43,000 --> 01:36:45,000
Hier, das ist eine Katze.

560
01:36:45,000 --> 01:36:51,000
Und auf der Grundlage der Daten wird dann ein bestimmtes Muster der Katze extrahiert.

561
01:36:51,000 --> 01:36:57,000
Und auf dieses Muster wird dann, bildlich gesprochen, auf die neuen Bilder draufgelegt.

562
01:36:57,000 --> 01:37:06,000
Und dann gibt es eine Wahrscheinlichkeit, die letztendlich in eins und null übersetzt wird, dass gesagt wird, das ist eine Katze oder das ist keine Katze.

563
01:37:06,000 --> 01:37:18,000
Und in diesem Fall ist sicherlich sehr viel Arbeit dahinter, unsichtbare Arbeit, die auch immer weiter in den globalen Süden,

564
01:37:18,000 --> 01:37:29,000
Mariana Dongos ist zum Beispiel eine alte Kollegin, die arbeitet da auch in der Insicht, wie das in Billiglohnländer letztendlich verlegt wird.

565
01:37:29,000 --> 01:37:37,000
Und die Frage, sicherlich, wenn das auf einmal 20 Euro die Stunde bezahlt werden würde, wäre das überhaupt sinnvoll.

566
01:37:37,000 --> 01:37:47,000
Und ich habe noch vielleicht aus der Eigenpreise mal kurz auch in einem Startup in Berlin gearbeitet, die in der Immobilienbranche arbeiten.

567
01:37:47,000 --> 01:37:57,000
Und deren Ziel ist, da ist alles, also so die ganzen Verträge und so weiter existieren in Papierform.

568
01:37:57,000 --> 01:38:11,000
Und die Information letztendlich in ein Dashboard digital einzuflegen, ist unheimlich zeitaufwendig, wenn dann die Menschen dort das versuchen einzutippen.

569
01:38:11,000 --> 01:38:24,000
Oder allein schon Ordner vom Download aus der E-Mail raus in einen bestimmten Ordner einzuflegen und die Datei umzubenennen, unheimlich viel Zeit anhalten.

570
01:38:24,000 --> 01:38:27,000
Und das ist die Hoffnung, dass das automatisch erkannt wird.

571
01:38:27,000 --> 01:38:39,000
Also so die nur noch eingestehend, die haben dann wahrscheinlich auch wieder Mindestlohnjobber, die mit anderen Unternehmen zusammenarbeiten, die einfach die Scanarbeit leisten.

572
01:38:39,000 --> 01:38:48,000
Und dann die Hoffnung, dass die Image Recognition von dem Algorithmus das richtig erkennt und die Aufgabe klassifiziert.

573
01:38:48,000 --> 01:38:52,000
Das ist ein Mietvertrag, das ist eine Jahresabrechnung und so weiter.

574
01:38:52,000 --> 01:38:57,000
Und sind nicht wirklich erfolgreich damit.

575
01:38:57,000 --> 01:39:03,000
Es ist ein relativ schweres Problem, aber haben sehr viel Kapital eingeworben.

576
01:39:03,000 --> 01:39:16,000
Und dann ist auch die Frage, dass auch in dem Unternehmen dann Menschen gearbeitet haben, die als Clickworker einfach auch Labels produziert haben.

577
01:39:16,000 --> 01:39:23,000
Das ist der Name hier. Das ist ein Datum des Vertragsabschlusses und so weiter.

578
01:39:23,000 --> 01:39:29,000
Und sind einfach durch die ganzen Dokumente gegangen, die relativ schlecht bezahlt waren.

579
01:39:29,000 --> 01:39:34,000
Und auch eine extrem entfremmende Arbeit, muss man dazu sagen.

580
01:39:34,000 --> 01:39:37,000
Also ich habe das selbst gemacht.

581
01:39:37,000 --> 01:39:49,000
Und wenn man das fünf Stunden macht, die Vorstellung ist, das kann man irgendwie mal ein paar Wochen machen.

582
01:39:49,000 --> 01:39:52,000
Das ist wie am Fließband arbeiten.

583
01:39:52,000 --> 01:39:56,000
Aber wenn man das wirklich ein Leben lang macht, dann stumpft man ab.

584
01:39:56,000 --> 01:39:59,000
Und letztendlich ist es aber die Grundlage, ohne geht es nicht.

585
01:39:59,000 --> 01:40:04,000
Ohne diese Arbeit funktionieren diese Algorithmen nicht.

586
01:40:04,000 --> 01:40:15,000
Und das ist natürlich besonders, wenn es dann, ich glaube, Christine hat von einem Shift gesprochen, dass die Arbeit einfach umverlegt wird.

587
01:40:15,000 --> 01:40:24,000
Also es wird nicht automatisiert, es wird nicht Arbeit verringert, sondern es wird einfach Arbeit in den globalen Süden geschickt.

588
01:40:24,000 --> 01:40:30,000
Also sie hat vor allem auch dann bei diesen, also jetzt nicht wirklich mit Machine Learning zusammen.

589
01:40:30,000 --> 01:40:38,000
Doch gibt es sicher auch als Trainingsdaten, um irgendwie Gewalt, also Facebook und so weiter,

590
01:40:38,000 --> 01:40:49,000
die versuchen ihre Plattform von Gewalt, Pornografie und so weiter zu befreien, eben Menschen dafür anstellen in sehr prekären Verhältnissen,

591
01:40:49,000 --> 01:41:00,000
die den ganzen Tag einfach durch diese traumatisierenden Bilder gehen müssen, um uns hier im Westen die glänzende, glatte Plattform zu ermöglichen.

592
01:41:00,000 --> 01:41:10,000
Aber wie gesagt, das sind vor allen Dingen, also das sind Klassifizierungsalgorithmen, die einfach in so einer 1-0-Logik sagen, ja, nein.

593
01:41:10,000 --> 01:41:18,000
Und da denke ich auch, da bin ich auch wesentlich kritischer in dem Hinblick, inwieweit diese Algorithmen,

594
01:41:18,000 --> 01:41:29,000
beispielsweise es gibt Experimente oder Leute, die das in den Raum stellen, ob Gerichtsurteile damit gemacht werden sollen,

595
01:41:29,000 --> 01:41:39,000
um irgendwie die subjektive Laune von Richterinnen einfach entgegenzuwirken, wo es auch Studien gibt,

596
01:41:39,000 --> 01:41:49,000
die irgendwie, dass es eine Stunde vor dem Mittagessen wesentlich wahrscheinlicher ist, dass man verknackt wird und noch ein extra,

597
01:41:49,000 --> 01:41:55,000
also auf die Länge sich, ich glaube in Amerika war es, wie ist das nochmal, die Schöffen entscheiden, schuldig oder nicht.

598
01:41:55,000 --> 01:42:00,000
Und ich glaube, die Richterin setzt das Strafmaß fest, glaube ich.

599
01:42:00,000 --> 01:42:06,000
Ich weiß nicht genau, wie das amerikanische Rechtssystem funktioniert, da hat sich Gott sei Dank noch kein Kontakt mit.

600
01:42:06,000 --> 01:42:17,000
Aber ja, es ist dann irgendwie eine fremdliche Vorstellung zu entscheiden, ob Amber Heard jetzt Johnny Depp diffamiert hat oder nicht.

601
01:42:17,000 --> 01:42:22,000
Ja, und die Frage an einen Algorithmus zu übergeben, aber diese Fragen stehen im Raum.

602
01:42:22,000 --> 01:42:29,000
Und ich denke, da muss man klar Linie ziehen, dass vielleicht auch kein Algorithmus entscheidet, ob man in die Universität kommt oder nicht,

603
01:42:29,000 --> 01:42:35,000
was praktisch oder einen Job bekommt, was praktisch heutzutage schon passiert.

604
01:42:35,000 --> 01:42:43,000
Und gerade weil du da diese extreme Ja und Nein Logik hast und auf der anderen Seite diese Vorhersagen, von denen ich rede,

605
01:42:43,000 --> 01:42:51,000
das sind ja Regressionsprobleme, wo es um die Bestimmung eines kontinuierlichen Zahlenwertes geht.

606
01:42:51,000 --> 01:43:02,000
Und ob es jetzt nächstes Jahr eine Million oder doch nur 800.000 Smartphones gibt, würde ich behaupten, gerade in dem Bereich der Konsumgüter.

607
01:43:02,000 --> 01:43:12,000
Und dann würde ich auch auf die Frage, die du am Anfang noch mal gestellt hast, oder die Frage, wo ich es wirklich einsetze.

608
01:43:12,000 --> 01:43:19,000
Es gibt auch Bereiche, wenn ich jetzt irgendwie ans Gesundheitswesen denke, wieviel Covid-Vaccine brauchen wir?

609
01:43:19,000 --> 01:43:23,000
Da würde ich auch ein bisschen vorsichtig sein, wenn es um Leben und Tod geht.

610
01:43:23,000 --> 01:43:29,000
Aber da wird auch sowieso noch mal was obendrauf gepackt.

611
01:43:29,000 --> 01:43:38,000
Also auch in der Produktion, wenn man eine Vorhersage hat, dass dann irgendwie ein Puffer noch mal draufgeschlagen wird.

612
01:43:38,000 --> 01:43:46,000
Und da auch wieder so ein Spiel von Produzentinnen, Leuten, die einfach in diesen Prozessen beteiligt sind.

613
01:43:47,000 --> 01:43:56,000
Wunderbar. Max, am Ende eines jeden Interviews stelle ich immer noch die Frage, wenn du dir Zukunft vorstellst, was stimmt dich freudig?

614
01:43:56,000 --> 01:44:08,000
Du sprichst mit einem Pessimisten, aber ich bin glaube ich an den Innovationsgeist,

615
01:44:08,000 --> 01:44:20,000
dass der Menschen doch überzeugt, auch so schlimm wie es vielleicht aussieht und wir vielleicht auch noch mal durch das Teil noch weiter hinabschreiten müssen.

616
01:44:20,000 --> 01:44:27,000
Bevor es vielleicht besser wird, bin ich vielleicht froh darüber, dass auch sehr viel mehr Menschen sich das Thema annehmen.

617
01:44:27,000 --> 01:44:41,000
Dass es auch durch deine Arbeit immer mehr eine Öffentlichkeit und eine Debatte darum gibt, um einfach diese Unausweichlichkeit der Gegenwart irgendwie zu entkommen.

618
01:44:41,000 --> 01:44:47,000
Und da freue ich mich auch dran beteiligt zu sein und auch den Weg weiterzugehen.

619
01:44:47,000 --> 01:44:56,000
Also ich habe das Gefühl, dass entsteht da einfach eine Wiederbelebung oder eine Weiterführung von dieser Arbeit über Zukunft nachzudenken.

620
01:44:56,000 --> 01:45:05,000
Und das ist vielleicht die Hoffnung, der Schimmer am Horizont, der sich so langsam auftut.

621
01:45:05,000 --> 01:45:09,000
Wunderbar. Max, vielen Dank für das Gespräch.

622
01:45:09,000 --> 01:45:24,000
Das war Future Histories für heute. Vielen Dank fürs Zuhören, Show-Notizen und vieles mehr findet ihr auf www.futurehistories.today.

623
01:45:24,000 --> 01:45:30,000
Diskutiert mit auf Twitter unter dem Hashtag Future Histories oder im eigenen Subreddit.

624
01:45:30,000 --> 01:45:37,000
Ihr könnt Future Histories nicht nur auf allen großen Podcast-Plattformen hören und abonnieren, sondern auch auf YouTube,

625
01:45:37,000 --> 01:45:43,000
wo ihr neben den Episoden dann auch Kurzvideos zu Kernbegriffen einzelner Episoden findet.

626
01:45:43,000 --> 01:45:52,000
Schreibt mir gerne unter jan at futurehistories.today. Ich freue mich immer sehr über interessante Rückmeldungen und Hinweise.

627
01:45:52,000 --> 01:46:02,000
Wenn ihr Future Histories unterstützen wollt, dann könnt ihr das auf patreon.com schrägstrich Future Histories oder auch via Spende auf unserer Homepage.

628
01:46:02,000 --> 01:46:12,000
Future Histories ist eine Produktion von MetaLapses zu finden auf meta-lapses.net. Bis zum nächsten Mal. Ich freue mich.

