start	end	text
0	6000	Herzlich willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft.
6000	12000	Mein Name ist Jan Groß und ich freue mich sehr, heute Max Franz-Johann Schnettker begrüßen zu dürfen.
12000	20000	Max ist Autor des Buches Transhumanistische Mythologien, in dem er sich kritisch mit bestimmten Strömungen des Transhumanismus auseinandersetzt.
20000	26000	Vielen, vielen Dank an Fabian für deine Unterstützung und vielen Dank auch für den Hinweis zu Maxes Buch.
26000	29000	Das war wirklich jetzt ein interessantes Interview und Gespräch.
29000	34000	Denn auch für mich waren einige der Bezüge, die Max da herstellt, durchaus neu.
34000	45000	Und als Max dann am Ende warnt, dass sich diese Formen des Denkens auch gerade anschicken, ganz konkret Nähe zu klassischen politischen Machtzentren zu suchen, da war ich erstmal ein bisschen erstaunt.
46000	67000	Aber ein paar Tage nach unserem Interview hat mir Max dann einen Artikel geschickt über einen Skandal um einen Berater von Boris Johnson, der öffentlich für Eugenik eingetreten ist und zum Beispiel die universelle Einführung von Langzeitverhütungsmitteln zu Beginn der Pubertät vorgeschlagen hat, um eine, Zitat, dauerhafte Unterschicht zu verhindern.
67000	80000	Das ist jetzt natürlich ein Extrembeispiel, muss man sagen, aber ganz im Sinne einer kritischen Analyse, auch von zukünftigen Herrschaftsverhältnissen, gilt es unbedingt, den transhumanistischen Diskurs kritisch zu befragen.
80000	83000	Genau das machen wir im heutigen Gespräch.
83000	93000	Wenn euch Future Histories gefällt, dann erzählt es doch bitte einem Freund oder einer Freundin, von der ihr glaubt, dass ihm oder ihr Future Histories vielleicht auch gefallen könnte.
93000	100000	Vielen Dank und ich wünsche euch viel Spaß bei dieser Episode mit meinem Gast Max Franz-Johann Schnettger.
106000	108000	Herzlich willkommen, Max.
108000	109000	Hallo.
109000	119000	Es gab schon einmal eine Folge Future Histories, in der der Transhumanismus zur Sprache kam, nämlich Folge 13 mit Julia Grillmeier zu Transhumanismus, Posthumanismus und Kompost.
119000	126000	Nicht alle werden aber diese Folge, die übrigens sehr empfehlenswert ist, möchte ich da noch anmerken, gehört haben.
126000	129000	Und so mag ich auch dich um eine Begriffsdefinition bitten.
129000	132000	Was ist das? Was ist Transhumanismus?
132000	146000	Ja, das auch ein ganz guter Einstieg, den ich vielleicht auch nutzen sollte, denn ich habe mir erlaubt, dadurch, dass ich mich kritisch mit dem Thema beschäftige, auch eine Begriffsdefinition vorzunehmen,
146000	150000	die sich von der Eigenbezeichnung von Transhumanisten ein bisschen unterscheidet.
150000	165000	Das ist ja vordergründig, sagt man, oder wenn man mit Transhumanisten redet, hört man oft, es ginge eigentlich nur um eine Verbesserung des Menschen durch Technologie und es könnte jede Form von Verbesserung käme da in Frage.
165000	178000	Ich bin aber der Meinung, dass sich da durchaus ein sich in einer Institutionalisierung befindendes ideologisches Narrativ ausmachen lässt.
178000	192000	Und dass es eben nicht nur um eine reine technologische Verbesserung des Menschen geht oder jede technologische Verbesserung des Menschen Transhumanismus wäre, sondern dass sich das recht genau umreißen lässt.
193000	213000	Um ein Beispiel zu geben, was es nicht ist, ich hatte bei einem kürzlichen Vortrag, da war jemand, der leidet an Parkinson und er hat noch gehts, aber er hat als langfristige Therapieform in Aussicht, dass er einen Hirnschrittmacher kriegt.
213000	233000	Da ist es dann ein kleiner Draht, der ins Gehirn implantiert wird, der an bestimmten Nervenzellen einen schwachen Strom abgibt, diese dadurch polarisiert und irgendwie, man weiß es nicht so genau, dafür sorgt, dass Parkinson Symptome unterdrückt werden.
233000	241000	Und der sah sich quasi schon, fing dann halt, hatte für sich die Fragestellung, ja damit bin ich doch Transhuman, das ist es doch.
241000	257000	Draht im Kopf und Implantat und das reguliert irgendwie, wo ich dann sagen würde, genau das ist tatsächlich nicht Transhuman, das ist zutiefst menschlich, weil er ausgeliefert bleibt an seinen Körper die Verhältnisse.
257000	274000	Und wenn man sich ein bisschen mit transhumanistischer Literatur beschäftigt, läuft es immer darauf hinaus Kontrolle zu erlangen, über die Eventualitäten des Lebens, Kontrolle über den Körper, Kontrolle über Krankheit und am Ende auch über den Tod.
274000	286000	Also es wäre zum Beispiel jemand, der auf medizinischen Wege eine neue Anwendung zur Bekämpfung einer Krankheit kriegt, den würde ich zum Beispiel nicht Transhuman nennen.
286000	295000	Das heißt, wir haben festgestellt, was es nicht ist. Was wäre dann aus deiner Perspektivierung das, was es schon ist?
295000	322000	Das, was es schon ist, das ist eine recht spezifische Ideologie, die also, der hat diverse Ursprünge, aber sie hat sich in den letzten 20 Jahren, würde ich sagen, gibt es einen Mainstream, der sehr viel zu tun hat mit dem Silicon Valley bzw. den dort neu entstandenen Geld- und Machteliten, die die Digitalisierung hervorgebracht hat.
322000	349000	Die immer wieder in ein Projekt des Fortschritts, der da ja irgendwie so das Leitbild gibt, dann halt auch die Verbesserung des Menschen mit einbeziehen und schlussendlich auf eben die Überwindung von Leid und so weiter abzielen, aber in einer Art und Weise, die, wenn Sie Mensch sagen, eigentlich so eine ganz spezifisch bürgerliche Subjektvorstellung zugrunde legt.
349000	357000	Und die quasi auf technologischen Säge sichern und verstetigen möchte.
357000	375000	Und da das Ganze nicht so sehr eingebettet ist in geisteswissenschaftliche Diskussionen, sondern zumeist irgendwie aus dem Techsektor kommt, gruppiert sich der Transhumanismus dann auch gar nicht so sehr nach irgendwelchen spezifischen Anthropologien,
375000	383000	sondern es geht dann, zum Beispiel gibt es da den Vorschlag einer Einteilung in Silizium-basierten, Kohlenstoff-basierten Transhumanismus.
383000	399000	Der Silizium-basierte würde darum kreisen, Menschen elektronische Implantate einzubauen und schlussendlich ihren Geist in Computer hochzuladen und auf diesem Wege mit Computern zu verschmelzen.
399000	411000	Der Kohlenstoff-basierte Transhumanismus kreist dann um Vorstellungen von genetischem Enhancement, genetischen Verbesserungen und der Überwindung des körperlichen Alterns.
411000	416000	Und da gibt es schon so unterschiedliche Strömungen und Institutionen tatsächlich auch.
416000	431000	Also in dem Kohlenstoff-basierten haben wir dann eher die Leute, die diese Bewegungen rund um MaxMor, die Wert darauf legen, sich einfrieren zu lassen, bis eben neue medizinische Technologien da sind,
431000	441000	während wir in dem Silizium-basierten eben die Erlösungsvorstellungen rund um KI und so weiter haben, mit denen ich mich dann auch spezifisch beschäftigt habe.
442000	451000	Das ist interessant, weil das war nämlich was, was in den Texten, die ich von dir jetzt gelesen habe, was ich mich da gefragt habe.
451000	461000	Es schien mir da phasenweise so, als ob du den Transhumanismus fast schon gleichsetzen würdest mit einer bestimmten Richtung der KI-Forschung, der künstlichen Intelligenzforschung,
461000	469000	die sich nämlich speziell mit den potentiellen existenziellen Risiken zukünftiger künstlicher Intelligenzen auseinandersetzt.
469000	483000	Aber so, wie du das jetzt gerade aufgemacht hast, ist das quasi ja dann nur eine Richtung unter dem Überschirm des Transhumanismus und dann wiederum auch nur eine Unterrichtung unter eigentlich dem Sektor,
483000	487000	den du jetzt Silikon-basiert genannt hast. Oder sehe ich das richtig?
487000	502000	Genau. Das liegt einfach im Fokus meiner Arbeit. Ich habe nicht den Anspruch, mit meinem Buch eine Gesamtkritik jeder transhumanistischen Strömung vorgelegt zu haben,
502000	516000	sondern ich habe mich spezifisch auf diese eingeschossen, allerdings auch unter der Prämisse, dass ich sie für dominierend halte oder zumindest das Potenzial dominierend für transhumanistische Diskurse,
516000	524000	weil sie so stark verflochten ist mit gesellschaftlichen Geld- und Machtstrukturen.
524000	536000	Also sprich, gerade bei einem Top-Hoster, der immer auftaucht, oder was ich vielleicht noch anmerken sollte, es gibt Autoren, die diese Strömung aus dem Transhumanismus ausklammern.
537000	554000	Dem würde ich widersprechen. Durchaus auch diese Idee der Superintelligenz, respektive des parallelen Menschen in Computer hochladen, sehe ich in einer expliziten transhumanistischen Dynamik oder Teleologie verortet.
554000	577000	Als es darum ging, woran ich arbeite, diese Form von Transhumanismus, die eine ist, also nicht die einzige, aber die, über die ich ein Buch geschrieben habe, hat Vertreter an Institutionen wie der Universität Oxford.
577000	591000	Oxford hat Fans unter Milliardären wie Elon Musk und Peter Seale, die einschlägige Forschungsinstitute zum Thema mit Millionenbeträgen zum Teil fördern.
591000	599000	Es gibt diesen Start-up-Incubator, der sich Singularity University nennt, wo die Singularität dann auch wieder im Namen steckt usw.
599000	617000	Für meinen Unterfangen jetzt eine Kritik des Transhumanismus zu unternehmen, die auch jetzt nicht nur rein akademischer Selbstzweck sein soll, sondern sollte, sondern sich mit neu aufkommenden Herrschaftsideologien beschäftigt.
617000	631000	Und das ist meine Stoßrichtung, dass ich diese Form von Transhumanismus zumindest potentiell für eine neu aufkommende Herrschaftsideologie halte, dadurch dann ja Fokussierung auf diese Form von Transhumanismus.
631000	636000	Zeichnen wir das doch mal für die Zuhörerinnen und Zuhörer ein bisschen nach.
636000	645000	Also du hattest schon angesprochen, einer der ganz prominenten Vertreter dieser spezifischen Richtung sitzt in Oxford.
645000	656000	Ganz konkret ist das Nick Bostrom, der das dortige Future of Humanity-Institut gegründet hat und dort eben Forschung zu existenziellen Risiken betreibt.
656000	667000	Er ist aber auch gleichzeitig, ich glaube mal Vorsitzender der World Transhumanist Association gewesen oder so, hat auf jeden Fall auch publiziert zum Thema Transhumanismus.
667000	677000	Also in ihm als Person vereinen sich diese beiden Stoßrichtungen, die du da beschreibst, auf jeden Fall mal ganz konkret.
677000	682000	Was sind denn seine grundlegenden Thesen?
682000	690000	Seine grundlegenden Thesen, er ist sehr produktiv, das auf jeden Fall, das kann man auf gar keinen Fall in Abrede stellen,
690000	697000	dass die Phase, in der er sich als Transhumanist bezeichnet hat, das war eher so vor 15 Jahren.
697000	710000	Ich würde sagen, aber sein Denken hat mit diesem Transhumanismus nie gebrochen, sondern er macht ihn dann zur weiteren Grundlage seines Nachdenks über andere Themen.
710000	717000	Das aktuelle Thema, zu dem er arbeitet, ist eben der Begriff des existenziellen Risikos.
717000	730000	Das sollen menschheitsvernichtende Risiken sein und er nähert sich der Thematik dann an mit den Werkzeugen des Utilitarismus und der analytischen Philosophie
730000	742000	und versucht da eine Philosophie zu entwickeln, die fast mathematischerweise, aber mit einer gewissen Genauigkeit, Risiken für die Menschheit abschätzt.
742000	750000	Mit auch durchaus einem politischen Impetus, der dafür sorgen soll, dass wir jetzt mal etwas unternehmen müssen an bestimmten Stellen usw.
750000	758000	Jeder Hörer wird jetzt natürlich denken, ja natürlich der Klimawandel, der ist es genau nicht tatsächlich,
758000	767000	sondern das Risiko, das ihn am meisten umtreibt und das sein anderer großer Forschungsgegenstand ist, ist die Superintelligenz.
767000	781000	Das soll salopp formuliert eine die Welt beherrschende künstliche Intelligenz sein und man nimmt so eine gewisse eindeutige Kontinuität von Fortschritt an,
781000	788000	die das zu einer Zwangsläufigkeit macht, oder fast zu einer Zwangsläufigkeit, dass so etwas entsteht.
788000	800000	Darum kreisen dann auch die meisten Abwägungen um das Thema existenzielle Risiken für die Menschheit.
800000	813000	Und dann hat das Ganze noch einen ganz spannenden Dreh, der auch dann zum Thema des Podcasts passt, dass es nicht nur um die jetzige Menschheit geht,
813000	823000	sondern auch immer um die potenziell in der Zukunft vorhandene Menschheit, der im Zweifelsfall auch, weil man annimmt,
823000	835000	dass wenn man es richtig macht, die Bevölkerungszahlen explodieren und man ja auch Utilitarist ist, man also dann in der Zukunft eine größere Zahl von Menschen,
835000	846000	die ein Wohl haben, die relevant sind für utilitaristische Erwägung und deren Glück und Wohl bestimmt werden kann, dass das sogar das größere Gewicht hat
846000	857000	und dass wir unsere politischen Aktivitäten, unser Handeln hier und jetzt quasi an der Maximierung dieses zukünftigen Menschheitsglücks ausrichten müssen.
857000	865000	Das fand ich interessant, dass das quasi gleichgestellt wird. Also um das nochmal vielleicht kurz zusammenzufassen, das heißt nämlich tatsächlich,
865000	873000	dass sie quasi in dem Glauben, also zum einen es gibt ein Glauben, man könne das quasi berechnen, also das Glück und Wohl der Menschen,
873000	889000	das ist ja eine Annahme, die dem Utilitarismus auch zugrunde liegt und dass dann aber in dieser Berechnung zukünftige Generationen Menschen mit hineingenommen werden,
889000	899000	aber eben nicht in einer Logik, in der man jetzt zum Beispiel aus der Ökologieströmung kommend irgendwie sagen würde, okay, wir müssen jetzt, was weiß ich,
899000	910000	ressourcenschonend vorgehen mit der Welt, weil wir müssen ja schauen, dass wir das Bestehende nicht für zukünftige Generationen zerstören,
910000	923000	sondern das Kalkül ist quasi ein anderes, das ist tatsächlich so ein im Grunde sich wertfrei gebendes quantitatives Kalkulieren, oder?
923000	933000	Ja, ziemlich genau, da hat er auch drüber promoviert quasi, dass es seine Doktorarbeit entworft, also so eine Aktualisierung,
933000	941000	und die literistische Moralphilosophie soll das sein, er übernimmt eigentlich aus der Physik, unter anderem, also in verschiedenen Wissenschaften,
941000	954000	nicht Physik, in der Kosmologie, gibt es das sogenannte anthropische Prinzip, das sich mit Fragestellungen greift, bei Fragestellungen der Eingerichtetheit des Universums,
954000	971000	also warum sind die Grundgrößen des Universums, die wir beobachten so und nicht anders, und dann gibt es da diesen Punkt, dass es sehr viele physikalische Konstanten,
971000	980000	wenn sie nur ein bisschen anders wären, aus verschiedenen Ebenen die Existenz menschlichen Lebens unmöglich machen würden,
981000	988000	Temperatur, Bindungsenergie zwischen Teilchen, was weiß ich was, dann können sie keine komplexen Strukturen mehr formen, nur noch kein Leben oder so,
988000	995000	oder Gravitation, plötzlich wären Himmelskörperdynamiken anders, ganz viel ihrer Kram, der vordergründig erst mal darauf drängt,
995000	1006000	dass man sich denkt, okay, oder wo so Argumente denkbar wären im Sinne von okay, es scheint so, als wäre das Universum feingetunt auf menschliches Leben,
1006000	1018000	wo man dann mit einem anthropischen Prinzip antwortet, nee, ist es nicht, das ist ein statistisches Artefakt quasi, ein Universum, das menschliches Leben verunmöglicht,
1018000	1030000	könnten wir ja gar nicht beobachten, wir wissen also, wir können davon da aus nicht schließen, ob das jetzt wahrscheinlich ist, dass Universen so aussehen oder nicht,
1030000	1040000	sondern wir können ja, also unser Sample ist eingeschränkt auf die, die wir wahrnehmen können, ein ähnliches Denken überträgt dann eine utilitaristische Moralfilosophie und sagt,
1040000	1056000	man solle in der utilitaristischen Philosophie also erst mal mitdenken, die eigene Situiertheit, und dann solle man, wenn man moralische Urteile fällt in diesem System,
1056000	1066000	systemanalytische Philosophie bzw. sich dabei üblicherweise zum Utilitarismus bedienen, dann solle man so schließen, nicht als sei man man selber,
1066000	1076000	sondern Teil einer zufälligen Referenzklasse von Beobachtern, und da bezieht er dann Zeitlichkeit mit ein.
1076000	1087000	Wenn wir also ein moralisches Urteil fällen wollen, sollten wir nicht voraussetzen, dass Moral sich irgendwie am Jetzt an unserer gegebenen Situation zu orientieren hat,
1087000	1098000	sondern wir sollten, wenn wir beurteilen, was richtig ist, dann sollten wir das so schließen, als seien wir zufällig über die Zeit gestreut,
1098000	1102000	als seien wir zufällig über die sich irgendwo in der Zeit befindliche Beobachter.
1102000	1109000	Da steckt natürlich dann die Vorstellung drin, dass man Vergangenheit und Zukunft auch irgendwie genau mathematisierbar erfassen kann,
1109000	1117000	um dann solche Aussagen zu machen, was denn bzw. dann Schlussfolgerungen darüber zu treffen, was moralisch ist und was nicht.
1117000	1123000	Und so kommt es dann auch, dass es eben nicht darum geht, irgendwie die Umwelt zu schützen oder einen Planeten zu erhalten oder so,
1123000	1127000	denn es soll ja quantifizierbar sein, es sind verschiedene Zukunften möglich.
1127000	1142000	Und ironischerweise ist in dem Aufsatz, indem man diese Idee des existenziellen Risikos entwickelt, die globale Dominanz einer ökologischen Bewegung ein existenzielles Risiko.
1142000	1149000	Also das ist die Katastrophe, die wir verhindern müssen, weil das einzig moralische ist, auf gar keinen Fall auf die Bremse zu treten,
1149000	1160000	den technischen Fortschritt so richtig durchzuballern, mehr Kapitalismus und so weiter, weil er davon ausgeht, dass sich dann zwangsläufig recht schnell dieser Zustand einstellen wird,
1160000	1169000	dass erstens eine Superintelligenz entsteht, die eh alles regelt und dann haben wir auch keine ökologischen Probleme mehr und Menschen ihre Körper verlassen.
1169000	1178000	Und das ist der Punkt, auf den wir raus müssen, die technologische Singularität, indem wir uns in Computer hochladen können
1178000	1187000	und dann verändern sich ja plötzlich die Ressourcen. Also wenn Menschen Computerprogramme sind, dann kann man viel mehr Menschen haben und man kann auch viel besser regulieren, wie es denen geht.
1187000	1201000	Und er kommt dann mit dieser auf den ersten Blick erstmal so, also wirkt jetzt nicht, erstmal zumindest schlüssigen Idee, dass man gucken sollte,
1201000	1210000	dass man die Zukunft mitbedenkt in seinen moralischen Handlungen, dann eben immer auf dieses sehr spezifisch transhumanistische Ergebnis.
1210000	1224000	Und das würde ich sagen, ist etwas, das sich durchzieht durch seine aktuelle Philosophie, dass er verschiedene, also durchaus erstmal zu griffigen Themen sehr einleuchtende Überlegungen erst mal anstellt,
1224000	1230000	die aber immer so konstruiert sind, dass man am Ende beim Transhumanismus landet.
1230000	1243000	Und ich glaube, was vielleicht wichtig ist herauszustellen ist, das funktioniert ja nur, wenn man eine bestimmte zu maximierende Zielgröße annimmt.
1243000	1259000	Also es muss ja, es wird dafür implizit etwas vorausgesetzt, was es zu maximieren gilt. Also das, was quasi als positiv angenommen wird, ist da schon eingeschrieben.
1259000	1278000	Wie würdest du das definieren? Also ist das, woran ist das orientiert? Ist das immer so ein zirkrationales, vielleicht auch an so Anthropologien wie dem Homo economicus orientiertes eigentlich Optimierungs- und Profitstreben?
1278000	1286000	Also was ist das, was es quasi zu mehrern gilt und woran wird es bemessen?
1286000	1301000	Ja, da ist ganz spannend, dass das gar nicht so wirklich diskutiert wird, sondern bei Bostrom, aber auch bei anderen Autoren, die sich in diesem Superintelligenztranshumanismus bewegen,
1301000	1310000	ist immer schon vorausgesetzt, dass so ein spezifischer Utilitarismus halt einfach die richtige Moralfilosophie ist.
1310000	1321000	So, also da ist das geklärt. Sie nennen es Glück oder sie nennen es Nützlichkeit. Utility ist dann immer der Begriff.
1321000	1332000	Das aber in der Geschichte des Utilitarismus immer so, eigentlich ist das eine Debatte. Also was soll es denn jetzt überhaupt sein? Die kann ich auch nicht beantworten, weil ich kein Utilitarist bin.
1332000	1343000	Wenn man zurückgeht bis Jeremy Bentham, bei dem gibt es Stellen, wo der dann irgendwann sagen muss, ja, also eigentlich ist es Geld. Also Glück kann man ja wohl in Geld bemessen.
1343000	1353000	Und da haben wir, weil sehr viele Leute dann mit der KI-Forschung auch zu tun haben, die irgendwie sich als Teil dieser Bewegung sehen.
1353000	1362000	Und da haben wir ja tatsächlich auch zur Steuerung von KI-Systemen diese Idee der Utility Function.
1362000	1372000	Also, dass man das definiert in gewisses Maße, numerisch bestimmbare Nützlichkeit, damit das System sich ausrichten kann.
1372000	1379000	Und dann können wir damit durchaus auch Systeme bauen, die sich irgendwie in der Welt orientieren können.
1379000	1384000	Wir haben dann aber das Ding, das setzt eigentlich immer am Ende gelabelte Daten quasi voraus.
1384000	1394000	Die philosophische Frage, was Utility ist, habe ich zumindest in dem, was ich bis jetzt vom Bostrom gelesen habe, nicht wirklich detailliert beantwortet gesehen.
1394000	1403000	Und auch bei anderen Transhumanisten nicht, die sich aber dieses Weltbild, das eigentlich darauf rekurriert, alle einkaufen.
1403000	1409000	Und das macht das Ganze auch so ein bisschen fragil, sage ich jetzt mal.
1409000	1415000	Also sobald man, weswegen ich dann auch darauf kam, mich damit so kritisch zu beschäftigen.
1415000	1424000	Es wird da sehr viel als selbstverständlich vorausgesetzt, dass sobald man nicht in so einer spezifischen,
1424000	1434000	Babel aus analytischer Philosophie und angelehnten KI-Sachen sich bewegt, eigentlich gar nicht mehr so einleuchtend wird.
1434000	1443000	Wir kommen sicher noch mal zu artverwandten Fragestellungen zurück, wie das, worüber du gerade gesprochen hast, nämlich,
1443000	1446000	auch dann in Bezug auf die Frage der Ideengeschichte.
1446000	1451000	Aber da lassen sich ja vielleicht dann manche Sachen noch anders vororten.
1451000	1460000	Aber bevor wir das machen, vielleicht noch mal kurz zur Orientierung dieser Ablauf, der da auch gedacht wird.
1460000	1463000	Nur, dass man sich das auch vorstellen kann als Hörer und als Hörer.
1463000	1468000	Der Gedanke ist, es gibt eine exponentielle technische Entwicklung.
1468000	1475000	Das heißt, es gibt einfach einen wirklich rapiden Anstieg an dem technologisch möglichen.
1475000	1482000	Und annehmend, dass sich das weiter so entwickeln wird, geht man davon aus,
1482000	1488000	dass irgendjemand, der sich so einen technologischen Anstieg anstellt,
1488000	1499000	dass sich das weiter so entwickeln wird, geht man davon aus, dass irgendwann die Rechenleistung so groß sein wird,
1499000	1508000	dass es zu einem Punkt gibt, wo eine künstliche Intelligenz eigentlich die eigene Leistung auf sich selbst anwenden kann.
1508000	1515000	Und sobald dieser Punkt erreicht ist, kommt es dann zu einer Art Intelligenz-Explosion, oder?
1515000	1521000	Vielleicht kannst du das noch mal kurz, diesen Gedanken gann, wie es zu dieser Singularität ja dann auch kommt.
1521000	1523000	Vielleicht kannst du das mal kurz noch mal beschreiben.
1523000	1529000	Was ist Singularität und wie wird das konzeptionalisiert, dass die entstehen kann?
1529000	1533000	Genau, also es sind zwei Topoi, die sich sehr eng aufeinander beziehen.
1533000	1536000	Das eine ist die Singularität.
1536000	1550000	Die technologische Singularität kommt eigentlich ursprünglich mal bestimmt in einem Aufsatz von Werner Winsch aus dem Jahr 1993.
1550000	1556000	Wurde dann in ähnlicher Weise aufgegriffen von Ray Kurzweil, der heute Chefentwickler bei Google ist
1556000	1562000	und einige Bücher geschrieben hat wie The Age of Spiritual Machines,
1562000	1576000	wo er quasi utopisch, quasi eschatologisch vorhersagt, was für eine Wunderwelt wir eintreten werden,
1576000	1578000	wenn erst die technologische Singularität da ist.
1578000	1583000	Die wird immer von Autor zu Autor ein bisschen unterschiedlich beschrieben.
1583000	1588000	Meist als eben ein Punkt, an dem der technische Fortschritt so groß ist, dass man es gar nicht mehr vorhersagen kann.
1588000	1594000	Und dass es selbstverstärkende Systeme sind, dass es immer weiter beschleunigt wird.
1594000	1605000	Und dass wir dann einen Punkt kriegen, wo die materielle Welt durch die Macht der Technik fundamental transformiert wird und wir auch.
1605000	1615000	Und zwar, da geht es dann um so Ideen wie Nanotechnologien, dass man da hinkommt, Materie auf Atomara-Ebene beliebig gestalten zu können.
1615000	1625000	Dass man diverse Energieprobleme einfach löst und natürlich, dass man den menschlichen Geist auch vollständig versteht,
1625000	1630000	wie er vom Gehirn instanziert wird und auf dem Computer reproduzieren kann.
1630000	1638000	Und praktisch ist es das technologische Himmelreich, deswegen wird es ironisch auch manchmal Rapture of the Nerds genannt.
1638000	1646000	Also dass wir an den Punkt kommen, einer technologischen Allmacht, die uns, wenn sie gut verläuft, in ein technologisches Himmelreich überführt.
1646000	1659000	Damit zusammenhängt dann bei denjenigen, die so eine Singularität am ehesten realisiert durch eine Superintelligenz vermuten, die Idee der Intelligenz-Explosion.
1660000	1674000	Das ist eine Voraussage über die Zukunft der Entwicklung künstlicher Intelligenz, die davon ausgeht, dass wir da einen plötzlichen Bruch erleben werden.
1674000	1682000	Nämlich in dem Moment, wenn es uns erst einmal gelingt, eine künstliche Intelligenz zu entwickeln.
1682000	1692000	Also man teilt da ein in schwache oder starke künstliche Intelligenz bzw. in spezialisierte und generelle künstliche Intelligenz.
1692000	1701000	Die Schwache bzw. Spezielle ist das, was wir so aus dem Alltag kennen, das den ganzen System zugrunde liegt, die wir auch alltäglich benutzen.
1701000	1714000	Das sind im Endeffekt statistische Verfahren, die auf spezifische, also z.B. dieses Machine Learning, dass man auf spezifische Sachverhalte trainiert.
1714000	1719000	Und das aber eben nur darauf anwendbar ist und nicht universalisierbar ist.
1719000	1727000	Während die generelle Intelligenz dann die menschengleiche sein soll, also die Kontext unabhängig agieren kann.
1727000	1735000	Da gibt es meines Wissens nach eigentlich keinen realistischen Ansatz, der irgendwie beschreibt, wie das realisierbar sein soll im Moment.
1735000	1741000	Das hält aber nicht davon ab, schon mal zu spekulieren, wie das sein wird, wenn wir das haben.
1741000	1748000	Und da ist die Idee, dass die generelle künstliche Intelligenz für sich selbst fungibel bleiben wird.
1748000	1756000	Also wir als Menschen haben ja irgendwie das Problem, dass wir uns nicht nur auf sehr aufwendigen Wegen irgendwie selber verbessern können.
1756000	1761000	Also wir müssen irgendwie jahrzehntelang in die Schule gehen oder irgendwie Sport treiben.
1761000	1767000	Also können wir uns schon in einer bestimmten Weise entwickeln und das auch mit Vorsatz.
1767000	1773000	Aber wir sind ja am Ende, unsere Körper und Grundlagen und das seien zu uns selber nicht fungibel.
1774000	1784000	Und diese künstliche generelle Intelligenz, die soll einerseits die Fähigkeiten eines Menschen haben, aber sie sei ja irgendwie programmiert, sie sei ja Software.
1784000	1793000	Und wenn wir jetzt eine künstliche Intelligenz hätten, die etwas klüger ist als ein Mensch, dann wäre sie ja auch besser darin, künstliche Intelligenzen zu programmieren als ein Mensch.
1793000	1799000	Und wenn man dann annimmt, dass sie vollständig für sich selber fungibel ist, dann kann sie sich ein bisschen besser programmieren.
1799000	1803000	Oder meinetwegen auch ein anderes paralleles System.
1803000	1808000	Und diese ganz kleine Verbesserung wäre dann ja auch wieder der etwas bessere Programmierer.
1808000	1812000	Also können sie sich diesen schritten und dann kriegt man plötzlich so einen Ex.
1812000	1823000	Soll man an dem Punkt, wo diese Grundlage erreicht ist, dass es etwas klüger ist als ein Mensch, etwas besser KI programmieren kann als ein Mensch, soll der Take-off erreicht sein.
1823000	1840000	Und ab dann kam es zu einem rapiden Umschwung, in dem recht plötzlich ein System dann um ein Vielfaches intelligenter wird als die versammelte Menschheit und uns quasi überwältigen kann.
1840000	1853000	Und das ist dann auch eines der zentralen existenziellen Risiken, um die es in der existential risk Philosophie und die angeschlossenen politischen Bewegungen geht.
1853000	1858000	Eben diese Idee von, wir müssen jetzt schon mal aufpassen, wir müssen uns jetzt mit der Frage befassen.
1858000	1863000	Also es kommt auf jeden Fall, es sei denn die Ökos gewinnen oder es gibt einen Atomkrieg, aber sonst kommt es auf jeden Fall.
1863000	1883000	Und wir müssen jetzt schon mal dafür sorgen, dass diese Wesenheit, die da entstehen wird, uns irgendwie wohlgesunden ist und Rücksicht auf uns nimmt und es nicht irgendwie behandelt, wie wir das mit einem Ameisenhaufen machen, wenn wir irgendwo einen Parkplatz bauen wollen.
1883000	1902000	Genau. Und da haben wir dann auch wieder so einen Punkt, dass in diesem Utilitarismus dann plötzlich wieder so eine, diese Sache ist das maximale Risiko, aber auch das maximale Potenzial, was wenn man dann utilitaristisch rangeht, rankommt, ja gut, dann machen wir uns unsere Berechnungen kommen.
1902000	1911000	Die Sache, mit der wir uns jetzt hauptsächlich beschäftigen sollten, ist die Perspektive auf diese künstliche Intelligenz und das mit dem Klimawandel oder globaler Armut oder so, das ist ja jetzt alles nicht mehr so dringend.
1911000	1925000	Und was sind dann die Methoden, die vorgeschlagen werden, um sich diesem diagnostizierten Problem zu widmen? Also was, was werden da für Vorkehrungen getroffen?
1925000	1949000	Da gibt es einerseits, gibt es das Machine Intelligence Research Institute in Berkeley, das in Berkeley ist, aber nichts mit der Uni zu tun hat, das versucht, ja am Ende eigentlich Handlungstheorien zu mathematisieren.
1949000	1970000	Eine andere Idee wäre, dass man das nicht von vornherein festlegt, weil wir ja auch das Problem haben, dass wir ja vielleicht gar nicht in unserem, also dass eine der Grundtorpoi, die da wieder vorausgesetzt werden, ist, dass wir ja irgendwie defizitär sind.
1970000	1981000	Wir sind zu dumm, zu gemein, zu asozial und das ist ja gerade eine der Sachen, die Superintelligenz für uns regelt, wir sind ja eigentlich unmündig.
1981000	2000000	Und dann haben wir die Frage, könnten wir denn jetzt schon vielleicht das vorherbestimmen? Und dann gibt es die Idee der Extrapolated Volition, die dann darin besteht, dass man sagt, dass wir der Superintelligenz Möglichkeiten an die Hand geben sollten,
2000000	2013000	die Sachen für uns so zu entscheiden, wie wir es wollen und wünschen würden, wenn wir eben weiterentwickelt weiser und sozialer wären.
2013000	2027000	Die konkreten Überlegungen dazu, also es ist jetzt nicht so, dass Technologien in der Schublade liegen, denn dann kommen wir dann auf die ganz, ganz basale oder die sehr, sehr profane Ebene des Ganzen.
2027000	2035000	Das, was man jetzt als erstes mal tun kann, ist dem Machine Intelligence Institute Geld spenden.
2035000	2046000	Da kommen wir dann auf die Verknüpfung mit der Bewegung für effektiven Altruismus, in der das alles eine Rolle spielt, die man vielleicht da höre oder auch kennt, weil die ja global an Universitäten präsent ist.
2046000	2054000	Die besteht jetzt nicht nur aus Superintelligenz, Transhumanisten ist aber ursprünglich aus diesem Milieu entstanden.
2054000	2061000	Und die spielen da schon eine Rolle. Und dann haben wir dann diese Debatte, was ist denn jetzt der effektivste Altruismus?
2061000	2069000	Und dann dieses Argument von, das Maximum an altruistischem Handeln erreichen wir, wenn wir die positive Superintelligenz verwirklichen.
2070000	2077000	Wenn wir jetzt also vor der Frage stehen, ich habe hier irgendwie keine Ahnung, 500 Euro rumliegen, was mache ich damit?
2077000	2084000	Ich will was Gutes tun, ich kann die Oxfam geben oder irgendwer, der Brunnen in Afrika baut oder ich gebe dir den Miri.
2084000	2094000	Und das Miri sorgt dann dafür, dass die Superintelligenz positiv ausfällt auf noch nicht geklärten Wegen, weil das ist ja auch ein schwieriges Problem so.
2095000	2105000	Sprache, Begriffe und Ähnliches in mathematisierter Form darzustellen, da würde ich auch sagen, das ist so ein Grundproblem, das geht halt einfach nicht.
2105000	2113000	Das ist die ganze Zeit die Schwierigkeit. Deswegen ist das, was man jetzt erstmal tun könnte, wäre, diesen Organisationen zu spenden.
2113000	2119000	Da kommen wir dann auf sehr, sehr frappante Ähnlichkeiten zu religiösen Organisationen.
2119000	2138000	Das ist dann überhaupt was, was du ja auch behandelt, nämlich die Frage, inwiefern eben es sich da, es steckt im Titel deines Buches schon drin, um Formen der Mythologie handelt.
2138000	2146000	In Anlehnung an einen Journalisten, Mark O'Connell heißt er, fällt da dann auch der Ausdruck, materialistischer Mystizismus.
2146000	2154000	Wie macht sich das bemerkbar? Wo sind da die Anknüpfungspunkte zu mystischen Narrativen?
2154000	2166000	Ich habe mich ein bisschen von Walter Benjamin inspirieren lassen, eben der Idee, dass in der Säkularisierung da durchaus theologische Potenziale noch aufgehoben sind.
2166000	2178000	Und da würde ich sagen, dass dieser Transhumanismus mit dieser Kontrollidee, dieser Idee, das materielle Universum am Ende vollständig umzugestalten und fungibel zu machen,
2178000	2185000	weil darauf läuft es am Ende raus, dass Energie und Materie fungibel werden wie Computerprogramme.
2185000	2190000	Erkläre das nochmal kurz, weil ich glaube, das ist den Hörerinnen und Hörern wahrscheinlich nicht so geläufig.
2190000	2200000	Mit fungibel meinst du ja, dass es quasi eine Austauschbarkeit gibt oder eine Kompatibilität auch unter den Dingen letztlich.
2200000	2202000	Dass das eine in das andere transformierbar sein.
2202000	2212000	Dass das eine in das andere transformierbar sein, dass es sich beliebigen Zugriffen eben, wenn ich das eine beherrsche, kann ich beliebig auf das andere zugreifen.
2212000	2218000	Also wenn ich irgendwie einen Computer programmieren kann, kann ich quasi das Universum programmieren und vor allem eine vollständige Zugreifbarkeit.
2218000	2227000	Wo war denn der Frage dazu?
2227000	2231000	Inwiefern das quasi mit einem Mystizismus zusammenhängt.
2231000	2233000	Entschuldige, dass ich dich da unterbrochen habe.
2233000	2236000	Inwiefern das mit einem Mystizismus zusammenhängt.
2236000	2244000	Die Idee mit dem materialistischen Mystizismus von Marco Connell, das bezieht sich, der hat Interviews geführt mit verschiedenen Leuten,
2244000	2248000	die in verschiedenen Ecken der transhumanistischen Bewegung unterwegs sind.
2248000	2254000	Also auch nicht nur mit den KI-Superintelligenz Leuten, mit denen ich mich da beschäftigt habe.
2254000	2265000	Der hat benutzt das als Beschreibung für diese Idee des Geistes in Computer-Hochladens.
2265000	2276000	Der vordergründig radikal-materialistisch daherkommt, also etwas wie Seele oder es gibt keine Essenz oder irgendwie das Menschen, die über natürlich ist.
2276000	2284000	Dann aber auch annimmt, dass sie dann ja auch vollständig manipulierbar und in Daten erfassbar ist.
2284000	2292000	Und dass man quasi, da wird eigentlich eine ganz saloppe Analogie, liegt dem zu Grunde.
2292000	2295000	Also das Gehirn ist ein Computer und Geist ist ein Programm.
2295000	2305000	Und so wie ich, keine Ahnung, mein altes Super-Nintendo-Spiel auf meinem PC jetzt irgendwie emulieren kann,
2305000	2316000	indem ich quasi auf dem besseren Gerät eine Umgebung und Software vortäusche, die der Hardware des älteren Geräts entspricht,
2316000	2318000	kann ich das ja dann auch mit Geist machen.
2318000	2326000	Wenn wir erstmal richtig leistungsfähige Computer haben, bauen wir einfach Gehirne auf neuronaler Ebene in Code nach.
2326000	2329000	Und dann können wir Menschen in Computer hochladen.
2329000	2340000	Und das nennt er materialistischen Mystizismus, weil es eigentlich unglaublich eng an Vorstellungen von Seelen, Wanderungen und Ähnlichem liegt,
2340000	2345000	nur zumindest vordergründig radikal materialistisch daherkommt.
2345000	2356000	Zu den grundsätzlicheren religiösen Bezügen, die ich da sehe, da ist so ein grundsätzlicher Punkt eben der Annahme,
2356000	2366000	dass die moderne Naturwissenschaft geistesgeschichtlich christliches Denken zur Voraussetzung hat.
2366000	2378000	Zum Beispiel Klaus-Peter Ortlieb ist ein ehemals Leiter des Instituts für Mathematische Modellierung an der Uni Hamburg,
2378000	2382000	hat das dann in einigen Aufsätzen sehr schön nachgezeichnet, aber auch andere Autoren,
2382000	2389000	haben eben diese Art des Denkens über die Welt, die die Naturwissenschaft zur Voraussetzung hat,
2389000	2399000	die eben nicht nur nach dem unmittelbar Gegebenen fragt, sondern nach dem dahinterliegenden Prinzip, das mathematisierbar ist,
2399000	2409000	hat zur Voraussetzung eigentlich ein Denken, das eben Konstrukteur annimmt, das so eine Gemachtheit der Welt annimmt,
2409000	2414000	die nach bestimmten Prinzipien funktioniert, die erkennbar sind.
2414000	2422000	Das ist jetzt keine Fundamentalkritik an den Naturwissenschaften oder sonst irgendwas, die finde ich sehr gut,
2422000	2432000	nur es gibt diese Voraussetzung und das, was einem da begegnet, glaube ich, in diesen Sachen,
2432000	2436000	die rund um Superintelligenz und so weiter kreisen, ist eigentlich eine Aktualisierung dessen,
2436000	2446000	dass wir dieses Denken haben, dass sich um Konstruiertheiten und so weiter, dass er implizit irgendwie doch so eine Gottesfigur drin hat
2446000	2452000	und die dann aber daraus wieder konstruiert wird und dann landen wir bei diesen Superintelligenz-Sachen.
2452000	2460000	Noch mal sehr viel konkreter dann, wenn wir dann noch mal hinkommen, dass das alles ja auch noch utilitaristisch ist.
2460000	2473000	Im Utilitarismus, der kommt aus einer spezifisch christlich-kalvinistischen Tradition und hat aus dieser auch durchaus seine Sinnbestimmung,
2473000	2480000	was ein Grund ist, warum ich annehmen würde, dass sich die ganze Sache auch außerhalb des englischsprachigen Raums nie so durchsetzen wird,
2481000	2492000	weil da so gewisse, ich würde es jetzt mal kulturell nicht ganz nennen, aber gewisse geistesgeschichtliche Voraussetzungen drin sind,
2492000	2496000	die man eher mitgekriegt hat, wenn man in England oder in den USA aufgewachsen ist.
2496000	2502000	Und das Ganze, um auf Marco Connell zurückzukommen, findet man dann auch tatsächlich noch mal in der Person,
2503000	2516000	wenn er dann Menschen beschreibt, die in evangelikalen christlichen Haushalten aufgewachsen sind, da dann irgendwie eine Glaubenskrise hatten
2516000	2527000	und jetzt eben zutiefst davon überzeugt sind, dass sie Atheisten sind, weil sie nicht glauben, dass die Erde 5000 Jahre alt ist
2527000	2541000	und das Noah eine Arche gebaut hat, die aber immer noch völlig in diesem Denken einer am Ende regulierten Welt drin stecken.
2541000	2551000	Und die füllen dann quasi diese Lücke mit und die halt dann auch Sterblichkeit nicht konfrontieren, sich damit arrangieren,
2551000	2557000	was ja auch irgendwie ein Prozess ist, den man als Atheist vielleicht auch irgendwie durchmacht, mit Sterblichkeit überhaupt nicht zurechtkommen,
2557000	2564000	allerdings eben dieses Tragegerüst des festen Glaubens verlieren und dann eben daran kommen, okay, da muss ich das jetzt aber technologisch lösen
2564000	2576000	und dann auch sehr viel mehr bereit sind, an Narrative zu glauben, die technologisch daherkommen, aber andererseits auch diese Ängste bedienen.
2576000	2582000	Also das ist ja ein ganz, ganz zentrales Ding beim Transformatismus, dass man nicht mehr sterben muss, darum geht es auch immer.
2582000	2588000	Da geht es auch bei den anderen Transformatismen rum und also bei dem, wo es sich einfrieren lässt beispielsweise
2588000	2595000	und in diesem Superintelligenz-KI-Transformatismus dann eben diese Idee von, okay, wenn ich erstmal meinen Körper los bin, der zerfällt,
2595000	2605000	der ist schmuddelig, der kriegt Krankheiten, wenn ich erstmal ein Computerprogramm bin, dann habe ich Sterblichkeit zumindest vordergründig überwunden.
2605000	2611000	Und das sind für mich mythologische und zum Teil mystizistische Elemente.
2611000	2623000	Ja, also das eine hattest du jetzt gerade auch dann schon konkret eben mit dem Mind Uploading, der Whole Brain Emulation, wie es ja dann auch heißt, benannt.
2623000	2634000	Da wittert man quasi die Unsterblichkeit. Die andere Sache, die Aufgehobenheit, die du angesprochen hast, vielleicht der Vollständigkeit halber noch erwähnt,
2634000	2640000	findet sich dann zum Beispiel in sowas wie einer Nanny-AI eigentlich, oder?
2640000	2656000	Also im Grunde einer allumfassenden künstlichen Intelligenz, die für uns alle quasi die profane täglichen Belange regelt in einer scheinbar besseren Art, als wir es denn jemals könnten, oder?
2656000	2666000	Das ist dann das Prinzip des Singleton, wie du es benannt hast oder wie bzw. die Protagonistin dieser Denkschule das dann auch benennen.
2666000	2670000	Vielleicht kannst du das nochmal kurz definieren, was das ist, ein Singleton?
2670000	2680000	Ein Singleton ist tatsächlich ein Konzept von Nick Bostrom. Das ist eben eher vordergründig, ist es eine Weltregierung, die halt so die totale Kontrolle hat.
2680000	2685000	Und er nennt das Koordinierungsprobleme, also die Koordinierungsprobleme löst.
2685000	2700000	Koordinierungsprobleme sind für ihn sowas wie Politik, ganz allgemein. Also alles, was nicht die klarste technische Lösung ist, das wird gelöst, dadurch, dass wir eine möglichst rationale Weltregierung haben.
2700000	2721000	Und dieser Singleton, er hat diesen Begriff, der ist so ein bisschen Kuddelmuddel, weil da auf der einen Seite ist er so definiert, so ein Singleton könnte jetzt auch ein totalitärer Weltstaat sein oder eine Alienherrschaft oder was weiß ich, was das Einzige wäre, dass es nicht mehr in Frage gestellt wird.
2721000	2729000	Also es geht, am Ende geht es um totale Herrschaft. Und dann gibt es da noch dieses Ding, das da aber eigentlich immer mit die Superintelligenz gemeint ist.
2729000	2745000	Also eine Superintelligenz, die diesen Take-off der Intelligenz-Explosion hinter sich lässt, dann ganz schnell dahin kommt, dass sie eben durch menschliche Manöver gar nicht mehr in Frage gestellt werden kann.
2745000	2761000	Und diese totale Herrschaft ist für ihn auch ein ganz wichtiger Punkt. Daher wird er oft missverstanden. Man liest seine Bücher, hört seine Vorträge und dann kommt da diese totale Weltherrschaft vor und man denkt, das muss ja irgendwie was Negatives sein.
2761000	2778000	Vordergründig warnt er auch davor. Also es ist schon ein existenzielles Risiko, wenn dieser Singleton dann eben unsere Menschen nicht für wertvoll erachtet und eben planiert wie Ameisen.
2778000	2792000	Aber eigentlich, wenn wir raus wollen auf dieses, was uns ja moralisch verpflichtet, das Realisieren der bestmöglichen Zukunft, dann müssen wir ganz ganz schnell hinkommen zu diesem Singleton, und zwar einem positiven.
2792000	2813000	In dem Moment, das ist dann auch eine der Sachen, die ich an der ganzen Nummer so schwierig finde, wo es dann eben auch die Dimension von, ja gut, das ist jetzt alles ein bisschen schrullig, aber auch vielleicht interessante Gedankenspiele verlässt.
2813000	2826000	Die haben diesen Herrschaftsanspruch, ein legitimatorisches Narrativ und es ist total hip bei den gerade neu aufkommenden Eliten. Also das finde ich sehr schwierig.
2826000	2845000	Eigentlich artverwandt mit diesem Thema der Frage der Positionierung des Menschen gegenüber der technischen Entwicklung und ob die als, ob man selbst, also der Mensch an sich quasi jetzt dann als defizitär empfunden wird oder nicht.
2845000	2860000	Daran angehängt ist vielleicht auch die Frage nach dem Bild von Intelligenz, das da unterstellt wird im Thema der Superintelligenz und du hattest das dann an anderer Stelle auch so dargestellt,
2860000	2874000	als ob dieses Denken in Superintelligenzen dann auch eine Art von, das heißt die Superintelligenz eine Art von verkörpert perfekter Rationalität ist, die dem Menschen eben abgesprochen wird.
2874000	2890000	Also da wird dann quasi wieder dieser Vergleich aufgemacht. Der Mensch, das zeige ja zum Beispiel die Verhaltensökonomie. Der Mensch, der sei eben nicht perfekt, der Handel immer wieder durch seine Emotionen bedingt ja eigentlich fehlerhaft und nicht rational.
2890000	2909000	Und man müsse jetzt quasi, um diesem defizitären Status zu entsteigen, eben quasi sich anderer Mittel bedienen, zum Beispiel der Superintelligenz. Was ist denn das Verständnis von Rationalität, was dem zugrunde liegt? Was ist, was gilt da als Rationalität?
2909000	2928000	Da würde ich es jetzt spezifisch eingrenzen auf die Rationalisten bzw. richtigerweise Neorationalisten. Das ist dann auch ganz spannend, weil es ein Verbreitungsvektor transhumanistischen Denkens, der auch eng verknüpft ist.
2928000	2954000	Also hat denselben Gründe, ist dasselbe Milieu wie dieses Machine Intelligence Research Institute, ist die neorationalistische Bewegung im Internet, die erstmal ansetzt bei diesen, bei den Erkenntnissen aus Verhaltensökonomik und Ähnlichem, dass wir eben halt nicht perfekt rationale Agenten sind.
2954000	2971000	Das ist ja durchaus auch in den Wirtschaftswissenschaften irgendwie Gegenstand von Debatten, also ich meine sogar nach wie vor, ob nicht dann die Modelle überarbeitet werden müssen, wenn Menschen am Markt gar nicht perfekt rationale Agenten sind.
2971000	2988000	Da wird halt die umgekehrte Schlussfolgerung gezogen. Wie können wir das werden? Und das hat erstmal so eine Selbsthilfedimension, dass man also versucht, das eigene Denken zu schulen, um rationaler zu sein.
2988000	3001000	Auch jetzt erstmal keine schlechte Idee, es ist wie bei, also ich finde auch so eine Sache, die sich da immer irgendwie durchzieht, es ist irgendwie dann immer die Urausführung, die so ein bisschen fragwürdig ist.
3001000	3014000	Man will das da nämlich erreichen, das ist ja jetzt auch nicht so, dass es nicht Systeme in der Gesellschaft gibt, die es einem ermöglichen, rationaler zu denken.
3014000	3020000	Man kann in die Schule gehen, man kann studieren, man kann sich mit der Geschichte der Philosophie beschäftigen usw.
3020000	3037000	Man kann sich vor allem klar machen, dass man eben fehlbar ist in seinen Entscheidungen und die hinterfragen das alles nicht, sondern man soll eine neue Form von Rationalität erlernen, die orientiert sich an der welchen Statistik.
3037000	3050000	Die Grundannahme ist, geist und menschliches Denken ist eigentlich eine ganz einfache Sache, das ist irgendwie so ein sequenziell belschte Fragestellung, lösen der Rechen-OP-Mechanismus.
3050000	3056000	Wenn man sich das bewusst macht und Verhedderungen vermeidet, dann wird man rationaler.
3056000	3079000	Dann gibt es diese völlig skurrilen Sachen rund um das Center for Applied Rationality, also für angewandte Rationalität, das einem beibringen soll, so zu denken, was einem ein Denken beibringen soll, was an der Funktionsweise von KI-Systemen orientiert ist.
3079000	3098000	Und was sich durch das alles schon ganz erkennbar durchzieht, ist ein sehr, sehr enger Begriff von Rationalität, der sich eben stark an ökonomischem Erfolg ausrichtet und auch das Ganze nicht mehr hinterfragt.
3098000	3114000	Man ist weit davon entfernt, so etwas aufzumachen, wie man es jetzt beispielsweise aus einer kritischen Theorie kennt, die Einteilung in eine subjektive und objektive Vernunft.
3114000	3126000	Und das eine ist die Vernunft des Zweck-Rational-Instrumentelle und das andere ist eine Vernunft, die die Frage stellt, sind die Ziele, die wir uns setzen, ist die Gesellschaft, wie wir sie einrichten, ist das überhaupt vernünftig?
3126000	3132000	Die zweite Art geht gar nicht, das macht die Superintelligenz dann irgendwann.
3132000	3150000	Und da kommen wir dann auch in den Bereich, wo ich Nähe zu faschistischem Denken sehe, bei dem Intelligenzbegriff, weil die Intelligenz ist das, was der EQ-Test misst.
3150000	3156000	In der Gedankenwelt, aus der sich der Transhumanismus entwickelt.
3156000	3165000	Und das ist ja auch eine numerische Größe, die kann größer oder kleiner sein, dann ist auch klar, wenn wir eine Maschine bauen können, die das auch irgendwie mehr hat, dann ist sie auch besser.
3165000	3181000	Und dadurch ziehen sich dann organische Ideen, die um Intelligenzoptimierung kreisen, weil wir hätten ja auch ein großes existenzielles Risiko in dem Moment, wo sich zu viele dumme Leute vermehren.
3181000	3183000	Das wäre etwas, wo man aufpassen müsste.
3183000	3193000	Das ist auch so ein Punkt, wo ich mich dann sehr wundere, warum das ganze Zeug so wenig skandalisiert wird, weil es ist ja jetzt eigentlich keine salonfähige Position.
3193000	3203000	Und die steht zwar nicht im Vordergrund der Überlegung, aber zum Beispiel durch das Werk von Nick Bostrom zieht sich das an mehreren Stellen.
3203000	3208000	Also Intelligenz ist eng begriffen, Rationalität ist eng begriffen.
3208000	3214000	Eine Diskussion, eine philosophische, wird eigentlich vermieden, was das sein soll.
3214000	3230000	An den Stellen, wo was dazu gesagt wird, ist es irgendwie ein rationaler Agent, hat was mit welcher Statistik zu tun und im Zweifelsfall ist das halt einfach das, was der EQ-Test misst.
3231000	3245000	Und das ist eben also jetzt nicht nur quasi irgendeine Splitter-Position innerhalb irgendeines Subforums von, wie heißt nochmal dieses Rationality-Wiki?
3245000	3246000	Das gibt es auch.
3246000	3248000	Less wrong heißen die.
3248000	3260000	Less wrong, das ist quasi nicht nur da eben so eine kuriose Sonderposition, sondern das ist was, was du durchaus auch eben bei Nick Bostrom im geschriebenen Wort und gesagtem Wort vor Ort ist.
3260000	3268000	Bei Nick Bostroms Buch über Superintelligenz ist es zum Beispiel, fasst er das schon auf den ersten paar Seiten als optimaler belgischer Agent.
3268000	3271000	Da können wir Intelligenz äußerlich bestimmen.
3271000	3273000	Da brauchen wir nicht.
3273000	3285000	Und auch diese Schlussfolgerung, dass quasi daraus eigentlich eugenische Handlungen zu setzen sind in irgendeiner Form, wird implizit da dann dann mitgegeben?
3285000	3292000	Also ich weiß nicht, ob man das in Superintelligenz, also es gibt einerseits diesen Aufsatz rund um existenzielle Risiken.
3292000	3295000	Da kann man das eigentlich nicht implizit nennen.
3295000	3313000	Das folgt dann nicht aus diesem aus der spezifischen intelligenten Definition, aber da taucht als eines der eines der Risiken, die wir auf die wir achten müssen, die da verhindern können, dass wir dieses Himmelreich erreichen.
3313000	3335000	Das Erreichen des Technologischen ist neben Meteoriteneinschlägen, böser Superintelligenz, der globalen Dominanz einer ökologischen Bewegung, auch die dysgenischer Druck, also die Generierung quasi,
3335000	3354000	durch die, weil Menschen dazu neigen, zu viel Nachkommenschaft zu produzieren, gerade auch die falschen Leute, und man halt dann zu einem Homophiloprogenitus, also das sich fortpflanzenliebend degenerieren würde.
3354000	3362000	Was dann auch, weil wir dann nicht mehr genug intelligente Leute haben, den Weg in das technologische Paradies verstellt.
3362000	3376000	Im Superintelligenz Buch werden eugenische Maßnahmen als einer der Wege überhaupt dahin zu kommen, dass wir solche superintelligenten Maschinen haben verhandelt.
3376000	3398000	Eine Sache, die ich jetzt beschrieben habe, war der Take-off. Es gibt aber auch ein einziges Unterkapitel zu biologischer Kognition, da geht es dann um IQ, und dann, wie wir mit ganz einfachen Maßnahmen dafür sorgen, dass sich besonders kluge Leute und besonders klugen Leute fortpflanzen,
3398000	3425000	da so eine Dimension haben, weil wir das am besten in vitro machen, eine Dimension von Selektion drin haben, und dann eben in sehr wenigen Generationen dazu kommen, dass wir durch genetische Selektion erstmal eine Elite an Forschern aufbauen, die in der Lage sind, dann uns dahin zu bringen, dass wir die nötigen technologischen Schritte machen können.
3425000	3434000	Also, das steht nicht im Vordergrund, aber ist jetzt auch nicht, dass da was implizit ist.
3434000	3451000	Wow, wild. Okay, da muss ich dann jetzt nochmal bei dem, du hattest das zwar eh schon angesprochen, aber da muss ich jetzt trotzdem nochmal nachhaken, wie einflussreich ist denn transhumanistisches Denken und was bedeutet das dann quasi für uns.
3451000	3463000	Ich meine, in dem, was du gerade gesagt hast, schimmert es ja schon durch, aber also Ray Kurzweil, du hattest ihn angesprochen, ist bei Google, ich kann mich erinnern, der leitet da glaube ich jetzt auch irgendeine Art von internem Think Tank oder sowas.
3463000	3484000	Peter Thiel, vielleicht für die Hörerinnen und Hörer, der hat mit Elon Musk zusammen PayPal gegründet und Palantir auch, nicht mit Elon Musk zusammen, aber Palantir ist eine Daten-Harvesting-Maschine, die auch mit Geheimdiensten zusammenarbeitet, mit dem Pentagon und so weiter.
3484000	3489000	Also der ist auf jeden Fall auch eine schillernde Figur, der, versteht er sich auch als transhumanist?
3489000	3498000	Ich bin mir nicht ganz sicher, ob es irgendwie ein Zitat von ihm gibt, dass er sich explizit selber als transhumanist bezeichnet, aber er fördert Projekte in dieser Richtung.
3498000	3521000	Er fördert vieles, aber er ist, wenn man sich dann in die entsprechenden Communities und so weiter begibt, ist auf jeden Fall immer, ist ein Ziel, das diskutiert wird, kann ich fördern, ist so eine Möglichkeit, wenn man so ein Projekt hat, das irgendwie so in einem transmonistischen Umfeld, ob man nicht von Peter Thiel auch irgendwie Förderung kriegen könnte.
3521000	3526000	Stimmt, das kann ich mich erinnern, da habe ich auch mal bei einem Podcast gehört, dass das diskutiert wurde.
3526000	3538000	Gut, also die Frage wäre, für wie einflussreich hältst du das, sagen diese Formen des Denkens und was bedeutet das für uns?
3538000	3560000	Ja, da stellt sich dann die Frage, deswegen sprach ich ja schon am Anfang von einem Mainstream, es gibt offensichtlich sehr einflussreiche Leute, die diesem Gedanken gut mindestens nahe stehen oder die große Möglichkeiten haben, auch Einfluss auf die Gesellschaft zu nehmen, weil sie eben über sehr viel Geld verfügen.
3560000	3589000	Und es hat jetzt in letzter Zeit, also es ist jetzt gerade passiert, es ist eine spannende Sache, was daraus wird, es ist ja jetzt Brexit und Boris Johnson ist Premierminister von Großbritannien und er hat ja diesen auch etwas schillernden Berater Dominic Cummins, der in der transhumanistischen Szene vernetzt ist und der in seiner Zeit schon mal im Bildungsministerium einen recht langen Aufsatz gemacht hat.
3590000	3605000	Er hat uns geschrieben, einer der Kernaussagen war, dass es bei dem Erfolg von Schülern wesentlich mehr auf ihr genetisches Potenzial ankäme als auf die Umstände ihrer Bildung.
3605000	3633000	Genau, der ist im Beraterstab des Premierminister von Großbritannien und hat kürzlich auf seiner Webseite Stellengesuche veröffentlicht, bei denen es darum geht, die Verwaltung der englischen Regierung zu optimieren, indem man sich eben Data-Scientists, Leute aus der KI-Programmierung, Unternehmer und was weiß ich was ins Boot holt, eben all diese Personen, die in der Transhumanistischen Szene vernetzt sind.
3635000	3660000	Dass die in der Transhumanismus so ein bisschen fundierenden, weltsichtentscheidenden Personen sind und da ist die Frage, wo ich jetzt mit etwas Spannung gucke, ob es tatsächlich passiert, dass sich in England transhumanistische Kreise in der Regierungsverwaltung etablieren.
3660000	3681000	Also das ist nicht ausgemacht, das ist eine völlig chaotische Situation, war aber auf jeden Fall auch so eine Sache, wo ich mir gedacht habe, hui, steht man da vor Stellengesuchen für die Downing Street Number Ten, die so einen transhumanistischen Vibe haben.
3681000	3699000	Und das ist aber nicht nur jetzt, weil Data-Scientists gibt es ja überall, also das ist ja jetzt noch nicht transhumanistisch irgendwie, da gab es da noch andere Hinweise, die jetzt quasi konkret in diese Richtung deuten, weil jetzt Big-Data-Nutzung gilt ja jetzt quasi schon als, muss man quasi drauf schreiben.
3699000	3719000	Ich habe jetzt hier die Stellenausschreibung. Das erste Zitat der Stellenausschreibung, also an erster Stelle wird Elisabeth J. Kauski zitiert als KI-Experte, das ist der Leiter des Machine Intelligence Research Institutes.
3719000	3735000	Das heißt, das hat eine spezifische Richtung aus, wer da abgefragt wird. Und das würde ich schon als einen, also es würde nicht schaden auf diese Stellenausschreibung zu antworten und man hätte schon seine Credentials als Transhumanist, sagen wir es so.
3736000	3742000	Max, als letztes stelle ich immer noch die Frage, wenn du dir Zukunft vorstellst, was stimmt dich freudig?
3742000	3768000	Was stimmt mich freudig? Ich sehe gerade, also tatsächlich interessiert mich gerade diese globale Welle, die es ja jetzt irgendwie im letzten Jahr gab von basisdemokratischen Protestbewegungen gegen ökonomische Ungleichheit,
3768000	3780000	die sich auch in Ländern abgespielt haben, wo man tatsächlich erwartet würde, das landet alles in irgendeinem Islamismus oder was weiß ich was oder in irgendwelchen anderen autokritären Ideologien.
3780000	3807000	Und dass es zumindest schon mal so aussah, als würde das nicht passieren und das lässt mich mit einer gewissen Erwartung darauf blicken, ob sich nicht die ja doch sehr solide wirkenden Vergesellschaftungsformen der Globalisierung auf so einer wirtschaftlichen Ebene
3807000	3823000	radikal in Frage stellen lassen. Es gibt ja von Mark Fischer diese Formulierung über capitalist realism, von David Graeber diese Formulierung, dass wir eigentlich für Zukunft wieder kämpfen müssen, Zukunft zu eröffnen, sowas wie Zukunft zu haben.
3824000	3835000	Und ich glaube, dass da in nächster Zeit sehr viel passieren wird, was den Blick auf Zukunft wieder öffnet, weil sich Möglichkeitenräume plötzlich eröffnen in kollektivem Handeln.
3836000	3841000	Wunderbar. Das ist doch ein schöner Ausblick. Max, vielen Dank für das Gespräch.
3842000	3843000	Ich danke dir, dass ich bei dir sein durfte.
3865000	3872000	Was ihr zu dem Ganzen denkt und wie euch diese Folge hier gefallen hat, unbedingt gut bewerten auf allen Podcast Plattformen, die ihr nutzt.
3873000	3880000	Für unsere Patreon Unterstützerinnen und Unterstützer gibt es auf www.patreon.com schrägstrich future histories vieles an Zusatzmaterial.
3881000	3884000	Da könnt ihr also auch vorbeischauen. Bis zum nächsten Mal. Ich freue mich.
