1
00:00:00,000 --> 00:00:05,720
Herzlich Willkommen bei Future Histories, dem Podcast zur Erweiterung unserer Vorstellung von Zukunft.

2
00:00:05,720 --> 00:00:10,720
Mein Name ist Jan Groß und ich freue mich sehr, heute Adrian Daupp begrüßen zu dürfen.

3
00:00:10,720 --> 00:00:16,720
Adrian ist Professor für vergleichende Literatur und Germanistik an der Stanford-Universität,

4
00:00:16,720 --> 00:00:19,520
also im Herzen des Silicon Valley.

5
00:00:19,520 --> 00:00:24,760
Er betreibt den Podcast The Feminist Present und ist zudem ein unbriebiger Autor.

6
00:00:24,760 --> 00:00:30,760
Ganz frisch erschienen bei Surkamp ist sein Buch, was das Valley Denken nennt.

7
00:00:30,760 --> 00:00:37,760
Bevor es losgeht, darf ich ganz herzlich Vainö in der Gemeinschaft der Future Histories Patroninnen und Patronen begrüßen.

8
00:00:37,760 --> 00:00:39,760
Vielen Dank für deine Unterstützung.

9
00:00:39,760 --> 00:00:43,760
Viel Freude bei der heutigen Folge Future Histories mit Adrian Daupp.

10
00:00:49,760 --> 00:00:51,760
Herzlich Willkommen, Adrian.

11
00:00:51,760 --> 00:00:52,760
Vielen Dank.

12
00:00:52,760 --> 00:00:59,760
Adrian, du setzt dich in deinem Buch mit geistesgeschichtlichen Ursprüngen der im Silicon Valley vorherrschenden Ideologien auseinander.

13
00:00:59,760 --> 00:01:03,760
Gleich zu Beginn des Buchs machst du dabei eine wichtige Einschränkung

14
00:01:03,760 --> 00:01:06,760
und ich finde, wir sollten diese auch unserem heutigen Gespräch vorausschicken.

15
00:01:06,760 --> 00:01:14,760
Deine Untersuchungen zu den vorherrschenden Idealisierungen, Mythen und Narrativen des Tech-Sektors bezieht sich auf die, und ich zitiere hier,

16
00:01:14,760 --> 00:01:20,760
sehr sichtbaren GründerInnen, Finanziers und MeinungsführerInnen der Branche.

17
00:01:20,760 --> 00:01:26,760
Dein Buch erhebt also bewusst nicht den Anspruch auf Vollständigkeit und ich möchte an dieser Stelle ergänzend vielleicht auf das Buch

18
00:01:26,760 --> 00:01:31,760
Voices from the Valley von Meurer Weigl und Ben Tarnow hinweisen, das kürzlich erschienen ist,

19
00:01:31,760 --> 00:01:34,760
das quasi einen komplimentären Zugang zu deinem wählt.

20
00:01:34,760 --> 00:01:40,760
Warum hast du dich für diese Linse entschieden, die bei dir ja auch eine kritische ist, und was bringt sie zutage?

21
00:01:40,760 --> 00:01:45,760
Naja, einerseits, weil ich eben als Geisteswissenschaftler an dieses Thema ran wollte.

22
00:01:45,760 --> 00:01:54,760
Das heißt, ich habe mich mit einer kulturellen Formation beschäftigen wollen und die existiert eben primär um diese Firmengründer,

23
00:01:54,760 --> 00:02:00,760
um den Medien- und Politikkult, der um diese Medien im Positiven wie auch im Negativen gemacht wird.

24
00:02:00,760 --> 00:02:07,760
Also für jeden Elon Musk gibt es einen Mark Zuckerberg, der uns eher als Negativfigur dient.

25
00:02:07,760 --> 00:02:12,760
Aber die sind eigentlich im Grunde genommen fast literarische Figuren.

26
00:02:13,760 --> 00:02:18,760
Das sind Figuren, denen mit den Mitteln der Kulturwissenschaft relativ gut beizukommen ist.

27
00:02:18,760 --> 00:02:26,760
Die Frage, wie man die Voices from the Valley, die Meurer und Ben in ihrem Buch eingefangen haben,

28
00:02:26,760 --> 00:02:30,760
wirklich nachweisen würde, das ist ja bei ihnen eher so eine Oral History.

29
00:02:30,760 --> 00:02:33,760
Ich glaube, das lässt sich auch ganz toll machen.

30
00:02:33,760 --> 00:02:41,760
Da müsste man aber 10.000 Fragebögen verschicken und da müsste ich noch einen Dotteltitel in Soziologie drauf.

31
00:02:41,760 --> 00:02:44,760
Darauf legen und gucken, ob Theodor Adorno noch abkömmlich ist.

32
00:02:44,760 --> 00:02:49,760
Und dann ginge das auch. Ich finde, das ist eine sehr spannende, sehr spannende Idee.

33
00:02:49,760 --> 00:02:56,760
Mir ging es aber eben wirklich mehr um die Art, wie wir das Valley mit diesen Figuren,

34
00:02:56,760 --> 00:03:02,760
mit diesen Gründerfiguren, diesen Dortliederfiguren zusammen konstruieren.

35
00:03:02,760 --> 00:03:08,760
Also das Feld, das sich sozusagen ergibt, aus dem Interesse einer Weltöffentlichkeit,

36
00:03:09,760 --> 00:03:15,760
die irgendwie davon ausgeht, nicht ganz unbegründeterweise, aber davon ausgeht,

37
00:03:15,760 --> 00:03:19,760
dass im Silicon Valley sozusagen die Geschichte der Zukunft geschrieben wird.

38
00:03:19,760 --> 00:03:25,760
Nicht in Shenzhen, nicht in Hyderabad, sondern in Silicon Valley.

39
00:03:25,760 --> 00:03:34,760
Und dann eben jenen im Valley, weil sie Geld brauchen, weil sonst ihr Businessmodell nicht funktioniert,

40
00:03:35,760 --> 00:03:44,760
weil sie denken, dass die Welt an ihrer Weisheit genesen kann, da mitmachen und die sich dem anbieten.

41
00:03:44,760 --> 00:03:48,760
Und es gibt auch Firmengründer im Valley, die sowas nicht tun.

42
00:03:48,760 --> 00:03:52,760
Die bewusst Interviews nur geben, wenn es um ihren Business geht und sagen,

43
00:03:52,760 --> 00:03:56,760
ja so haben wir das gemacht, bitte kaufen Sie unsere Aktien ungefähr.

44
00:03:56,760 --> 00:03:59,760
Aber das ist eben nicht Elon Musk, das ist nicht Mark Zuckerberg.

45
00:03:59,760 --> 00:04:06,760
Die werden nicht eingeladen, um Reden an Unis zu halten und würden das wahrscheinlich auch nicht tun.

46
00:04:06,760 --> 00:04:12,760
Es geht also um einen Komplex, der sich konstituiert durch das Interesse an diesen Unternehmen

47
00:04:12,760 --> 00:04:19,760
und das diesen Unternehmen eine Wichtigkeit beimisst für die Art und Weise,

48
00:04:19,760 --> 00:04:24,760
in der wir alle leben oder leben werden und umgekehrt den Kräften im Valley,

49
00:04:24,760 --> 00:04:27,760
denen daran gelegen ist, so verstanden zu werden.

50
00:04:30,760 --> 00:04:36,760
Und einer der zentralen Mythen, die da florieren und auch lange schon kursieren,

51
00:04:36,760 --> 00:04:39,760
der dreht sich um die Disruption.

52
00:04:39,760 --> 00:04:45,760
Du schreibst dazu, paradoxerweise ist die Disruption letzten Endes also etwas wie Neuheit für Menschen,

53
00:04:45,760 --> 00:04:47,760
die sich vor genuin Neuem fürchten.

54
00:04:47,760 --> 00:04:52,760
Eine Revolution für Menschen, die sich von der Revolution keinen Vorteil erwarten dürften.

55
00:04:52,760 --> 00:04:55,760
Das ist eine sehr wichtige Feststellung, finde ich.

56
00:04:55,760 --> 00:04:59,760
Vielleicht kannst du uns ein wenig die Genese dieses Konzepts der Disruption näherbringen

57
00:04:59,760 --> 00:05:02,760
und warum es sich hierbei eben nicht um eine Revolution handelt.

58
00:05:02,760 --> 00:05:10,760
Die Disruption speist sich ganz stark aus Joseph Schumpeters Begriff der kreativen,

59
00:05:10,760 --> 00:05:14,760
der schöpferischen Zerstörung, sorry auf Deutsch, schöpferischen Zerstörung.

60
00:05:16,760 --> 00:05:21,760
Und der wiederum bezieht sich auf Karl Marx und Friedrich Engels im kommunistischen Manifest.

61
00:05:21,760 --> 00:05:30,760
Und seine Theorie war seinerzeit dazu angelegt, zu erklären, warum Teile ihrer Kapitalismuskritik absolut zutreffen,

62
00:05:30,760 --> 00:05:35,760
warum es aber trotzdem wahrscheinlich nicht zu einer Revolution kommen wird.

63
00:05:35,760 --> 00:05:47,760
Das heißt, im Grunde genommen war die Schöpferische Zerstörung eine Art Sublimierung der Revolution

64
00:05:47,760 --> 00:05:50,760
in den Vollzug des Kapitalismus selber.

65
00:05:50,760 --> 00:05:57,760
Und das hat sich in den letzten 80 Jahren gewandelt, dadurch, dass Schumpeter das annahm,

66
00:05:57,760 --> 00:06:04,760
dass dadurch sozusagen, dass durch die Tatsache, dass der Kapitalismus immer dabei ist,

67
00:06:04,760 --> 00:06:10,760
immer schon alles kaputt zu machen, immer schon alle Konstanten zu negieren,

68
00:06:10,760 --> 00:06:18,760
dass das irgendwie die Menschen dazu führen würde, etwas außerhalb des Kapitalismus zu suchen und sich zu wünschen.

69
00:06:18,760 --> 00:06:24,760
Und er nahm an und er fand das, soweit ich ihn verstehe, gar nicht mal positiv,

70
00:06:24,760 --> 00:06:28,760
aber er meinte, das macht eine Art Staatssozialismus relativ unausweichlich.

71
00:06:28,760 --> 00:06:35,760
Das ist in den letzten 80 Jahren verloren gegangen und Disruption ist derzeit eher, wie ich es im Buch beschreibe,

72
00:06:35,760 --> 00:06:37,760
eine Theorie C des Hyperkapitalismus.

73
00:06:37,760 --> 00:06:45,760
Das heißt, sie ist sozusagen, sie beglaubigt den Kapitalismus noch, anstatt dass sie ihm sozusagen seine Grenzen aufzeigt.

74
00:06:45,760 --> 00:06:54,760
Und insofern ist das, und sie ist sozusagen das Scharnier geworden durch das ganz bestimmte Branchen,

75
00:06:54,760 --> 00:06:59,760
das war nicht ursprünglich die Tech-Industrie, das war ursprünglich die Finanzindustrie,

76
00:06:59,760 --> 00:07:02,760
aber jetzt mittlerweile vor allem die Technologieindustrie,

77
00:07:02,760 --> 00:07:09,760
anderen Wirtschaftszweigen ihre Logik als gesamtgesellschaftliche Logik überstülpen können.

78
00:07:10,760 --> 00:07:19,760
Wenn wir kommen können und wir krempeln dein Geschäftsmodell innerhalb von zwei Jahren so um, dass du Bankrott gehst,

79
00:07:19,760 --> 00:07:24,760
dann zeigt das doch eigentlich, dass du es nicht verdient hattest zu überleben.

80
00:07:24,760 --> 00:07:37,760
Das ist das Fatale an diesem Diskurs, weil er im Grunde genommen, ich meine, was wurde denn nicht schon alles disrupted?

81
00:07:37,760 --> 00:07:44,760
Und es gibt, das will ich sofort dazu sagen, es gibt Momente, in denen Disruption sehr wohl beschreibt, was vor sich geht,

82
00:07:44,760 --> 00:07:53,760
auch genau beschreibt und, sag ich mal, relativ und auch, sag ich mal, einen Prozess beschreibt,

83
00:07:53,760 --> 00:07:58,760
von dem wir alle sagen können, der ist gesellschaftlich wahrscheinlich sogar wünschenswert.

84
00:07:58,760 --> 00:08:05,760
Das Problem ist aber, dass es eben als, als Sie sagen, öffne dich für so ungefähr alles jetzt verwendet wird.

85
00:08:05,760 --> 00:08:13,760
Ja, was heißt das, wenn man eine Branche wie, was weiß ich, die Grundschule disrupted?

86
00:08:13,760 --> 00:08:18,760
Also ich meine, in Deutschland ist man noch nicht ganz so weit, aber in den USA hört man schon so Sachen.

87
00:08:18,760 --> 00:08:24,760
Oder Trump disrupted den Staat, in dem er eben komplett inkompetent ist.

88
00:08:24,760 --> 00:08:27,760
Also na gut, das ist keine Disruption mehr, das ist Destruction.

89
00:08:27,760 --> 00:08:32,760
Und Schumpeter war sehr, sehr bewusst, dass das eine eben nicht das andere ist.

90
00:08:32,760 --> 00:08:38,760
Aber es ist eben mittlerweile richtig eine Art, eine Spielart, mit der mit der Unterschiede,

91
00:08:38,760 --> 00:08:42,760
soziale Unterschiede nivelliert werden können und einfach gesagt werden können kann.

92
00:08:42,760 --> 00:08:51,760
Jede Art Neuordnung ist an und für sich gut und an und für sich legitimer als das, was sie neu ordnet.

93
00:08:51,760 --> 00:08:58,760
Weil das, was disrupted werden kann, es irgendwie halt schon verdient hat.

94
00:08:58,760 --> 00:09:03,760
Wobei ja bestimmte Sachen dann eigentlich durchwegs unangetastet bleiben.

95
00:09:03,760 --> 00:09:08,760
Also das, so hatte ich jetzt das bei dir auch verstanden, dass im Grunde ja auf der einen Seite eben,

96
00:09:08,760 --> 00:09:13,760
so wie du es jetzt auch als Beispiel genannt hast, sich also dieses Konzept hergenommen wird, um zu legitimieren,

97
00:09:13,760 --> 00:09:17,760
dass man in ganz viele Bereiche auch hineingeht, in denen es eigentlich nicht adäquat wird.

98
00:09:17,760 --> 00:09:24,760
Aber gleichzeitig ist ja zum Beispiel alles, wo es jetzt zum Beispiel darum ginge, sich vom Profitmotiv zu entfernen.

99
00:09:24,760 --> 00:09:28,760
Das ist ja davon dann irgendwie aus dem Vorgehalten, scheint mir.

100
00:09:28,760 --> 00:09:35,760
Genau. Also wir haben gerade in Kalifornien eine lange und wirklich fürchterliche Wahlkampagne

101
00:09:35,760 --> 00:09:38,760
über diese Proposition 22 über uns ergehen lassen müssen.

102
00:09:38,760 --> 00:09:47,760
Das war der Staat Kalifornien hatte sich, hatte entschieden, dass Leute, die für Uber und Lift fahren,

103
00:09:47,760 --> 00:09:50,760
als Belegschaft behandelt werden müssen.

104
00:09:50,760 --> 00:09:54,760
Nicht als Vollzeitbeschäftigte, aber auch zumindest als Teilzeitbeschäftigte.

105
00:09:54,760 --> 00:10:01,760
Und dass denen somit gewisse Versicherungen und so weiter zustehen.

106
00:10:01,760 --> 00:10:09,760
Und dagegen haben sich die Unternehmen verwehrt aus dem ganz einfachen Grunde,

107
00:10:09,760 --> 00:10:14,760
dass sie wahrscheinlich bankrott gehen würden, wenn sie ihre Fahrer nach diesem Prinzip bezahlen würden.

108
00:10:15,760 --> 00:10:21,760
Und haben stattdessen 200 Millionen Dollar ausgegeben, um eine Proposition, also einen Volksentscheid zu erwirken,

109
00:10:21,760 --> 00:10:34,760
der auch tatsächlich durchgekommen ist, der eben besagt, dass die Fahrer für Uber und Lift von diesem Gesetz ausgenommen sind.

110
00:10:34,760 --> 00:10:37,760
Also so haben die sich sozusagen über die Runde gerettet.

111
00:10:38,760 --> 00:10:49,760
Aber wie sie das gemacht haben, es ging immer darum, wir wollen unseren Fahrern mehr Flexibilität und mehr Autorität zubilligen.

112
00:10:49,760 --> 00:10:55,760
Wie kann es der böse Staat wagen, sich da einzumischen und das ist halt alles so altmodisch und so weiter.

113
00:10:55,760 --> 00:11:00,760
Und es wurde nie offen, natürlich haben sie es nicht offen gesagt, aber es war erstaunlich,

114
00:11:00,760 --> 00:11:09,760
wie viel Nonsense die eigentlich generieren konnten, um sozusagen nichts sagen zu müssen.

115
00:11:09,760 --> 00:11:14,760
Unsere Profitmargen hängen davon ab, dass diese Menschen unterbezahlt werden.

116
00:11:14,760 --> 00:11:17,760
Wir müssen sie weiter unterbezahlen dürfen, sonst gibt es uns nicht mehr.

117
00:11:17,760 --> 00:11:22,760
Und das kam sogar zu Spaß, wir müssten dann unsere Operation woanders hin verlegen.

118
00:11:22,760 --> 00:11:29,760
Ja klar, weil bei fairer Bezahlung das System sehr schnell kollabiert.

119
00:11:29,760 --> 00:11:34,760
Und das ist für mich eben so ein Moment, wo Disruption sich eben sehr stark,

120
00:11:34,760 --> 00:11:43,760
sie lässt die Mächtigen, die Mächtigen werden mächtiger oder bleiben genau gleichmächtig,

121
00:11:43,760 --> 00:11:48,760
das Geld fließt genau so wie es vorher floss, aber alle tun so,

122
00:11:48,760 --> 00:11:54,760
als seien die alten Kapitalismusformen irgendwie ausgehebelt oder umformiert worden.

123
00:11:54,760 --> 00:12:00,760
Also es gibt dann bei jedem so einem Startup dann einen Artikel, der irgendwie beschreiben will,

124
00:12:00,760 --> 00:12:06,760
wie jetzt angeblich dieses oder jenes Metier komplett revolutioniert wird

125
00:12:06,760 --> 00:12:10,760
und dass eben häufig der Middleman dann wegfällt und so weiter.

126
00:12:10,760 --> 00:12:14,760
Aber im Grunde genommen handelt es sich immer um eine Art Sales Pitch,

127
00:12:14,760 --> 00:12:20,760
um eine Art Publicity, die eben kaschieren soll, dass im Grunde genommen

128
00:12:20,760 --> 00:12:24,760
die alten Machtgefüge relativ konstant bleiben werden,

129
00:12:24,760 --> 00:12:31,760
aber dass eben jetzt eine neue Schicht von Bossen reich werden wird.

130
00:12:31,760 --> 00:12:36,760
Und dass vor allem häufig ja nicht mal die Bosse, Uber oder Lyft, sondern häufig die Geldgeber,

131
00:12:36,760 --> 00:12:41,760
häufig dieselben Investoren, die früher in die kleineren Unternehmen investiert hätten,

132
00:12:41,760 --> 00:12:45,760
aber dass die jetzt eben genauso so reich werden und dass keiner sich mit dem Taxifahren

133
00:12:45,760 --> 00:12:49,760
eine goldene Nase verdient, haben sie früher auch nicht, werden sie heute auch nicht.

134
00:12:49,760 --> 00:12:55,760
Wer reich wird, ist Uber. Oder wer reich wird, sind die Uber Investoren.

135
00:12:55,760 --> 00:13:03,760
Und wenn es denn also so ist, dass die Disruption letzten Endes etwas wie Neuheit ist für Menschen,

136
00:13:03,760 --> 00:13:08,760
die sich vor dem genuin Neuen fürchten, dann schließt sich da eigentlich die Frage an,

137
00:13:08,760 --> 00:13:13,760
wie würde eine tatsächliche Neuerung denn aussehen, also welche Kategorien müsste man bereit sein,

138
00:13:13,760 --> 00:13:18,760
in Frage zu stellen, um wirklich zu einer genuinen Neuerung zu kommen?

139
00:13:18,760 --> 00:13:21,760
Ich glaube, du hast es vorhin schon angesprochen, das Profitmotiv wäre,

140
00:13:21,760 --> 00:13:23,760
das stünde für mich an allererster Stelle nicht.

141
00:13:23,760 --> 00:13:28,760
Es gibt Formen, also Wikipedia wäre eine Sache, die hat wirklich, das ist wirklich eine Disruption gewesen,

142
00:13:28,760 --> 00:13:35,760
aber das ist wirklich etwas, wo sehr wenig, wo ja wirklich kaum jemand Profit daraus schlägt

143
00:13:35,760 --> 00:13:53,760
und wo wirklich wir etwas aufgebaut haben, das genuin neu ist, aber genuin und genuin anders funktioniert als herkömmliche Lexika.

144
00:13:53,760 --> 00:13:58,760
Das heißt nicht, dass Wikipedia keine Probleme hat oder dass man nicht vielleicht auch manchmal Experten ranlassen sollte,

145
00:13:58,760 --> 00:14:04,760
statt dass Tante Erna da irgendwie an ihren Lieblingseinträgen schraubt.

146
00:14:04,760 --> 00:14:10,760
Aber es heißt doch, dass das Modell an sich wirklich das leistet, was es erstmal verspricht.

147
00:14:10,760 --> 00:14:19,760
Und da gibt es viele Beispiele und ich glaube, es gibt viele Ansätze, gerade auch an den Universitäten,

148
00:14:19,760 --> 00:14:28,760
gerade auch was Open Access angeht und so weiter, auch im Verlagswesen gibt es wirklich tolle Ideen.

149
00:14:28,760 --> 00:14:36,760
Und das sind die Ideen, wo man allen Beteiligten anmerkt, dass sie ganz erschrocken darüber nachdenken,

150
00:14:36,760 --> 00:14:42,760
ja, aber wie überleben wir denn dann? Das sind wirklich die, die nämlich ein Risiko auf sich, indem sie das machen.

151
00:14:42,760 --> 00:14:49,760
Das, was ich interessant finde bei all dem Risikokapital, das hier rumschwappt in San Francisco, immer noch, muss man sagen, trotz Covid,

152
00:14:50,760 --> 00:14:59,760
dass das eigentlich die falsche Bezeichnung dafür ist. So wahnsinnig viele riskieren diese Menschen gar nicht.

153
00:14:59,760 --> 00:15:05,760
Die geben hundert Wetten ab und sind sich ziemlich sicher, dass zwei oder drei von denen das große Los sind.

154
00:15:05,760 --> 00:15:12,760
Ich meine, klar, das ist ein gewisses Risiko, aber es ist ein Risiko, dass wenn du oder ich das Geld hätten,

155
00:15:12,760 --> 00:15:15,760
wir sicherlich auch gerne auf uns stehen würden. Das ist die Frage, wie viel Geld der Mensch hat.

156
00:15:16,760 --> 00:15:21,760
Und ich glaube aber, es gibt eben andere Ansätze, wo Menschen wirklich genuin was riskieren.

157
00:15:21,760 --> 00:15:29,760
Und es ist eben auffällig, dass gesellschaftlich oder was die Politik angeht, wenn deutsche Politiker

158
00:15:29,760 --> 00:15:37,760
oder auch österreichische Politiker nach Silicon Valley kommen, gehen sie zu Google, gehen sie nach Stanford,

159
00:15:37,760 --> 00:15:46,760
gehen sie, schauen sie möglicherweise bei Uber vorbei. Das ist da, wo die die Zukunft verorten.

160
00:15:46,760 --> 00:15:50,760
Und das ist eine Wahl, das ist eine Entscheidung. Man könnte es auch anders machen.

161
00:15:50,760 --> 00:15:56,760
Man könnte auch bei irgendwelchen komischen Hacker-Kollektiven vorbeischauen, gucken, wie macht ihr das denn eigentlich?

162
00:15:56,760 --> 00:16:07,760
Aber nein, was wir uns als Gallionsfigur für das 21. Jahrhundert auserkoren haben, ist das Megastartup,

163
00:16:07,760 --> 00:16:18,760
dessen Risiko eigentlich Makulatur ist, dessen Disruption eigentlich nur eine Neuordnung des Bestehenden,

164
00:16:18,760 --> 00:16:28,760
eine Neuordnung des bestehenden Machtbefüges ist und deren Zukunft, würde ich mal sagen,

165
00:16:28,760 --> 00:16:34,760
ins Dystopische, wenn man sie wirklich zu Ende denkt, ins Dystopische bis hin zum Neofeudalistischen geht,

166
00:16:34,760 --> 00:16:39,760
was manche dieser Gründer auch offen aussprechen. Und dann muss man einfach fragen,

167
00:16:39,760 --> 00:16:49,760
was macht dann ein Forschungsminister bei Google, anstatt sich mit irgendwelchen Hackern in einem Café zu treffen?

168
00:16:49,760 --> 00:17:01,760
Es gibt da ganz tolle Ansätze. Das Problem ist, dass man die Aufmerksamkeitsökonomie Silicon Valleys nennen könnte,

169
00:17:01,760 --> 00:17:06,760
die das Augenmerk immer auf die anderen lenkt.

170
00:17:06,760 --> 00:17:13,760
Du beschreibst in deinem Buch auch diese eigentümliche Mischung des Silicon Valleys aus Lokalismus und extrem geschlossenem

171
00:17:13,760 --> 00:17:21,760
und auch sehr homogenem Umfeld auf der einen Seite und gleichzeitig aber einem Gestus des Universalismus auf der anderen Seite.

172
00:17:21,760 --> 00:17:27,760
Ich habe einen Begriffsvorschlag dafür, nämlich provenzieller Universalismus, musste ich sofort denken, das würde passen.

173
00:17:27,760 --> 00:17:30,760
Was ist das für eine Melange, die du da beschreibst?

174
00:17:30,760 --> 00:17:37,760
Ein Beispiel, das ich im Buch nicht bringe, das habe ich vor Jahren mal in einem Text in der NZZ gebracht.

175
00:17:37,760 --> 00:17:47,760
Das war für mich der Moment, das muss 2018 zur Wahl gewesen sein, bin ich in ein kleines kalifornisches Städtchen.

176
00:17:47,760 --> 00:17:54,760
Ungefähr 80.000 Einwohner im Central Valley, vornehmlich von mexikanischen Amerikanern bewohnt.

177
00:17:55,760 --> 00:18:01,760
Es war eine ganz andere Welt vom Bay Area, nur 200 Kilometer weg oder 300 Kilometer weg, aber total anders.

178
00:18:01,760 --> 00:18:04,760
Und dann kam Lunch und dann habe ich gedacht, wie mache ich das jetzt?

179
00:18:04,760 --> 00:18:07,760
Und dann habe ich Yelp angestellt und es war faszinierend.

180
00:18:07,760 --> 00:18:14,760
Yelp hat unglaublich viel rezensiert worden, aber eben von der Art Mensch, die Yelp benutzt.

181
00:18:14,760 --> 00:18:22,760
Das heißt, ich konnte vor einer Tacerea stehen, wo ich danach auch gegessen habe, das war fantastisch und die kam bei Yelp nicht vor.

182
00:18:22,760 --> 00:18:29,760
Und daneben war eine andere Tacerea, die hatte nur zwei Sterne, weil irgendjemand das Gefühl hatte, dass eine Maus durchgelaufen ist.

183
00:18:29,760 --> 00:18:35,760
Was in einer Tacerea häufig hervorkommt, ist halt so. Das Essen ist oben, das ist egal.

184
00:18:35,760 --> 00:18:44,760
Aber es war eindeutig, es war unglaublich proppenvoll in der Tacerea, die laut Yelp nicht existierte.

185
00:18:44,760 --> 00:18:51,760
Und dann gab es so eine etwas bourgeois angelegte Tacerea um die Ecke und die hatte irgendwie 5000 Rezensionen auf Yelp.

186
00:18:51,760 --> 00:18:54,760
Das fand ich dann doch auch interessant.

187
00:18:54,760 --> 00:19:06,760
Dann habe ich angefangen, mich durch meine Bay Area Apps, die also im Bay Area geschaffen werden, aber die angeblich eine Geografie der ganzen Welt mir zur Verfügung stellen sollten.

188
00:19:06,760 --> 00:19:08,760
Das war 2018, es kann sein, dass jetzt mittlerweile etwas geändert hat.

189
00:19:08,760 --> 00:19:12,760
Ich habe damals Uber angemacht, Lyft gab es damals dort noch nicht.

190
00:19:12,760 --> 00:19:20,760
Und es gab vier Autos, was natürlich in so einer Gegend gar nicht wenig ist und sie waren alle Toyota Prius.

191
00:19:20,760 --> 00:19:24,760
Also alle Hybridfahrzeuge, was in San Francisco jeder fuhr damals.

192
00:19:24,760 --> 00:19:30,760
Mittlerweile ist es auf Elektroauto umgestellt, aber das war damals das Auto im Bay Area.

193
00:19:30,760 --> 00:19:37,760
Aber dort sah ich erst mal gar keins. Das waren Trucks, das waren sehr, sehr alte amerikanische Modelle, viele Chevys und so weiter.

194
00:19:37,760 --> 00:19:44,760
Viele Sachen, die eben auch, sage ich mal, für eine Fahrt auf den Acker passen würden.

195
00:19:44,760 --> 00:19:47,760
Kein Prius. Aber sämtliche Lifts waren Prius.

196
00:19:47,760 --> 00:19:51,760
Und das hat damit natürlich zu tun, dass erstens die Kundschaft das erwartet,

197
00:19:51,760 --> 00:19:57,760
und zweitens, dass man für den Prius, glaube ich, irgendwie kriegt man eine Zulage von Uber.

198
00:19:57,760 --> 00:20:01,760
Oder kann man das von Uber sich leasen lassen, irgendwie sowas.

199
00:20:01,760 --> 00:20:05,760
Es hieß also, und das habe ich dann mit allen Apps gemacht, und das wiederholte sich immer,

200
00:20:05,760 --> 00:20:10,760
dass sozusagen diese Apps so taten, als würden sie eine Geografie wiedergeben.

201
00:20:10,760 --> 00:20:17,760
Eine genuin lokale Geografie. Aber im Grunde genommen in Wahrheit die Geografie,

202
00:20:17,760 --> 00:20:27,760
die Lebenswelt der Programmierer dieser Apps, dieser doch ziemlich verschiedenen Gegend, einfach überstöten.

203
00:20:27,760 --> 00:20:33,760
Und das habe ich damit gemeint, dass einerseits die Fragen, wie diese Apps funktionieren,

204
00:20:33,760 --> 00:20:36,760
eindeutig einer ganz spezifischen Lebenswelt entnommen werden.

205
00:20:36,760 --> 00:20:40,760
Einer relativ privilegierten Lebenswelt, aber auch einfach einer lokalen Lebenswelt.

206
00:20:40,760 --> 00:20:43,760
Eine Lebenswelt, die nicht so irre groß ist.

207
00:20:43,760 --> 00:20:51,760
7 Millionen Menschen, 6 Counties, ich weiß jetzt nicht wie viele Square Miles, aber nicht so irre viele.

208
00:20:51,760 --> 00:20:58,760
Und das eben aber doch so mit dem Verständnis angetreten wird, dass das doch für alles jetzt funktionieren wird.

209
00:20:58,760 --> 00:21:03,760
Jeder, der mal versucht hat, durch eine mittelalterliche Stadt mit Google Maps zu fahren, hat das auch schon erlebt.

210
00:21:03,760 --> 00:21:10,760
Dass Google Maps eindeutig sich entschieden hat, als Straße zu werten, was lokal als Straße gewertet wird.

211
00:21:10,760 --> 00:21:16,760
Und das ist auch so eine Sache, wo einfach einem Bewohner des Bay Area eben nicht einfallen würde,

212
00:21:16,760 --> 00:21:19,760
dass in mittelalterlichen Städten eine Straße sehr wohl existieren kann.

213
00:21:19,760 --> 00:21:25,760
Dass man sie aber mit einem Auto wirklich nicht befahren sollte, wenn man es vermeiden kann.

214
00:21:25,760 --> 00:21:32,760
Also das sind so Sachen, wo man einfach merkt, es sind nicht nur so lokale Produktionen diese Apps.

215
00:21:32,760 --> 00:21:35,760
Sondern sie kommen auch aus einem ganz bestimmten Milieu.

216
00:21:35,760 --> 00:21:47,760
Und dieses Milieu hat, sage ich mal, wenig Einbildungskraft, was lokale Besonderheiten angeht.

217
00:21:47,760 --> 00:21:51,760
Das heißt, diese Menschen rekrutieren sich aus einer sehr bestimmten Schicht.

218
00:21:51,760 --> 00:21:56,760
Aus sehr bestimmten Unis, aus sehr bestimmten Regionen.

219
00:21:57,760 --> 00:22:02,760
Und dadurch werden gewisse Aspekte gar nicht sichtbar.

220
00:22:02,760 --> 00:22:10,760
Ich hatte einmal ein Gespräch, um die Gedanken abzuschließen, bei einer Party mit einem Freund, der bei Uber arbeitete.

221
00:22:10,760 --> 00:22:16,760
Und der mir sagte, dass Uber sehr viel besser sei als die Taxiunternehmen.

222
00:22:16,760 --> 00:22:22,760
Weil viele Taxiunternehmen natürlich in Gebiete mit hoher schwarzer Bevölkerung prinzipiell nicht hinfahren.

223
00:22:22,760 --> 00:22:24,760
Das stimmt auch, da hatte er recht.

224
00:22:24,760 --> 00:22:27,760
Und er sagte, Uber hat das eben ausgeschaltet.

225
00:22:27,760 --> 00:22:30,760
Was nicht stimmte, aber das wusste er damals nicht.

226
00:22:30,760 --> 00:22:32,760
Es gibt Indizien, dass die es genauso machen.

227
00:22:32,760 --> 00:22:38,760
Aber dann habe ich ihn gefragt, jeder kann eben unseren Service benutzen.

228
00:22:38,760 --> 00:22:42,760
Und dann sagte ich, was ist denn mit jemandem, der keine Kreditkarte hat oder kein Smartphone?

229
00:22:42,760 --> 00:22:44,760
Und dann sagte er, oh.

230
00:22:44,760 --> 00:22:50,760
Und dann dachte ich, Moment, du arbeitest seit zwei Jahren bei dieser Firma.

231
00:22:50,760 --> 00:22:55,760
Und du hast noch keinen Gedanken darauf verschwendet, dass es Menschen gibt in dieser Stadt, die keine Kreditkarte haben.

232
00:22:55,760 --> 00:22:57,760
Und die kein Smartphone haben.

233
00:22:57,760 --> 00:22:59,760
Und dann sprichst du ständig von allen.

234
00:22:59,760 --> 00:23:01,760
Das ist für alle da. Uber ist für alle da.

235
00:23:01,760 --> 00:23:03,760
Das ist doch ein Universales.

236
00:23:03,760 --> 00:23:06,760
In seiner Welt hatte einfach jeder Kreditkarte und Smartphone.

237
00:23:06,760 --> 00:23:08,760
Die Vorstellung, das hört man häufig.

238
00:23:08,760 --> 00:23:10,760
Everyone's got a Smartphone.

239
00:23:10,760 --> 00:23:12,760
No, not everyone has a Smartphone.

240
00:23:12,760 --> 00:23:19,760
Das sind so die Momente, wo die Grenzen ihrer Welt, sehr schnell die Grenzen unserer Möglichkeiten werden.

241
00:23:19,760 --> 00:23:21,760
Wo wir plötzlich merken, oh, wir sind damit nicht gemeint.

242
00:23:21,760 --> 00:23:29,760
Nicht weil ihr irgendwie das Böse gemeint habt, sondern wenn ihr genuin nicht kapiert habt, dass es Menschen gibt, die nicht so sind wie ihr.

243
00:23:29,760 --> 00:23:40,760
Und tatsächlich ist ja die Uni, an der du arbeitest, Stanford, durchaus aktiv beteiligt an der Fabrikation dieser sozio-technischen Imaginationen des Silicon Valley.

244
00:23:40,760 --> 00:23:43,760
Vielleicht können wir da noch ein bisschen genauer eintauchen.

245
00:23:43,760 --> 00:23:50,760
Also worin besteht der, sagen wir, der Anteil von Stanford an diesem Prozess des Bounds?

246
00:23:50,760 --> 00:23:55,760
Und mich würde auch interessieren, ob du einen Wandel feststellen kannst.

247
00:23:55,760 --> 00:24:03,760
Ich kann mich erinnern, in deinem Buch, da nimmst du einmal auch Bezug auf das Buch von Fred Turner, From Counterculture to Cyberculture.

248
00:24:03,760 --> 00:24:10,760
Und wenn ich mich richtig erinnere, grenzt du das aber ein bisschen ab und stellst fest, okay, die Generation, die der Fred Turner damals beschreibt,

249
00:24:10,760 --> 00:24:17,760
und das war 2006, glaube ich, das Buch, das ist schon noch irgendwie eine andere Generation als die, die du jetzt dort antrittst.

250
00:24:17,760 --> 00:24:21,760
Was macht da den Unterschied aus und was ist die Rolle von Stanford insgesamt in dem Ganzen?

251
00:24:21,760 --> 00:24:30,760
Ja, also wie der Titel von Freds Buch hier schon besagt, und das lege ich allen Zuhörern ans Herz, ein wirklich tolles, ein wirklich tolles Buch.

252
00:24:30,760 --> 00:24:39,760
Ja, also Freds Buch bezieht sich, wie der Titel ja sagt, auf das Nachleben der Gegenkultur in den Tech-Unternehmen.

253
00:24:39,760 --> 00:24:47,760
Und das stimmt tatsächlich, dass die Kollegen bei mir in der Informatik waren bis vor kurzem noch, einige sind es immer noch,

254
00:24:47,760 --> 00:24:57,760
im Grunde genommen Hippies, die Computer benutzt haben, um sich Gedanken zu machen über Medien, Bewusstsein, die Gesellschaft.

255
00:24:57,760 --> 00:25:01,760
Bei die waren Computer sozusagen eine Spielart der Gegenkultur.

256
00:25:01,760 --> 00:25:07,760
Das waren natürlich auch diejenigen, die häufig nicht in die Unternehmen gegangen sind, sondern stattdessen sich eben für den Campus entschieden haben,

257
00:25:07,760 --> 00:25:13,760
was natürlich auch noch mal eine Art Präselektion war, das heißt, die sind natürlich nicht repräsentativ.

258
00:25:13,760 --> 00:25:21,760
Aber ich denke eben, dass diese Kollegen immer mehr verzweifelt sind, ich zitiere auch einen Kollegen, der wirklich daran verzweifelt ist und Stanford verlassen hat,

259
00:25:21,760 --> 00:25:31,760
weil er immer mehr, was er The Get Rich Quick Brigade genannt hat, also diejenigen, die einfach für diese Industrie eben ein ganz starkes,

260
00:25:31,760 --> 00:25:41,760
ganz stark mit dem Profit-Motiv verbunden war und die im Grunde genommen in seine Kurse kamen, um zu lernen, wie man das macht.

261
00:25:41,760 --> 00:25:46,760
Und das ist für diese Kollegen war das eine wirklich große Enttäuschung.

262
00:25:47,760 --> 00:25:58,760
Und viele von ihnen haben den rasanten Anstieg an Informatik-Studenten an Stanford eher als persönliche Katastrophe wahrgenommen, als Triumph.

263
00:25:58,760 --> 00:26:03,760
Das ist mehr wie ein Zauberlehrling. Für die Geister, die sie riefen, werden sie nicht los.

264
00:26:03,760 --> 00:26:09,760
Also es ist, sie machen einerseits ihre Sache halt so gut, dass man um die nicht herumkommt.

265
00:26:09,760 --> 00:26:17,760
Umgekehrt heißt es, dass sich immer mehr Studenten herumschlagen müssen, von denen immer weniger sich wirklich genuin für die Fragen interessieren,

266
00:26:17,760 --> 00:26:25,760
die die überhaupt erst in die Informatik getrieben haben und immer mehr sich für den Schnickschnack drum herum interessieren,

267
00:26:25,760 --> 00:26:29,760
der meinen Kollegen dem Empfinden nach eher peinlich ist, um ganz ehrlich zu sein.

268
00:26:29,760 --> 00:26:34,760
Das ist das Erbe der Gegenkultur doch eher Verhalten, würde ich sagen.

269
00:26:34,760 --> 00:26:38,760
Und das ist schon ein sehr wichtiger generationeller Einschnitt.

270
00:26:38,760 --> 00:26:46,760
Ich will in dem Buch zeigen, dass es natürlich schon, also Turner ist nicht, Turner's Narrativ ist jetzt nicht komplett abgelöst.

271
00:26:46,760 --> 00:26:54,760
Es gibt es noch, die lebt weiter, aber so direkt, wie man noch 1995 wahrscheinlich diese Linie hätte ziehen können,

272
00:26:54,760 --> 00:27:01,760
auf jeden Fall 2006 noch, als Fred das Buch schrieb, würde ich sagen, das geht so nicht mehr.

273
00:27:01,760 --> 00:27:09,760
Also da ist das Erbe doch, sage ich mal, verhaltener oder einfach angereichert durch andere Einflüsse.

274
00:27:09,760 --> 00:27:21,760
Allerdings würde ich sagen, diese Generation mag jetzt, das zeigt sich ganz, ganz behutsam.

275
00:27:21,760 --> 00:27:26,760
Ich stelle das als Vermutung, als Vermuten der Diagnose an.

276
00:27:27,760 --> 00:27:31,760
Es kann sein, dass ich mir in zwei Jahren nochmal anhöre und sage, ach Gott, du Naivling.

277
00:27:31,760 --> 00:27:36,760
Aber das ist so mein Gefühl, dass sich das Blatt wieder wendet.

278
00:27:36,760 --> 00:27:45,760
Also mein Kollege Eric Roberts, den ich in dem Buch auch zitiere, der Informatiker in Stanford war jetzt am Reed College in Portland, Oregon.

279
00:27:45,760 --> 00:27:53,760
Der sagte eben, uns hat es hart erwischt, dass wir 2008 die Einzigen waren, dass die Technologie die Einzige war,

280
00:27:53,760 --> 00:27:59,760
die nicht abgekratzt ist während der Finanzkrise. Und dann kamen eben diese Get Rich Quick Typen.

281
00:27:59,760 --> 00:28:06,760
Und ich habe das auch beobachtet, genau das, was er da gesehen hat, habe ich auch bei meinen Studenten beobachtet.

282
00:28:06,760 --> 00:28:11,760
Auch das Elterndruck gemacht haben, das Komilitonendruck gemacht haben.

283
00:28:11,760 --> 00:28:17,760
Dass jemand sagt, was machst du denn mit dem Englisch-Major? Willst du da nur Burgerflippen gehen oder sowas?

284
00:28:17,760 --> 00:28:22,760
Also wirklich hartes Zeugs. Das ändert sich jetzt wieder, habe ich den Eindruck.

285
00:28:22,760 --> 00:28:29,760
Und zwar nicht, aber nicht in der Hinsicht, dass plötzlich Leute Hippies da in den Vorlesungen sitzen, sondern dass Menschen da sitzen,

286
00:28:29,760 --> 00:28:34,760
die begriffen haben, die sozusagen den Kapitalismus voll mit an Bord genommen haben und sagen,

287
00:28:34,760 --> 00:28:42,760
okay, wir werden ausgebildet, um Arbeiter zu werden in einem Konzern. Und wir treten da auf als Belegschaft.

288
00:28:42,760 --> 00:28:47,760
Und das heißt, wir verstehen sehr wohl, dass wir streiken können, dass wir klagen können,

289
00:28:47,760 --> 00:28:53,760
dass es Bürgerrechte gibt, die wir haben, die wir einklagen können, dass es Antidiskriminierungsgesetze gibt,

290
00:28:53,760 --> 00:28:57,760
die, wenn sie missachtet werden, wir eine Pflicht haben, anzuzeigen.

291
00:28:57,760 --> 00:29:05,760
Also dass die den Kapitalismus, den Silicon Valley in den letzten zwölf Jahren einerseits absolut gemacht hat,

292
00:29:05,760 --> 00:29:13,760
hypostatisiert hat, aber andererseits eben immer weggewischt hat und gesagt, nein, nein, nein, wir sind kein Unternehmen, wir sind eine Familie.

293
00:29:13,760 --> 00:29:17,760
Nein, nein, nein, wir müssen ja keinen Profit machen, wir verändern ja die Welt.

294
00:29:17,760 --> 00:29:23,760
Diesen Bullshit lassen sie denen nicht mehr durchgehen, sagen, ja, wenn Kapitalismus dann aber, wenn A dann auch B.

295
00:29:23,760 --> 00:29:28,760
Wenn Kapitalismus für die Investoren gilt, dann gilt es auch für die Belegschaft.

296
00:29:28,760 --> 00:29:37,760
Und das heißt, wir bleiben weg, wenn ihr anfängt mit Erdogan irgendwelche Geschäfte von wegen IP-Tracking aufzunehmen.

297
00:29:37,760 --> 00:29:52,760
Das heißt, wenn ihr die Cafeteria-Arbeiter, wenn ihr die Leute, die uns den Lunch vorsetzen, wenn ihr die nicht ausreichend bezahlt, dann streiken wir Programmierer auch.

298
00:29:52,760 --> 00:29:55,760
Und so klingen meine Studenten jetzt.

299
00:29:55,760 --> 00:30:04,760
Also es kann sein, dass Fred eine Generation beschrieben hat, ich jetzt die nächste beschreibe, im Moment ihre Ablösung.

300
00:30:04,760 --> 00:30:08,760
Es kann wirklich sein, dass wir in zwei Jahren, dass ich ein ganz neues Buch schreiben müsste.

301
00:30:08,760 --> 00:30:11,760
Ich glaube es nicht ganz, ich glaube nicht ganz daran.

302
00:30:11,760 --> 00:30:14,760
Ich glaube, das Kapital findet immer einen Weg.

303
00:30:14,760 --> 00:30:27,760
Aber auf jeden Fall die Art Geläubigkeit, die mich zuerst dazu gebracht hat, dieses Buch zu schreiben und die mich sehr beängstigt hat, muss ich sagen.

304
00:30:27,760 --> 00:30:34,760
Das war so 2012, 13, 14, also die Ideen, die in dieses Buch dann einflossen zum ersten Mal für mich wichtig wurden.

305
00:30:34,760 --> 00:30:41,760
Die, glaube ich, sind nicht mehr so dominant, wie sie einmal waren.

306
00:30:41,760 --> 00:30:47,760
Es gibt sie noch, ich habe noch ganz viele Unterhaltungen mit Studenten, die so klingen, aber ich habe viel mehr mit den anderen.

307
00:30:47,760 --> 00:30:52,760
Und die Rückmeldungen auf die englische Fassung des Buchs von Studenten ist genau in die Richtung.

308
00:30:52,760 --> 00:30:55,760
Ich will in die Tech-Industrie einsteigen.

309
00:30:55,760 --> 00:30:57,760
Wie mache ich das ethisch?

310
00:30:57,760 --> 00:30:58,760
Wie kann ich sicherstellen?

311
00:30:58,760 --> 00:31:04,760
Was für Fragen soll ich denn da stellen, damit ich sicherstellen kann, dass die auch auf ihre Belegschaft hören?

312
00:31:04,760 --> 00:31:11,760
Mit wem soll ich reden und zu schauen, dass LGBT und das People of Color da willkommen sind?

313
00:31:11,760 --> 00:31:14,760
Und ich muss sagen, weiß ich nicht, aber es ist eine tolle Frage.

314
00:31:14,760 --> 00:31:16,760
Und es ist eine richtige Frage.

315
00:31:16,760 --> 00:31:20,760
Wenn du da so einsteigst, dann wird das Unternehmen auch schon dadurch besser.

316
00:31:20,760 --> 00:31:25,760
Dass jemand sagt, ja, hör mal, so funktioniert die App, aber wo ich herkomme, gar nicht.

317
00:31:25,760 --> 00:31:27,760
Es wird auch das Produkt besser machen.

318
00:31:27,760 --> 00:31:34,760
Aber es wird auch vor allem diese Firmen, es wird diese toxische Monokultur sehr schnell verändern, glaube ich.

319
00:31:34,760 --> 00:31:47,760
Du schreibst dann auch in deinem Buch, dass der Tech-Sektor, wie wir ihn heute kennen, entstanden ist, als ein unhinterfragtes Wertesystem auf große Mengen Geld traf, die keine andere Antwortmöglichkeit fanden.

320
00:31:47,760 --> 00:31:52,760
Und du hast jetzt schon mehrmals auch das Kapital und im Speziellen eben das Risikokapital angesprochen.

321
00:31:52,760 --> 00:31:59,760
Welche Rolle spielt denn dieses Risikokapital in der Gestaltung der Technologien, die uns alle ja umgeben?

322
00:31:59,760 --> 00:32:11,760
Eine enorme Rolle, denn viele der genuin interessanten Ideen, die Silicon Valley in den zwölf Jahren, die ich hier gelebt habe, generiert hat, sind ja nie zu Markt gekommen.

323
00:32:11,760 --> 00:32:19,760
Weil die Frage ja nicht ist, wird das die Welt verändern, sondern wird es unsere Investoren reich machen?

324
00:32:19,760 --> 00:32:35,760
Und sag ich mal, weil der Anreiz einen Mythos um sich selber und um das eigene Unternehmen zu stricken, anstatt einfach sich hinzusetzen und ein Produkt zu schaffen, natürlich da am wichtigsten ist, wo Risikokapital bedient werden muss.

325
00:32:35,760 --> 00:32:47,760
Das heißt, die mediale Zumüllung, die wir alle erfahren durch Menschen wie Elon Musk und so weiter, das ist ein Stil des Thought Leadership, das sozusagen ohne Risikokapital gar nicht zu denken wäre.

326
00:32:47,760 --> 00:32:54,760
Denn eigentlich spielen die ja nicht, du und ich sind kollateral im Publikum dafür.

327
00:32:54,760 --> 00:32:57,760
Das eigentliche Publikum sind die Kapitalgeber.

328
00:32:57,760 --> 00:33:02,760
Wenn wir uns für Elon Musk irgendwie interessieren, dann interessieren sich auch die Kapitalgeber für ihn.

329
00:33:02,760 --> 00:33:30,760
Und das ist glaube ich äußerst wichtig, dass dieser Mythos, den diese Unternehmen um sich gestrickt haben, ganz stark damit einhergeht, dass sie einerseits eben von den Ideen und den Hobbys fast, den Grillen der Kapitalgeber abhängen, aber dass sie andererseits eben fast nie Geld verdienen.

330
00:33:30,760 --> 00:33:37,760
Das hat diese sehr interessante, ich habe das vorhin die Aufmerksamkeitökonomie genannt, das ist glaube ich kein schlechtes Wort dafür.

331
00:33:37,760 --> 00:33:44,760
Dass es wichtig ist, sozusagen alle mit Silicon Valley-Stories zuzuspammen, damit eben das Geld weiterfließt.

332
00:33:44,760 --> 00:33:57,760
WeWork ist ein ziemlich gutes Beispiel dafür, wo der Mythos eben dazu da war, ich sage es jetzt mal brutal, zu kaschieren, dass das eigentlich ein Vermieter war, der kein Geld verdient hat.

333
00:33:57,760 --> 00:34:02,760
Was man als Vermieter in dieser Lage erstmal schaffen muss.

334
00:34:02,760 --> 00:34:05,760
Das ist gar nicht so einfach, als Vermieter Geld zu verlieren.

335
00:34:05,760 --> 00:34:16,760
WeWork hat es spektakulär geschafft, aber hat eben sozusagen dann den Jargon und den Persönlichkeitskult von Unternehmen wie Apple oder Google kopiert,

336
00:34:16,760 --> 00:34:26,760
um eben sozusagen eine Runway, eine Startbahn zu erzeugen, die sozusagen es allen ermöglicht, ist in Ordnung, wenn die ein paar Milliarden verbraten.

337
00:34:26,760 --> 00:34:31,760
Das wird ja am Ende dann total disruptive und toll und dann kriegen wir alle unser Geld zurück.

338
00:34:31,760 --> 00:34:42,760
Das scheint jetzt eher ein Pustekuchen zu sein, aber gut, das ist, da will ich jetzt kein, das Wort Schadenfreude will ich jetzt nicht bedienen.

339
00:34:42,760 --> 00:34:55,760
Aber es ist auffällig eben, dass das Risikokapital eigentlich ganz stark nicht nur die Industrie selber geprägt hat, sondern eben auch unsere Wahrnehmung dieser Unternehmen.

340
00:34:55,760 --> 00:35:09,760
Und hinzu kommt aber eben auch, dass das Risikokapital, also ich will jetzt nicht sagen, dass das Risikokapital sozusagen der Bad Guy ist in meinem Buch.

341
00:35:09,760 --> 00:35:24,760
An Schurken hat das, es hat viele Schurken, sage ich mal, aber es ist schon eine besonders fragwürdige Instanz in Silicon Valley.

342
00:35:24,760 --> 00:35:31,760
Ich gebe drei Beispiele. Erstens ist Risikokapital ein Riesengrund, warum diese Industrie so homogen ist.

343
00:35:31,760 --> 00:35:47,760
Es gibt Versuche von Kapitalgebern und von Denkern, könnte man zum Beispiel Ellen Pow nennen, die bei kleiner Perkins ausgestiegen ist vor ein paar Jahren, ziemlich spektakulär.

344
00:35:47,760 --> 00:35:58,760
Die versuchen eben Finanzstrukturen aufzubauen, die es nicht weißen und nicht männlichen Founders ermöglichen sollen, an Risikokapital zu kommen.

345
00:35:58,760 --> 00:36:09,760
Das ist derzeit sehr, sehr schwierig. Viele dieser Risikokapitalgeber sind die Gründer von vor 20 Jahren oder vor 10 Jahren, 15 Jahren nicht, also Peter Thiel, Sam Altman und so weiter.

346
00:36:09,760 --> 00:36:30,760
Das reproduziert sich immer selber. Das sind häufig Stanford-Absolventen oder Harvard-Absolventen, die weiter Geld an weiße männliche Stanford- und Harvard-Absolventen schaufeln, damit die irgendwie eine neue App schaffen können, die es revolutionieren soll, wie wir Katzenbilder verteilen oder sowas.

347
00:36:30,760 --> 00:36:49,760
Das ist das Erste. Die Homogenität in Silicon Valley ist teilweise, oder wer hier gewinnt und wer hier verliert, ist ganz stark abhängig von der Ethnie, vom Geschlecht, vom Habitus, vom Sozialstatus, von der Uni, die man besucht hat und so weiter.

348
00:36:49,760 --> 00:36:54,760
Und daran sind ganz maßgeblich die Kapitalgeber schuld.

349
00:36:54,760 --> 00:37:13,760
Zweitens ist diese Art Risikobereitschaft, die eigentlich eine Art Hasenfüßigkeit ist, das heißt eine, die so tut, die den Gestus eines Risikos zwar liebt, andererseits aber doch relativ scheu vor Genuim Neuen ist, wie wir es vorhin gesagt haben, ist auch häufig ein Artefakt dieser Kapitalgeber.

350
00:37:13,760 --> 00:37:27,760
Das sind Milliardäre, die Milliardäre bleiben wollen. Die haben keinen Anreiz, etwas zu machen. Ich weiß noch nicht, wie das Geld verdienen soll, aber wäre das nicht toll, wenn alle sauberes Wasser bekommen würden.

351
00:37:27,760 --> 00:37:37,760
Das ist nicht interessant. Wenn irgendjemand in dein Haus kommt und die Wäsche für dich wäscht und dann weniger bezahlt bekommt, als wenn er das jetzt machen würde, dann gehören sie alle hin.

352
00:37:37,760 --> 00:37:46,760
Das ist die Art Revolution, die sie sich vorstellen können. Jeder Gründer im Valley muss sich fragen lassen, wie viel Revolution sich machen lässt, wenn eine Revolution von Milliardären finanziert wird.

353
00:37:46,760 --> 00:37:57,760
Das ist eben, was bei diesen Kapitalgebern, bei den angel Investors und bei den Venture Capital Funds eben immer die Frage ist.

354
00:37:57,760 --> 00:38:10,760
Und dann drittens, würde ich dazu sagen, sind diese Menschen ganz maßgeblich an dem Mythos der Meritocracy beteiligt im Silicon Valley.

355
00:38:10,760 --> 00:38:23,760
Das heißt, das sind häufig Menschen, die, um es ganz ehrlich zu sagen, einmal riesig Glück hatten. Die sind nach Monte Carlo gefahren, haben alles auf 38 Schwarz gesetzt und dann kam 38 Schwarz. Super! Fantastisch!

356
00:38:23,760 --> 00:38:38,760
Und jetzt sind sie Milliardäre. Toll! Und jetzt als Geldgeber gehen sie davon aus, dass diese eine Wette eigentlich doch ein Indiz sei, dass sie absolut brillant sind, dass sie die absoluten Übergenies sind.

357
00:38:38,760 --> 00:39:07,760
Das ist eben der Punkt. Diese Kapitalgeber verkaufen Glück als Verdienst und umgekehrt verkaufen Unglück, verkaufen es nicht geschafft zu haben, sowohl unter Programmierern als auch unter denen, die für Uber fahren oder für DoorDash Pizzen austragen, als im Grunde genommen ebenso moralisch gedeckt.

358
00:39:07,760 --> 00:39:30,760
Die haben irgendwas falsch gemacht. Die waren nicht disruptive genug. Die waren nicht aktiv genug. Aber die basale Wahrheit, dass sie eben nicht auf 38 Schwarz gesetzt haben, dass sie nicht Glück gehabt haben, dass sie vielleicht auch nicht das Geld hatten nach Monte Carlo zu fahren, das kann in diesem Ökosystem nicht zur Sprache kommen und es wird radikal ausgeblendet.

359
00:39:30,760 --> 00:39:47,760
Also ich würde sagen, dass in diesen drei Punkten sind die Risikoinvestoren wirklich sehr verantwortlich, stark verantwortlich, nicht absolut verantwortlich, aber stark verantwortlich für das toxische Umfeld, das viele dieser Unternehmen geschaffen haben.

360
00:39:48,760 --> 00:40:05,760
Sehr spannend, ja. Also es gibt ja verschiedene Moves, die sagen, die Tech-Industrie darauf hat, dass die von die jetzt Beschriebenen mit dem Risikokapital sind sicher unter den Einflussreicheren.

361
00:40:05,760 --> 00:40:24,760
Ein anderer unglaublich geschickter Move, muss man sagen, ist der, dass sie es geschafft haben, so zu tun, als seien Social Media Plattformen quasi neutrale Infrastruktur und sollten deshalb nicht für die durch sie vertriebenen Inhalte verantwortlich gemacht werden.

362
00:40:24,760 --> 00:40:32,760
Damit es einmal erwähnt ist, was ist der Communication Decency Act und wieso gibt es die behauptete Neutralität der Plattform eben nicht?

363
00:40:32,760 --> 00:40:45,760
Ja, also das ist die berühmte Section 230 des Communication Decency Act, die eben sagen soll, die einerseits, also ich habe mehrere Kollegen, die sich damit von der juristischen Seite beschäftigen und die sagen, das hat natürlich schon seine Begründung.

364
00:40:45,760 --> 00:41:08,760
Die Überlegung ist die, dass Twitter für einen Inhalt natürlich nicht redaktionell gerade stehen kann, einfach auch aus der reinen Masse der Tweets heraus, wie jetzt, sage ich mal, der San Francisco Chronicle für einen Text, den er selber angefordert, bezahlt, gesetzt und in Druck gegeben hat.

365
00:41:08,760 --> 00:41:12,760
Also es hat im Grunde genommen eine relativ logische Grundlage.

366
00:41:12,760 --> 00:41:19,760
Wozu es aber geführt hat, ist eben, dass sich diese Plattformen eben komplett neutral geben können, ohne es wirklich zu sein.

367
00:41:19,760 --> 00:41:24,760
Ich meine, diese Kritiken stammen nicht von mir, das ist nicht, das kann man bei anderen viel besser nachlesen.

368
00:41:24,760 --> 00:41:33,760
Aber das Problem ist einerseits eben, dass für sowohl Twitter als auch für Facebook Engagement das Wichtigste ist.

369
00:41:34,760 --> 00:41:48,760
Das heißt, da das im Grunde genommen Unternehmen sind, die per Werbung getragen werden, ist jemand, ist ein Twitter User, der aufhört zu doom scrollen, wie man heute sagt, ein schlechter User, jemand, der sich von Facebook auslockt, um eine Zeitung zu lesen, ist ein schlechter Facebook User.

370
00:41:48,760 --> 00:41:56,760
Und das heißt, dass die immer den Content priorisieren, der die stärkste emotionale Wirkung auslösen.

371
00:41:56,760 --> 00:42:08,760
Das heißt, dass eine falsche Meldung über Flüchtlinge, die hunderttausendmal geteilt wird von jedem rassistischen Onkel, der sich von Facebook auslockt, ein schlechter User ist.

372
00:42:08,760 --> 00:42:37,760
Das heißt, dass eine falsche Meldung über Flüchtlinge, die hunderttausendmal geteilt wird von jedem rassistischen Onkel in ganz Mitteleuropa, für die viel, viel wertvoller ist als ein Interview mit sechs Geflüchteten über ihre Erfahrungen, mit schönen Bildern und mit einem sehr melancholischen oder nachdenklichen Fazit am Schluss.

373
00:42:37,760 --> 00:42:42,760
Das wird zwar auch geteilt werden, aber ist nicht so schnell konsumierbar.

374
00:42:42,760 --> 00:42:53,760
Es hat keinen offensichtlichen, hat einen komplizierteren emotionalen Pitch und ist deswegen eben dann vom Engagement her kleiner.

375
00:42:53,760 --> 00:43:07,760
Das heißt, die sind im Grunde genommen dazu ausgelegt, darauf ausgelegt, eine ständige Aufregeökonomie zu betreiben.

376
00:43:07,760 --> 00:43:14,760
Wir kennen das ja alle. Man schaltet Twitter an und der Puls rast nach drei Minuten.

377
00:43:14,760 --> 00:43:19,760
Das spricht dieser Toilet, wie alle sagen.

378
00:43:19,760 --> 00:43:35,760
Was ich in dem Buch, was das ver.li.denken nennt, neu dazu beitrage, es kann sein, dass jemand anderes das schon gesagt hat, in dem Fall entschuldige ich mich, aber das war sozusagen für mich ein Gedanke, den ich noch nicht gelesen hatte,

379
00:43:35,760 --> 00:43:45,760
war eben, dass die Leute wie Jack Dorsey, der Gründer und derzeitige CEO von Twitter, derzeit mit Rauschebart im Kongress zu beobachten,

380
00:43:45,760 --> 00:43:57,760
dass die sich gerne auf so einen alten Topos zurückziehen, nämlich die Enttäuschung, dass wir die schönen Tools, die sie uns geschaffen haben, missbrauchen.

381
00:43:57,760 --> 00:44:07,760
Wenn wir nur die Schönheit dieses Mediums erkennen könnten, dann wäre alles besser.

382
00:44:07,760 --> 00:44:13,760
Das ist für mich ein ganz fataler Topos.

383
00:44:13,760 --> 00:44:20,760
Enttäuschung mit den Kommunikationsmedien ist ein äußerst konservativer Move.

384
00:44:20,760 --> 00:44:27,760
Nicht nur auf der konservativen Seite muss man sagen, es ist ein relativ Wohlfeil einerseits.

385
00:44:27,760 --> 00:44:40,760
Es ist andererseits eine Art Pauschalisierung, also wenn man im deutschen Feuilleton liest, auf Twitter war zu hören, dann merkt man gleich, aha, da werden jetzt die Schmuddelkinder sozusagen in ihre Ecke gestellt.

386
00:44:40,760 --> 00:44:49,760
Ich halte diese Art Enttäuschung, man kann beides sagen.

387
00:44:49,760 --> 00:44:53,760
Einerseits ist viel von Twitter ziemlich scheiße.

388
00:44:53,760 --> 00:44:59,760
Andererseits finde ich Enttäuschung über Twitter ostentative, Enttäuschung über die sozialen Medien genauso scheiße.

389
00:44:59,760 --> 00:45:06,760
Das sind imperfekte Kommunikationsplattformen, ebenso wie alle unsere anderen Kommunikationsplattformen.

390
00:45:06,760 --> 00:45:11,760
Und da haben wir, tragen wir eine Mitschuld dran und da sollten wir uns das besser machen.

391
00:45:11,760 --> 00:45:18,760
Aber ganz, ganz stark trägt Jack Dorsey eine Mitschuld daran und der muss seine Plattform ändern.

392
00:45:18,760 --> 00:45:20,760
Und das fängt ja jetzt an.

393
00:45:20,760 --> 00:45:26,760
Also nach vier Jahren Trump werden diese Tweets endlich mal als Fehlinformation markiert.

394
00:45:26,760 --> 00:45:34,760
Dass sie das nicht gewagt haben, wer der Präsident ist, wird immer ein Makel auf diesem Unternehmen sein.

395
00:45:34,760 --> 00:45:39,760
Aber es zeigt ja doch, dass sie sich das schon überlegt haben.

396
00:45:39,760 --> 00:45:41,760
Die hatten diese Strategie.

397
00:45:41,760 --> 00:45:50,760
Und dieses kleine Informationszeichen unter diesen Tweets oder dieses kleine Do you want to see this content und so weiter

398
00:45:50,760 --> 00:45:59,760
ist im Grunde genommen ein Armutszeugnis für Twitter, weil es sagt, so transparent wie wir uns geben, sind wir halt nicht.

399
00:45:59,760 --> 00:46:03,760
Machtstrukturen beeinflussen halt doch, was hier passiert.

400
00:46:03,760 --> 00:46:05,760
Wir sind nicht alle gleich.

401
00:46:05,760 --> 00:46:11,760
Auf einer abstrakten Ebene sind ich und Donald Trump genauso Twitterer, aber eben doch nicht.

402
00:46:11,760 --> 00:46:18,760
Ich habe etwas unfreundliches bei Faschos getweetet und durfte dafür 48 Stunden von Twitter weg.

403
00:46:18,760 --> 00:46:23,760
Wurde blockiert, weil mich natürlich irgendwie ein, nach dem Netz-DG, irgendjemand in Deutschland,

404
00:46:23,760 --> 00:46:26,760
ich habe den Fehler gemacht, das auf Deutsch zu tweeten, nehme ich an.

405
00:46:26,760 --> 00:46:37,760
Aber umgekehrt durfte Trump ja unmögliches verbreiten und alle möglichen Guidelines verletzen und durfte trotzdem weitermachen.

406
00:46:37,760 --> 00:46:46,760
Also insofern hat Twitter sozusagen seine eigene, ist seinem eigenen Anspruch, eine Art Forum zu sein, nie gerecht geworden.

407
00:46:46,760 --> 00:46:53,760
Er hat es nie wirklich ernst genommen, dieses Versprechen von dem und hat andererseits doch dann immer den Enttäuschten markiert.

408
00:46:53,760 --> 00:47:05,760
Wenn ihr nur bessere Twitter-User wäret, dann gäbe es nicht so viele white nationalists auf Twitter.

409
00:47:05,760 --> 00:47:07,760
Nein, nein, nein.

410
00:47:07,760 --> 00:47:17,760
Die Art, die dieses Unternehmen Geld verdient, das Geschäftsmodell ist darauf ausgelegt, dass es genau so etwas hier gibt.

411
00:47:17,760 --> 00:47:24,760
Und dass das damit muss Jack Dorsey leben. Und wenn er das nicht kann, dann soll das ändern.

412
00:47:24,760 --> 00:47:30,760
Und letztlich muss man sagen, speist sich ja diese Enttäuschung eigentlich auch nur aus der vorhergegangenen Überhöhung, würde ich sagen, oder?

413
00:47:30,760 --> 00:47:33,760
Also ohne die ist das Ganze letztlich auch nicht denkbar.

414
00:47:33,760 --> 00:47:42,760
Und wir sind jetzt schon sehr nah an einem anderen Thema, was du in deinem Buch ansprichst, was mir auch große Freude gemacht hat beim Lesen, muss ich sagen.

415
00:47:42,760 --> 00:47:44,760
Und zwar geht es da um Trolle.

416
00:47:44,760 --> 00:47:49,760
Das fand ich wirklich überaus interessant oder ein guter Abschnitt in deinem Buch.

417
00:47:49,760 --> 00:47:57,760
Und im Grunde so, wenn ich das richtig verstehe, sagst du eigentlich, dass der Troll eigentlich die Violine spielt, wie sie gespielt werden soll.

418
00:47:57,760 --> 00:47:58,760
Genau.

419
00:47:58,760 --> 00:48:02,760
Vielleicht kannst du das ein bisschen beschreiben. Was ist die Logik des Trollens?

420
00:48:02,760 --> 00:48:07,760
Also für mich war, es gibt natürlich ganz viele verschiedene Arten des Trollens.

421
00:48:07,760 --> 00:48:11,760
Es gibt auch welche, die ich sehr, sehr lustig finde, muss ich zugeben, oder die ich sehr kreativ finde.

422
00:48:12,760 --> 00:48:17,760
Ich selber habe manchmal, wir sind ja alle irgendwie Trolle, die Vorstellung, dass es den Troll als Typen gibt.

423
00:48:17,760 --> 00:48:20,760
Also es ist eine Bandbreite.

424
00:48:20,760 --> 00:48:31,760
Aber eine sehr wichtige, eine sehr wichtige Art des Trollens finde ich eben die Art Intervention, von der gar nicht klar ist, was sie eigentlich für eine Art Kommunikation sein soll.

425
00:48:32,760 --> 00:48:39,760
Der Reply Guide zum Beispiel, der irgendwas beifügt, das irgendwie gar nicht zur Sache tut.

426
00:48:39,760 --> 00:48:44,760
Und wenn du ihn darauf hinweist, dann sagst du, ja, da bin ich halt missverstanden worden.

427
00:48:44,760 --> 00:48:51,760
Aber sich nie die Frage stellt, die z.B. Jacques Deux, die sich auch nicht stellt.

428
00:48:51,760 --> 00:48:54,760
Nämlich, wozu sollte das denn jetzt gut sein?

429
00:48:54,760 --> 00:48:57,760
Was war meine Kommunikation, sondern wozu sollte sie dienen?

430
00:48:57,760 --> 00:49:00,760
Was wäre eine gute Antwort darauf gewesen?

431
00:49:00,760 --> 00:49:04,760
Und das ist für mich eine Essenz, eine Art des Trollens.

432
00:49:04,760 --> 00:49:11,760
Es gibt andere Arten, das will ich gar nicht in Abrede stellen, aber ich glaube, ein Großteil des Trollens lässt sich darauf reduzieren,

433
00:49:11,760 --> 00:49:18,760
dass im Grunde genommen eine Kommunikation hergestellt wird, nur um enttäuscht zu werden.

434
00:49:18,760 --> 00:49:21,760
Ich wollte ja nur eine Frage stellen.

435
00:49:21,760 --> 00:49:24,760
Ich wollte ja nur sagen, dass ich das so nicht beobachtet habe.

436
00:49:24,760 --> 00:49:32,760
Ich wollte ja nur bitten, dass Sie, eine Person of Color, mir Belege bringen dafür, dass Sie rassistisch behandelt worden sind.

437
00:49:32,760 --> 00:49:34,760
Just asking questions.

438
00:49:34,760 --> 00:49:42,760
Wie das aussehen sollte, dass so ein Beweis gar nicht existiert, wird sozusagen, stillschweigend, vorausgesetzt, aber auch verschluckt.

439
00:49:42,760 --> 00:49:46,760
Das heißt, der Troll ist im Grunde genommen absolut enttäuschbar.

440
00:49:46,760 --> 00:49:48,760
Er ist immer schon enttäuscht.

441
00:49:48,760 --> 00:49:50,760
Egal, was zurückkommt, er wird erstmal ganz enttäuscht sein.

442
00:49:50,760 --> 00:49:52,760
Ich habe das ab so ernst gemeint.

443
00:49:52,760 --> 00:49:54,760
Ich habe das so nett gefragt.

444
00:49:54,760 --> 00:49:58,760
Und dann kommen Sie so mit Ihrer Cancel Culture.

445
00:49:58,760 --> 00:50:00,760
Mein Gott, wie können Sie nur?

446
00:50:00,760 --> 00:50:02,760
Das ist der Troll. Das ist der Jesus des Troll.

447
00:50:02,760 --> 00:50:08,760
Und das ist genau, wie du gesagt hast, das ist eigentlich keine Perversion der sozialen Netzwerke.

448
00:50:08,760 --> 00:50:12,760
Der Troll spielt die Orgel genauso, wie sie gebaut ist.

449
00:50:12,760 --> 00:50:14,760
Er drückt alle Tasten.

450
00:50:14,760 --> 00:50:18,760
Er nutzt die Kürze aus.

451
00:50:18,760 --> 00:50:22,760
Er ist persönlich getroffen, wenn es für ihn gut ist.

452
00:50:22,760 --> 00:50:24,760
Und er ist absolut unpersönlich.

453
00:50:24,760 --> 00:50:26,760
Der Geist der Maschine, wenn es gut für ihn ist.

454
00:50:26,760 --> 00:50:30,760
Das Beispiel, das ich bringe, ist die Journalistin Sarah Jong.

455
00:50:30,760 --> 00:50:40,760
Die vor Jahren sich von einem Nazitroll hat dazu verführen lassen, seine Logik sozusagen auf Weiße anzuwenden.

456
00:50:40,760 --> 00:50:42,760
In einem sehr lustigen Twitter-Thread.

457
00:50:42,760 --> 00:50:50,760
Der aber eben einfach gezeigt hat, was wäre, wenn ich eure Tweets auf Weiße Personen beziehen würde.

458
00:50:50,760 --> 00:50:58,760
Und dann wurde sie von den New York Times als Editorial Writer angeheuert.

459
00:50:58,760 --> 00:51:02,760
Also sozusagen als Leitartikelautorin angeheuert.

460
00:51:02,760 --> 00:51:06,760
Und dann kam die Trolle mit ihren alten Tweets.

461
00:51:06,760 --> 00:51:08,760
Aus dem Kontext gerissen natürlich.

462
00:51:08,760 --> 00:51:10,760
Jedes Mal, wenn sie irgendwas tweetet, kommen die.

463
00:51:10,760 --> 00:51:18,760
Was ich faszinierend fand, ich hab mal ungefähr 28 Stunden mit ihrem Twitter verbracht, wie schnell das kam.

464
00:51:18,760 --> 00:51:20,760
Und wie automatisch.

465
00:51:20,760 --> 00:51:22,760
Und wie eigentlich sachunbezogen.

466
00:51:22,760 --> 00:51:26,760
Und ich hab irgendwann gemerkt, das ist fast wie der umgekehrte Touring-Test.

467
00:51:26,760 --> 00:51:35,760
Ich konnte nicht sagen, ob das Menschen waren, die einfach obsessiv sich einen Alert zurechtgelegt haben, wenn Sarah Jong twittert.

468
00:51:35,760 --> 00:51:37,760
Oder ob das tatsächlich automatisiert ist.

469
00:51:38,760 --> 00:51:41,760
Und in dem Moment ist es ja eigentlich auch egal.

470
00:51:41,760 --> 00:51:43,760
Es kam aufs selbe raus.

471
00:51:43,760 --> 00:51:45,760
Und das war für mich so der Moment.

472
00:51:45,760 --> 00:51:57,760
Ja, das sind Menschen, die sozusagen den Spammer und den obsessiven Nerd sozusagen in eines führen.

473
00:51:57,760 --> 00:52:11,760
Und das ist so der Moment, in dem sie eigentlich, ja, sich mit der Struktur dieses, mit der Hitze, wie McLuhan sagen würde, dieses Mediums identisch machen.

474
00:52:11,760 --> 00:52:19,760
Das ist der Moment, in dem sie sagen, ich benutze dieses Ding jetzt genau so, wie Twitter es von mir will.

475
00:52:19,760 --> 00:52:31,760
Viel Engagement, viel Emotionalität, viel Aggro, sag ich mal.

476
00:52:31,760 --> 00:52:34,760
Aber dann auch Ewiges hin und her.

477
00:52:34,760 --> 00:52:43,760
Also ein Troll ist ja dadurch, auf häufiger Kennzeichnung, dass es gibt die Möglichkeit, einen zu trollen, indem man einfach einen Satz zurückschreibt.

478
00:52:43,760 --> 00:52:45,760
Delete your account.

479
00:52:45,760 --> 00:52:47,760
Das ist eine Art, das ist eine beliebte Art des Trollens.

480
00:52:47,760 --> 00:52:49,760
Was ich auch sehr lustig finde.

481
00:52:49,760 --> 00:52:52,760
Aber der Punkt ist, dass man nicht zurückschreibt.

482
00:52:52,760 --> 00:53:02,760
Aber viele dieser Trolle, indem sie dann so tun, als sei ihre erste Intervention tatsächlich eine Kommunikationsakt gewesen, schreiben dann zurück, ja, warum antworten sie mir nicht?

483
00:53:02,760 --> 00:53:03,760
Warum debattieren sie mich nicht?

484
00:53:03,760 --> 00:53:07,760
Warum fürchten sie sich vor mir?

485
00:53:07,760 --> 00:53:11,760
Allein schon daran, die generieren einfach unglaublich viele Tweets.

486
00:53:11,760 --> 00:53:14,760
Die sind also eigentlich die perfekten Twitter User.

487
00:53:14,760 --> 00:53:17,760
Die sind genau die User, die sich Jack Dorsey wünscht.

488
00:53:17,760 --> 00:53:22,760
Und das ist eben im Grunde genommen die Wahrheit, vor der er sich zu verstecken sucht.

489
00:53:22,760 --> 00:53:29,760
Dass diese Menschen nicht diese Form ad absurdum führen, sondern dass sie im Grunde genommen seine Jünger sind.

490
00:53:29,760 --> 00:53:38,760
Dass sie sich seinen Konstrukt angeschaut haben und gesagt haben, ich habe mich entschieden, kein Rebell zu sein.

491
00:53:38,760 --> 00:53:40,760
Ich bin jetzt der Todesstern.

492
00:53:40,760 --> 00:53:42,760
Jack Dorsey hat mir einen schönen Todesstern gebaut.

493
00:53:42,760 --> 00:53:44,760
Das benutze ich jetzt mal.

494
00:53:44,760 --> 00:53:53,760
Und das ist, glaube ich, da ist der Trolle der Virtuose von Twitter.

495
00:53:53,760 --> 00:53:58,760
Das ist aber etwas, was sich Twitter selber nicht eingestehen wird.

496
00:53:58,760 --> 00:54:08,760
Und was ich total gut fand, war, du hast dann auch in diesem Abschnitt zur Kommunikation, hast du diesen Mechanismus, den du jetzt gerade in Bezug auf die Online-Trolle beschreibst,

497
00:54:08,760 --> 00:54:14,760
nämlich dass man so tut, als hätte man eigentlich die Hand ausgestreckt in einem kommunikativen Akt,

498
00:54:14,760 --> 00:54:24,760
aber eigentlich in Wirklichkeit überhaupt gar nicht eine Antwort, eine produktive Antwort oder einen Diskurs gesucht hat, sondern im Grunde nur die Enttäuschung gesucht hat.

499
00:54:24,760 --> 00:54:38,760
Diesen Mechanismus, den beschreibst du dann auch ganz schön an einem Real-World-Beispiel und zwar dem des Autors dieses Google-internen Memos, mir ist jetzt der Name entfallen.

500
00:54:38,760 --> 00:54:41,760
James Damore, ich glaube, so spricht sich das aus, ja.

501
00:54:41,760 --> 00:54:51,760
James Damore, aha, ja, weil das fand ich nämlich auch sehr aufschlussreich, weil ich das Gefühl habe, dass das nämlich so ein Diskursvollzug ist oder eben kein Diskursvollzug letztlich,

502
00:54:51,760 --> 00:55:02,760
die Antäuschung eines Diskurses, wenn man so will, dass das etwas ist, was man jetzt immer wieder auch einfach in vielen verschiedensten gerade politischen Kontexten eigentlich auch wiederfindet.

503
00:55:02,760 --> 00:55:10,760
Und dass das aber eigentlich eine sehr perfide Move ist eben. Vielleicht kannst du das nochmal kurz beschreiben, wie das da ablief.

504
00:55:10,760 --> 00:55:28,760
Ja, genau, es ist, als James Damore eben diese Google-Memo schrieb und danach relativ schnell dann auch von Google eben rausgeschmissen wurde, war das jetzt so eine perfekte Opfergeschichte für eben konservative Kreise.

505
00:55:28,760 --> 00:55:35,760
Und der Gestus war immer, ja, ich stelle ja nur ein paar Fragen.

506
00:55:35,760 --> 00:55:38,760
Kannst du kurz sagen, welche Fragen er da gemeint hat?

507
00:55:38,760 --> 00:55:49,760
Ja, das ist gar nicht, das ist gar nicht mal so klar. Er hat das nie, er hat das nie, also es schien so, dass er sagen wollte, Google hat, der eigentliche Titel der Memo war Google's Ideological Echo Chamber.

508
00:55:49,760 --> 00:55:54,760
Also im Grunde genommen hat er gesagt, es gibt zu viele Linke bei Google und konservative Fragen dürfen nicht gestellt werden.

509
00:55:54,760 --> 00:56:11,760
Aber es war eine Reaktion auf ein Diversity Training, also auf die Frage, wie man mit, wie man in einem Arbeitsplatz funktioniert, in dem es halt Menschen gibt, die anders sind, die nicht weiße Männer sind.

510
00:56:11,760 --> 00:56:26,760
Die Memo hat also ziemlich klar eben sagen wollen, ich so, es ist ein Problem, dass Google keinen Platz macht für Menschen, die sagen, dass Frauen und People of Color bei Google nichts zu suchen haben.

511
00:56:26,760 --> 00:56:33,760
Und genauso wurde es auch aufgenommen. Und genauso wurde das, so hat Google das auch verstanden und hat gesagt, das geht nicht.

512
00:56:34,760 --> 00:56:48,760
Du kannst nicht ein Drittel unserer Belegschaft sagen, dass sie ihre IQ und ihre, was weiß ich, Schädelmessungen nahelegen, dass sie hier nur als Fehler sind und dass sie eigentlich rausschliegen sollten.

513
00:56:48,760 --> 00:56:57,760
Das ist mit unserer Firmenkultur nicht vereinbar. Aber das wurde dann eben als unmögliche Zensur ausgelegt.

514
00:56:57,760 --> 00:57:04,760
Aber Teil dessen war eben, dass eben gesagt wurde, er habe ja nur Fragen gestellt. Er habe ja nur ein bisschen Research zitiert.

515
00:57:04,760 --> 00:57:14,760
Dass das ein Research war von Menschen, die eindeutig Rassenkunde im Sinne des Dritten Reiches betreiben, wurde sozusagen erst mal geflissentlich beiseite gelassen.

516
00:57:14,760 --> 00:57:17,760
Er hat ja nur wissenschaftliche Texte zitiert.

517
00:57:18,760 --> 00:57:26,760
Ja, das Wichtige daran ist eben, dass es sozusagen vorfabriziert war für diese Art Enttäuschung.

518
00:57:26,760 --> 00:57:33,760
Wie enttäuschend, dass Silicon Valley so sich für diese Ideen verschließt, dass es diese Ideen nicht mehr ernst nimmt.

519
00:57:33,760 --> 00:57:44,760
Aber die Frage war eben, wie hätte das denn ausgesehen? Wie sieht das denn aus, wenn eine schwarze Frau, die als Programmiererin bei Google tätig ist, eine Debatte führt mit James Damore?

520
00:57:44,760 --> 00:57:51,760
Ja, ich sollte hier beschäftigt sein dürfen. Was ist das für eine Debatte? Wer würde denn da hingehen?

521
00:57:51,760 --> 00:58:00,760
Was für eine Debatte wird denn da gesucht? Du sollst nicht sein, ist keine interessante Debattenvorgabe.

522
00:58:00,760 --> 00:58:11,760
Das ist ziemlich perverse. Aber weil eben die Reaktion das eigentliche Thema wurde, konnte das sozusagen geflissentlich übersehen werden.

523
00:58:11,760 --> 00:58:21,760
Das ist ganz ähnlich wie das Sprachspiel der politischen Korrektheit in Deutschland oder in deutschsprachigen Medien.

524
00:58:21,760 --> 00:58:29,760
Wo immer die Reaktion, die neue Intoleranz zum Thema gemacht wird und die Frage, was sollte das denn anderes eigentlich bewirken?

525
00:58:29,760 --> 00:58:33,760
War das nicht genau die Reaktion, die du eigentlich wolltest?

526
00:58:33,760 --> 00:58:48,760
Was war die andere Reaktion, die die ausgeblieben ist angeblich, die du intendiert hattest, die du dir vorgestellt hast in dem Moment, als du Dieter Nuhr deinen hoch komischen Text vorgelesen hast über Alisaster sowas.

527
00:58:48,760 --> 00:58:58,760
Was hattest du dir vorgestellt, was da jemand sagt? Was war die Erwartung, die so brutalst enttäuscht wurde?

528
00:58:58,760 --> 00:59:07,760
Und ich glaube, diese Leute können das nicht beantworten, einfach weil sie diese Reaktion natürlich vorher gesehen haben und sie es auf diese Reaktion auch angelegt hatten.

529
00:59:07,760 --> 00:59:17,760
Und das ist ja auch gut, kann man sagen, das macht die bei gewissen Menschen sehr beliebt. Ich denke mal an, die verdienen sich damit eine goldene Nase. Warum würde man das sonst machen?

530
00:59:17,760 --> 00:59:31,760
Okay, das Problem ist, wenn wir das als Gesellschaft, als genuine Kommunikation und die Reaktion von anderen als genuine Kommunikationsverweigerung wahrnehmen,

531
00:59:31,760 --> 00:59:41,760
wenn wir sagen, sind wir jetzt schon so weit, dass sich in Deutschland Menschen nicht dazu herablassen, ihre eigene Existenz zu debattieren.

532
00:59:41,760 --> 00:59:56,760
Wie intolerant von ihnen, dass sie sagen, dass sie sich mit der Position, ihr gehört alle abgeschoben, nicht auseinandersetzen wollen, nur weil sie halt einen deutschen Pass haben und so weiter.

533
00:59:56,760 --> 01:00:07,760
Also das ist für mich das Fatale. Wenn das in einem gewissen Sektor des Internets sowas gut sieht, klar, es ist geschenkt.

534
01:00:07,760 --> 01:00:15,760
Dass gewisse Menschen das ausschlachten, ja, Scheiße ist aber so. Free Country.

535
01:00:15,760 --> 01:00:28,760
Dass aber das dann irgendwie gesamtgesellschaftlich so reflektiert wird, als würden unsere Kommunikationskanäle irgendwie schlechter funktionieren als früher, halte ich für entfahrend.

536
01:00:28,760 --> 01:00:35,760
Das halte ich eben für genau denselben Fehler, den Jack Dorsey macht. Das ist der Fehler häufig vieler Deutscher, nicht alle, aber vieler.

537
01:00:35,760 --> 01:00:43,760
Und ich denke, das ist eben diese Art heereenttäuschung, die nie wirklich sagen kann, in was sie denn jetzt eigentlich enttäuscht wurde.

538
01:00:43,760 --> 01:00:52,760
Was ihr genuines Angebot war, das angeblich so gemein ausgeschlagen wurde.

539
01:00:52,760 --> 01:00:56,760
Absolut, also da kann ich nur aus ganzem Herzen zustimmen, muss ich sagen.

540
01:00:56,760 --> 01:01:01,760
Wir haben jetzt über Disruptoren, über Risikokapital und jetzt zuletzt über Trolle gesprochen.

541
01:01:01,760 --> 01:01:08,760
Und du hattest es eigentlich vorhin auch schon im Grunde auf eine Art beantwortet oder angesprochen.

542
01:01:08,760 --> 01:01:14,760
Zumindest ist, du hast auf der einen Seite diesen Generationswechsel beschrieben in Richtung Get Rich Fast Orientierung.

543
01:01:14,760 --> 01:01:18,760
Aber du hast auch schon angedeutet, es gibt natürlich auch die andere Seite.

544
01:01:18,760 --> 01:01:32,760
Das ist nicht, das ist kein ganzes Bild, diese Get Rich Fast Orientierung, sondern es gibt eben auch viele Menschen, die immer noch in die Tech-Branche strömen, mit ganz anderer Orientierung, mit durchaus einer idealistischen Orientierung.

545
01:01:32,760 --> 01:01:38,760
Vielleicht können wir quasi gegen Ende nochmal diese optimistische Rampe nehmen.

546
01:01:38,760 --> 01:01:44,760
Wo siehst du sie denn hinstreben, diese Idealistinnen und Idealisten, die in die Tech-Branche gehen?

547
01:01:44,760 --> 01:01:50,760
Ja, also ich muss zugeben, unter meinen jüngeren Studenten habe ich nicht das Gefühl, dass sie sehr idealistisch sind.

548
01:01:50,760 --> 01:01:54,760
Sie sind realistisch, sie verlangen das Unmögliche.

549
01:01:54,760 --> 01:02:01,760
Also sie sagen, wenn wir wirklich genuin Neues in dieser Wirtschaftszweigerzeugung, dann lass uns das auch machen.

550
01:02:01,760 --> 01:02:09,760
Also sozusagen, sie lassen sich nicht mehr mit Versprechungen abspeisen, sondern sie stellen einfach Fragen.

551
01:02:10,760 --> 01:02:21,760
Es ist der Idealismus einer guten Gewerkschaft, die sagen soll, wir können doch alle davon leben, das muss doch irgendwie möglich sein.

552
01:02:21,760 --> 01:02:29,760
Oder es muss doch möglich sein, Geld zu verdienen in dieser Gesellschaft, ohne dass andere Menschen in absolute Armut versinken.

553
01:02:29,760 --> 01:02:37,760
Das kann man für einen Idealismus halten, aber das halte ich für einen sehr realistischen Optimismus.

554
01:02:37,760 --> 01:02:53,760
Es ist wirklich eine sehr, es ist einfach eine Unwilligkeit, gewisse Aussparungen, gewisse Abstraktionen so hinzunehmen und einfach nachzufragen.

555
01:02:53,760 --> 01:03:00,760
Und ich glaube, da hilft es sehr, dass viele dieser Unternehmen, da muss man ihnen wirklich auch einfach credit where credit is due,

556
01:03:00,760 --> 01:03:06,760
dass sie doch eindeutig versuchen, nicht mehr ganz so monokulturell zu funktionieren.

557
01:03:06,760 --> 01:03:11,760
Dass es ihnen wichtig ist, dass da Menschen am Tisch sitzen, die andere Erfahrungen mitbringen.

558
01:03:11,760 --> 01:03:19,760
Dass sie häufiger eben doch, auch jetzt gerade während der Trump-Jahre, immer wieder gesagt haben, das sind unsere Werte.

559
01:03:19,760 --> 01:03:31,760
Und da ist es uns scheißegal, ob das jetzt uns zum Nachteil gereicht mit den White Supremacists im Weißen Haus.

560
01:03:31,760 --> 01:03:35,760
Und das sind für mich alles sehr, sehr positive Signale.

561
01:03:36,760 --> 01:03:49,760
Ich glaube, dass das utopische, also eine Art der Utopie, die ich nicht habe vorhersagen können, als ich 2015 mit der Arbeit an diesem Buch angefangen habe,

562
01:03:49,760 --> 01:03:55,760
die mich immer wieder überrascht hat, ist der Utopismus so zu sein wie alle anderen.

563
01:03:55,760 --> 01:04:05,760
Es ist eine Branche, unter vielen sein könnte, die ihre Segnungen hat und birgt, aber umgekehrt eben auch einfach nur mit Wasser kocht.

564
01:04:05,760 --> 01:04:13,760
In dem letzten Kapitel des Buchs geht es um das Scheitern und darum, dass eigentlich Silicon Valley das Scheitern unmöglich gemacht hat.

565
01:04:13,760 --> 01:04:21,760
Was einerseits natürlich eine wunderschöne Vorstellung ist, aber andererseits eben doch unglaublich mit der Machtpolitik in Silicon Valley zu tun hat

566
01:04:21,760 --> 01:04:24,760
und damit, wer man ist und wo man herkommt und wie jung man ist.

567
01:04:24,760 --> 01:04:33,760
Und in den Recherchen für den Artikel, auf dem dieses Kapitel basiert, habe ich ein Gespräch geführt mit einem Firmengründer,

568
01:04:33,760 --> 01:04:41,760
dessen Firma einmal das ganz große neue Ding sein sollte und dann irgendwann nach drei Jahren haben die entdeckt, daraus wird nichts.

569
01:04:41,760 --> 01:04:47,760
Und dann war die Frage, ja, sollen wir unsere Willigschaft rausschmeißen und einfach neues Risikokapital für das nächste Ding einsammeln?

570
01:04:48,760 --> 01:04:55,760
Und stattdessen haben die zwei Gründer gesagt, du, was ist denn, wenn wir das ist, was wir hier haben, ist eigentlich ein schönes Mittelstandsunternehmen.

571
01:04:55,760 --> 01:05:07,760
20 Belegschaften, irgendwie 20, 25 Leute. Wir können unsere Sekretärinnen gut bezahlen, wir können die Empfangsdame gut bezahlen, alles toll.

572
01:05:07,760 --> 01:05:15,760
Wir machen unsere Sache gut, unsere Kunden mögen unser Produkt, wachsen werden wir nicht mehr, aber das ist auch in Ordnung.

573
01:05:15,760 --> 01:05:21,760
Und er sagt, das Verrückte ist, das ist für Silicon Valley, für unsere Geldgeber war das ein Scheitern.

574
01:05:21,760 --> 01:05:28,760
Aber wir haben sie überzeugen können, dass wir das machen wollen, wir haben uns freigekauft und seitdem, ich verdiene nicht viel, aber ich verdiene genug.

575
01:05:28,760 --> 01:05:38,760
Und wir kommen zur Arbeit, wir arbeiten nicht zu viel, wir beuten uns gegenseitig und uns selber nicht mehr aus, wir können alt werden, wir können gut alt werden in diesem Betrieb.

576
01:05:38,760 --> 01:05:46,760
Und diese Utopie, wir sind wie eine Automechaniker-Werkschaft im Grunde genommen, aber eben für Software, das ist sowas von schön.

577
01:05:46,760 --> 01:06:00,760
Und ich glaube, das ist ein bisschen die Utopie meiner Studenten, dass sie sagen, ich gehe dahin, das ist auch nicht anders, als würde ich im Werk arbeiten oder in der Werft.

578
01:06:00,760 --> 01:06:12,760
Ich komme als Arbeiter dahin und ich stelle etwas her, was gesamtwirtschaftlich natürlich wichtig ist und Impulse geben kann, was ein Wirtschaftszweig mächtig und groß machen kann.

579
01:06:12,760 --> 01:06:22,760
Das kann ja auch was Schönes sein, aber ich bin eben ein Arbeitnehmer und das heißt, ich muss einklagen, dass dieses Unternehmen mit dem Klima gut umgeht,

580
01:06:22,760 --> 01:06:28,760
dass es mit der ganzen Belegschaft umgeht, dass nicht nur ich gut behandelt werde, sondern auch andere Arbeiter gut behandelt werden.

581
01:06:28,760 --> 01:06:41,760
Und wenn nicht, dann habe ich meine Mechanismen, dann kann ich streiken, dann kann ich mir woanders hingehen und so weiter und so weiter.

582
01:06:41,760 --> 01:06:54,760
Also es gibt verschiedene Arten des Tech-Utopismus, aber den, der mich sozusagen überrascht hat, den, den ich nicht vorhergesagt habe, ist eine Art Sparflammen-Utopismus,

583
01:06:54,760 --> 01:07:03,760
dass bei diesen überzogenen Zukunftserwartungen, die diese Industrie habituell uns weckt, es manchmal unglaublich utopisch sein kann.

584
01:07:04,760 --> 01:07:16,760
Nein, seien wir doch mal normal, seien wir doch, orientieren wir uns doch daran, was andere gemacht haben.

585
01:07:16,760 --> 01:07:32,760
Also ein wunderschöner Moment, auch dank der Kollegen Moira Weigel und Ben Tarnow, die vorhin schon erwähnt wurden, war ein Penner ganz am Anfang der Trump-Jahre.

586
01:07:32,760 --> 01:07:46,760
Tech against Trump. Und das war wirklich, das waren lauter Leute von Facebook und so weiter und Google, aber nicht jetzt obere Etage, aber doch Programmierer und ganz viele Gewerkschafter.

587
01:07:46,760 --> 01:07:54,760
Und der Grundtenor des Abends war nicht, dass die Technologisten uns mal wieder die Welt erklären.

588
01:07:54,760 --> 01:07:59,760
Wie können wir Twitter dazu bringen, was weiß ich? Nein, die waren da, um von den Gewerkschaftern zu lernen.

589
01:07:59,760 --> 01:08:05,760
Wie macht ihr das? Wir wollen unsere Belegschaft, wir sind eine Belegschaft, wir begreifen das jetzt. Wir wollen nicht mehr Teil des Problems sein.

590
01:08:05,760 --> 01:08:12,760
Wie habt ihr das gemacht? Wie organisiert man eine Ölraffinerie? Wie kann ich das beim Facebook Campus machen?

591
01:08:12,760 --> 01:08:27,760
Das hat mich unglaublich bewegt. Das fand ich wunderschön. Einfach die Vorstellung, dass der Exzeptionalismus dieser Branche,

592
01:08:27,760 --> 01:08:39,760
der selbst den Reichsten in dieser Branche häufig zum Nachteil gereicht hat, selbst vielen, die es geschafft haben in dieser Branche zum Nachteil gereicht hat, dass dieses Ausnahmedenken ausgehebelt wurde.

593
01:08:39,760 --> 01:08:50,760
Wir können lernen von Typen in Overalls, die die Schiffe zusammenschrauben oder die Ölpipelines verlegen. Die können uns erklären, wie man sowas macht.

594
01:08:50,760 --> 01:09:00,760
Und das fand ich ganz, ganz toll. Und das ist so ein bisschen die Hoffnung, die unerwartete Hoffnung, die mich beschlichen hat im Schreiben dieses Buches.

595
01:09:00,760 --> 01:09:07,760
Total interessant, muss ich sagen. Das höre ich mit absolut gemischten Gefühlen, muss ich sagen.

596
01:09:07,760 --> 01:09:24,760
Auf der einen Seite ist es natürlich total ein super erster Schritt und ganz großartig nämlich auch, dass ja gerade die Tech-Worker sich im Grunde auch als eine Art von Schlüsselindustrie mit all der Macht, die damit einhergeht, empfinden lernen.

597
01:09:24,760 --> 01:09:32,760
Und diese Macht dann auch bewusst einsetzen, um ihre Arbeiterinnenrechte dann eben einzufordern. Das ist ja fantastisch und da bin ich natürlich absolut dafür.

598
01:09:32,760 --> 01:09:46,760
Gleichzeitig ist natürlich quasi das Weinen der Auge ist dann eigentlich entsteht dadurch, dass das auch was darüber aussagt, wie weit wir eigentlich weg waren von dem Ganzen.

599
01:09:46,760 --> 01:09:57,760
Also wenn schon so eine ganz milde Sozialdemokratie, also normale Sozialdemokratie, also irgendwie eine Absicherung angestellt sein und irgendwie gewisse Rechte haben.

600
01:09:57,760 --> 01:10:05,760
Wenn das schon quasi die Hero-Utopie ist, dann sagt das natürlich auch sehr viel aus, von woher man gestartet ist im Grunde.

601
01:10:05,760 --> 01:10:12,760
Und ich würde ja ganz klar dafür votieren, dass wir das als einen Zwischenschritt sehen sollten und weit darüber hinaus schießen.

602
01:10:12,760 --> 01:10:15,760
Aber auf jeden Fall total spannend, muss ich sagen.

603
01:10:15,760 --> 01:10:22,760
Ja, da stimme ich auch ganz mit dir überein. Das ist immer ein Zeichen, wie in welch dunklen Zeiten wir leben.

604
01:10:23,760 --> 01:10:34,760
Das ist jetzt eigentlich mein Stichwort zu der letzten Frage, die ich am Ende eines jeden Podcasts stelle, nämlich wenn du dir Zukunft vorstellst, was stimmt dich freudig?

605
01:10:34,760 --> 01:10:49,760
Naja, also schon gerade wenn es was die Technologie betrifft, die Vorstellungen, was diese doch unglaublich beeindruckenden Technologien einmal leisten könnten,

606
01:10:49,760 --> 01:10:57,760
wenn sie nicht im Dienst von ein paar Risikokapitalisten wären, stimmt mich schon sehr, sehr.

607
01:10:58,760 --> 01:11:03,760
Ich meine, der Weg dahin ist steinig und lang und es kann auch ganz, ganz anders kommen.

608
01:11:03,760 --> 01:11:11,760
Aber ich denke, wenn es so käme, das wäre schon irgendwie unglaublich und wäre schon irgendwie inspirierend.

609
01:11:14,760 --> 01:11:21,760
Ich denke auch, dass, was mich auch hoffnungsvoll stimmt, sind einfach junge Menschen.

610
01:11:21,760 --> 01:11:29,760
Ich meine, ich habe dieses Buch in Dialog mit jungen Menschen geschrieben und habe eben gemerkt, dass junge Menschen keine, das weiß man ja, aber es sind keine Konstante.

611
01:11:29,760 --> 01:11:42,760
Und dass diese Generation eben, das ist in den USA die Generation, die unter Barack Obama eben Kinder waren, mit Bernie Sanders erwachsen wurden und die jetzt eben ins Arbeitsleben kommen.

612
01:11:42,760 --> 01:11:52,760
Das ist die Generation, die unter Hunderttausenden Dollar von Schulden jetzt schon echt, Mitte 20.

613
01:11:52,760 --> 01:12:11,760
Und das ist die Generation, die Covid dazu benutzt hat, ihr Verständnis von gesellschaftlich Verantwortlichem Handeln nochmal zu explizieren und gegen die Unverantwortlichkeit der Babyboomer ehrlich gesagt zu verteidigen.

614
01:12:11,760 --> 01:12:22,760
Um es mal ganz runter raus zu sagen. Ich kann, ich will nicht zu hoffnungsvoll sein, aber es ist für mich schwer vorstellbar, dass es eine Generation ist, mit der sich nicht, die nicht viel erreichen kann.

615
01:12:22,760 --> 01:12:36,760
Die haben viel durchgemacht, aber sie haben, es sind ihm glaube ich Impulse eingeimpft worden, die es ihnen ermöglichen, was vorige Generationen nicht vermocht haben.

616
01:12:36,760 --> 01:12:45,760
Also wenn ich Hoffnung brauche, dann gehe ich in meine Seminarräume, was ich jetzt in einer Stunde auch nochmal tun werde.

617
01:12:45,760 --> 01:12:54,760
Für ein Seminar, das heißt der Faschismus nach dem Faschismus. Und da sitzen ganz viele Leute, die dann irgendwann bei Twitter arbeiten werden und bei Facebook und so weiter und so weiter.

618
01:12:54,760 --> 01:13:00,760
Und die Fragen, die die stellen, die geben mir die allergrößte Hoffnung für die Zukunft.

619
01:13:00,760 --> 01:13:12,760
Das sind junge Menschen, die sich für das Klima verantwortlich fühlen, die sich für ihre Mitmenschen verantwortlich fühlen, die sich für den Kapitalismus verantwortlich fühlen, was der anrichtet.

620
01:13:12,760 --> 01:13:17,760
Auf eine Art und Weise, die ich selbst vor sechs Jahren, acht Jahren bei meinen Ständen festgestellt habe.

621
01:13:17,760 --> 01:13:30,760
Und die bei allem Zynismus, den sie sich wirklich verdient haben, doch eindeutig dafür plädieren, es noch einmal darauf ankommen zu lassen und zu gucken, was geht.

622
01:13:30,760 --> 01:13:32,760
Und das gibt mir ganz enorme Hoffnung.

623
01:13:32,760 --> 01:13:36,760
Wunderbar. Großartig. Vielen Dank für das Gespräch.

624
01:13:36,760 --> 01:13:37,760
Danke Jan.

625
01:13:42,760 --> 01:13:44,760
Das war Future Histories für heute.

626
01:13:44,760 --> 01:13:46,760
Vielen Dank fürs Zuhören.

627
01:13:46,760 --> 01:13:52,760
Show-Notizen und vieles mehr findet ihr auf www.futurehistories.today.

628
01:13:52,760 --> 01:13:57,760
Diskutiert mit auf Twitter unter dem Hashtag Future Histories oder auf Reddit.

629
01:13:57,760 --> 01:14:01,760
Lasst mich wissen, was ihr zu dem Ganzen denkt und wie euch diese Folge hier gefallen hat.

630
01:14:01,760 --> 01:14:05,760
Unbedingt gut bewerten auf allen Podcast-Plattformen, die ihr nutzt.

631
01:14:05,760 --> 01:14:13,760
Für unsere Patreon-Unterstützerinnen und Unterstützer gibt es auf www.patreon.com schrägstrich Future Histories vieles an Zusatzmaterial.

632
01:14:13,760 --> 01:14:18,760
Da könnt ihr also auch vorbeischauen. Bis zum nächsten Mal. Ich freue mich.

