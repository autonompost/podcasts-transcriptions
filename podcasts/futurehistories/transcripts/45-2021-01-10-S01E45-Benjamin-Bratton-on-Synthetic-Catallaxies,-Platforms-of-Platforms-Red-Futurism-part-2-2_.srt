1
00:00:00,560 --> 00:00:01,940
Welcome to Future Histories.

2
00:00:01,940 --> 00:00:05,360
My name is Jan Gross, and what you are about to hear today

3
00:00:05,360 --> 00:00:07,680
is the second part of an interview I did

4
00:00:07,680 --> 00:00:11,360
with Benjamin Bratton in the context of a guest lecture

5
00:00:11,360 --> 00:00:13,080
that I was invited to hold

6
00:00:13,080 --> 00:00:16,200
at the Goldsmiths College in London.

7
00:00:16,200 --> 00:00:19,440
Before we start, I want to thank Carmen, Florian,

8
00:00:19,440 --> 00:00:22,800
and David for their kind donations.

9
00:00:22,800 --> 00:00:26,560
But now please enjoy the second part of the interview

10
00:00:26,560 --> 00:00:30,440
with Benjamin Bratton on Synthetic Catalaxy's

11
00:00:30,440 --> 00:00:34,680
Platforms of Platforms and Red Futurism.

12
00:00:40,000 --> 00:00:42,600
With more than one of my guests, I have hit a wall

13
00:00:42,600 --> 00:00:45,400
when asking how post-human political constellations

14
00:00:45,400 --> 00:00:46,920
could actually look like.

15
00:00:46,920 --> 00:00:49,660
Your writing and thinking, as we just experienced,

16
00:00:49,660 --> 00:00:51,420
is very illuminating in that regard,

17
00:00:51,420 --> 00:00:53,740
and it absolutely confirms my suspicion

18
00:00:53,900 --> 00:00:56,740
that the idea of the individual in the strict sense

19
00:00:56,740 --> 00:00:59,180
needs to be overcome in order to really get

20
00:00:59,180 --> 00:01:02,720
to fundamentally different sociopolitical arrangements.

21
00:01:02,720 --> 00:01:06,180
You advocate for the disindividuation of the user position.

22
00:01:06,180 --> 00:01:08,220
Could you explain what you mean by that?

23
00:01:09,480 --> 00:01:10,320
Sure.

24
00:01:11,660 --> 00:01:14,700
So this also goes back to the interface layer discussion

25
00:01:14,700 --> 00:01:18,060
that we had about the ways in which the interface layer

26
00:01:18,060 --> 00:01:22,860
can be, is a kind of map, operates as a kind of map

27
00:01:22,860 --> 00:01:24,480
of the way in which the system works.

28
00:01:24,480 --> 00:01:27,060
And I don't mean to, it sounds abstract,

29
00:01:27,060 --> 00:01:30,340
but I mean it, again, just to remind your listeners

30
00:01:30,340 --> 00:01:32,460
in this very simple sense of,

31
00:01:32,460 --> 00:01:34,260
there's lots of things you can do with your computer,

32
00:01:34,260 --> 00:01:37,500
but the graphical user interface presents you trillions

33
00:01:37,500 --> 00:01:40,300
of things you could do, build a bomb, do whatever.

34
00:01:40,300 --> 00:01:43,020
But the graphical user interface presents you

35
00:01:43,020 --> 00:01:46,880
with this mechanism of several dozen menu options

36
00:01:46,880 --> 00:01:48,740
that you sort of pick and choose.

37
00:01:48,740 --> 00:01:53,740
So it's, part of it is that in this,

38
00:01:53,780 --> 00:01:57,460
a little bit has to do with the history of interface design,

39
00:01:57,460 --> 00:02:02,460
there is a presumption that is built into

40
00:02:04,140 --> 00:02:06,420
the interface structure that we're talking of,

41
00:02:06,420 --> 00:02:10,540
that the way in which the system should present itself

42
00:02:10,540 --> 00:02:15,540
to human users is one human user at a time.

43
00:02:15,700 --> 00:02:20,060
That the fact that our culture of interface design

44
00:02:20,060 --> 00:02:23,240
is built around this sort of individuated,

45
00:02:23,240 --> 00:02:27,220
psychologized, single-serving homo sapien user,

46
00:02:28,100 --> 00:02:31,980
separated from other single-serving homo sapien users

47
00:02:31,980 --> 00:02:34,500
in and of itself is not,

48
00:02:34,500 --> 00:02:39,240
is not, we take it as a highly naturalized condition,

49
00:02:39,240 --> 00:02:41,520
but it's not necessarily,

50
00:02:42,460 --> 00:02:45,020
it's not necessarily historically,

51
00:02:45,940 --> 00:02:50,400
it's a highly contingent kind of arrangement.

52
00:02:50,400 --> 00:02:54,020
We have lots of interfaces that are meant for plural,

53
00:02:54,020 --> 00:02:57,140
a plurality of users, like traffic signals.

54
00:02:57,140 --> 00:02:59,300
A traffic signal is an interface system

55
00:02:59,300 --> 00:03:01,580
that doesn't make any sense for one user,

56
00:03:01,580 --> 00:03:03,460
I mean, for users at a time.

57
00:03:03,460 --> 00:03:05,580
The whole thing, like it's green light for me

58
00:03:05,580 --> 00:03:07,540
because it's red light for you and yellow,

59
00:03:07,540 --> 00:03:11,180
and something that we all recognize that the way

60
00:03:11,180 --> 00:03:13,420
in which the street interface is presented to me

61
00:03:13,420 --> 00:03:15,580
is conditional in relationship to other users.

62
00:03:15,580 --> 00:03:20,580
And we are, once you sort of, when it's green light for me,

63
00:03:21,460 --> 00:03:23,460
I am a green light user of the street

64
00:03:23,460 --> 00:03:25,340
and you are a red light user of the street.

65
00:03:25,340 --> 00:03:27,300
And therefore I know what you're going to do

66
00:03:27,300 --> 00:03:29,300
because you're a red light user.

67
00:03:29,300 --> 00:03:33,340
And we're all in a way interpolated through this interface

68
00:03:33,340 --> 00:03:37,020
as being red light, green light drivers in this sort of way.

69
00:03:37,020 --> 00:03:40,340
But also we understand and can negotiate the relationship

70
00:03:40,340 --> 00:03:43,140
with each other in this differential.

71
00:03:43,780 --> 00:03:44,620
If it's made clear.

72
00:03:44,620 --> 00:03:47,180
So the traffic again is a kind of simple example

73
00:03:47,180 --> 00:03:50,460
of what a plural interface would be.

74
00:03:50,460 --> 00:03:55,100
Now, in a stupid sense, Facebook attempted to make,

75
00:03:56,300 --> 00:03:58,620
in a way attempted in social network software,

76
00:03:58,620 --> 00:04:01,140
attempts to make interfaces

77
00:04:01,140 --> 00:04:03,540
that are meant for pluralities of users,

78
00:04:04,620 --> 00:04:07,740
but do so in a way that I think are actually,

79
00:04:07,740 --> 00:04:11,860
that actually concretizes and refortifies

80
00:04:12,420 --> 00:04:15,700
the fiction of the autonomous individual

81
00:04:15,700 --> 00:04:17,940
in relationship to those, in relation to the kind of thing.

82
00:04:17,940 --> 00:04:21,220
It produces a subjectivity.

83
00:04:21,220 --> 00:04:23,100
And in our society, as I mentioned,

84
00:04:23,100 --> 00:04:26,020
subjectivity and agency are utterly conflated.

85
00:04:26,020 --> 00:04:29,540
And within the kinds of interpolations of the user

86
00:04:29,540 --> 00:04:31,220
that you see in social media software,

87
00:04:31,220 --> 00:04:33,580
that this conflation is not only re-emphasized,

88
00:04:33,580 --> 00:04:38,580
but there's a construction of a social subjectivity,

89
00:04:38,580 --> 00:04:43,460
of a social subjectivity of this individuated user

90
00:04:43,460 --> 00:04:46,540
as this kind of encaps, self-encapsulated,

91
00:04:48,660 --> 00:04:52,300
sort of piloting creature of its own data

92
00:04:52,300 --> 00:04:56,420
and its own presentation of self-identity

93
00:04:56,420 --> 00:04:58,700
in relationship to this.

94
00:04:58,700 --> 00:05:02,700
One of the arguments that I sometimes make,

95
00:05:02,700 --> 00:05:07,380
find myself making arguments against the,

96
00:05:07,380 --> 00:05:11,900
making arguments against those whose primary concern

97
00:05:11,900 --> 00:05:14,340
with the social function of planetary's computation

98
00:05:14,340 --> 00:05:16,300
is in terms of surveillance.

99
00:05:17,940 --> 00:05:21,100
And the argument that I make is basically twofold.

100
00:05:21,100 --> 00:05:22,620
One is that,

101
00:05:26,900 --> 00:05:28,260
one is ultimately,

102
00:05:28,260 --> 00:05:30,260
I mean ultimately comes down to the term surveillance

103
00:05:30,260 --> 00:05:32,060
has been overinflated to describe

104
00:05:32,060 --> 00:05:34,500
so many different kinds of ways in which we would sense

105
00:05:34,500 --> 00:05:36,540
and model and construct images of the world,

106
00:05:36,540 --> 00:05:38,060
that it's beginning,

107
00:05:38,060 --> 00:05:39,540
that we have a kind of a surveillance,

108
00:05:39,540 --> 00:05:41,300
anti-surveillance bubble.

109
00:05:41,300 --> 00:05:43,980
That climate science and the way in which we would sense

110
00:05:43,980 --> 00:05:45,180
and model and structure the world

111
00:05:45,180 --> 00:05:47,260
is also a giant surveillance regime,

112
00:05:47,260 --> 00:05:49,020
if you really want to think about it this way.

113
00:05:49,020 --> 00:05:51,300
But the key point in relationship

114
00:05:51,300 --> 00:05:52,660
to what we're discussing is

115
00:05:54,100 --> 00:05:56,580
using planetary scale computation

116
00:05:56,580 --> 00:05:59,220
for the sensing, modeling and prediction

117
00:05:59,220 --> 00:06:01,940
of what individual homo sapiens

118
00:06:01,940 --> 00:06:05,140
are likely to wanna look at next and click on next

119
00:06:05,180 --> 00:06:07,620
in which kind of video or funny picture

120
00:06:07,620 --> 00:06:09,260
they're gonna wanna see next

121
00:06:09,260 --> 00:06:14,260
is incredibly tragic misuse

122
00:06:14,540 --> 00:06:16,740
of planetary scale computation as a whole.

123
00:06:19,420 --> 00:06:21,820
It goes deeper than the fact

124
00:06:21,820 --> 00:06:23,620
that these people are being surveilled, right?

125
00:06:23,620 --> 00:06:27,020
And so you think of the Shoshana Zuboff kind of critique.

126
00:06:27,020 --> 00:06:31,340
The problem is not just that you have these individual people

127
00:06:31,340 --> 00:06:34,180
are constructed and are being observed and tracked

128
00:06:34,180 --> 00:06:35,540
and surveilled and manipulated

129
00:06:35,540 --> 00:06:36,660
by these large scale platforms.

130
00:06:36,660 --> 00:06:37,660
This is a problem.

131
00:06:37,660 --> 00:06:40,220
This is a tragic misuse of the apparatus.

132
00:06:40,220 --> 00:06:43,740
The deeper problem is that society is,

133
00:06:43,740 --> 00:06:46,340
is it through this individuated interpolation

134
00:06:46,340 --> 00:06:48,500
of the user as the user as this figure

135
00:06:49,540 --> 00:06:52,900
is that society is being defined and constructed

136
00:06:52,900 --> 00:06:57,620
as the aggregation of these atomic individual subject,

137
00:06:57,620 --> 00:07:00,780
agent, actors in the first place.

138
00:07:01,380 --> 00:07:04,420
It's a misrecognition of what a society is.

139
00:07:04,420 --> 00:07:08,420
It's a misorganization of how it is that the relations

140
00:07:08,420 --> 00:07:12,940
between a social species such as humans is constructed.

141
00:07:12,940 --> 00:07:17,420
It is absolutely 100% predicated, I believe,

142
00:07:17,420 --> 00:07:22,420
upon the kind of self-congratulatory self-atomizing logics

143
00:07:25,460 --> 00:07:29,460
of liberal individualism and legal subjectivity,

144
00:07:29,460 --> 00:07:32,700
which of course is why someone like Shoshana Zuboff

145
00:07:32,700 --> 00:07:34,700
can't make this critique at that level

146
00:07:34,700 --> 00:07:39,700
because as someone from the world of the law,

147
00:07:40,340 --> 00:07:44,700
this formulation of society as an aggregation

148
00:07:44,700 --> 00:07:47,100
of self-transparent and self-sufficient

149
00:07:47,100 --> 00:07:50,780
atomic liberal individualisms is a sacred concept.

150
00:07:51,860 --> 00:07:54,980
And so the only thing that she's able to do is to say

151
00:07:54,980 --> 00:07:59,100
that these sovereign individuals have been

152
00:07:59,540 --> 00:08:04,540
manipulated into forming improper contractual relationships

153
00:08:05,940 --> 00:08:07,020
with these institutions,

154
00:08:07,020 --> 00:08:10,020
these manipulated contractual relationships,

155
00:08:10,020 --> 00:08:15,020
and that we need to resolve this jurisprudence

156
00:08:19,180 --> 00:08:21,180
to make these contractual relationships

157
00:08:21,180 --> 00:08:23,500
between these sovereign individuals and these platforms,

158
00:08:23,500 --> 00:08:25,740
in fact, more fair and more transparent.

159
00:08:25,740 --> 00:08:27,420
And I'm arguing is that, no,

160
00:08:27,420 --> 00:08:29,820
it's this hyper-individuation of society

161
00:08:29,820 --> 00:08:31,260
through that usually that's the problem

162
00:08:31,260 --> 00:08:33,300
and that's a much deeper problem.

163
00:08:33,300 --> 00:08:35,820
This is something I think that Ghani and I also agree on,

164
00:08:35,820 --> 00:08:37,860
I think, in terms of some of the things

165
00:08:37,860 --> 00:08:39,060
that he's written about Zuboff.

166
00:08:39,060 --> 00:08:43,500
I think it's that we probably have a common interest

167
00:08:43,500 --> 00:08:48,500
and common point about that as well.

168
00:08:50,540 --> 00:08:52,580
So part of the question then,

169
00:08:52,580 --> 00:08:55,300
to your question of this multiplication of the user layer

170
00:08:55,300 --> 00:08:56,140
here has to go with,

171
00:08:56,140 --> 00:09:00,900
is also an understanding of ways in which we can learn

172
00:09:00,900 --> 00:09:03,180
to think about our subjectivity and our agency

173
00:09:03,180 --> 00:09:04,580
in relationship to these systems

174
00:09:04,580 --> 00:09:09,100
that is not through this lens of this kind of figure.

175
00:09:09,100 --> 00:09:13,580
Now, the other thing I should say is two points on this,

176
00:09:13,580 --> 00:09:16,940
I think, examples that I think will kind of specify

177
00:09:16,940 --> 00:09:19,180
what I mean as possible alternatives here.

178
00:09:20,660 --> 00:09:24,500
One is, and I just finished this book on the pandemic,

179
00:09:24,500 --> 00:09:25,940
which I just wrote for Verso,

180
00:09:25,940 --> 00:09:28,140
which will be coming out in June.

181
00:09:28,140 --> 00:09:30,260
It's a book called The Revenge of the Real,

182
00:09:30,260 --> 00:09:32,460
post-pandemic politics.

183
00:09:32,460 --> 00:09:34,380
And one of the things I talk about in this book

184
00:09:34,380 --> 00:09:37,300
is what I call the epidemiological mode of society.

185
00:09:37,300 --> 00:09:41,020
That is one of the things that we learned from the pandemic

186
00:09:41,020 --> 00:09:45,860
was to see society the way epidemiologists see society.

187
00:09:45,860 --> 00:09:48,100
Epidemiologists don't see society

188
00:09:48,100 --> 00:09:53,100
as a bunch of atomic monads

189
00:09:54,620 --> 00:09:56,500
that happen to once in a while

190
00:09:56,500 --> 00:09:59,500
enter into contractual relationships with one another.

191
00:09:59,500 --> 00:10:03,620
They see society as a kind of landscape of organisms,

192
00:10:03,620 --> 00:10:06,020
each of which is a medium

193
00:10:06,020 --> 00:10:08,140
for the transmission towards one or the other.

194
00:10:08,140 --> 00:10:10,700
But they see it in terms of a kind of

195
00:10:10,700 --> 00:10:13,900
aggregate biological population scale

196
00:10:13,900 --> 00:10:16,940
that indeed is, I think, a good lesson for us to learn.

197
00:10:19,180 --> 00:10:21,740
It's a conceptualization of society

198
00:10:21,740 --> 00:10:23,380
that we should bring forward with us

199
00:10:23,380 --> 00:10:26,220
into a post-pandemic world,

200
00:10:26,220 --> 00:10:29,820
and I think is one that is more accurate,

201
00:10:29,820 --> 00:10:32,620
more social, and more viable

202
00:10:32,620 --> 00:10:37,620
than the kind of atomic individual version of this.

203
00:10:37,940 --> 00:10:40,260
The other point in terms of the plurality of interfaces,

204
00:10:40,260 --> 00:10:42,380
part of the longer term, what now,

205
00:10:42,380 --> 00:10:44,340
what should we do next question is,

206
00:10:45,580 --> 00:10:47,580
it's not enough to take back our data,

207
00:10:48,900 --> 00:10:51,020
because the data that we would be taking back

208
00:10:51,060 --> 00:10:52,500
is not the data we need.

209
00:10:54,540 --> 00:10:56,300
Because something like Facebook,

210
00:10:56,300 --> 00:10:58,060
and this is also where Zuboff and I

211
00:10:58,060 --> 00:11:00,420
would depart from each other,

212
00:11:00,420 --> 00:11:02,460
it's not enough that Facebook,

213
00:11:02,460 --> 00:11:05,980
because Facebook has mismodeled society so tragically,

214
00:11:05,980 --> 00:11:08,820
that its model of society as this aggregation

215
00:11:08,820 --> 00:11:12,820
of acquisitive atomic individuals

216
00:11:12,820 --> 00:11:16,180
is such an inaccurate model of society,

217
00:11:16,180 --> 00:11:20,140
that I could say, here you go, you got it all.

218
00:11:20,300 --> 00:11:24,220
Here is all of the information on all of the Facebook users,

219
00:11:24,220 --> 00:11:26,660
all four and a half billion of them or whatever,

220
00:11:26,660 --> 00:11:29,140
all the likes and all the cat videos

221
00:11:29,140 --> 00:11:32,020
and all the conspiracy memes and all the rest of this.

222
00:11:32,020 --> 00:11:33,860
Here it is, you have it.

223
00:11:33,860 --> 00:11:37,300
The government of whatever, EU, take it all.

224
00:11:37,300 --> 00:11:38,140
You've got it.

225
00:11:38,140 --> 00:11:41,060
Now use this to solve climate change.

226
00:11:41,060 --> 00:11:42,580
Go.

227
00:11:42,580 --> 00:11:44,860
You can't, it's the wrong data.

228
00:11:44,860 --> 00:11:49,860
Data about what it is about this model of society

229
00:11:50,460 --> 00:11:52,860
is not the data that we need.

230
00:11:52,860 --> 00:11:54,860
And this is kind of the other,

231
00:11:54,860 --> 00:11:58,860
so taking it back from Facebook is useless.

232
00:11:58,860 --> 00:12:01,100
What we need is to produce the right data.

233
00:12:01,100 --> 00:12:03,580
What we need is to actually understand

234
00:12:03,580 --> 00:12:05,620
what data would we need

235
00:12:05,620 --> 00:12:08,060
in order to actually enter in these transformations.

236
00:12:08,060 --> 00:12:10,580
And so simply think is that to simply,

237
00:12:10,580 --> 00:12:14,620
again, to reclaim the property of the data

238
00:12:14,620 --> 00:12:17,300
that Facebook has produced about us

239
00:12:17,300 --> 00:12:22,060
isn't enough because in essence it's the wrong data.

240
00:12:22,060 --> 00:12:23,940
So anyway, those are some thoughts on this question

241
00:12:23,940 --> 00:12:27,820
about the user position, the necessity for its plurality,

242
00:12:27,820 --> 00:12:29,660
the problems of its over-individuation

243
00:12:29,660 --> 00:12:32,660
and where my thinking sort of aligns and differentiates

244
00:12:32,660 --> 00:12:35,660
from some other people who have thought about it.

245
00:12:35,660 --> 00:12:36,740
Super interesting.

246
00:12:36,740 --> 00:12:39,500
And I will skip the question on the UBI,

247
00:12:39,500 --> 00:12:42,220
which would be a kind of riddle

248
00:12:42,220 --> 00:12:44,620
on how to actually apply it on.

249
00:12:44,660 --> 00:12:47,340
I can say something real quick about it if you like.

250
00:12:47,340 --> 00:12:50,300
So because it connects with the catalaxy idea.

251
00:12:50,300 --> 00:12:52,140
Part of, I think the more convincing argument

252
00:12:52,140 --> 00:12:53,540
about universal basic income

253
00:12:53,540 --> 00:12:55,940
also has to do with a kind of distortion.

254
00:12:56,940 --> 00:13:00,260
And I think it's a distortion in the value

255
00:13:00,260 --> 00:13:03,620
that society gets from its own participants,

256
00:13:04,900 --> 00:13:06,740
that there is a distortion in this.

257
00:13:06,740 --> 00:13:09,300
And I don't know if you call it a price distortion.

258
00:13:09,300 --> 00:13:10,900
I think that might be a bit awkward,

259
00:13:10,900 --> 00:13:14,340
but it is a distortion of value at the very least.

260
00:13:14,340 --> 00:13:19,340
When you have a comp lit PhD making coffee

261
00:13:20,140 --> 00:13:23,660
because that's the best job that she can get,

262
00:13:23,660 --> 00:13:28,500
even though the contributions that she could make to society

263
00:13:28,500 --> 00:13:33,500
are so much greater than the provision of cups of coffee,

264
00:13:34,500 --> 00:13:36,020
there's a distortion at work.

265
00:13:36,020 --> 00:13:40,220
Or when you have a genius,

266
00:13:40,220 --> 00:13:45,220
some genius kid doing other kinds of menial work

267
00:13:45,660 --> 00:13:48,140
because they need to support themselves,

268
00:13:48,140 --> 00:13:51,740
because the provision of basic food, shelter,

269
00:13:51,740 --> 00:13:55,740
healthcare or whatever is only available to them

270
00:13:55,740 --> 00:14:00,740
because they are trading most of their working hours

271
00:14:01,020 --> 00:14:03,540
for the provision of these basic things.

272
00:14:03,540 --> 00:14:07,180
Society as a whole is not getting from them

273
00:14:07,180 --> 00:14:09,340
what we should be getting from them.

274
00:14:09,340 --> 00:14:14,340
That there is an entire second economy worth of value

275
00:14:16,780 --> 00:14:21,660
that is being suppressed by the under participation

276
00:14:21,660 --> 00:14:26,180
of people doing things that are trivial

277
00:14:26,180 --> 00:14:30,740
compared to their real talents and capacities to contribute.

278
00:14:30,740 --> 00:14:32,460
And so I see this in some ways,

279
00:14:32,460 --> 00:14:35,420
you could see this in a way as a distortion

280
00:14:36,060 --> 00:14:40,220
of social value that is much greater

281
00:14:40,220 --> 00:14:41,660
than anything high equity side

282
00:14:41,660 --> 00:14:43,340
with the socialist pricing problem

283
00:14:43,340 --> 00:14:45,340
of how much the bananas should cost.

284
00:14:46,340 --> 00:14:49,700
This is trivial compared to what we're missing out

285
00:14:49,700 --> 00:14:52,980
from a lifetime of work of people doing something

286
00:14:52,980 --> 00:14:56,460
that quite easily could be done by machine

287
00:14:57,340 --> 00:15:00,460
if we were allowing them to do so.

288
00:15:00,460 --> 00:15:04,420
And I think when I think about the long-term value

289
00:15:04,420 --> 00:15:07,300
of something like UBI in terms of how to measure this,

290
00:15:07,300 --> 00:15:09,660
how to price it or kind of something like this,

291
00:15:11,580 --> 00:15:13,420
this is the sort of the bigger picture

292
00:15:13,420 --> 00:15:16,020
that I'm trying to keep in mind

293
00:15:16,020 --> 00:15:19,180
is not having to do with does it cost more or less

294
00:15:19,180 --> 00:15:21,540
than some other kind of welfare policy?

295
00:15:21,540 --> 00:15:22,700
Does it cost more or less

296
00:15:22,700 --> 00:15:23,980
in the relationship of this as well?

297
00:15:23,980 --> 00:15:26,180
But rather that in the long-term,

298
00:15:26,180 --> 00:15:28,180
what does the world look like

299
00:15:28,180 --> 00:15:33,140
when the true social catalaxy is possible?

300
00:15:33,140 --> 00:15:36,780
When it's actually possible for people to contribute

301
00:15:36,780 --> 00:15:39,140
to the production of society one with the other

302
00:15:39,140 --> 00:15:42,180
in ways in which half their time is not being produced

303
00:15:42,180 --> 00:15:44,980
on something idiotic and trivial and depressing.

304
00:15:46,860 --> 00:15:47,740
In order to get there

305
00:15:47,740 --> 00:15:50,460
and you touched up on it before already,

306
00:15:50,460 --> 00:15:52,460
we need different kinds of data.

307
00:15:52,460 --> 00:15:55,900
And so let's talk about data governance

308
00:15:55,900 --> 00:15:58,540
since this is actually essential to more or less

309
00:15:58,540 --> 00:16:00,700
all of the topics we discussed today.

310
00:16:00,700 --> 00:16:02,220
If I understand it correctly,

311
00:16:02,220 --> 00:16:04,780
you state that on a very fundamental level,

312
00:16:04,780 --> 00:16:08,580
there's basically always a kind of Potemkin ontology at work,

313
00:16:08,580 --> 00:16:10,180
which, and I quote you here,

314
00:16:10,180 --> 00:16:14,140
attempts to reduce reality to the level of complexity

315
00:16:14,140 --> 00:16:17,660
that the control system is capable of thinking with,

316
00:16:17,660 --> 00:16:18,500
end quote.

317
00:16:19,380 --> 00:16:21,620
You touched upon this already before

318
00:16:21,620 --> 00:16:24,060
quite at the beginning of our talk.

319
00:16:24,060 --> 00:16:27,100
I'm asking myself if this leaves us with a battle

320
00:16:27,100 --> 00:16:29,500
around the agency of different models

321
00:16:29,500 --> 00:16:32,140
that are used to interpret data

322
00:16:32,980 --> 00:16:37,100
and I'm also asking myself if and how one can successfully

323
00:16:37,100 --> 00:16:39,980
incorporate the reductiveness of one's model

324
00:16:39,980 --> 00:16:43,380
into the way the model is being applied.

325
00:16:44,660 --> 00:16:46,220
Sure.

326
00:16:46,220 --> 00:16:47,060
Yeah, good question.

327
00:16:47,060 --> 00:16:51,300
So there's a kind of a philosophical approach to this

328
00:16:51,300 --> 00:16:53,740
and more of a practical approach to this

329
00:16:53,740 --> 00:16:56,300
and maybe they can converge at some point,

330
00:16:56,300 --> 00:16:59,100
but just to sort of restate the question

331
00:16:59,140 --> 00:17:01,900
in a different way that,

332
00:17:03,620 --> 00:17:04,780
first of all, I should say that,

333
00:17:04,780 --> 00:17:07,260
I think part of the way in which approach this

334
00:17:07,260 --> 00:17:09,900
is to think of data not as something that's extracted,

335
00:17:09,900 --> 00:17:11,260
but as something that's produced.

336
00:17:11,260 --> 00:17:14,260
Data is produced about a phenomenon.

337
00:17:14,260 --> 00:17:16,940
Data doesn't exist out in the wild like strawberries

338
00:17:16,940 --> 00:17:19,420
where you can go and pick it and bring it back.

339
00:17:19,420 --> 00:17:20,780
It is produced in such a way

340
00:17:20,780 --> 00:17:24,420
that you can have 10 data scientists

341
00:17:24,420 --> 00:17:26,620
approach the same strawberry field

342
00:17:26,620 --> 00:17:28,140
and ask them to make a model of it

343
00:17:28,140 --> 00:17:30,780
and you get 20 different models of the strawberry field,

344
00:17:30,780 --> 00:17:33,940
each one of which might be statistically,

345
00:17:33,940 --> 00:17:36,420
scientifically accurate based on the questions

346
00:17:36,420 --> 00:17:37,980
and preconditions that it's asking

347
00:17:37,980 --> 00:17:39,900
and what it's looking for.

348
00:17:39,900 --> 00:17:43,220
And it's not necessarily one is more true than the other

349
00:17:43,220 --> 00:17:47,460
anyway more than like, you can say the word strawberry,

350
00:17:47,460 --> 00:17:50,540
you can say the phrase strawberry field in English

351
00:17:50,540 --> 00:17:53,020
and French and German and Dutch and Italian

352
00:17:53,020 --> 00:17:55,100
and they're all true.

353
00:17:55,100 --> 00:17:57,660
It's not that, obviously English is more true

354
00:17:57,660 --> 00:17:59,060
than all of the other ones.

355
00:17:59,940 --> 00:18:02,980
I'm joking, but none of the languages are more,

356
00:18:02,980 --> 00:18:05,260
the ontologies of the language are none of them

357
00:18:05,260 --> 00:18:06,300
are more true than the other.

358
00:18:06,300 --> 00:18:09,140
They are sort of producing a symbolic differentiation,

359
00:18:09,140 --> 00:18:10,420
a symbolic reference of this one.

360
00:18:10,420 --> 00:18:13,460
This is how I think about quantification as well

361
00:18:13,460 --> 00:18:14,500
in a certain sense,

362
00:18:14,500 --> 00:18:17,660
though that there are ways obviously then

363
00:18:17,660 --> 00:18:22,660
that the value of the model works

364
00:18:23,660 --> 00:18:28,660
not only in terms of its capacity for rhetorical rhetorically

365
00:18:28,780 --> 00:18:32,420
but also for its value in terms of realism

366
00:18:32,420 --> 00:18:37,420
and direct mimetic relation to the described.

367
00:18:38,180 --> 00:18:42,260
This is why we have things like astronomy and so forth.

368
00:18:42,260 --> 00:18:44,100
So what I mean by that is this,

369
00:18:44,100 --> 00:18:46,020
there's at least three different kinds of models

370
00:18:46,020 --> 00:18:47,300
that we want to be talking about here

371
00:18:47,300 --> 00:18:49,060
in terms of governance.

372
00:18:49,060 --> 00:18:51,340
There are descriptive models, predictive models

373
00:18:51,340 --> 00:18:53,220
and projective models.

374
00:18:53,220 --> 00:18:54,900
And they have different social functions,

375
00:18:54,900 --> 00:18:57,020
they have different epistemic functions

376
00:18:57,020 --> 00:18:59,140
and they have different political functions

377
00:19:00,100 --> 00:19:01,780
and scientific functions.

378
00:19:01,780 --> 00:19:04,700
A descriptive model basically is a model

379
00:19:04,700 --> 00:19:09,340
that's value is produced according to its correspondence

380
00:19:09,340 --> 00:19:11,500
to a mind external reality.

381
00:19:12,340 --> 00:19:16,100
In that heliocentrism is a reductive model

382
00:19:16,100 --> 00:19:19,060
of the solar system that it can be described

383
00:19:19,060 --> 00:19:22,260
by a series of styrofoam circles.

384
00:19:23,140 --> 00:19:25,380
It's a highly reductive model of the solar system

385
00:19:25,380 --> 00:19:27,660
but it's one that is more accurate

386
00:19:27,660 --> 00:19:31,820
in its representation of the solar system

387
00:19:31,820 --> 00:19:36,340
than a geocentric model of the solar system is in this way.

388
00:19:36,340 --> 00:19:39,540
Its correspondence to the real is the basis of its value.

389
00:19:41,500 --> 00:19:44,060
And that there's a politics of this

390
00:19:44,060 --> 00:19:45,740
in the sense to which it obviously has to do

391
00:19:45,740 --> 00:19:47,220
around the issues of climate science

392
00:19:47,220 --> 00:19:49,460
and our ability to, for example,

393
00:19:49,460 --> 00:19:54,380
is to produce a model at planetary scale

394
00:19:54,380 --> 00:19:58,820
of planetary material ecological processes

395
00:19:58,820 --> 00:20:01,540
that we believe to be accurate in the same way

396
00:20:01,540 --> 00:20:03,580
in which heliocentrism is accurate

397
00:20:04,620 --> 00:20:08,860
that would therefore give us confidence

398
00:20:08,860 --> 00:20:11,260
for acting recursively on its behalf

399
00:20:12,900 --> 00:20:16,500
because we have confidence in its representational capacity.

400
00:20:16,500 --> 00:20:18,580
But importantly, it's also one that,

401
00:20:18,580 --> 00:20:20,700
as I've mentioned before, that that model,

402
00:20:20,700 --> 00:20:24,060
just the way in which heliocentric astronomy

403
00:20:24,060 --> 00:20:25,180
could never have been produced

404
00:20:25,180 --> 00:20:27,740
without the technical abstraction of the telescope,

405
00:20:29,100 --> 00:20:32,980
the concept of climate change and planet earth science

406
00:20:32,980 --> 00:20:36,540
and that capacity for us to understand those processes

407
00:20:36,540 --> 00:20:40,780
with a realist model at any degree of sophistication

408
00:20:40,780 --> 00:20:43,180
is also dependent upon the technical abstraction

409
00:20:43,180 --> 00:20:44,860
of planetary scale computation.

410
00:20:46,500 --> 00:20:47,340
That's in fact, again,

411
00:20:47,340 --> 00:20:49,820
what planetary scale computation is for.

412
00:20:49,820 --> 00:20:52,020
There's also then a predictive model.

413
00:20:52,020 --> 00:20:54,100
So predictive models have to do with the value

414
00:20:54,100 --> 00:20:55,980
of the predictive model is not necessarily

415
00:20:55,980 --> 00:20:58,620
in how much they correspond to the real,

416
00:20:58,620 --> 00:21:01,580
but in how much they allow you to anticipate

417
00:21:01,580 --> 00:21:03,020
what is likely to happen.

418
00:21:04,300 --> 00:21:05,940
A simulation is to some extent,

419
00:21:05,940 --> 00:21:07,700
a kind of a blurring between the predictive

420
00:21:07,700 --> 00:21:09,420
and the realist model in this regard.

421
00:21:09,420 --> 00:21:11,140
It's particularly in terms of climate structures,

422
00:21:11,140 --> 00:21:14,540
but more stronger predictive model

423
00:21:14,540 --> 00:21:15,940
is more like what Wall Street does

424
00:21:15,980 --> 00:21:16,980
where they're trying to figure out

425
00:21:16,980 --> 00:21:20,540
what the likely price of Bitcoin is going to be next month

426
00:21:20,540 --> 00:21:23,740
or whether it's gonna make more sense

427
00:21:23,740 --> 00:21:28,740
to put money in Microsoft or Alibaba or something

428
00:21:30,060 --> 00:21:33,380
where the value of it has more to do

429
00:21:33,380 --> 00:21:35,260
with just the ability to predict

430
00:21:35,260 --> 00:21:36,620
what is likely to happen next.

431
00:21:36,620 --> 00:21:38,540
It's a kind of perspective heuristic.

432
00:21:39,580 --> 00:21:41,980
But then there's also then the projective model.

433
00:21:41,980 --> 00:21:45,900
The projective model is a normative model.

434
00:21:45,900 --> 00:21:48,380
It's a model that's not describing

435
00:21:48,380 --> 00:21:51,980
what is happening right now empirically.

436
00:21:51,980 --> 00:21:53,380
It's not a model that's describing

437
00:21:53,380 --> 00:21:55,460
what is most likely to happen.

438
00:21:55,460 --> 00:21:57,660
It's a model describing what should happen,

439
00:21:58,580 --> 00:22:00,980
what should happen, a drawing of what should happen.

440
00:22:00,980 --> 00:22:03,140
And so architecture, for example,

441
00:22:03,140 --> 00:22:06,420
most of its expertise is with the perspective model.

442
00:22:06,420 --> 00:22:08,420
It's you don't hire an architect

443
00:22:08,420 --> 00:22:11,020
to make a model of a building that already exists.

444
00:22:11,020 --> 00:22:12,580
You don't hire an architect to make a model

445
00:22:12,580 --> 00:22:14,820
of a building that's most likely to happen.

446
00:22:14,820 --> 00:22:16,540
You hire them to make a model of the building

447
00:22:16,540 --> 00:22:17,540
that should happen.

448
00:22:18,620 --> 00:22:22,140
And part of the role in I think both for politics,

449
00:22:22,140 --> 00:22:25,540
for design, even for political science

450
00:22:25,540 --> 00:22:30,540
is in the construction of projective models

451
00:22:30,700 --> 00:22:35,700
and prospective models based on descriptive models

452
00:22:35,700 --> 00:22:40,700
and grounded in descriptive models

453
00:22:41,220 --> 00:22:45,980
such that we have some ability not only to predict

454
00:22:45,980 --> 00:22:49,700
what is likely to happen in the case of climate catastrophe,

455
00:22:49,700 --> 00:22:52,620
but also to actually model what should happen.

456
00:22:52,620 --> 00:22:55,700
And so your question about where does governance

457
00:22:55,700 --> 00:22:57,940
and politics fit into this direction of data,

458
00:22:57,940 --> 00:23:00,180
I think there's at least three different answers

459
00:23:00,180 --> 00:23:03,140
to this question in relationship to the descriptive model,

460
00:23:03,140 --> 00:23:05,180
the projective model and the projective model

461
00:23:05,180 --> 00:23:09,180
that there's a logic for of how it is that we,

462
00:23:09,180 --> 00:23:11,420
for example, how it is that we might describe

463
00:23:12,380 --> 00:23:13,980
the planetarity that we want,

464
00:23:13,980 --> 00:23:18,980
describe what a viable planetarity is in a normative sense,

465
00:23:19,540 --> 00:23:22,660
in a projective sense, in an aspirational sense

466
00:23:22,660 --> 00:23:25,420
through the models, through its models

467
00:23:26,620 --> 00:23:29,060
that is also dependent upon the use of models

468
00:23:29,060 --> 00:23:34,060
to actually produce some kind of reliable description

469
00:23:35,060 --> 00:23:36,820
of the circumstance.

470
00:23:36,820 --> 00:23:41,260
And you can imagine, you can imagine,

471
00:23:41,260 --> 00:23:42,740
sort of skipping forward a little bit here,

472
00:23:42,740 --> 00:23:45,580
but you can imagine the ways in which this kind of,

473
00:23:45,580 --> 00:23:47,580
where algorithmic governance,

474
00:23:47,580 --> 00:23:50,300
which again would imply both how we govern algorithms

475
00:23:50,300 --> 00:23:53,060
and how we algorithms become part of the governing function

476
00:23:53,060 --> 00:23:56,260
more generally, how it is that algorithmic governance

477
00:23:56,260 --> 00:24:00,820
could become so ingrained in how it is that we function,

478
00:24:00,820 --> 00:24:03,820
how it is the city functions, how it is that states function,

479
00:24:03,820 --> 00:24:06,100
how it is the corporations function and so forth and so on

480
00:24:06,100 --> 00:24:09,100
that you can imagine something like a political party

481
00:24:10,060 --> 00:24:14,820
that is basically a software stack

482
00:24:14,820 --> 00:24:17,780
where you could imagine you've got four political parties

483
00:24:17,780 --> 00:24:22,020
all vying for being for the city government.

484
00:24:22,020 --> 00:24:23,780
And each one of these political parties

485
00:24:23,780 --> 00:24:25,620
is in essence running a simulation

486
00:24:25,620 --> 00:24:29,940
of what they think the city of the next few years

487
00:24:29,940 --> 00:24:32,260
is going to be based on the variables

488
00:24:32,260 --> 00:24:33,940
that they think is important

489
00:24:33,940 --> 00:24:36,900
based on what their political ideology is,

490
00:24:36,900 --> 00:24:39,580
running this in a sort of massive simulation

491
00:24:39,580 --> 00:24:40,980
of what this future would be.

492
00:24:40,980 --> 00:24:42,260
And then the voters decide,

493
00:24:42,260 --> 00:24:45,860
I'm going to like party number three wins the election.

494
00:24:45,860 --> 00:24:48,700
And once you win the election, your servers go live.

495
00:24:49,660 --> 00:24:54,660
And that in fact, and that becomes the basis of the city.

496
00:24:54,660 --> 00:24:58,860
I mean, this is one way of sort of thinking about that,

497
00:24:58,860 --> 00:25:00,660
thinking about that kind of dynamic.

498
00:25:01,580 --> 00:25:03,980
There's a bigger question though, again,

499
00:25:03,980 --> 00:25:06,980
around sort of the longer term arc of this

500
00:25:06,980 --> 00:25:10,780
of not just how it is that the data can be used

501
00:25:10,780 --> 00:25:13,260
within the existing political institutional structures

502
00:25:13,260 --> 00:25:17,860
that we already have, city governments, state governments,

503
00:25:17,860 --> 00:25:20,140
country governments, UN, whatever,

504
00:25:20,140 --> 00:25:24,140
but the ways in which that at a certain scale

505
00:25:24,140 --> 00:25:28,340
and at a certain point that it becomes a qualitatively,

506
00:25:28,340 --> 00:25:33,340
it constitutes and enables qualitatively different forms

507
00:25:34,300 --> 00:25:37,900
of governance per se that could not have existed otherwise.

508
00:25:37,900 --> 00:25:40,700
And that not only demand,

509
00:25:40,700 --> 00:25:44,860
but indeed already constitute other institutional forms

510
00:25:44,860 --> 00:25:45,860
in the first place.

511
00:25:45,860 --> 00:25:50,860
And it should be clear while I'm interested in the former,

512
00:25:52,780 --> 00:25:56,540
how would it, with my servers going live scenario,

513
00:25:56,540 --> 00:25:58,660
my longer term interest is in the latter.

514
00:25:58,660 --> 00:26:02,020
My longer term interest is in how planetary scale

515
00:26:02,020 --> 00:26:06,780
computation as a whole constitutes the basis

516
00:26:06,780 --> 00:26:10,140
by which it becomes possible, perhaps for the first time

517
00:26:11,740 --> 00:26:15,300
for an always already planetary scale human society

518
00:26:16,980 --> 00:26:21,540
to be able to produce reliable technical abstractions

519
00:26:21,540 --> 00:26:26,060
about its own processes at a scale commensurate

520
00:26:26,060 --> 00:26:27,700
with those processes itself,

521
00:26:27,700 --> 00:26:29,940
which is to say planetary scale,

522
00:26:29,940 --> 00:26:32,820
that would allow for a reorganization

523
00:26:32,820 --> 00:26:37,820
of some of the fundamentals of a economic, political

524
00:26:38,820 --> 00:26:42,820
and ecological circumstance.

525
00:26:42,820 --> 00:26:45,260
That is where I try to link this question

526
00:26:45,260 --> 00:26:46,500
of planetary scale compilation

527
00:26:46,500 --> 00:26:49,500
to some of the questions of planetarity per se

528
00:26:49,500 --> 00:26:52,420
that animates the work of people like Spivak or Mbembe

529
00:26:52,420 --> 00:26:55,060
and where they have an emphasis on literacy,

530
00:26:55,060 --> 00:26:56,860
which in my mind is a bit more numeracy.

531
00:26:58,020 --> 00:27:03,020
The bigger question of how it is that it's possible

532
00:27:03,820 --> 00:27:08,820
for collective reason to be made to manifest itself.

533
00:27:09,620 --> 00:27:14,180
How is it possible for society to compose itself?

534
00:27:14,180 --> 00:27:16,580
And I think one of the things we've seen in the pandemic

535
00:27:16,580 --> 00:27:20,820
in the West, the calamity of how the West has dealt

536
00:27:20,820 --> 00:27:25,180
with the pandemic is a dramatic example

537
00:27:25,180 --> 00:27:30,180
of how much the West is now unable to compose itself,

538
00:27:30,180 --> 00:27:35,180
unable for a society to organize itself in a kind of way.

539
00:27:35,980 --> 00:27:39,780
Certainly the United States and UK and Italy

540
00:27:39,780 --> 00:27:44,780
and Germany are some of the more tragic examples of this.

541
00:27:46,740 --> 00:27:49,140
But this is the real question

542
00:27:49,140 --> 00:27:52,780
of how can a society sense itself

543
00:27:53,740 --> 00:27:55,900
so that it knows what's going on?

544
00:27:55,900 --> 00:27:58,380
How can it model itself in different ways

545
00:27:58,380 --> 00:28:01,540
so that it can produce multiple and different conceptions

546
00:28:01,540 --> 00:28:04,100
of its own collective image?

547
00:28:04,980 --> 00:28:07,820
How can it simulate its possible futures

548
00:28:07,820 --> 00:28:11,620
so that it understands what its possible capacities are?

549
00:28:11,620 --> 00:28:14,060
And then how can these models of the future

550
00:28:14,060 --> 00:28:17,060
recursively act back upon that society

551
00:28:17,060 --> 00:28:19,900
so that it is able to manifest this capacity

552
00:28:19,900 --> 00:28:22,500
for self-composition and collective reason?

553
00:28:23,780 --> 00:28:25,340
That's what data governance is for.

554
00:28:25,340 --> 00:28:26,700
That's what data governance is, I think,

555
00:28:26,700 --> 00:28:27,860
to be in the long-term.

556
00:28:29,500 --> 00:28:33,020
Fantastic. Benjamin, I would like to leave some time

557
00:28:33,020 --> 00:28:34,540
for the students to ask questions,

558
00:28:34,540 --> 00:28:37,540
but there is one closing question

559
00:28:37,540 --> 00:28:39,340
I'd like to ask all of my guests.

560
00:28:39,340 --> 00:28:41,580
And that is, if you think about the future,

561
00:28:41,580 --> 00:28:43,180
what makes you joyful?

562
00:28:47,940 --> 00:28:50,380
I'll just give a simple answer.

563
00:28:54,300 --> 00:28:56,500
My son, my 12-year-old son,

564
00:28:56,500 --> 00:28:58,660
I have more the idea of thinking about

565
00:29:00,100 --> 00:29:04,020
just the process of watching him understand

566
00:29:04,020 --> 00:29:07,300
more and more of how the world works around him

567
00:29:07,300 --> 00:29:10,260
and seeing his interest and frustration

568
00:29:10,260 --> 00:29:11,100
in the rest of this.

569
00:29:11,100 --> 00:29:16,100
And so, probably the ability to think about

570
00:29:17,420 --> 00:29:19,740
the world that he will grow up in

571
00:29:19,740 --> 00:29:21,580
and the world that he will sort of go through

572
00:29:21,580 --> 00:29:23,300
and just sort of think about it on that arc,

573
00:29:23,300 --> 00:29:27,260
it kind of gives you, there's just a sense of,

574
00:29:27,260 --> 00:29:30,900
there's a sense of the stakes of what's at stake,

575
00:29:32,060 --> 00:29:33,540
what's at stake for the future

576
00:29:34,620 --> 00:29:37,420
and where, sort of, to mean.

577
00:29:37,420 --> 00:29:40,820
So, I mean, that's, I mean, it's a simple, stupid answer,

578
00:29:40,820 --> 00:29:42,220
but it's really, you know, like the most,

579
00:29:42,220 --> 00:29:44,860
that kind of like immediately honest one.

580
00:29:45,860 --> 00:29:47,460
You know, more philosophically,

581
00:29:47,460 --> 00:29:49,740
it kind of depends on what we mean by the future.

582
00:29:49,740 --> 00:29:51,820
You know, there's a, we have a problem

583
00:29:51,820 --> 00:29:52,940
of thinking about the future

584
00:29:52,940 --> 00:29:55,580
in terms of the scale of human lifespans,

585
00:29:57,540 --> 00:30:01,460
but, you know, the environments and ecologies

586
00:30:01,460 --> 00:30:04,420
in which we live operate on a different kind of scale.

587
00:30:04,420 --> 00:30:07,300
But, I don't know, there's more specific things,

588
00:30:07,300 --> 00:30:08,660
but I'll just sort of leave it,

589
00:30:08,660 --> 00:30:10,460
I'll kind of leave it at that, maybe.

590
00:30:11,460 --> 00:30:12,300
Fantastic.

591
00:30:12,300 --> 00:30:14,100
Benjamin, thank you so much for your time

592
00:30:14,100 --> 00:30:16,780
and thanks a lot for being part of Future Histories.

593
00:30:16,780 --> 00:30:17,620
My pleasure.

594
00:30:17,620 --> 00:30:18,900
Thank you for inviting me.

595
00:30:24,620 --> 00:30:25,940
Thank you so much for listening.

596
00:30:25,940 --> 00:30:28,340
This has been the interview with Benjamin Breton

597
00:30:28,340 --> 00:30:30,860
that I did in the context of my guest lecture

598
00:30:30,860 --> 00:30:33,540
at the Goldsmiths College in London.

599
00:30:33,540 --> 00:30:36,340
Thanks a lot to Mattia for inviting me

600
00:30:36,340 --> 00:30:41,340
and thanks a thousand times to Benjamin for taking part.

601
00:30:41,500 --> 00:30:44,180
I could not have imagined a better transition

602
00:30:44,180 --> 00:30:47,940
from 2020 into 21 than having Benjamin Breton

603
00:30:47,940 --> 00:30:51,020
as a guest in the last episode of 2020

604
00:30:51,020 --> 00:30:54,540
and then the second part as a start for this year,

605
00:30:54,540 --> 00:30:57,020
so I absolutely love it.

606
00:30:57,020 --> 00:31:00,220
You will now hear the discussion that took place afterwards

607
00:31:00,220 --> 00:31:03,260
and since we didn't have any consent from the students

608
00:31:03,260 --> 00:31:08,260
in terms of releasing their questions as the original audio,

609
00:31:08,460 --> 00:31:12,460
I will simply restate them in order to avoid any problems

610
00:31:12,460 --> 00:31:14,740
in terms of privacy.

611
00:31:14,740 --> 00:31:17,100
The first question comes from Mattia,

612
00:31:17,100 --> 00:31:19,620
so this one I won't have to restate,

613
00:31:19,620 --> 00:31:21,500
but then afterwards I will do so.

614
00:31:21,500 --> 00:31:22,940
Please enjoy.

615
00:31:22,940 --> 00:31:27,940
Perhaps I can ask one question that made all together

616
00:31:28,700 --> 00:31:30,940
what has been said in such detail.

617
00:31:33,900 --> 00:31:37,820
You presented very poignantly

618
00:31:37,860 --> 00:31:42,180
the problem of not thinking technology, politics,

619
00:31:42,180 --> 00:31:45,180
and subjectivity in the classic.

620
00:31:45,180 --> 00:31:46,820
I absolutely agree it is paramount

621
00:31:46,820 --> 00:31:48,980
that we look at these issues.

622
00:31:48,980 --> 00:31:50,620
You did say something at some point

623
00:31:50,620 --> 00:31:52,580
that seemed to me to go against the grain

624
00:31:52,580 --> 00:31:53,900
of the rest of what you were saying

625
00:31:53,900 --> 00:31:56,580
and probably just the way I heard it,

626
00:31:56,580 --> 00:31:59,500
but I think it's important to expand on it.

627
00:31:59,500 --> 00:32:03,420
At some point you said that your best guess

628
00:32:03,420 --> 00:32:08,420
or your look forward was that the superstructure

629
00:32:08,740 --> 00:32:11,620
would prevail over the base structure

630
00:32:11,620 --> 00:32:15,540
in terms of where agency and gravity are located.

631
00:32:15,540 --> 00:32:16,620
No, no, no, no, no, no.

632
00:32:16,620 --> 00:32:19,460
The other way that I was arguing,

633
00:32:19,460 --> 00:32:22,060
just on the point of cause and effect,

634
00:32:22,060 --> 00:32:26,300
I was suggesting that if we want to ask the question

635
00:32:26,300 --> 00:32:28,580
in the totally over reductive way

636
00:32:28,580 --> 00:32:29,860
or if I want to answer the question

637
00:32:29,860 --> 00:32:31,460
in this very over reductive way

638
00:32:31,540 --> 00:32:35,220
of whether or not the culture causes infrastructure,

639
00:32:35,220 --> 00:32:37,460
infrastructure causes culture,

640
00:32:37,460 --> 00:32:40,660
and where we should invest our time,

641
00:32:40,660 --> 00:32:45,220
I would argue I'm on team base causes infrastructure,

642
00:32:45,220 --> 00:32:46,300
base causes superstructure,

643
00:32:46,300 --> 00:32:47,460
base causes superstructure, right,

644
00:32:47,460 --> 00:32:50,900
so that the geotechnology causes geoculture

645
00:32:50,900 --> 00:32:54,060
was more where I was trying to come down on that.

646
00:32:54,060 --> 00:32:56,500
The first student question is,

647
00:32:56,500 --> 00:32:58,900
since you were talking about pricing the future,

648
00:32:58,900 --> 00:33:01,140
I was interested in how that applies

649
00:33:01,140 --> 00:33:04,540
to Shojana Zuboff's surveillance capitalism approach

650
00:33:04,540 --> 00:33:07,820
and how pricing the future could impact individuals

651
00:33:07,820 --> 00:33:10,460
and the kind of ethical implications of that.

652
00:33:11,940 --> 00:33:14,260
Right, so you're right.

653
00:33:14,260 --> 00:33:17,100
I think it's certainly correct

654
00:33:17,100 --> 00:33:20,700
that this question of pricing the future

655
00:33:20,700 --> 00:33:24,780
is something that already exists.

656
00:33:24,780 --> 00:33:26,540
It's not something that would be,

657
00:33:26,860 --> 00:33:31,860
it's already part of the way in which our economies work.

658
00:33:33,540 --> 00:33:35,340
Our economies in many respects are,

659
00:33:35,340 --> 00:33:37,340
whether that's the stock market

660
00:33:37,340 --> 00:33:41,580
or pricing the future attention of an individual user

661
00:33:41,580 --> 00:33:42,980
or something like that,

662
00:33:42,980 --> 00:33:46,980
that pricing the future is not something

663
00:33:46,980 --> 00:33:49,940
that would need to be introduced ex nihilo

664
00:33:49,940 --> 00:33:51,580
or invented from tabula rasa.

665
00:33:51,580 --> 00:33:54,540
It's actually already part of the system.

666
00:33:55,220 --> 00:33:59,980
And then what I'm suggesting then is that the recognition

667
00:33:59,980 --> 00:34:03,020
of this as a strategy and the recognition of this

668
00:34:03,020 --> 00:34:05,900
as something that we have already built a degree

669
00:34:05,900 --> 00:34:08,260
of sophistication and capability with

670
00:34:08,260 --> 00:34:11,140
is something that should not be overlooked

671
00:34:11,140 --> 00:34:15,940
if the goal of the deployment of that capacity

672
00:34:15,940 --> 00:34:17,900
is for something other than predicting

673
00:34:17,900 --> 00:34:19,540
whether or not a user is,

674
00:34:20,060 --> 00:34:25,060
the purpose of this is for rectifying the pathologies

675
00:34:25,340 --> 00:34:28,100
identified as part of the capless pricing problem

676
00:34:28,100 --> 00:34:31,540
as opposed to predicting whether or not a user

677
00:34:31,540 --> 00:34:35,140
is likely to look at this particular cat video

678
00:34:35,140 --> 00:34:36,860
or that particular cat video,

679
00:34:37,740 --> 00:34:41,420
that the relevancy of this technical capacity

680
00:34:41,420 --> 00:34:44,820
is being suppressed by the stupidity

681
00:34:44,820 --> 00:34:46,660
of the way in which we are using

682
00:34:46,660 --> 00:34:48,620
planetary scale computation.

683
00:34:49,500 --> 00:34:50,980
To underscore the point,

684
00:34:52,580 --> 00:34:56,220
one of the differences I have with Zuboff on this point is,

685
00:34:56,220 --> 00:34:59,300
whereas I think for Zuboff, the individual,

686
00:34:59,300 --> 00:35:02,100
the privacy and sovereignty of the individual

687
00:35:02,100 --> 00:35:05,540
as the core unit of planetary scale computation

688
00:35:05,540 --> 00:35:08,020
is not only left unquestioned,

689
00:35:08,020 --> 00:35:11,820
it's in fact re-fortified as the basis of something

690
00:35:11,820 --> 00:35:14,460
that needs to be re-privatized,

691
00:35:14,460 --> 00:35:17,300
that needs to be re-individuated,

692
00:35:17,300 --> 00:35:20,340
that needs to be further individuated

693
00:35:20,340 --> 00:35:24,260
from the supervisory manipulative molestation

694
00:35:24,260 --> 00:35:25,460
from the platforms.

695
00:35:28,980 --> 00:35:32,260
I think deeper and probably more fundamental critique

696
00:35:32,260 --> 00:35:33,940
of the way planetary scale computation works

697
00:35:33,940 --> 00:35:38,940
is that this unit of the self-sovereign private

698
00:35:39,300 --> 00:35:42,300
and privatized individual as the space unit

699
00:35:42,300 --> 00:35:45,340
is itself a kind of original sin

700
00:35:45,340 --> 00:35:47,660
for how we have organized planetary scale computation.

701
00:35:47,660 --> 00:35:52,100
And there is no solution, no kind of social dilemma,

702
00:35:53,780 --> 00:35:55,340
restructuring our privacy,

703
00:35:55,340 --> 00:35:58,660
re-fortifying our anonymity in relationship to one another

704
00:35:58,660 --> 00:35:59,940
in relation to the system

705
00:35:59,940 --> 00:36:02,580
that will ultimately solve that problem.

706
00:36:02,580 --> 00:36:06,780
I think in many ways it's actually re-fortifying that problem

707
00:36:06,780 --> 00:36:08,580
by re-conquering this idea.

708
00:36:08,580 --> 00:36:12,580
So saying the same thing in a few different ways,

709
00:36:12,580 --> 00:36:17,580
but the more fundamental point of the predictive capacity,

710
00:36:18,700 --> 00:36:20,460
the kind of preemptive logic,

711
00:36:21,580 --> 00:36:23,940
the pricing of preemption,

712
00:36:23,940 --> 00:36:27,380
even within planetary scale computation

713
00:36:27,380 --> 00:36:28,260
is something that exists

714
00:36:28,260 --> 00:36:30,460
both in terms of something we might admire,

715
00:36:30,460 --> 00:36:32,220
as in climate science,

716
00:36:32,220 --> 00:36:35,380
where we are preemptively simulating the future

717
00:36:35,380 --> 00:36:37,020
through scenarios,

718
00:36:37,020 --> 00:36:38,780
and something we might not admire

719
00:36:38,780 --> 00:36:40,660
in terms of the preemptive simulation

720
00:36:40,660 --> 00:36:43,620
of what individual users might click on.

721
00:36:43,620 --> 00:36:44,460
But you're correct

722
00:36:44,460 --> 00:36:47,300
that this capacity for preemption already exists.

723
00:36:47,300 --> 00:36:49,540
The next student question is,

724
00:36:49,540 --> 00:36:51,060
picking up on your last point

725
00:36:51,060 --> 00:36:52,700
of predictive, prescriptive,

726
00:36:52,700 --> 00:36:54,980
and projective models of governance,

727
00:36:54,980 --> 00:36:57,100
I was curious how well you think humans

728
00:36:57,100 --> 00:36:58,580
are even able to determine

729
00:36:58,580 --> 00:37:01,940
how well computers or algorithms are modeling.

730
00:37:01,940 --> 00:37:04,540
So when we move into global computation,

731
00:37:04,540 --> 00:37:06,780
or we've already been in global computation,

732
00:37:06,780 --> 00:37:08,420
how well we are actually able

733
00:37:08,420 --> 00:37:11,260
to evaluate models going forward.

734
00:37:11,260 --> 00:37:13,780
Taking chess or Go as an example,

735
00:37:13,780 --> 00:37:17,020
which are comparatively extremely simple systems,

736
00:37:17,020 --> 00:37:19,500
but we already struggle to evaluate

737
00:37:19,500 --> 00:37:21,420
how well computers model them.

738
00:37:21,420 --> 00:37:24,100
They play a lot of moves that we think look wrong,

739
00:37:24,100 --> 00:37:27,140
and only turn out to be effective much later on,

740
00:37:27,140 --> 00:37:29,820
or much further down the road at the end of the game.

741
00:37:29,820 --> 00:37:31,860
So I'm wondering from our perspective,

742
00:37:31,860 --> 00:37:33,780
how well we are able to evaluate

743
00:37:33,780 --> 00:37:36,180
how good the models actually are.

744
00:37:37,140 --> 00:37:40,740
Yeah, it's a really important question,

745
00:37:40,740 --> 00:37:42,460
and one that is doesn't have a,

746
00:37:42,460 --> 00:37:46,140
one that gets more complicated and more interesting

747
00:37:46,140 --> 00:37:51,140
the more you continue to ask it with greater specificity.

748
00:37:53,180 --> 00:37:54,260
So thank you for that.

749
00:37:54,260 --> 00:37:59,260
I think it has a bit of a question around,

750
00:38:01,100 --> 00:38:03,180
if we keep this differentiation as I proposed

751
00:38:03,180 --> 00:38:05,980
between descriptive, predictive, and projective models,

752
00:38:06,820 --> 00:38:09,420
we might have different ways of answering that.

753
00:38:09,420 --> 00:38:11,980
If that is a descriptive model,

754
00:38:11,980 --> 00:38:14,180
the function of which has the ability,

755
00:38:14,180 --> 00:38:17,180
is supposed to be a kind of reductive,

756
00:38:17,180 --> 00:38:20,380
a reductive approximation of a mind-independent reality,

757
00:38:20,380 --> 00:38:22,100
like heliocentrism or something,

758
00:38:22,100 --> 00:38:24,500
at least we have the experimental method

759
00:38:24,500 --> 00:38:26,620
to try to test the model over and over again,

760
00:38:26,620 --> 00:38:28,380
and to try to find out,

761
00:38:28,380 --> 00:38:31,500
to try to test the descriptive capacity of the model

762
00:38:31,500 --> 00:38:33,580
through its predictive capacity.

763
00:38:33,580 --> 00:38:36,980
That is, if this model is true,

764
00:38:36,980 --> 00:38:38,500
then it should be able to predict

765
00:38:38,500 --> 00:38:41,820
what is going to happen under experimental conditions,

766
00:38:41,820 --> 00:38:42,860
X, Y, or Z.

767
00:38:43,780 --> 00:38:45,180
And if under those conditions,

768
00:38:45,180 --> 00:38:46,580
it's not able to predict it,

769
00:38:46,580 --> 00:38:49,260
then we realize that its description might be a bit wrong.

770
00:38:49,260 --> 00:38:51,660
And so, you know, science marches forward

771
00:38:51,660 --> 00:38:56,420
through that kind of testing capacity.

772
00:38:57,300 --> 00:38:59,460
The projective models are ones

773
00:38:59,460 --> 00:39:01,780
that are a little bit more difficult,

774
00:39:01,780 --> 00:39:03,140
but it's also interesting to speak,

775
00:39:03,140 --> 00:39:05,580
since we're talking about temporality of models,

776
00:39:05,580 --> 00:39:06,900
you know, one of the interesting things

777
00:39:06,900 --> 00:39:09,460
about climate models is the way in which

778
00:39:09,460 --> 00:39:12,860
the future is validated against the past.

779
00:39:13,860 --> 00:39:16,140
And what I mean by that is this,

780
00:39:16,140 --> 00:39:17,500
the ways in which,

781
00:39:17,500 --> 00:39:19,340
and I'm sure you're probably aware of that,

782
00:39:19,340 --> 00:39:20,780
but I'll just mention the point

783
00:39:20,780 --> 00:39:23,140
in the context of this question,

784
00:39:23,140 --> 00:39:25,260
the way in which we have some degree of confidence

785
00:39:25,260 --> 00:39:27,660
in why it is that we think that the world

786
00:39:27,660 --> 00:39:30,580
will look a certain way in 2040 or 2050,

787
00:39:31,420 --> 00:39:34,860
given whatever ecological variables

788
00:39:34,860 --> 00:39:37,740
we wish to emphasize,

789
00:39:37,740 --> 00:39:40,780
is because you test that model against past data.

790
00:39:40,780 --> 00:39:42,380
And so, for example, you'll take,

791
00:39:42,380 --> 00:39:43,420
here's the model,

792
00:39:43,420 --> 00:39:46,180
what we think is gonna happen between 2020 and 2050

793
00:39:46,180 --> 00:39:49,060
in that 30-year arc based on these variables.

794
00:39:49,060 --> 00:39:51,060
Let's take that model and try to predict

795
00:39:51,060 --> 00:39:54,460
what would happen between 1820 and 1850

796
00:39:55,340 --> 00:39:57,260
based on what that model should tell us

797
00:39:57,260 --> 00:39:59,660
what would likely happen.

798
00:39:59,660 --> 00:40:03,060
And then you go back and look at what did happen in 1850.

799
00:40:03,060 --> 00:40:05,980
And if the prediction turned out to be true,

800
00:40:05,980 --> 00:40:07,500
if the prediction of the future

801
00:40:07,500 --> 00:40:09,780
turns out to be able to predict the past,

802
00:40:09,780 --> 00:40:11,820
then you have a degree of confidence

803
00:40:11,820 --> 00:40:16,140
in the way in which it would work.

804
00:40:16,140 --> 00:40:17,820
Now, your question, though,

805
00:40:17,820 --> 00:40:20,340
about the kind of the patterns within this,

806
00:40:20,340 --> 00:40:22,300
and I think a lot of it has to do with

807
00:40:22,300 --> 00:40:23,980
the way in which models allow us

808
00:40:23,980 --> 00:40:28,500
to deduce and abstract patterns.

809
00:40:28,500 --> 00:40:29,700
And as I've said a few times,

810
00:40:29,700 --> 00:40:32,460
this capacity for technical abstraction

811
00:40:32,460 --> 00:40:34,300
of collective technical abstraction

812
00:40:34,300 --> 00:40:37,740
is one of the important epistemological functions

813
00:40:37,740 --> 00:40:39,460
of planetary scale computation.

814
00:40:39,460 --> 00:40:41,460
And I'll just emphasize the point here.

815
00:40:42,580 --> 00:40:44,940
There is, in many ways,

816
00:40:44,940 --> 00:40:47,660
the arguments I'm making have as much to do

817
00:40:47,660 --> 00:40:49,220
with the way in which the technologies

818
00:40:49,220 --> 00:40:50,620
function instrumentally.

819
00:40:50,620 --> 00:40:52,700
That is, what are we able to do with them?

820
00:40:52,700 --> 00:40:54,820
But equally importantly, if not more,

821
00:40:54,820 --> 00:40:57,220
is the epistemological function of the technologies.

822
00:40:57,220 --> 00:40:59,660
How is it that through using of these technologies,

823
00:40:59,660 --> 00:41:01,060
we're able to know things

824
00:41:01,060 --> 00:41:03,500
that we wouldn't have been able to know otherwise?

825
00:41:03,500 --> 00:41:04,340
And in many cases,

826
00:41:04,340 --> 00:41:05,780
it's the epistemological function

827
00:41:05,780 --> 00:41:07,820
of planetary scale computation that's most important,

828
00:41:07,820 --> 00:41:10,700
that's more important in the long run, I think.

829
00:41:10,700 --> 00:41:13,020
But your examples of AlphaGo and the chess

830
00:41:13,020 --> 00:41:15,060
and the rest of this bring up an important point,

831
00:41:15,060 --> 00:41:18,580
and that is, in theory,

832
00:41:18,580 --> 00:41:20,980
the function of something like an AI

833
00:41:20,980 --> 00:41:25,380
would be that it is able to see patterns in the world

834
00:41:25,380 --> 00:41:26,620
and patterns in the data

835
00:41:26,660 --> 00:41:29,060
that we would not be able to intuit on our own.

836
00:41:29,060 --> 00:41:31,700
Otherwise, why would we bother building them?

837
00:41:31,700 --> 00:41:34,780
That it's able to see something we can't see.

838
00:41:36,940 --> 00:41:41,140
But what happens when it seems to see something

839
00:41:41,140 --> 00:41:45,460
that seems so weird and unlikely

840
00:41:45,460 --> 00:41:50,460
that we're not sure whether or not it's stupid or ingenious?

841
00:41:50,540 --> 00:41:52,180
We don't know whether or not

842
00:41:52,180 --> 00:41:56,540
there's obviously a deep error in our presumptions

843
00:41:57,460 --> 00:41:58,940
and we've produced a machine that's incapable

844
00:41:58,940 --> 00:42:02,020
of producing nothing but stupid noise,

845
00:42:02,020 --> 00:42:04,180
or we've produced this genius machine

846
00:42:04,180 --> 00:42:05,260
that's able to see patterns

847
00:42:05,260 --> 00:42:07,700
that we never would have seen otherwise

848
00:42:07,700 --> 00:42:10,220
and cause and effect relationships between dynamics

849
00:42:10,220 --> 00:42:14,580
that we've overlooked for our entire evolutionary career.

850
00:42:14,580 --> 00:42:15,740
How would we know?

851
00:42:16,620 --> 00:42:20,180
How would we know whether a totally unlikely pattern

852
00:42:20,180 --> 00:42:25,180
is trivial or fantastically important?

853
00:42:26,180 --> 00:42:31,100
And someone needs to invent a name for this within AI,

854
00:42:31,100 --> 00:42:34,060
I think, where the AI finds a pattern

855
00:42:34,060 --> 00:42:36,860
that we don't recognize as being logical

856
00:42:36,860 --> 00:42:40,220
and yet we have to, in essence, take this,

857
00:42:40,220 --> 00:42:45,220
we have to decide in a way to decide to believe the pattern

858
00:42:45,980 --> 00:42:48,220
or decide not to believe it in a way.

859
00:42:49,420 --> 00:42:53,060
And this is again part of the epistemological complexity

860
00:42:53,060 --> 00:42:53,900
of these technologies.

861
00:42:54,060 --> 00:42:56,380
The example that you gave of AlphaGo

862
00:42:56,380 --> 00:42:57,940
is the key one here,

863
00:42:57,940 --> 00:42:59,940
is the one that everyone refers to

864
00:42:59,940 --> 00:43:01,460
in relationship to this phenomenon,

865
00:43:01,460 --> 00:43:03,820
is that, and for those that,

866
00:43:03,820 --> 00:43:07,100
the computer made this move that at the time,

867
00:43:08,140 --> 00:43:09,460
early in the game,

868
00:43:09,460 --> 00:43:13,740
move 33, I think, of the game against Lee Sedol,

869
00:43:13,740 --> 00:43:18,340
that everyone thought, oh my God, the machine, it's broken.

870
00:43:18,340 --> 00:43:19,300
The AI is broken.

871
00:43:19,300 --> 00:43:21,860
This is very embarrassing for Google.

872
00:43:21,860 --> 00:43:23,660
Right in the middle of game three,

873
00:43:24,420 --> 00:43:25,740
their computer went nuts

874
00:43:25,740 --> 00:43:28,540
and placed a stone way off in the middle of nowhere

875
00:43:28,540 --> 00:43:33,420
and, oh shit, this Google stock's gonna go down,

876
00:43:33,420 --> 00:43:34,420
everything's horrible.

877
00:43:34,420 --> 00:43:36,100
And then, lo and behold,

878
00:43:36,100 --> 00:43:38,740
over a period of the rest of the game,

879
00:43:38,740 --> 00:43:41,140
the whole game arcs towards this one stone

880
00:43:41,140 --> 00:43:44,060
in such a way that it turned out to be ingenious

881
00:43:44,060 --> 00:43:46,220
and as the Sedol, the Go player said,

882
00:43:46,220 --> 00:43:48,340
no human ever would have made that move.

883
00:43:49,220 --> 00:43:53,020
And it was also seen example of the ways in which

884
00:43:54,580 --> 00:43:57,380
it was something that we could take as optimistic,

885
00:43:57,380 --> 00:43:58,460
at least in this regard,

886
00:43:58,460 --> 00:44:03,460
that part of the problem of reinforcement learning-based AIs

887
00:44:03,500 --> 00:44:08,500
and, indeed, using big data models of the past

888
00:44:09,340 --> 00:44:11,620
in order to simulate the future

889
00:44:11,620 --> 00:44:13,940
is that you run the risk of, in essence,

890
00:44:13,940 --> 00:44:17,100
just replicating pre-existing patterns

891
00:44:17,100 --> 00:44:19,940
and presuming that pre-existing patterns

892
00:44:19,940 --> 00:44:22,460
will be continuous into the future

893
00:44:22,460 --> 00:44:25,220
in ways that, in essence, make it so.

894
00:44:25,220 --> 00:44:28,220
You're enforcing the possibility

895
00:44:28,220 --> 00:44:31,740
that pre-existing patterns would be the future patterns

896
00:44:31,740 --> 00:44:33,500
by, in essence, predicting it

897
00:44:33,500 --> 00:44:35,140
and then acting on those predictions.

898
00:44:35,140 --> 00:44:38,580
And so some of the people who do serious work

899
00:44:38,580 --> 00:44:39,940
around AI bias,

900
00:44:39,940 --> 00:44:42,260
there's a lot of un-serious work around AI bias too.

901
00:44:42,260 --> 00:44:44,660
People who do serious work around AI bias,

902
00:44:44,660 --> 00:44:46,500
a lot of the work is based on this question

903
00:44:46,500 --> 00:44:47,740
that you have previous patterns

904
00:44:47,740 --> 00:44:49,900
and that making predictions and policies

905
00:44:50,020 --> 00:44:52,460
and the previous patterns will enforce this,

906
00:44:52,460 --> 00:44:56,140
which is a real and serious general problem

907
00:44:57,820 --> 00:45:01,220
about the ways in which previous models replicate themselves.

908
00:45:01,220 --> 00:45:03,580
What it showed with the AlphaGo thing

909
00:45:03,580 --> 00:45:08,220
was at least the possibility that, no, novelty is possible,

910
00:45:08,220 --> 00:45:10,340
that there is some way in which,

911
00:45:11,180 --> 00:45:13,380
even through the reinforcement learning methods

912
00:45:13,380 --> 00:45:15,700
of the built AlphaGo,

913
00:45:15,700 --> 00:45:18,500
that in this production and its conceptualization

914
00:45:18,500 --> 00:45:22,140
and its prediction and its sort of stochastic perspective,

915
00:45:22,140 --> 00:45:26,540
prediction of what the right move would be.

916
00:45:26,540 --> 00:45:28,340
And in this case, the right move would be part

917
00:45:28,340 --> 00:45:29,940
of what we're calling a projective model,

918
00:45:29,940 --> 00:45:32,380
a normative model, not a descriptive predictive,

919
00:45:32,380 --> 00:45:34,660
but a normative model of what the right move would be,

920
00:45:34,660 --> 00:45:36,420
that it could come up with something

921
00:45:36,420 --> 00:45:40,020
that we would never have thought of itself.

922
00:45:40,020 --> 00:45:44,340
That it was an example that AI is capable of being

923
00:45:44,340 --> 00:45:47,300
a kind of epistemic machine

924
00:45:47,300 --> 00:45:52,140
that's capable of producing ideas, producing novelty,

925
00:45:52,140 --> 00:45:55,500
producing patterns we wouldn't have been able to see.

926
00:45:55,500 --> 00:46:01,420
And in that sense, I take the weird alienation

927
00:46:01,420 --> 00:46:03,220
we may have had from the logic of that move

928
00:46:03,220 --> 00:46:09,020
as very optimistic, as very, very good news in this kind of regard.

929
00:46:09,020 --> 00:46:14,220
But again, your question about how do we validate the model

930
00:46:14,220 --> 00:46:15,980
and how do we not only validate the model,

931
00:46:15,980 --> 00:46:17,780
whether it's come up with something stupid,

932
00:46:17,780 --> 00:46:22,100
but how do we ensure that even the validity of past models,

933
00:46:22,100 --> 00:46:25,580
how do we outsource size ourselves from this position

934
00:46:25,580 --> 00:46:30,740
where the previous models are simply replicating themselves,

935
00:46:30,740 --> 00:46:33,580
becoming recursive in the bad sense,

936
00:46:33,580 --> 00:46:39,220
becoming a kind of echo effect where we're using all of these systems

937
00:46:39,220 --> 00:46:43,060
as simply a way to enforce the condition

938
00:46:43,100 --> 00:46:46,540
by which the future is just an echo of the past.

939
00:46:46,540 --> 00:46:49,540
This is also a way in which our relationship to these models

940
00:46:49,540 --> 00:46:54,180
must be seriously interrogated.

941
00:46:54,180 --> 00:46:57,260
The other side of this is, so you could think of it in this way,

942
00:46:57,260 --> 00:46:59,380
one, how do you use these models in such a way

943
00:46:59,380 --> 00:47:03,500
that you can act upon their implications recursively,

944
00:47:03,500 --> 00:47:06,340
which is what we want to do with climate change models,

945
00:47:06,340 --> 00:47:11,340
but also how do you ensure that these models continue to accelerate

946
00:47:11,340 --> 00:47:15,540
the space-based search function by which they're able to identify

947
00:47:15,540 --> 00:47:21,140
and look for and produce novelty, produce innovation,

948
00:47:21,140 --> 00:47:24,460
produce something that hasn't happened before?

949
00:47:24,460 --> 00:47:30,380
And I think a lot of the philosophy of computation

950
00:47:30,380 --> 00:47:34,900
of the next several decades will be based upon that conflict

951
00:47:34,940 --> 00:47:40,180
between modulating recursion

952
00:47:40,180 --> 00:47:45,820
and modulating face-based search and novelty production.

953
00:47:45,820 --> 00:47:49,300
So the last student question was asked with a strong British accent,

954
00:47:49,300 --> 00:47:51,860
and I hope I managed to capture the essence.

955
00:47:51,860 --> 00:47:56,780
The question brings up Andrew Geim and how he used very off-the-charts methods

956
00:47:56,780 --> 00:48:02,020
and ideas in his so-called Friday experiments when discovering graphene.

957
00:48:02,020 --> 00:48:05,860
In relation to that, AI seems very methodical and logical,

958
00:48:05,860 --> 00:48:11,580
and so there's the question of how AI could incorporate these acts of randomness,

959
00:48:11,580 --> 00:48:17,540
and also when it does so, how it knows when it found anything of value.

960
00:48:17,540 --> 00:48:20,460
Yeah, I mean, it's the same thing with the Friday experiments,

961
00:48:20,460 --> 00:48:24,140
is that many of them, the value of them is uncertain,

962
00:48:24,140 --> 00:48:28,540
where it may be that it's not as though...

963
00:48:28,580 --> 00:48:35,540
It's not as you can expect that through some sort of randomization process

964
00:48:35,540 --> 00:48:40,500
that by definition, some kind of fitness,

965
00:48:40,500 --> 00:48:43,100
some sort of process will necessarily hold.

966
00:48:43,100 --> 00:48:46,700
It's the same kind of dynamic of mutation and evolution, I suppose, in that regard.

967
00:48:46,700 --> 00:48:50,660
Most mutations are useless.

968
00:48:50,660 --> 00:48:53,100
But that's probably the same for the AI, too,

969
00:48:53,100 --> 00:48:57,420
that you're expecting them to every time come up with this is probably inaccurate.

970
00:48:57,420 --> 00:49:01,140
But I should say that there's a whole other lecture to describe about the ways...

971
00:49:01,140 --> 00:49:06,700
I think that also going forward, this term AI will hopefully

972
00:49:06,700 --> 00:49:09,500
sort of fork into a much more specific terminology,

973
00:49:09,500 --> 00:49:13,620
that when we're talking about the kinds of...

974
00:49:13,620 --> 00:49:16,460
The things that different kinds of AI are good for,

975
00:49:16,460 --> 00:49:21,860
where reinforcement learning versus other kinds of techniques,

976
00:49:21,860 --> 00:49:25,460
Judea Pearl and other people, and Gary Marcus are trying to bring back

977
00:49:25,500 --> 00:49:28,660
a more symbolic modeling type of structures here as well.

978
00:49:28,660 --> 00:49:33,060
That AI is lots of different technologies, and AI is lots of different techniques,

979
00:49:33,060 --> 00:49:38,380
and AI is built upon its sensing capacity as much of its calculative capacity,

980
00:49:38,380 --> 00:49:44,020
that the question of how can we guarantee AI is heading in one direction in terms of that,

981
00:49:44,020 --> 00:49:54,180
I think it will be able to ask the question with a greater deal of specificity and context.

982
00:49:54,220 --> 00:49:59,020
So, and I don't know, I probably would not agree with the idea that in general,

983
00:49:59,020 --> 00:50:11,460
AI is just a kind of brute force rationalization as its only capacity and its core capacity.

984
00:50:11,460 --> 00:50:15,260
But at the same time, I might suggest that there's something quite amazing

985
00:50:15,260 --> 00:50:18,020
about brute force rationalization in its own sense,

986
00:50:18,020 --> 00:50:25,100
and that it may be that many of the most interesting forms of mind-bending,

987
00:50:25,100 --> 00:50:32,340
pattern-finding abstraction that we learn from AI is from its brute force rationality,

988
00:50:32,340 --> 00:50:40,340
that we shouldn't assume that rationality and creativity are somehow the opposite of one another.

989
00:50:41,220 --> 00:50:51,820
In many cases, they're quite at home, and that many of the ways in which we kind of lapse into,

990
00:50:51,820 --> 00:51:00,380
on the human side of the ledger, lapse into convention and cliché and stereotype and muddy thinking

991
00:51:00,420 --> 00:51:10,620
and sort of replicating the known is because of a reliance on sort of arbitrary,

992
00:51:10,620 --> 00:51:19,100
irrational processes of semiotic symbolization, that in many cases the fact that we're constantly

993
00:51:19,100 --> 00:51:26,500
repeating ourselves is more to do with culture than it has to do with math.

994
00:51:26,780 --> 00:51:31,900
It may be that rationality does provide a certain kind of escape route that we shouldn't overlook.

995
00:51:31,900 --> 00:51:41,420
There was a question about Ted Chiang. People are probably most familiar with Ted Chiang,

996
00:51:41,420 --> 00:51:48,660
he's the author of the movie Arrival was based upon. Anyone who enjoyed that movie,

997
00:51:48,660 --> 00:51:53,260
I would strongly suggest reading the short story, it's called The Story of Your Life,

998
00:51:53,260 --> 00:52:04,580
which is a really fascinating story. It's based around this idea of artificial linguistics,

999
00:52:04,580 --> 00:52:09,860
and linguistics. It's a short story that you kind of need to know a little bit about linguistics

1000
00:52:09,860 --> 00:52:13,900
theory in order to make your way through it, or if you make your way through the story,

1001
00:52:13,900 --> 00:52:19,540
you will have learned quite a bit about linguistics theory by reading the story.

1002
00:52:19,540 --> 00:52:28,700
But in terms of things like, there's a lot of interest of late, of course, in things like GPT-3

1003
00:52:28,700 --> 00:52:37,340
and other ways in which the algorithmic production of different kinds of language as a predictive

1004
00:52:37,340 --> 00:52:43,100
model, language as structuring model of here as well. I think if we want to go deeper on this

1005
00:52:43,100 --> 00:52:48,700
question of where it is that the technologies of thought and the technologies of inscription,

1006
00:52:48,740 --> 00:52:53,180
technologies of modeling, technologies of description, the basis of inscription and

1007
00:52:53,180 --> 00:52:57,740
ontology in relationship to some of these kinds of dynamics, the relation between our own kind

1008
00:52:57,740 --> 00:53:04,660
of cognitive prospection, the ways in which our models of the world, the Bayesian prediction

1009
00:53:04,660 --> 00:53:10,900
functions of our models of the world are the basis of our own neuroscience, and how that gets

1010
00:53:10,900 --> 00:53:17,980
inscribed into our capacities for signification and communication through language. This field

1011
00:53:17,980 --> 00:53:24,540
of artificial linguistics is one that would be certainly a rich area for anyone to spend some

1012
00:53:24,540 --> 00:53:28,700
time with. Thank you very much. It has been extremely interesting. Oh, thank you. Thanks

1013
00:53:28,700 --> 00:53:39,900
for the invitation. Thanks a lot, Benjamin. That was our show for today. Thanks a lot for listening.

1014
00:53:39,900 --> 00:53:45,180
If you want to support future histories, you can do so on Patreon, or you can just simply tell a

1015
00:53:45,180 --> 00:53:50,300
friend that you heard of the show and that he or she might like it as well.

1016
00:53:50,940 --> 00:53:53,580
Have a good time and hear you in two weeks.

