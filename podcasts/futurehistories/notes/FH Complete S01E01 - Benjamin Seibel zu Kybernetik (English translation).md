# FH Complete S01E01 - Benjamin Seibel on cybernetics

Welcome to Future Histories, the podcast to expand our idea of the future. My name is Jan Gro√ü and I am very happy to welcome you here for the first episode. If you want to learn a little bit more about the podcast, I encourage you to check out episode 0, where I introduce the podcast a little bit. Today's guest on Future Histories is Benjamin Seibel, head of the Ideation and Prototyping Lab at the Technologie Stiftung Berlin and author of the book Cybernetic Government, Information Technology and the Rationality of Government from 1943 to 1970. I read the book with really great interest, because cybernetics seems to me essential when it comes to questions of the contemporary and especially the future exercise of power. If you don't know what cybernetics is, don't wait any longer. We jump right into the conversation with Benjamin Seibel. Welcome Benjamin. Hello Jan. Well, as I said in the introduction to this episode, cybernetics seems to me to be a very central element for understanding contemporary and future exercises of power, but at the same time the term is not really familiar anymore and I would say that most people really don't have any idea what it means. So first of all the question, what is cybernetics? This is actually not so easy to answer. First of all, cybernetics is a scientific discipline whose origin can be dated relatively well to the book with the same title Cybernetics by Norbert Wiener published in 1948. And yes, if someone has never heard of it, I sometimes say so casually, it's a precursor science to computer science. That's not entirely true, but at least it's not entirely false either. So in essence, it's really a theory of information-processing machines. That is really something very new at that time. At the same time, however, cybernetics also stands for a kind of technological epochal threshold, i.e. really for a technological revolution and also for the dawn of a new age. That's how it was sold by the protagonists and that's how it was perceived by the public at the time. So in the 50s and 60s cybernetics is also a popular topic. This impression of an epochal threshold is not entirely unjustified in that cybernetics actually brought together for the first time certain developments that we would today call digitalization. At that time, we did not speak of digitization, but of cybernetics. The reason for the success of this book, or to a certain extent the punch line of Norbert Wiener's book, is that on the one hand he writes a theory of information-processing machines, but at the same time he claims or assumes that this theory is transferable to all kinds of things. That one can understand basically also living beings as information-processing machines, which function with similar mechanisms, which take up thus over their senses information, which feedback mechanisms work, have in itself and then adapt again and again also to environment. And on this basis, that one can actually regard everything as an information system, cybernetics can then also spread and also begin to change other scientific disciplines. And that's what happens. So you see in the 1950s, 60s then really the emergence of cybernetic biology, of cybernetic psychology, of cybernetic linguistics and so on. So there's a huge hype at that time. In your book Cybernetic Government, you looked at a specific place where cybernetic thought had an impact, the question of government. So this way in which cybernetics looked at the world, as you have just said, this integration into an actually generalizable functional logic, was then also transferred to the question of the good form of government. How did that work out? What were the problems that people thought they could solve with it? What were the hopes and images of the future that were associated with it? Yes, as I said, these cybernetic models are spreading out in all possible directions, not only into engineering and the natural sciences, but also into the sciences of man and society, and thus also into political theory and government science. In principle, there is a very long tradition in political knowledge, going back to antiquity, of thinking politics and technology together. This means that the state is compared with the prevailing technologies of the time, perhaps with a ship in antiquity, or with primeval plants in the early modern period, for example. And what I wanted to show in my work was that this is not simply meant metaphorically, but that these models of the state as technology conceal very specific ideas of what governing means, who governs, how it is governed, for what purpose it is governed, and so on. So cybernetics now says well, if people are information-processing systems and societies are also information-processing systems, which we can think of as something like a computer network, for example. What does that mean for our understanding of society and how can we use this knowledge or this perspective to better understand how societies can be controlled or coordinated? And so a current of political cybernetics emerged in the 1950s and 1960s. One of the protagonists is Karl Wolfgang Deutsch, who also wrote a book that is called political cybernetics in German, and one can actually observe a very interesting retranslation. That is, first you assume that people function like machines and then you come to the conclusion, well, if people function like machines, then they can also be governed by machines. That is, we start to think about whether the task of a state could not be taken over by an information system. So we could imagine society being governed by a computer. And this is played out by the representatives of this current and the whole thing happens at a time, so actually immediately after the Second World War, many of these information technologies are originally military technologies. This is happening at a time when in America, and this is the context I was looking at, people in America are convinced that liberalism is the best form of social organization. There's a broad consensus in society about that. But at the same time, liberalism is also seen as endangered. Not least against the background of the bloc confrontation with the Soviet Union, people think, oh, there's socialism over there somehow, that's the competitive system, and that works pretty well. In the 1950s, people had the impression that the Soviets were doing really well, they were launching satellites into space, they were doing atomic bomb tests and so on. In other words, there's a bit of concern that liberalism, if left unchecked, might fall behind. Consequently, one believes that liberalism must be technically improved and supported, and that's where cybernetics comes into play, so to speak. Because I already said that there are older models of thinking about the state in technical terms. But these models were sooner or later discarded because they were perceived as too rigid and did not take into account the freedom of the individual, so to speak. So this absolutist model, the state is a clockwork, the prince is somehow the spring and all the other people are just cogs. With the French Revolution, at the latest, that was somehow a bit outdated, because people said, wait a minute, individual freedom, and it is precisely liberalism that relies very strongly on the freedom of the individual. Not only for humanistic reasons, but above all for economic reasons. And this freedom of the individual, it was believed, was not compatible with technical models until cybernetics came along, which said, hey, we have a whole new kind of technology here, of flexible, adaptive technology, which can always adapt, even to different circumstances. And this technology, it was then believed, was perfectly compatible with liberalism and freedom. It was, so to speak, a technology of freedom. This is literally how Stafford Beer, a leading cyberneticist, described it. Cybernetics as a technology of freedom and thus also compatible with the liberalism of the Americans. So there were an unbelievable number of things in there, where I simply have the feeling that one can apply a great deal to a contemporary situation as questions, i.e. contemporary questions. At least I have the feeling that liberalism is being questioned in a different way nowadays. In this case, it's not about this classic bloc conflict of the Cold War. But I also have the feeling that the previous justification mechanisms are no longer able to really convince. And here, too, cybernetics or digitalization jumps into the breach and at least pretends to have alternative solutions or at least to be able to develop them somehow. But maybe that's going too far right now. I'd like to go back for a moment to the way you yourself look at the question of technology. If I could make a polemical point of it, I would say that there are somehow three camps, and one camp is actually afraid of everything and feels that technological change is too much or perhaps even wrong. They often believe that something worth protecting, something real and original is being lost. Sometimes this is nature, sometimes the essence of man is the assumed or an assumed balance, a natural thing or also his immediacy and things like that. Then there is, so to speak, this technology-enthusiastic camp, which then are rather techno-opotists and basically use technology as a kind of substitute religion. But there's always a kind of technological determinism inscribed there, where it's said that there's technological progress, that it's inevitable, and that it's absolutely welcome and will lead us all into a better future. People then believe, so to speak, that all the problems that arise along the way will somehow be solved. Then there's the group of people who don't really deal with such questions and who use the technology, but who don't question it any further. Now I had the feeling that you were trying to suggest a slightly different approach. Can you perhaps give us a bit more insight into that? Yes, first of all, I think you've described it quite aptly, and apart from the people who aren't interested in it, who can't be helped, there are of course actually these two camps of the rather optimistic and rather pessimistic view of technology. Both also, of course, have a long history in the philosophy of technology or in the philosophy of culture and cultural criticism. Now it is the case that technology, and this is a central argument in my book, first of all opens up spaces of possibilities for action for us, and that means that technology opens up possibilities for action for us, which can be both good and bad. Therefore, it is clear that both the optimistic and the purely pessimistic perspective are each in their own way truncated. So one would counter the pessimists now from a philosophy of technology point of view that their ideas of originality, of nature and of the nature of man are actually constructed ideas. Philosophy has dealt with this very intensively in the 20th century. So this origin, it does not exist in this form, but we construct it for ourselves. Bruno Latour has done some beautiful work on this, but Martin Heidegger, for example, has also worked out the thesis that we actually develop the whole world for ourselves technically, that we also develop our understanding of ourselves technically, and that technology is not added to us humans afterwards, when we are already finished, but that the use of technology actually makes us humans in the first place. And that's where this harsh juxtaposition comes from: there's pure man, and then there's technology, and then technology, I don't know, approaches us and bothers us, so it's actually a thesis that can't be upheld. To the optimists who think everything is great about technology, one would probably counter that it is true that technology always opens up new possibilities for action for us, and that these are often exciting and interesting and good possibilities for action, but that this expansion of our possibilities for action is always accompanied by risks and impossibilities. So we can use technology, but at the same time we have to submit to the conditions that technology imposes on us. So we are not completely sovereign in dealing with technology, but we also have to fit in with technology, and technology development is also uncontrolled, at least in part, and we may only see many risks when they occur. This means, of course, that caution is called for and that it is always necessary to carry out technology, criticism and also risk analysis. Now, there is a second distinction that you mentioned and which, to a certain extent, cuts across this and concerns the question of how much we as people or as a society can influence the development of technology at all. Here, too, there are historically two extreme positions in the philosophy of technology, namely technology determinism, which says, well, technology development actually follows its own logic of efficiency and we can't have that much influence on it, but rather that technology influences us and shapes and changes us as a society, and we as humans don't have that much room for maneuver. By the way, this also exists in optimistic and pessimistic form. You can say that technology is our savior or you can say that technology is our downfall, but both currents would say that it is not really in our hands. That would be the extreme position of technological determinism, and on the other hand, there are social constructivist positions, so-called positions, which claim or assume that technology can be shaped and is thus of course also social and political, and this goes so far in the extreme position that one would assume that technology can be shaped at will and is thus actually only an expression of our social conditions. Now, from a power-analytical point of view, and this is the one that also interests you, both of these extreme positions are also difficult. If technology really determines us completely, then we basically have to capitulate to it, then we have no possibilities of influence at all. But if technology can actually be shaped at will, then it does not become a problem in terms of power analysis, so to speak, but then we have to look for the problems differently. Then the problems may lie in the economy or in other areas, and technology is only one expression of them. My aim was to mediate a bit between these perspectives and to bring together the impulses that I consider correct from both strands, and I ended up saying that yes, there is indeed a determinism of technology, but it lies at the level of our possibilities for action. That is, technology provides us with spaces of possibilities for action. But it does not give us, it does not force us to realize a certain possibility, but we have room for maneuver. You can use technology for different purposes, you can perhaps also creatively repurpose it, but you can't use it arbitrarily; certain things work and others don't work. From this point of view, technology certainly has a social power and, for example, technical changes also have the potential to massively change society. But at the same time, we as a society naturally have room for maneuver, and that makes technology a highly political matter. So if technology itself and cubernet thinking, which also underpins this technology, creates such spaces of possibility for us, then the question arises all the more, as you just said, what are these spaces of possibility in concrete terms that arise in the course of today's technologies and what forms of use are revealed to us. I'm thinking specifically of technologies such as big data or, more broadly, the growing influence of algorithmic logic on all our lives. Artificial intelligence and biotechnology are very close to all this, also in the sense of a question about governance. Is there any way to fan that out? So can you create some kind of overview of this vastness of the possibility space and the form of use? So do you feel like you're overlooking that in some way? Yes, it's the case with possibility spaces that you can't actually map and describe them exhaustively. So you can observe what happens in them, you can also imagine what could happen, but of course surprises are always possible and options are realized that you might not have seen before. That also happens all the time. But from that point of view, of course, it's still enormously important theoretically and politically to understand what our options are for action and what the risks are and so on. And what I tried to do in my work was to identify certain fundamental issues that were defined comparatively early on, in the 1950s, and that in a way continue to preoccupy us today. So in the book I really look at this period from the 1940s to the end of the 1960s, and at the same time it is important to me to show that what is being discussed there is highly relevant for the present. And that's also a bit of the idea when you work geniologically, you try to understand how we became what we are today. In other words, the present always resonates, even in historical analyses, and it's really about understanding the present from the past. And during the research, I was really amazed myself at how much of what concerns us today, as you have just mentioned a few topics, was already latently present back then, even if technology was still a long way off. But people basically anticipated this quite well, be it fields such as artificial intelligence, algorithms, or the way communication works today in social media, for example. All of this has actually already been thought out and defined, and perhaps one could actually say that many of the problems we face today are actually only refinements or extensions of this cybernetic dispositif. So I can perhaps give you an example from the book, rather anecdotally, so that you can perhaps get a better idea of this. Cybernetics is the first science to assume that information is a category that can be considered quantitatively. That's a very important aspect of cybernetic thinking. So before, communication always had something a bit magical about it, and cybernetics looks at it from the point of view of communications technology and says that communication is basically signal transmission, and we can measure and quantify and trace these signals, for example. That's taken for granted today in the digital age because all our communication is digital, but back then it was just new. And then there are also social scientists who are asking, what can we do with this new perspective? And a really nice story that I discovered in the course of my research, there's a researcher in the early 1950s in the U.S., his name is Stuart Dodd, and he takes this mathematical communication theory and says, hey, we can apply this to society and we can use it to try to better understand how communication works in society. And then he does an experiment. Namely, he takes a tethered balloon and drops leaflets over a small town and on these leaflets, there's a slogan on it and then there's a note on it, remember this slogan, in the next few days someone will come to your house and if you know the slogan, then somehow you'll get a package of coffee as a gift or something. That's an experiment. And then he drops leaflets over the city and then a few days later he sends his staff door to door in this city and they ring the doorbells everywhere and they ask everybody, do you have knowledge of what's on this leaflet? And if so, how did you find out? And then you sort of start mapping the society in this small town as a communications network and you start identifying certain nodes and you discover things. You discover, for example, that there are large nodes and small nodes, that there are individuals who have a lot of communicative contacts. For example, it's often children. That's quite nice in this story. So they notice, a lot of people in the city have received this information from children, because children are outside a lot and children have a lot of social contacts and are very talkative. And children are in this sense very important nodes and today you would say for example influencers in social networks, so the people with a lot of contacts. And so a social communicative network is actually already mapped there or a kind of viral communication, one would also say today. These terms don't exist yet, of course. But also, for example, the thesis that information spreads in a similar way to diseases, that it can therefore infect, that perhaps in the marketplace, where many people can also catch the flu, you can also infect yourself with information in the same way. This is a completely new way of thinking about the topic of communication, which, for example, is already being thought about today in the social networks, which are also based on a totally quantitative logic, which is totally up-to-date and which, at that time, was still being thought about with very rudimentary means, namely somehow with pen and paper. This is, for example, a very good example of how problem areas are defined that still occupy us today, even though technology has, of course, developed massively and today we are actually experiencing a form of quantification, also of data processing of the entire world, of which the Kubernetes back then would only have dreamed or in part also dreamed, that each of us has a smartphone in his pocket and tracks his movements and all communication is stored digitally. That is, of course, something that was still a vision of the future back then. It must also be said that back then it was still a vision of the future that was rather positively charged, i.e. that people thought we could then use this data to simply coordinate society better, to make society better. And well, today we see that it is mainly large corporations that collect this data for profit. This was not thought of in this way at the time, but it's just one example of how things always turn out differently than you think they will at the beginning. And what kind of, let's say, ideological assumptions are involved? So what is this better? I would think that the better in this context is mostly a concept of efficiency, isn't it? So the point is that the exchange of communication, to which everything else is also linked from this perspective, can take place more smoothly and that somehow believed hurdles can be cleared out of the way, so that a social process can run more efficiently, right? So that's already this idea of better, so to speak, isn't it? Exactly, these technical models of society are basically always based on an idea of efficiency. That's what technology does. And if you now apply such a technical model to a society, then of course you also adopt these technical categories, then a society is primarily good if it functions according to the technical specifications. For example, when communication can flow as freely as possible and messages are not lost along the way. So there is an interesting interconnection of technical defect and social defect, where it is no longer really asked whether this is socially desirable at all or politically desirable at all, but rather one has a certain model of how society and how people function and then one tries to promote them so that they actually function in the way that this machine logic actually dictates. But in fact, for example, this intensification of communication is such an important coordinate and I find that interesting especially from a critical perspective, because more socio-critical perspectives have often believed that power would try to prevent communication or would try to suppress our free communication. Whereas with cybernetics, we have a type of power that actually permanently promotes communication and permanently tries to achieve more communication and establish more connections, which is, for example, exactly the ideology that corporations like Facebook follow today when they say we want to integrate the whole world into our network. That's not even about excluding people anymore. So at least in a first step, it's not about excluding people, it's about integrating everyone. And that's a very interesting development from a power-analytical point of view. And today's dissidents who oppose this are often people who also come from this crypto scene, where it is said, okay, we need strong encryption mechanisms and a pronounced privacy in order to undermine this form of exercising power, and when reading your book I asked myself, among other things, to what extent this does not also run into the void, because, at least as I had understood it, within cybinetics it is not the content of the message that is of great importance, but the act of communication itself. And if we now say that we operate encrypted communication, is that at all a starting point to undermine this form of power logic, I asked myself. That's an interesting thought, yes. In fact, one could probably argue that it comes to nothing on this point, because this idea of communication comes from kybinetics and is actually one that says, first of all, the more communication, the better, and if we can all communicate with everyone without friction, then the rest will organize itself, I say, somewhat flippantly, because kybinetics is always about self-organization, which is also an emancipatory idea. It's not all bad in cybinetics, you could say at this point. So you could actually say that it doesn't matter whether you encrypt or not, but of course there are also other power vectors within cybinetics and another one is the visualization of information and data in order to make them the basis for decisions. In other words, there is an early line of power that says everything should be stored, everything should be brought together in large central databases, so that we can then build intelligent machines that are perhaps even better than humans at making decisions that affect our society. And at this point, something like cryptography can perhaps also be so promising, if you say, yes, you may be able to tap our data, but you can't read it. And the readability of the content of the message is, do you think, still necessary for a real penetration by the power apparatus even then, because in order to really make a political decision based on the data, it's not enough to intercept the act of communication and maybe its metadata, but it also needs the actual content, so to speak. Phew, that's not easy to answer, because there's not just one idea of cybanetic governance, there are different ones. There were, for example, also considerations in socialism to set up cybanetic societies. This means that these cybanetic technologies can be used under quite different auspices. We can actually imagine a free, self-organized society in which digital technology is actually used to distribute resources efficiently, to create more justice, whatever. And in the same way, we can imagine a dictatorship that used cybanetic technology to control all people seamlessly. And depending on what form of rule you imagine or what form of organization of society you imagine, of course other aspects then become important. That's why you can't give such a general answer. Yes, that is a very, very interesting aspect that you mention. And that actually refers back to what you said at the beginning, namely that there are basically these spaces of opportunity and we have to decide how we want to use these spaces of opportunity now. In the course of your discussion, even if the book was more about the US-American area, did you actually look into cybernetics, in the GDR or in the Soviet Union and say the inherent argumentation logics, which were then used there again. You also mentioned Stafford Beer, who initiated Project CyberSyn in Chile, which I also found very interesting. Did you ever, that is, did you also deal with it, or was that beyond the scope? Well, I've already looked at all that. I had to rather, when I wrote the book, I decided to leave it out, because it's just a completely different context and then the book would have been twice as long. But of course I looked closely at these developments in the Soviet Union, in the GDR, and also in Chile. There is also quite good literature on this. I have to say that I found this GDR discussion in particular rather ponderous and very ideologically charged, and I had the feeling that it was not really all that productive. But this story in Chile and the Allende is of course highly exciting. And there you can see once again that cybernetics was also compatible with such rather socialist or planned economy systems, where the idea was actually to use computer systems, for example, to distribute resources differently. This is also an idea that is still current. I mean, we all know that huge amounts of resources are wasted in capitalism, that people suffer from hunger and that others throw away food, etc. And that's definitely something where you have to be aware of. And that's something you can see in this adventurous project in Chile, which also seems very futuristic. So it is really worthwhile to google this, Project CyberSyn, where exactly such questions became virulent. So cybernetics can't help the planned economy achieve a breakthrough? Well, this is also an interesting discussion within economic theory, I don't want to go too far, but within economic theory. There was a debate about it, the so-called Socialist Calculation Debate, where the question was, is the market the most efficient information processor, so to speak, or can we imagine a better one? And in my view, this question has not been conclusively settled. At that time, there were people like Friedrich von Hayek who said that we don't have a better processor, that the market is the best CPU and that we have to follow the market. But this question can of course be asked again and again with the further development of technology and say, well, is that actually still the case or can we imagine other systems in the meantime? That's why it remains super exciting and can always be updated. Absolutely, I think that's a very, very, very exciting topic. Because I think I'm really going to do a separate episode on the question of the Socialist Pricing Debate, because I really feel like that addresses a core contemporary power question. I'd like to then look again with you into the future and definitely ask that system question again. But before we do that, I think we need to clarify something else. Namely, the question of when we now say, okay, you can use technology in different ways, it opens up spaces of opportunity, but it is not fixed in what form we then commit them. If we now look at Kubernetes, there is still this origin myth of Claude Shannon and his information theory, in which there is a kind of omission. And I think the technology critics also like to refer to this. And as I understood it in your book, it's that in order to be able to develop his theory of information and communication, he necessarily left out a certain area, which he then called noise. And now, of course, a valid criticism would be to say, okay, but listen, if you're now saying we've created a new way of looking at the world that allows us to explain virtually everything about feedback loops and self-regulating systems. If you claim that, then you cannot arrive and exclude a certain part of the world from this systematization from the beginning. Because then you have not created a mechanism for the description of the world, which is complete. What was the logic of argumentation? Well, the logic of argumentation is that technical models always give a reduced picture of the world. The people who use these models are often aware of this. The argument is, so to speak, that the model becomes productive precisely because we leave out a great deal. That is the case with every scientific model and every theory. Models are productive because they do not capture the entire complexity of the world, but rather a section of it, which then helps us to better understand certain things. So these theories and models are necessarily underdetermined, so to speak. And that also means that these models are always confronted with what you have now called noise or what Shannon also calls noise, so to speak, with their other. We have an explanatory model and say that explains the whole world. And then we apply it and then we realize that it doesn't explain the whole world, but it explains a certain aspect of the world. And then other things come into view as problems. So we think of man as an information processor or as a completely rational information processor. This is not only the way cybernetics has done it, but also game theory and economics have adopted it. And then, after you apply this model, you realize, people often don't act rationally at all. This, for example, is now a very current topic in economics, that one is only now beginning to deal with it and to say, why do people not always act homo economicus, although we have assumed for 50 years or more in our economic models that it does. In other words, depending on which models you apply, you always produce a kind of background noise that then reports back as a problem, so to speak. And in the same way, models are developed further so that one then says, okay, the model is now no longer sufficient, it does not capture a certain aspect. And then you try to expand and extend the model. And at some point, you might reach the point where you discard the model completely because you say it's no longer up to date. And then there's a paradigm shift and you somehow find a whole new model. That's really how science evolves. But precisely, especially from a power-analytical or critical perspective, it is of course always interesting to look at what is not covered by the model. What is the other of the technical modeling and how does it speak out, so to speak? But that also means that if you want to use cybernetic thinking in a way that is not only aware of the fact that there is this omission, but that also includes this omission in the resulting action, then you would actually always have to have other, I don't know, mechanisms in addition to the cybernetically functioning apparatuses in which this noise can articulate itself or something, right? Yes, cybernetics also tries to think about it in that it says that cybernetic systems are fundamentally open to new things in the way they are designed, because they have the possibility of taking in information from their environment and reacting to it. So this is to some extent taken into account, that these systems are not rigid and always function in the same way, but that is, by the way, a very important and central figure in political cybernetics, the openness of the government system to the unexpected and new. This should be given to a certain extent, but one could now say that this unexpected and new is in a way already preconfigured so that the system can perceive it. Maybe there is something new on a completely different level and the system is not designed for it at all. And it is not able to see it too easily, because it communicates or does not communicate on a level in quotation marks, which is not perceivable by the system. But I mean, it almost sounds like that, as you said at the beginning, as if this is basically always mentioned in the formation of a theory and that it is then perhaps above all a matter of being aware of this and perhaps also of preventing the misunderstandings that follow from it. Because a big problem, I have the feeling, is this tendency to totalitarianism, that perhaps not even necessarily each of the acting actors themselves, for example now people who build technologies that also have a cybernetic functional logic inscribed in them, that they have to think this way, but that on the side of the addressees this is then in turn charged in such a way that one then that people believe, okay, but this is now, this is me, the solution for all problems or something. I have the feeling that there is often a tendency towards totalitarianism. So I see that now, for example, things like blockchain technology or so, if you look at the discourse. Even if there are players who build systems that have, let's say, more moderate positions in terms of what this technology could achieve, there are then again on the side of the fandom or so, so also among the enthusiasts then very widespread absolutely irrationally exaggerated charges, where one believes that this would now be just really ultimately the solution to all social problems or so. Yes, these early euphorias are often simply grounded by reality, sooner or later. Incidentally, this is also what happened to cybernetics itself, i.e. after this phase of great euphoria subsided, and it subsided precisely when you start and try to make this technology really productive. So blockchain is a good example, because everyone in the IT scene is talking about it now, and at the same time there are hardly any applications at the moment that are really productive or where it even makes sense to use a blockchain. And precisely when the hype cycle reaches the plateau of productivity, so to speak, a lot of these exaggerated expectations are trimmed back again. But that is of course the case, especially when something new is created, that first everything possible and also exaggerated forms are projected into it. And there, too, criticism is important, of course, in order to keep things a bit in balance, I would say. And can one now say that with regard to the political systems that have tried to justify or also develop government action with cybernetically informed thinking, yes, there is quasi then the attempt to save liberalism, as you had already nicely said. There are, as it were, the failed and also just actually not completed attempts within communism, socialism. And there is a bit like the still continuing narrative of the technologically underpinned self-organization on a broad level. So that which nowadays is somehow also formed a bit under the marketing-technically very well functioning term of decentralization. I would actually be interested in all three, I must say. Let's start with socialism. For example, there was this project of Stafford Beer in Chile under the short rule of Allende. The question is, has the project not primarily failed or are there possibilities to think about a kind of socialist-informed cybernetics, which includes today's technological means and what, how would that look like? And is that actually that maybe you could say, okay, the presumption is that projects at that time simply had to fail also because of such trivial things as Schira computing power and but that that would simply have to be re-evaluated under today's conditions? Yes, that's really hard to say, of course. Well, yes, although what you might think of as socialism is always being renegotiated and also always has to be renegotiated. So I don't think any of us would like to see a renaissance of Soviet or GDR socialism under new technical conditions. No, no, no, absolutely not. Of course, we can't imagine that either. But at the same time, of course, this left-wing, socialist idea is still alive, and it's also an idea that can always draw strength from technological progress, even if it perhaps doesn't always do so to a sufficient degree. So there was also this debate about accelerationism, etc., which accused the left, so to speak, of adhering to a technophobic back-to-nature idea instead of finally using the further development of the productive forces, so to speak, for its own purposes. But you also have to be creative and innovative and ask yourself again and again what the ideas are that are being fought for and which of them are worth preserving and how we can use technology to implement them. And if we look at it now, there are certainly, for example, in the area of open source software development or so non-commercial approaches in the area of free knowledge, etc., which one could certainly relate to certain basic socialist motives, I would now say cautiously. But despite the commercialization of the Internet and the problematic tendencies that go hand in hand with it, there is still a lively, civil-society, non-profit-oriented form of digital technology. There are super successful open source projects, there is Wikipedia, etc., and they all have their own problems. But nevertheless, it seems to me that something is being transported that gives these ideas of self-organization, of alternative economy and so on, that gives these ideas further strength. So the last word has certainly not yet been spoken. Absolutely, although I always ask myself to what extent this then refers to such niches, that is, to such niches, and precisely the left-wing acczellationism that you mentioned also says, okay, but we need an announcement that goes a long way. Not only does it say that we can somehow create our own open source islands within a larger system that is still capitalistically oriented, but we also need a narrative, which I find interesting. Above all, a narrative that is scalable to a global context. And that's where I think the question that you've already mentioned, the socialist pricing debate and the question of the extent to which this narrative of capitalism, namely being the highest possible mechanism for increasing efficiency, can be broken with technological underpinnings. And that brings us back to the question of a planned economy, i.e., a computer-supported planned economy, which does not necessarily have to be coupled, or should not be coupled, to something like a central committee or something. But then I also ask myself, how else could something like that look? Well, a central challenge will certainly be to transfer this digital sphere back into our material world, because sharing software code is one thing or file sharing is another, because you have virtually low marginal costs or you can simply reproduce things at will. And that is of course a bit more difficult with material goods. But here, too, we can ask ourselves whether these platform co-ops are a very interesting development, where we are considering how we can combine the platform economy with a more cooperative model, i.e., a transfer service that belongs to the drivers themselves and is managed by them or something like that. Here, too, you can see that these classic models are constantly being updated by new technological innovations. If we now take another look at cybernetic thinking, the view of the world from a cybernetic perspective, perhaps we can fundamentally question this again. There is this book Cybernetics and Revolt by Ticun, this French authors' collective, and at least as I understood it, they say no, it is not possible to use such logics and also such technologies, I think, without somehow surrendering to the power mechanisms inscribed in them. Did you have a look at them in the course of the debate and what would be your feeling about how to classify their positions? Because I have the feeling that it would be too easy to say that you somehow categorize them on the side of people who are simply critical of technology out of fear and just want to preserve some kind of naturalness, because I didn't have the feeling that that was the tenor of their line of argument. On the contrary, I had the feeling that they are actually quite good at proving how a certain form of thinking, which is cybernetically informed, is actually necessarily linked to certain power logics. Yes, so I think it's a good book. I enjoyed reading it. It's a very polemical book, and it's been another three or four years now that I've read it. I didn't agree with everything, but basically it's an interesting perspective. It's a very radical perspective, and I had the impression that, well, you don't really see any alternative possibilities for action within the existing system, but that you only see sabotage or noise, the production of invisibility, etc. as a way out. If you take such a radical approach and, as it were, reject the entire orientation of cybernetic thinking as technicist or as instrumental thinking, which also has a long tradition in philosophy, then you come to the point where you naturally withdraw to a position and say that basically we can only try to prevent it. I found that unsatisfactory. I think it's still possible to read something like that with profit, and I can also imagine situations in which such a form of radical negation is actually useful or necessary. I don't know, if I'm a dissident in a totalitarian state, then maybe it's really about becoming invisible in digital terms. But I think the challenges we have to face here are more about how we design these technical systems and not about how we prevent them or how we dismantle them. Yes, that's right, I totally agree with you actually. I also had the feeling that the level of analysis had a lot to offer, but that the final conclusion didn't quite work for me. But from this thorough analysis, one can draw conclusions with regard to the question of how future uses could be designed. Perhaps there is, and that gives us now also, the ramp in the direction of the final, if one likes. What prospects of future technologically driven governance do you see then? Very broad question, I know. Yes, so a little bit of looking into the crystal ball, that's always difficult, of course. I think what can be observed at the moment, and what is a very central challenge for us, is that we have large companies that now exercise a certain form of sovereignty that actually exceeds the depth of intervention of state action. So I say, companies like Facebook, Google, etc., the usual suspects, they already basically have more influence on our everyday lives and on our everyday actions than the state has now, you could say at least. At the same time, we see that the state and administration are having an extremely hard time with the topic of digitization. You can see that in Germany right now. And that, of course, reinforces this shift in sovereignty. Frank Pascale has coined the term "functional sovereignty," I believe, in which he shows that these large platforms are increasingly taking on tasks that we would traditionally have said were genuinely state tasks. And that's where I see a central area of conflict at the moment, that is, that companies, which of course are also not democratically legitimized, are increasingly dictating the conditions under which we live. This model of government, which I have taken over from Foucault, is also very broad. That is, government is not necessarily something state-related, but governing means first of all exerting influence on the actions of others. And companies can do that, too, of course. And you have to look very closely at who influences us in our everyday lives and how we can maintain and expand our self-determination and sovereignty instead of falling further and further into the clutches of certain companies that primarily have an interest in profit and always claim that they want to improve our lives. But that comes second. Therefore, at least looking into the near future, this is a conflict that we will have to deal with very strongly. And I believe that we simply need a digitally competent civil society and a digitally competent state. I find this interesting, especially in view of the visions of political cybernetics, which very naturally assumed that the state would be the driving force in the digitization of society. And today, that is really not the case at all; instead, the state is lagging behind by what feels like 20 years, and we are governed by companies that didn't even exist 20 years ago, which is also interesting. And then again, so that I don't end on such a fatalistic note, the very fact that these companies didn't even exist 20 years ago also shows here that digitization offers a whole host of opportunities for shaping a whole host of new players and that I can now sit down here somewhat casually with my computer, with a good idea and a bit of programming know-how and change the world, as they say. Today, that has become easier with digital means, because not everyone could put a steam engine in their living room, but everyone has a computer today, or almost everyone has access to one. And therefore, I believe that these design possibilities still exist, even if we are currently in a phase in which the 1990s and 2000s were characterized by an emancipatory way of thinking about technology. It was said that the Internet would somehow bring democratization and so on, and right now it all feels a bit disillusioned and you think crap, somehow it's brought us new problems and populism and fake news and whatnot, but I think that this emancipatory potential is still there somewhere. So that wasn't a mistake, but perhaps it wasn't called upon so well and I believe that we as a society simply have to understand better how we use this potential and from that point of view I believe that it will remain exciting for the future. I believe that the reason for the disillusionment is that this apparent promise of freedom has led to an enormous platform power, right? The fact is that, with regard to certain things, this promise that an individual can change something and come up with a good idea no longer works, because the power of the platform is already so pronounced that the network effect simply means that a competitor is no longer able to build up this size at all. So when Diaspora or ILO or whatever the other Facebook alternatives are called, when they compete, they enter a playing field where so much of the entire field has already been allocated that it seems as if it would not be possible to replace them. Yes, that's true. There are also Marxists who say that it's good if the whole world belongs to three companies, then we only have to expropriate three at the end. Yes, I'm not entirely serious, but yes. You just said it, end on a joyful note. Maybe at the very end the question, when you imagine the future, what makes you happy? I'm happy because that's also the field in which I'm working now. I'm no longer working in academia, but in civil society, and I'm happy to see that there are a large number of very active, very smart players who have lots of great ideas, who are highly motivated, and that a kind of diversity is beginning to find its way into the field of digital policy that we've been missing for a long time. And there are simply an incredible number of exciting things happening and there is still an optimistic, cautiously optimistic mood, which makes it fun to work with them. And as long as I can see, especially here in Berlin, this is of course also a privileged position, where there are tens of actors who are doing totally important and good civil society work in the area of digitization. And as long as all of them are still there, I'm hopeful that we can still make a difference here. Wonderful, that's a nice conclusion. Benjamin, thank you very much for your time and your expertise. If people want to find out about your work or get in touch with you, where can they find you? Yes, it's relatively easy to google me and find my professional email address. I usually answer mails as well, and otherwise I'm fairly active on Twitter. You can follow me there under my real name. Benjamin, thank you very much. Thank you. That's Future Histories for today. Thank you very much for listening. You can find show notes and more at www.futurehistories.today. Join the discussion on Twitter under the hashtag Future Histories or on Reddit. Let me know what you think about it all and how you liked this episode here. For our Patreon supporters, there is a lot of additional material at www.patreon.com slash Future Histories. For example, every month I read in a text that fits the respective topic. So you can drop by there, too. See you next time. I'm looking forward to it.


Episode Keywords:

#Kybernetik, #Digitalisierung, #Cybersyn, #BenjaminSeibel, #JanGroos, #FutureHistories, #Zukunft, #PolitischeKybernetik, #CyberneticGovernment, #Informationstechnologie, #Regierungsrationalit√§t, #Gouvernementalit√§t, #Herrschaftstechnologien, #DasRegierenderAlgorithmen, #Algorithmen, #Algorithmisierung, #Gesellschaft, #Vernetzung, #Netzwerke, #Regierbarkeit, #Kybernetisierung, #PolitischeTechnologien, #SimonSchaupp, #Cybernetics, #PhilippFrey, #Zuk√ºnfteDerAutomatisierung, #SocialistCalculationDebate
