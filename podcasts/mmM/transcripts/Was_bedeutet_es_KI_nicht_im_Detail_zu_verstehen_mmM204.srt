1
00:00:00,000 --> 00:00:07,880
Niemals kann man da erwarten, dass dahinten ein perfektes gutes Urteil oder ein gutes Weltmodell über die Gesellschaft rauskommt, wenn die Gesellschaft

2
00:00:08,080 --> 00:00:12,200
für die Bürokratie so aussieht, als wäre sie ein Haufen oberflächliche Zahlentupel.

3
00:00:12,920 --> 00:00:20,320
Und das ist ja der Punkt. Man kann also gar nicht erwarten, dass eine Bürokratie sinnvolle Entscheidungen treffen kann, wenn sie so ein unterkomplexes Weltmodell hat.

4
00:00:20,840 --> 00:00:28,160
Insbesondere, weil sich die Außenwelt permanent ändert und in einer Bürokratie, das ja überhaupt nicht so angelegt ist. Die Bürokratien sind ja gar nicht darauf

5
00:00:28,720 --> 00:00:33,880
angelegt, dass da eine Dynamik irgendwo stattfindet. Und eine Dynamik abbilden und Emergenz abbilden schon mal gar nicht.

6
00:00:46,440 --> 00:00:53,320
So Leute, ich mach nochmal so ein Video über Bewusstsein und Nachdenken und so ein Weltmodell, ihr wisst Bescheid.

7
00:00:53,720 --> 00:00:57,720
Was macht jetzt das Weltmodell und was macht das Bewusstsein?

8
00:00:57,920 --> 00:01:06,720
Ich habe ja schon erklärt, unser Hirn löst das inverse Problem, was hat unsere Inputdaten verursacht, mit dem Zweck, die Vorhersagen, um bessere Entscheidungen treffen zu können

9
00:01:07,720 --> 00:01:17,120
und sozusagen die evolutionäre Fitness zu maximieren. Und ich habe ja auch erklärt, wir konstruieren sozusagen uns dabei ein Weltmodell und erzählen uns eine Geschichte darüber.

10
00:01:18,120 --> 00:01:23,120
Und wir sind Protagonisten in dieser Geschichte und mit diesen Protagonisten identifizieren wir uns selber.

11
00:01:24,120 --> 00:01:32,120
Und daraus folgt zum Beispiel auch, wenn wir andere bewerten wollen, dass die energiesparendste Möglichkeit wahrscheinlich die mit der bösen Absicht ist, dazu habe ich schon Videos gemacht.

12
00:01:33,120 --> 00:01:44,120
Und ich habe jetzt hier nochmal folgendes Statement, was man immer hört, wenn man so Experten zuhört, die sich viel mit Deep Learning und Machine Learning und KI und so beschäftigen.

13
00:01:45,120 --> 00:01:50,120
Und zwar die sagen, wir verstehen nicht im Detail, wie KI funktioniert, wie diese Netzwerke funktionieren.

14
00:01:51,120 --> 00:01:59,120
Also was passiert ist, wir geben eine Architektur vor, Trainingsdaten und dann trainiert das Netzwerk, wir verstehen, wieso es das tut.

15
00:02:00,120 --> 00:02:06,120
Aber dann intern, wenn wir fertig trainiert sind und wir wollen die Frage an das Netzwerk stellen, wieso hast du diese und diese Entscheidung getroffen?

16
00:02:07,120 --> 00:02:08,120
Zum Beispiel beim autonomen Fahren oder so.

17
00:02:09,120 --> 00:02:24,120
Können wir natürlich zurückverfolgen, wie das Signal sich da drinnen verausbreitet und im Prinzip besteht es aus einer unfassbaren Menge an Multiplikationen, Additionen und so und Softmax und hin und her und richtig viele Kombinationen von Rechenschritten.

18
00:02:25,120 --> 00:02:35,120
Und wir verstehen halt einfach nur nicht, wie das passiert. Warum? Weil wir im Prinzip es geschafft haben, durch Mathematik den Trick mit der Emergenz abzubilden auf diese Zahlenkolonnen.

19
00:02:36,120 --> 00:02:42,120
Und wenn wir sagen, wir verstehen es nicht, meinen wir damit, wir verstehen diesen Prozess innen drinnen nicht mehr.

20
00:02:43,120 --> 00:02:49,120
Und daraus emergiert aber sozusagen das, was hinterher diese Netzwerke tun, zum Beispiel Entscheidung treffen und klassifizieren und so.

21
00:02:50,120 --> 00:02:53,120
Wobei die Image-Klassifikator noch ungefähr klar sind, weil wir da noch eine Intuition haben.

22
00:02:53,120 --> 00:03:14,120
Und ich hatte ja auch schon ein Video gemacht darüber, dass wir ja durch diese Sprachmodelle jetzt eine relativ gute Schnittstelle zu KI haben, weil wir die KI fragen können oder ein Sprachmodell fragen können, was es gerade tut.

23
00:03:15,120 --> 00:03:20,120
Und wir können einer KI auch Geschichten geben und diese KI kann mit diesen Geschichten weiterarbeiten.

24
00:03:20,120 --> 00:03:25,120
Das heißt, was Geschichten eigentlich sind, ist so eine Art Schnittstelle.

25
00:03:26,120 --> 00:03:38,120
Und das ist interessant, denn ich habe ja auch schon das Video gemacht, dass wir als Gesellschaft Geschichten brauchen, um miteinander zu kommunizieren und dass die Geschichte selbst notwendig ist für den performativen Akt der Gesellschaft.

26
00:03:39,120 --> 00:03:47,120
Und das reiht sich jetzt alles irgendwie ein in diese Idee, die ich jetzt sozusagen hatte, als ich nochmal darüber nachgedacht habe, dass wir ja KI eigentlich gar nicht verstehen.

27
00:03:47,120 --> 00:03:52,120
Und jetzt nochmal zurück auf der Ebene des Zahlensalats verstehen wir nicht, wie diese Entscheidung funktioniert.

28
00:03:53,120 --> 00:04:02,120
Und dann dachte ich kurz danach und habe festgestellt, na ja, wenn ich jetzt zum Beispiel ich programmiere ja viele numerische Verfahren, die so Lösungen finden für so schlecht gestellte Probleme und so.

29
00:04:03,120 --> 00:04:07,120
Und wenn ich mir den Zahlensalat angucken würde, dann würde ich den auch nicht verstehen.

30
00:04:07,120 --> 00:04:14,120
Dann würde ich den auch nicht verstehen, schon allein weil so ein, sagen wir mal, so ein Datensatz aus richtig vielen Zahlen besteht.

31
00:04:15,120 --> 00:04:21,120
Wenn ich auf die Zahlen drauf gucke oder noch schlimmer, auf die Rohdaten, würde ich überhaupt nichts erkennen, wenn ich die Binäre mir angucken würde oder so.

32
00:04:22,120 --> 00:04:32,120
Ich verstehe erst was auf einer höheren Ebene der Emergenz, wo sozusagen die Bits genommen werden, in eine Abbildung gesteckt werden und diese Funktion gibt mir als Output ein Bild oder so oder einen Grafen oder so.

33
00:04:32,120 --> 00:04:37,120
Dann verstehe ich was da passiert, aber auf der untersten Ebene verstehe ich es auch nicht, das heißt, das ist eigentlich kein großer Unterschied.

34
00:04:38,120 --> 00:04:43,120
Was da dazwischen steckt, damit ich es verstehen kann, nennen wir Sprache, zum Beispiel Mathematik.

35
00:04:44,120 --> 00:05:00,120
Oder aber, wenn ich zu jemandem erklären will, warum ich die und die Entscheidung getroffen habe, dann werde ich ihm doch auch nicht erklären, na ja, meine Neurotransmitter, meine Hormone, meine gesamte Vergangenheit, mein Genmaterial und was unsere Zivilisation vor 1000 Jahren gemacht hat, hat dazu geführt, dass ich diese Entscheidung getroffen habe.

36
00:05:01,120 --> 00:05:08,120
Ich weiß es doch selber nicht, das weiß ich doch alles gar nicht, das nehme ich ja gar nicht wahr, das ist ja nicht Teil meines bewussten Messprozesses.

37
00:05:09,120 --> 00:05:26,120
Und genau so gehen ja Maschinen auch vor und wenn ihr euch reinzieht, was die neuesten Anwendungen von GPT-4 sind, dann geht das alles in diese Richtung, dass wir versuchen, durch das Tool der Geschichte, GPT dazu zu bringen, Dinge zu tun für uns.

38
00:05:26,120 --> 00:05:35,120
Und ganz ähnlich, wie ich das in meinem Video gesagt habe, wie ich jetzt so eine KI und einen Roboter schreiben würde, habe ich gesehen, jetzt gibt es das mit Minecraft.

39
00:05:36,120 --> 00:05:49,120
Minecraft ist ja Touring vollständig und es gibt jetzt sozusagen Papiere, die nichts anderes machen, außer in Minecraft durch Sprachmodelle eine KI emergieren zu lassen, die sich selber Code schreibt, um da drinnen Probleme zu lösen.

40
00:05:49,120 --> 00:05:59,120
Und ich glaube, die Zielfunktion, die das Ding optimiert, ist einfach nur, werde der beste Minecraft-Spieler der Welt, das heißt, baue alles, was möglich ist oder so und versuche so viel Tech-Tri wie möglich zu erschaffen und so.

41
00:06:00,120 --> 00:06:05,120
Irgendwie so, ich werde das Paper mal verlinken, wenn ihr Zeit habt, könnt ihr euch das mal angucken, ist auf jeden Fall interessant.

42
00:06:06,120 --> 00:06:28,120
Und das geht so, dass sich sozusagen wirklich das Sprachmodell überprompt, also GPT ist eine Schnittstelle, die aus Code und Anweisungen Geschichten produziert, die dann in ein Interface reingehen, die mit Minecraft kommunizieren, um da drinnen eine KI zu steuern, um da drinnen einen Menschen zu steuern, also einen Player zu steuern, der dann was baut und so.

43
00:06:28,120 --> 00:06:43,120
Und das Ding, das GPT selbst sieht ja keine, sieht ja keinen Screen vor sich, sondern es hat sozusagen eine Syntax, die textbasiert ist, sowas wie du hast so und so viel Zeug in deinem Inventar, die Koordinaten von deiner Schatztruhe sind hier und da und um dahin zu kommen, muss man so und so.

44
00:06:44,120 --> 00:06:52,120
Das ist alles textbasiert und nur über diese Text-Schnittstelle wird sozusagen dieser Roboter gesteuert. Das ist im Prinzip so, wie ich mir das damals vorgestellt habe in meinem alten Video.

45
00:06:52,120 --> 00:07:05,120
Und jetzt nochmal zurück zur Physik. Wenn ich jetzt zum Beispiel in der Physik Differential-Gleichung hinschreibe und die Natur hier beschreiben will, zum Beispiel in der allgemeinen Relativitätstheorie, dann blickt da niemand durch.

46
00:07:05,120 --> 00:07:12,120
Ich finde, selbst die normale Tensor-Schreibweise der Feldgleichung von Einstein sind so ultraheftig, da checkt man nichts.

47
00:07:12,120 --> 00:07:34,120
Und ich habe mir sagen lassen von einem Kumpel, der Mathe studiert hat, der hat Differential-Geometrie als Spezialfach in seinem Master und die haben eine moderne Schreibweise für Differential-Geometrie, die viel intuitiver ist und die auch die einsteinischen Feldgleichungen viel intuitiver hinschreibt und auch das Rechnen mit diesen Gleichungen viel intuitiver macht.

48
00:07:34,120 --> 00:07:50,120
Das ist so ein bisschen wie, als würde man keine lineare Algebra können und trotzdem die ganze Zeit Fourier-Analyse machen. Wenn man das nicht oder sagen wir mal, man probiert Quantenmechanik zu machen ohne Matrizenschreibweise und ohne lineare Algebra-Kennnisse, das würde gehen.

49
00:07:50,120 --> 00:08:03,120
Aber diese kompakte Schreibweise und dieser komplette Satzbau der linearen Algebra, der ist extrem hilfreich fürs Verständnis. Also wieder, da passiert irgendwas mit Zahlenkolonnen und wir können das nicht so richtig begreifen.

50
00:08:03,120 --> 00:08:16,120
Wir müssen es erst auf eine Art und Weise ausdrücken durch am besten eine bijektive Abbildung, also eine, die eindeutig umkehrbar ist in Sprache und dann verstehen wir es. Und das haben wir auch in der normalen klassischen Mathematik und in der klassischen Physik auch.

51
00:08:16,120 --> 00:08:29,120
Das heißt, diese Aussage, wir verstehen nicht genau, was Deep Learning macht, ist meiner Meinung nach jetzt habe ich es erst so richtig durchdrungen. Das ist genau das gleiche, was es auch schon vorher war, genauso wie mit meiner Aussage, dass wir nicht verstehen, wie eine CPU funktioniert von einem Computer.

52
00:08:29,120 --> 00:08:39,120
Wir verstehen, wie die Building Blocks funktionieren, aber auf der binären Ebene checken wir nicht, was da passiert. Ein Elektrotechnik-Mensch, so wie der Michael, mit dem ich gequatscht habe auf meinem Kanal, der baut ja solche Teile.

53
00:08:40,120 --> 00:08:52,120
Man versteht ungefähr, wie ein Building Block funktioniert, aber wie die anderen damit dann verschaltet werden und was es dann in Summe schon macht, ist schon übelst kompliziert. Auf höheren Leveln der Emergenz kann man das verstehen.

54
00:08:52,120 --> 00:08:59,120
Auf dem unteren Level der Bits und Bytes kann man es nicht checken und unterhalb davon, also auf der quantenmechanischen Ebene, kann man es schon mal gar nicht verstehen.

55
00:09:00,120 --> 00:09:11,120
Und so ist es ja im Prinzip, mit unserem Bewusstsein auch. Wir erzählen uns ja auch permanent Geschichten darüber, wieso wir Entscheidungen getroffen haben.

56
00:09:11,120 --> 00:09:22,120
Und wir fangen wirklich an, Overfitting zu betreiben und uns die Vergangenheit schön zu reden mit Geschichten. Dabei ist sozusagen nachgewiesen, ich lese gerade das Buch von Robert Sapulsky und das ist natürlich großartig.

57
00:09:22,120 --> 00:09:41,120
Er ist schon in den ersten Kapiteln, fängt er direkt an, so ein paar geile Experimente zu erklären, von denen ich auch schon mal gehört hatte, zum Beispiel abhängig davon, ob der Raum, in dem man einen Test macht über Verhalten und Entscheidungstreffen und so, ob das da stinkt oder nicht, ist man eher pro-sozial und eher kooperativ oder nicht und alle solche Sachen.

58
00:09:41,120 --> 00:09:48,120
Und ich habe auch schon mal gesagt, abhängig davon, ob man viel Zucker zum Frühstück isst oder eher fettig, ist man mehr risikofreudig oder nicht und so und all diese Sachen.

59
00:09:48,120 --> 00:09:56,120
Wir werden ständig, also unterbewusst durch Hormone und Inputdaten beeinflusst in unseren Entscheidungen und hinterher erfinden wir die Geschichte, warum wir uns so entschieden haben.

60
00:09:56,120 --> 00:10:04,120
Und das ist total interessant. Und das liegt einfach nur daran, dass wir natürlich gar nicht durchdringen, wieso wir Entscheidungen getroffen haben.

61
00:10:04,120 --> 00:10:13,120
Und das liegt auch daran, dass wir natürlich permanent Overfitting über unsere Vergangenheit betreiben. Und das habe ich letztens in irgendeinem Video auch erklärt, wo ich irgendwie über Konservativismus rede oder so.

62
00:10:14,120 --> 00:10:23,120
So, worauf will ich jetzt eigentlich in dem Video raus? Naja, also das war jetzt der erste Gedanke. Und ich wollte auch nochmal diesen Schwenk zum Bewusstseinsmodell machen.

63
00:10:23,120 --> 00:10:34,120
Wir konstruieren uns ja ein Modell der Welt, wie Mono-Kausal am besten einfache lineare Zusammenhänge funktionieren, die uns erklären und vorhersagen können, was als nächstes passiert.

64
00:10:34,120 --> 00:10:37,120
Also wenn ich meine Flasche fallen lasse, dann geht sie wahrscheinlich kaputt, so nach dem Motto.

65
00:10:37,120 --> 00:10:47,120
Und jetzt ist es so, wir sind sozusagen eine zentrale Datenverarbeitung. Wir machen ja, wir kriegen Input-Daten und die werden hier oben in unserem Kopf verstoffwechselt zu weiteren Informationen.

66
00:10:47,120 --> 00:10:54,120
Und die Neuronen feuern, wenn bestimmte Sachen passieren und so. Das ist alles nicht linear, hochgradig vernetzt, emergent, klar.

67
00:10:54,120 --> 00:11:03,120
Und jetzt ist sozusagen das Bild, was ich im Buch zeichne, Machthierarchien, zum Beispiel Verwaltung, machen das ja auch.

68
00:11:04,120 --> 00:11:08,120
Die kriegen ja von uns übelst viel Input-Daten und müssen dann Entscheidungen treffen.

69
00:11:08,120 --> 00:11:21,120
Und das Problem ist, die sind nicht durch Evolutionsdruck gewachsen, also nicht über Jahr, Milliarden von Jahren, so wie wir, sondern die sind gewachsen, weil wir sie am Reißbrett entworfen haben.

70
00:11:21,120 --> 00:11:30,120
Und das ist der Grund, warum die Scheiße ständig fehlt. Die können gar nicht richtig funktionieren, weil sie würden, wenn dann durch Zufall die aus Versehen die richtigen Zahlen messen.

71
00:11:30,120 --> 00:11:36,120
Wir betreiben eine Menge Datenkomprimierung, wenn wir irgendwas sehen. Zum Beispiel das, was wir sehen, da ist eine Menge Interpolation dazwischen.

72
00:11:36,120 --> 00:11:42,120
Wir nehmen nicht alle Photonen, die hier ankommen auf der Retina, sondern da hinten in der Retina findet schon Datenkomprimierung statt.

73
00:11:42,120 --> 00:11:48,120
Daher folgen dann auch so viele Missverständnisse und Illusionen und optische Täuschungen und so, ist ja klar.

74
00:11:48,120 --> 00:11:55,120
Und Bürokratien jetzt haben ja ein vollständig unterkomplexes Weltmodell, weil sie ja wirklich nur ein paar Kennzahlen überhaupt messen.

75
00:11:56,120 --> 00:12:01,120
Also für eine Bürokratie ist es völlig egal, was für eine Person davor steht.

76
00:12:01,120 --> 00:12:08,120
Sie fragt einfach nur so ein paar Daten ab, wie Geburtstag, ein Nettoeinkommen, was auch immer, Geburtstagszeit, so ein Scheiß.

77
00:12:08,120 --> 00:12:15,120
Niemals kann man da erwarten, dass da hinten ein perfektes gutes Urteil oder ein gutes Weltmodell über die Gesellschaft rauskommt,

78
00:12:15,120 --> 00:12:21,120
wenn die Gesellschaft für die Bürokratie so aussieht, als wäre sie ein Haufen oberflächliche Zahlentupel.

79
00:12:21,120 --> 00:12:28,120
Und das ist ja der Punkt. Man kann also gar nicht erwarten, dass eine Bürokratie sinnvolle Entscheidungen treffen kann, wenn sie so ein unterkomplexes Weltmodell hat.

80
00:12:28,120 --> 00:12:34,120
Insbesondere, weil sich die Außenwelt permanent ändert und in einer Bürokratie das ja überhaupt nicht so angelegt ist.

81
00:12:34,120 --> 00:12:39,120
Die Bürokratien sind ja gar nicht darauf angelegt, dass da eine Dynamik irgendwo stattfindet.

82
00:12:39,120 --> 00:12:44,120
Und eine Dynamik abbilden und Emergenz abbilden schon mal gar nicht. Und das ist ja das, was wir permanent beobachten.

83
00:12:44,120 --> 00:12:47,120
Bürokratien sind überhaupt nicht fähig, die Realität überhaupt nur abzubilden.

84
00:12:47,120 --> 00:12:52,120
Deswegen sind sie auch nicht fähig, irgendwas zu machen. Deswegen kollabieren sie auch auf der Scythe-Skala von ein paar Jahrzehnten ständig.

85
00:12:52,120 --> 00:13:04,120
Das ist Schwachsinn. Und wenn wir da noch weiter darüber nachdenken, gibt es doch auch diesen geilen Spruch von dem Daniel Schmachtenberger,

86
00:13:04,120 --> 00:13:10,120
von dem habe ich mir auch mal was reingezogen. Der sagt ja, wir als Gesellschaft sind schon eine AGI.

87
00:13:11,120 --> 00:13:17,120
Stellt euch mal vor, wir sind ja ein Haufen kleine Touring-Maschinen. Wir alle optimieren sozusagen eine lokale Zielfunktion.

88
00:13:17,120 --> 00:13:24,120
Und das, was wir im Moment global machen, also die Gesellschaft, die daraus immergiert, aus unseren Wechselwirkungen untereinander,

89
00:13:24,120 --> 00:13:27,120
ist im Prinzip sowas wie eine Artificial General Intelligence.

90
00:13:27,120 --> 00:13:36,120
Das Problem ist bloß, dass die Zielfunktion dieser Artificial General Intelligence misaligned, und das geht so wie in meinem Video zum Misalignment-Problem zurück,

91
00:13:36,120 --> 00:13:45,120
mit dem Wohl für alle. Das gesellschaftliche Problem, wie ich sehr gerne nenne, lautet ja eigentlich, maximiere das Wohl für alle unter den Nebenbedingungen, Gewalt zu minimieren.

92
00:13:45,120 --> 00:13:50,120
Und was meine ich mit Gewalt? Naja, ich habe meine Gewaltdefinition schon mal gebracht in einem anderen Video.

93
00:13:50,120 --> 00:13:57,120
Was die AGI unserer Gesellschaft im Kapitalismus normalerweise gerade optimiert, ist halt leider die Kapitalakkumulation.

94
00:13:57,120 --> 00:14:02,120
Das habe ich schon erklärt. Und das geht zurück zu meinem Video hier von wegen, nimm dieses Schaubild, damit kannst du eigentlich alles erklären,

95
00:14:03,120 --> 00:14:10,120
weil wir ja alles in Pyramiden sortieren und so. Und das ist eigentlich ziemlich straight forward, diese Vorstellung.

96
00:14:12,120 --> 00:14:20,120
Und während ich also jetzt wieder da saß und wieder über die Geschichten, AGI und Bewusstseinsmodelle, Weltmodelle und so einen Scheiß nachgedacht habe,

97
00:14:20,120 --> 00:14:27,120
ist mir erst klar geworden, wozu Geschichten eigentlich da sind. Man kann Geschichten als solche jetzt nochmal ganz neu interpretieren,

98
00:14:27,120 --> 00:14:33,120
nämlich das ist, wir haben eine interne Datenverarbeitung. Wir sehen nicht, was unsere Datenverarbeitung.

99
00:14:33,120 --> 00:14:43,120
Wir selber verstehen unsere eigene Datenverarbeitung nur wenig bis gar nicht. Und wenn wir unsere Datenverarbeitung mit anderen Datenverarbeitungen,

100
00:14:43,120 --> 00:14:50,120
zum Beispiel anderen Menschen, synchronisieren wollen, benutzen wir dafür Sprache, weil Geschichten das Einzige sind,

101
00:14:50,120 --> 00:14:58,120
was irgendwie so viel Daten komprimiert und auf Wesentliches so runter bricht, weil wir sozusagen zum Beispiel auf konkrete Objekte verweisen können,

102
00:14:58,120 --> 00:15:04,120
denen wir einen Namen gegeben haben, zum Beispiel Bierflasche. Wir schreiben ja nicht die quantenmechanische Konfiguration dieser Bierflasche hin.

103
00:15:04,120 --> 00:15:08,120
Wir gehen ja nicht in den Zahlen-Salat rein, sondern wir sagen, wir haben eine Bierflasche.

104
00:15:08,120 --> 00:15:14,120
Es ist auch gar nicht zweckmäßig genau zu erklären, wie die jetzt aufgebaut ist. Für den meisten Zwecke ist es nur sinnvoll zu wissen, es ist eine Bierflasche.

105
00:15:14,120 --> 00:15:24,120
Und genau so funktionieren dazu sind Geschichten da. Das heißt, Geschichten sind eigentlich ein Interface dieser Datenverarbeitung.

106
00:15:24,120 --> 00:15:31,120
Und die Geschichten, die wir mit Machthierarchien teilen, haben vor allem das Problem, dass es besonders oberflächliche Geschichten sind.

107
00:15:31,120 --> 00:15:41,120
Und insbesondere zwängen uns die Machthierarchien die Syntax dieser Geschichten auf in Form von Zetteln und Formularen und reduzieren unsere Geschichten auf oberflächliche Kennzahlen.

108
00:15:41,120 --> 00:15:50,120
Und das ist das Problem. Das heißt, in Wahrheit liegt da permanent ein permanentes Missverständnis vor mit der AGI, die wir da konstruieren,

109
00:15:50,120 --> 00:15:55,120
wenn wir mit den Bürokratien und den Staaten und den anderen Machthierarchien uns unterhalten.

110
00:15:55,120 --> 00:16:04,120
Wir kommunizieren mit einer minderbewussten Entität, die aus unseren Wechselwirkungen emergiert, zum Beispiel den Sachbearbeitern und dem Staat,

111
00:16:04,120 --> 00:16:13,120
der irgendwie irgendwelche Zielfunktionen vorgibt. Und dann wird irgendwie hinten erwartet, dass hinten aus dieser Datenverarbeitung was sinnvolles rauskommt.

112
00:16:13,120 --> 00:16:19,120
Und nochmal, das ist Schwachsinn. Unsere zentrale Datenverarbeitung ist ja nur deswegen so krass, weil wir so schon so lange gewachsen sind.

113
00:16:19,120 --> 00:16:28,120
Und auch die ist noch lange nicht fertig. Ich habe jetzt im Buch von Robert Sapolsky gelesen, dass wir noch keinen Unterschied machen können,

114
00:16:28,120 --> 00:16:43,120
zwischen wenn wir angeekelt sind aufgrund von evolutionärer Nahr-Fitness, also zum Beispiel wir riechen, dass etwas eklig ist, zum Beispiel verschümmelt oder wir finden jemanden besonders hässlich.

115
00:16:43,120 --> 00:16:51,120
Wir können das, das spricht im Moment bei uns, weil das erst ein paar hunderttausend Jahre da ist, in unserem Gehirn dasselbe Areal an.

116
00:16:51,120 --> 00:16:59,120
Und das ist natürlich der Grund, warum wir sozusagen hässliche Menschen genauso scheiße bewerten wie irgendetwas, was wir eklig finden.

117
00:16:59,120 --> 00:17:06,120
Und das geht auch so weit, dass wir zum Beispiel Verhalten, was wir widerlich finden, genauso einordnen.

118
00:17:06,120 --> 00:17:16,120
Und das Framing, was dann intern sogar passiert ist, wir würden hässlicheren Menschen eher das schlimme Zeug zusprechen.

119
00:17:17,120 --> 00:17:29,120
Und tatsächlich sehen wir, dass dieser Effekt erst rausgenommen werden kann im Experiment mit Menschen, wenn wir noch mehr Zusatzinformationen rüberreichen.

120
00:17:29,120 --> 00:17:35,120
Aber natürlich wissen wir alle, dass diese Zusatzinformationen oft nicht vorliegen und deswegen böse Absicht kommt.

121
00:17:35,120 --> 00:17:41,120
Also ihr seht sozusagen, das ist super geil eigentlich, wenn man darüber nachdenkt, wozu Geschichten eigentlich dienen.

122
00:17:42,120 --> 00:17:52,120
Also erstmal ist es irgendwie intuitiv klar, Geschichten sind zur Kommunikation da, aber wenn man das mal wirklich ernst nimmt und wirklich weiter zu Ende denkt, ist das schon irgendwie geil.

123
00:17:52,120 --> 00:18:05,120
Und so wie ich jetzt sozusagen mir vorstellen würde, dass ein Roboter mit einem Roboterarm intern sich Geschichten baut, damit der Roboterarm der Signale sendet, hier nach da Signale sendet und zum ganzen Körpersignale sendet, so funktioniert es bei uns innen drin auch.

124
00:18:05,120 --> 00:18:17,120
Wir senden Signale in Form von Hormonen, irgendwelchen anderen Signen, Botenstoffen, das wird alles codiert intern zu Geschichten, die sozusagen nur dazu da sind, dass unsere Datenverarbeitung möglichst effizient arbeitet.

125
00:18:17,120 --> 00:18:21,120
Und die Effizienz kommt daher, dass sie lange über Evolutionsdruck gewachsen ist.

126
00:18:21,120 --> 00:18:28,120
Und nochmal, unsere lokalen Datenverarbeitungen, die wir selber emigrieren lassen, unsere Verwaltung und so, sind bei weitem nicht so kompetent, ist doch klar.

127
00:18:28,120 --> 00:18:31,120
Die wurden ja am Reisbrett entworfen.

128
00:18:31,120 --> 00:18:51,120
Und wenn wir jetzt sozusagen die Kapitalakkumulation vorantreiben mit unserer AGI als Gesellschaft, dann benutzen wir tatsächlich sozusagen ausschließlich Geschichten und oberflächliche Kennzahlen, die irgendwie unsere eigenen Geschichten auch irgendwie untermauern sollen.

129
00:18:51,120 --> 00:18:57,120
Zum Beispiel unser Verhalten oder so, wenn wir uns rechtfertigen vor, keine Ahnung, einer zentralen Autorität oder so.

130
00:18:57,120 --> 00:19:03,120
Also dieses Video ist jetzt wirklich schon wieder so ein Brainstorm, ich weiß auch noch nicht, wie ich es nenne und so.

131
00:19:03,120 --> 00:19:06,120
Ich mache auch gleich einen Stream an.

132
00:19:06,120 --> 00:19:17,120
Ich hatte bloß gerade noch diesen Gedanken zu Ende gedacht, mit dieser Sache von wegen, was das eigentlich bedeutet, dass wir die KI auf dieser Zahlenebene nicht verstehen.

133
00:19:17,120 --> 00:19:19,120
Und stellt euch das wirklich nochmal vor.

134
00:19:19,120 --> 00:19:31,120
In der normalen klassischen Mechanik könnte ich mir ein System aus Pendeln und Kugeln, die irgendwo runterrollen und, dass die verkabelt sind, irgendwie hinschreiben mit Zahlensalat und das komplett ausrechnen.

135
00:19:31,120 --> 00:19:32,120
Das ist gar kein Problem.

136
00:19:32,120 --> 00:19:35,120
Ich kann die partielle Differenzhergleichung numerisch lösen.

137
00:19:35,120 --> 00:19:37,120
Auf der Zahlenebene verstehe ich nur nicht, was da rauskommt.

138
00:19:37,120 --> 00:19:46,120
Erst wenn ich diese Zahlen wieder nehme und in Größen verwandele, die für das System charakteristisch und nicht oberflächlich sind, kann ich verstehen, was in diesem dynamischen System vor sich geht.

139
00:19:46,120 --> 00:19:51,120
Also zum Beispiel irgendwelche Winkelkonfiguration von irgendwelchen Pendeln oder so.

140
00:19:51,120 --> 00:19:53,120
Auf der Zahlensalat-Ebene checke ich sowieso nicht.

141
00:19:53,120 --> 00:19:59,120
Ich checke es erst, wenn ich es wieder zurücktransformiere in eine für uns lesbare und verstehbare Sprache.

142
00:19:59,120 --> 00:20:04,120
Und die nennen wir typischerweise Physik und kanonische Variablen und Phasenraum und so.

143
00:20:04,120 --> 00:20:09,120
Aber ja, das erstmal jetzt hierfür und reingehauen, YouTube.

144
00:20:16,120 --> 00:20:18,120
Oh.

145
00:20:46,120 --> 00:20:47,120
Oh.

146
00:21:16,120 --> 00:21:17,120
Oh.

147
00:21:46,120 --> 00:21:47,120
Oh.

148
00:22:17,120 --> 00:22:23,120
Übrigens, der Kanal ist wie eine schöne Vorlesung aufgebaut.

149
00:22:23,120 --> 00:22:30,120
Wenn ich unten Videos verlinke, dann wäre es angebracht, sich die auch reinzuziehen, weil das aufeinander aufbaut.

150
00:22:30,120 --> 00:22:33,120
Bestimmte Begriffe werden definiert, viele Beispiele werden genannt.

151
00:22:33,120 --> 00:22:41,120
Und ja, ich denke mir schon was dabei, weil es sozusagen meinen eigenen Erkenntnisprozess abbildet, die Reihenfolge, in denen ich die Videos hier hochlade.

152
00:22:46,120 --> 00:22:47,120
Ja.

153
00:22:47,120 --> 00:22:48,120
Ja.

154
00:22:48,120 --> 00:22:49,120
Ja.

155
00:22:49,120 --> 00:22:50,120
Ja.

156
00:22:50,120 --> 00:22:51,120
Ja.

157
00:22:51,120 --> 00:22:52,120
Ja.

158
00:22:52,120 --> 00:22:53,120
Ja.

159
00:22:53,120 --> 00:22:54,120
Ja.

160
00:22:54,120 --> 00:22:55,120
Ja.

161
00:22:55,120 --> 00:22:56,120
Ja.

162
00:22:56,120 --> 00:22:57,120
Ja.

163
00:22:57,120 --> 00:22:58,120
Ja.

164
00:22:58,120 --> 00:22:59,120
Ja.

165
00:22:59,120 --> 00:23:00,120
Ja.

