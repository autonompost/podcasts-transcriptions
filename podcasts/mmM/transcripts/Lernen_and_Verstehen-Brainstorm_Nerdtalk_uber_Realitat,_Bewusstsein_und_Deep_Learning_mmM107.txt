Das Gehirn erzählt sich ja selber eine Geschichte darüber, wie es wäre, wenn es eine Person gäbe,
von die so ist wie wir und die in einer Situation ist, die wir Gegenwart nennen.
Und wir konstruieren, während wir den sensorischen Input über die Gegenwart bekommen,
diese Person und stellen uns vor, wie es wäre, so eine Person zu sein.
Wir simulieren das.
Das ist das, was das Gehirn macht.
Deswegen sagt er, nur eine Simulation kann überhaupt Bewusstsein haben.
Riesen Sorry schonmal an alle, die sich dieses Video jetzt hier rein gönnen.
Ich glaube, es ist absolut unmöglich zu verstehen, was ich jetzt hier in diesem Video quatsche,
wenn ihr mein Video zum Bewusstsein nicht zuerst gesehen habt.
Das baut er halt darauf auf und ich benutze viele komische Fremdworte.
Ich glaube, die ergeben alle überhaupt keinen Sinn, wenn ihr das Video mit dem Bewusstsein nicht vorher geguckt habt.
Das ist nur so schon mal als Warnung.
Das ist ein absolutes Nerd-Video.
Ich habe das gestern aufgenommen und da hatte ich auch schon einen im Tee.
Und jetzt habe ich mir halt angeguckt und dachte mir so, ja, okay, schon klar.
Aber das kann glaube ich keiner verstehen, wenn man nicht irgendwie das mindset dafür hat.
Und dafür ist das andere Video auch gut geeignet.
Also guckt euch vorher an, bevor ihr jetzt hier weiter guckt.
So Leute, jetzt mal wieder eins von diesen Deep Philosophical U-Bow-Videos des Todes und der Vorläufer zu diesem Video, würde ich sagen, ist das Video zum Bewusstsein.
Und ich möchte hier erst mal mit euch über Emergenz reden, weil das braucht man irgendwie ständig.
Und dann so ein bisschen mehr über, naja, was ist die Realität?
Was ist das Bewusstsein?
Und was soll das alles?
Einfach mal ein bisschen euch mal ein bisschen mal was rein knallen an krasser Erkenntnis, die ich so in den letzten Jahren, ich würde sagen im letzten Jahr so ungefähr hatte.
Und ja, also was ist jetzt Emergenz?
Ich habe schon ein paar Mal verwendet das Wort.
Emergenz ist immer dann etwas, wenn ihr etwas beobachtet, was erstmal total kompliziert wirkt, wenn ihr da reingucken wollt.
Von außen sieht es irgendwie krass aus und ihr denkt, okay, das hat irgendwie einen Mechanismus, das ist heftig, aber wenn man reinguckt, steht man fest, es besteht aus ganz vielen simplen Teilen.
Und irgendwie ist die Summe dieser Teile mehr als einfach nur, also die Summe der Teile ergibt mehr als einfach nur das, was man sich vorstellen würde, wenn man die Summe der Teile tatsächlich addieren würde.
Was meine ich damit?
Na ja, zum Beispiel ein Ameisenhaufen.
Die kleinen Ameisen, die sind alle sehr einfach, wie die funktionieren.
Trotzdem ist die Gesamtheit der Ameisen, das Konglomerat, so eine Art komplizierter Lebens, ein komplizierter Metabolismus, der sich verhält wie ein Lebewesen.
Und wenn das Objekt, was ihr seht, nur aus Verbindungen besteht, die irgendwie auch rein virtuell dadurch sind, die sind ja nicht anfassbar.
Man kann ja nicht sagen, ach, diese Wechselwirkung zwischen den Ameisen, die macht das erst so interessant.
Aber genau darum geht es.
Das ist die Emergenz.
Das ist etwas, was man nicht so greifen kann, sondern es entsteht als ein Prozess höherer Ordnung zwischen Wechselwirkungen von einfacheren Mechanismen, die man sehr wohl verstehen kann.
Und darum ist Emergenz nicht greifbar.
Und das ist immer das Problem.
Das seht ihr ganz oft.
Das ist immer, wenn es um gesellschaftliche Themen geht.
Gesellschaft ist zum Beispiel eine emergente Struktur.
Sie entsteht aus den ganz vielen Interaktionen zwischen Menschen.
Wenn wir die alle addieren, kriegen wir die Gesellschaft raus.
Und Evolution ist auch so was.
Evolution entsteht ja nur dadurch, dass wir einen Selektionsdruck haben, der nur dadurch entsteht, dass es sozusagen eine äußere Umgebung gibt, die sozusagen dazu führt,
dass bestimmte Lebensformen, die besser, ich würde mal sagen, negative Entropie farmen können oder besser den Gradienten in die Entropie runtergehen können als andere und dadurch sozusagen einen Wettbewerbsvorteil gegeneinander haben und sich dann durchsetzen.
Und Schwarmintelligenz ist auch so was wie Emergenz.
Und der Markt, das ist das, was die FDP-Menschen nicht verstehen.
Die raffen es ja nicht.
Aber der Markt ist eine emergente Struktur.
Und weil das so unbegreifbar ist, dachte damals Hayek auch, und das ist sozusagen so eine Art Gott für ihn und versteht mich da nicht falsch.
Es ist natürlich eine emergente Struktur und es ist natürlich interessant, darüber nachzudenken.
Aber nur weil es kompliziert ist oder irgendwie geil aussieht oder man ein bisschen Mathematik damit machen kann, heißt es ja nicht, dass das sozusagen die Lösung aller Probleme ist.
Aber genau so geht Hayek daran.
Das habe ich auch schon mal in einem anderen Video erklärt, von wegen welches Problem lösen die Märkte eigentlich.
So und was soll ich sagen, wenn es etwas in den letzten Jahren gab, was ich mir sehr gerne reingezogen habe, dann sind das Videos von Joscha Bach.
Und ich kann euch wirklich nur empfehlen, schmeißt alles in die Ecke.
Jo Roggen Podcasts oder alle möglichen Lex Friedman Interviews oder sonst welche Sachen, die ihr im englischen YouTube drin gesehen habt.
Das nächste, was ihr bei euch auf die Watchlist drauf tut, ist der erste Talk von Joscha Bach.
Und der zweite, den könnt ihr gleich noch hinten dran hängen.
Dann habt ihr sechs Stunden lang komprimierteste Todesweisheit des Todes.
Der Typ ist der lebende Sheldon Cooper.
Das ist der krasseste Wichser, den ich je irgendwo gehört habe.
Ich glaube, das ist so ein verdammtes Genie.
Und der lebt heutzutage und ich habe ihn schon auf Twitter vollgequatscht, er soll mal mit mir reden, aber natürlich, warum sollte der das tun?
Der hat einfach eine volle Inbox, der hat keine Zeit mit einem scheiß Ossi zu reden.
By the way, Joscha Bach ist selber ein Ossi.
Aber ihr müsst euch den Typen reinziehen.
Der alles, was er jemals in seinem Leben gelesen hat, hat er hier oben drin und kann sofort abrufen.
Der ist krass, der Typ.
Und ich bin übrigens nur auf den gestoßen, weil jemand mir den empfohlen hat unter einem englischen Matrix-Video.
Hat mir jemand Joscha Bach empfohlen.
Dafür hat sich der englische Kanal schon gelohnt.
Das ist super.
Und jetzt wollte ich ein bisschen, jetzt haben wir das geklärt mit der Emergenz, ich habe jetzt dieses Wort etabliert.
Jetzt will ich ein anderes wichtiges Wort für euch etablieren, weil das ist natürlich auch so ein Ding, wo die Leute immer rumschlavieren.
Und irgendwie so so eine Krämer-Laber-Attitüde haben.
Was ist jetzt eigentlich Intelligenz?
Also guter Freund von mir hat damals zu mir gesagt, Intelligenz ist die Fähigkeit, Analogien zu bilden.
Und das ist eine ziemlich gute Definition, wenn man da mal drüber nachdenkt, weil damit kann man eine ganze Menge erschlagen.
Quasi ich habe hier, sagen wir mal, verstanden, wie das eine Ding funktioniert.
Und jetzt habe ich hier ein anderes Ding, das heißt anders.
Aber der Mechanismus, der hier abläuft, ist genau derselbe Mechanismus wie in dem Ding, was ich schon verstanden habe.
Wenn ich also die Analogie bilden kann und feststellen kann, dass abgesehen von den Bezeichnungen, dass da was da passiert, dasselbe oder das gleiche ist,
dann habe ich eine Analogie gebildet und dann bin ich krass.
Und der King der Analogien, meiner Meinung nach, ist Slavoj G. Jack.
Der hat die witzigsten Analogien.
So und Joscha Bach jetzt, der sagt, Intelligenz ist die Fähigkeit, Modelle zu bauen.
Also Modelle über das, was man sieht.
Und was meint man jetzt damit?
Ein mathematisches Modell typischerweise hat was damit zu tun, dass man eine Komprimierung macht.
Man kompressiert, man komprimiert irgendwie etwas, was man sieht, auf das Wesentliche herunter.
Das ist das, was beim Komprimieren passiert.
Und da muss man natürlich sich genau fragen, in welcher Sprache habe ich es auf das Wesentliche, auf das Minimum runtergekocht?
Und das ist genau die Fragestellung, die man beim Archivieren von Dateien auch hat.
Kann man sozusagen ein Muster finden, auf die man es runterbrechen kann?
Kann ich das Muster sozusagen einmal abspeichern und dann nur noch sagen, jetzt kommt das Muster und dann spare ich mir 500 Bits oder so?
So eine Idee ist das.
Und darauf basieren dann sozusagen die ganzen modernen Komprimierungsverfahren auch.
Im Wesentlichen, in der Mathematik würde man sagen, man findet eine Vektorbasis oder im Kompress-Censing würde man sagen, man findet eine Basis,
die irgendwie im Sinne der L2-Norm oder beziehungsweise in der L1-Norm, eigentlich in der L0-Norm, ich glaube es ist tatsächlich die L0-Norm oder die L1-Norm, da wo das sozusagen ein Minimum annimmt.
Das ist quasi Kompress-Censing, aber nur für die Geeks und Nerds, die sich damit auskennen.
Ansonsten, ihr könnt euch einfach vorstellen, wann kann ich sozusagen etwas aufs Wesentliche so weit runterbrechen, bis es nicht mehr weiter runtergeht?
Bis ich es sozusagen auf die Einsen und Nullen runtergebrochen habe.
Und Sprache ist sozusagen in diesem Kontext sozusagen eine High-Level-Abstraktion, weil sie ist sehr schwammig und Mathematik ist quasi Low-Level.
Man kann sozusagen das eine in das andere überführen, aber es ist sehr langwierig.
Bestimmte Sachverhalte lassen sich mit Sprache in ein, zwei Sätzen erklären und man müsste einen riesen Apparat Mathematik drauf werfen, um dasselbe in Mathematik auszudrücken.
Joscha Bach sagte, Mathematik ist die Domäne aller Sprachen und mittlerweile glaube ich, da hat er natürlich recht.
Das ist ziemlich krass, denn es ist so, Sprache in diesem Sinne, das Kompress-Censing zum Beispiel, ist eine Projektion von Inhalt.
Wir haben hier dieses Ding, wir haben diese echten Inhalte, die sind kompliziert und mit Sprache vereinfachen wir die.
Wir machen schon so eine Art Komprimierung, wir komprimieren schon den Inhalt, sodass wir ihn rüberreichen können und natürlich ist dann sozusagen Informationsverlust.
Und das ist bei jeder Projektion, jeder der lineare Algebra schon mal gehört hat, weiß, Projektionen verlieren Informationen und das ist da auch der Fall.
Und das ist ja klar, Sprache kann beim Empfänger anders ankommen, als wir es eigentlich als der Empfänger, als der Aussender der Sprache es eigentlich sagen wollte.
Und ja, Wittgenstein zum Beispiel dachte, dass man alles mit Sprache aufbauen kann und das war sozusagen sein Fail.
Er hat sozusagen nicht runterbrechen können auf Mathematik, sondern er dachte Sprache ist sozusagen der Shit.
Und deswegen sage ich ja auch, Wittgenstein hätte die Sache mit dem Word Embeddings in Deep Learning auch richtig gut gefallen.
Ja, aber so Sachen wie Bilder oder Geometrie mit Sprache zu beschreiben, ist halt völlig Fail.
Da ist völlig klar, dass die etabliert, also die bessere Variante irgendwie Mathematik sein muss.
Und jetzt wollte ich mal erklären, was nennen wir eigentlich Realität bzw. was nennen wir unser Universum?
Na ja, wir bezeichnen mit Realität typischerweise das, was unser Modell als Ursache angibt für den sensorischen Input, den wir erfahren.
Das einzige, was unser Gehirn bekommt, ist der sensorische Input über unsere Augen, unsere Sinnesvornehmungen und so.
Wir wissen nichts über die Welt da draußen, außer wir sind nur beschränkt darauf auf den sensorischen Input, den wir haben und daraus schlussfolgern wir alles.
Und das Gehirn, das habe ich ja in meinem Bewusstheitsvideo schon erklärt, versucht sozusagen das mathematische schlechtgestellte inverse Problem zu lösen.
Was hat die Inputdaten verursacht? Wir wissen ja nicht, was die verursacht haben.
Unser Gehirn, quasi unser Verstand, unser was auch immer, unser Gehirn versucht zu beschreiben und zu erklären, was diese Inputdaten verursacht hat.
Und dabei konstruieren wir das, was wir Realität nennen.
Und das beste, was Urscha Bachter immer sagt, ist, es gibt in dieser, also die beste Sprache, die wir im Moment dafür haben, ist sozusagen die Physik, die physikalischen Gesetze.
Und in dieser Sprache gibt es keine Geräusche und es gibt auch keine Farben.
Das sind einfach nur höhere Ordnung von Strukturen, denen wir diese Bedeutung zuweisen im Sinne von einer Komprimierung.
Und jetzt ist es so...
Übrigens, das ist der Grund, wenn man jetzt irgendwie, sagen wir mal, ich nehme mir jetzt das Lineal, tue das hier auf den Tisch und knall hiergegen, dann hör ich so ein Brrrrrrr.
Und diese höheren Schwingungsmoden und so, diese ganzen Sachen mit den Schwingungen, Sounds sind auch fraktale.
Da gibt es ein ziemlich geiles Video von Adam Neely, falls ihr den kennt.
Das ist ein sehr witziges Video, das werde ich verlinken.
Dass sozusagen sich auch da durch die höheren Schwingungsmoden, Sounds wie, also Geräusche und Töne wie fraktale verhalten.
Also man kann da immer weiter reinzoomen und die werden dann immer wieder selbst ähnlich.
Und das ist super geil, denn das bedeutet im Prinzip, dass man alles auf eine Ringstruktur abbilden kann.
Deswegen kann man Farben auch in einem Ring anordnen und bei Tönen kann man die sozusagen auf diese Oktaven abbilden.
Und das hat damit zu tun, dass sie sozusagen fraktale darstellen.
Und in echt existiert das nicht.
Das ist was, was unser Gehirn konstruiert, genauso wie, was weiß ich, wenn wir irgendwie rumgucken mit unseren Augen,
dann wird der Hauptinput, der wird interpoliert und auch extrapoliert hier am Rand und so.
Unser Gehirn kann sozusagen die Daten, die eigentlich aufgenommen werden müssten, um das, was wir hier sehen, zu konstruieren, kann es gar nicht verarbeiten.
Das braucht das Gehirn nicht.
Unser Gehirn ist so krass, dass es übelst Rechenleistung investiert, um das alles zu interpolieren.
Und in dem Sinne ist es halt so,
Unser Gehirn leistet diese Komprimierungsarbeit schon für uns und diese periodischen Eigenschaften von zum Beispiel Geräuschen und Farben machen, dass man die auf einem Ring anordnen kann.
Und wir existieren jetzt, also das, was wir als wir bezeichnen, wir existieren in dieser virtuellen Realität, die unser Gehirn konstruiert, um zu erklären, was die Messdaten verursacht hat.
Und das habe ich ja in dem Video über das Bewusstsein schon erklärt.
Also unser Gehirn konstruiert diese virtuelle Realität und auf diesem, weil das Ding ist, auf diesem Level von diesem äußerst merkwürdigen Quantengraf,
den wir jetzt, von dem wir annehmen, dass es, dass der existiert durch unsere mathematischen Modelle und unsere Physik und so,
da existiert wirklich nur kalte Algebra.
Von einem Zustand des Universums zum nächsten transformieren die physikalischen Gesetze diesen Quantengraf und wir können nur einen ganz kleinen Auschnitt davon messen.
Durch unseren sensorischen Input.
Und das, was die Philosophen dann sozusagen als Qualia bezeichnen, das ist genauso eine Illusion wie der Freie Wille.
Das ist einfach nur eine emergente Struktur, die auf unserem Gehirn entsteht, Qualia.
Und Joscha Bach nimmt jetzt als Beispiel für Realität, ziemlich geiles Beispiel, wie ich finde, das Mandelbrot-Fraktal.
Vielleicht binde ich das jetzt hier auch in das Video ein, da gibt es bestimmt ein cooles Gift oder so.
Das ist so ein Fraktal, das entsteht im Wesentlichen, wenn man eine iterative Abbildung lösen will.
Ja genau, man hat eine quadratische iterative Abbildung in einer komplexen Ebene und guckt für welche Werte von einer konstanten komplexen Zahl die konvergiert oder nicht.
Und wenn man das sozusagen macht für die komplexe Zahlenebene und alles was divergiert mit schwarz abbildet, dann kriegt man dieses Fraktal und so baut man das.
Das ist relativ einfach das zu bauen tatsächlich, aber das Muster was rauskommt, das sieht halt super krass aus.
Und wenn man sich jetzt vorstellt, wir leben auf so einer fraktalen Oberfläche von dem Mandelbrot-Fraktal, dann würden wir sehen, okay, da gibt es so eine rechtsdrehende Spirale.
Wenn man die jetzt reingeht, würde man irgendwann an einer Singularität ankommen.
Und wenn man die sozusagen, wenn man darüber hinweg guckt, gibt es quasi Periodenverdopplung oder ich weiß gar nicht mehr wie dieser Effekt heißt, auf jeden Fall, dann beginnt diese Spirale von vorne.
Dann beginnt sozusagen die Oberfläche von vorne zu wachsen, dann kommt diese Selbstähnlichkeit, die kickt rein bei dem Fraktal und dann sieht es wieder von vorne so aus.
Und man müsste wieder die Spirale weiter reingehen, bis man wieder zur Singularität kommt und dann wieder reingehen und so weiter.
Und wenn man so mehrere Layers bauen würde von seiner eigenen Realität, weil wir leben ja auf diesem Fraktal, dann wäre das eine gute Approximation für die Realität.
Was wir niemals sehen würden, ist sozusagen das komplette Picture, weil das Fraktal ist.
Es ist ein unendlich großes und selbstähnliches periodisches Muster.
So und so ist es mit unserem Universum auch.
Wir haben halt diese physikalischen Gesetze, sie sind nicht perfekt, sie sind aber eine gute Beschreibung für das, was wir haben, was wir sehen und so.
Und je näher wir uns ran tasten an die Realität, desto besser werden wir.
Irgendwann würden wir, wenn wir auf diesem Fraktal leben, in der Mandelbrotmenge, irgendwann würden wir diese paar Zeilen Code, die das braucht, um das zu generieren, vielleicht bauen können.
Und dann hätten wir es gekickt, dann hätten wir die Realität vollständig beschrieben.
Das heißt, was man machen muss, um die Realität zu beschreiben, ist man muss sich aus First Principles Schluss folgern.
Und das geht natürlich nicht so als Schlussfolgerung, sondern das ist im Prinzip zwar ein Error.
Also man muss Mathematik machen, betreiben und man muss es solange mit 3 in Error machen, bis man irgendwie auf das kommt, was sozusagen die minimale Information beinhaltet, die alles beschreibt, was wir haben.
Das ist das Prinzip von Okams Racer auch.
Also wir wollen so wenig wie möglich voraussetzen oder so wenig wie möglich annehmen.
Und das soll maximal viel von dem, was wir beobachten, beschreiben.
Und wenn wir etwas haben, was alles mit einem Formalismus beschreibt, dann sind wir fertig.
Das ist die Idee. Das ist sozusagen das Ideal, an das ich sozusagen die Wissenschaft da ran tasten möchte.
So und wenn wir also, Joshua Bach gibt auch noch so einen anderen coolen Spruch, nämlich er sagt, die physikalische Realität hat kein Bewusstsein und da gibt es auch kein Bewusstsein.
Nur eine Simulation kann Bewusstsein haben.
Das ist das, was er sagt und das ist ein ziemlich cooler Spruch, weil was er damit meint ist, wenn wir jetzt ein Buch lesen und da ist ein Protagonist drin und der fühlt irgendwas oder dem geht es irgendwie scheiße.
Dann empfinden wir das, während wir das lesen.
Das liegt daran, dass wir in unserem Kopf uns ein Bild davon, ein Abbild dieser Person in dem Buch, die da beschrieben wird durch Sprache übrigens, bauen und dadurch wird es real.
Und der Witz ist, zwischen dieser Person in dem Buch und dem, was wir uns selbst nennen, gibt es eigentlich keinen Unterschied.
Denn das Gehirn erzählt sich ja selber eine Geschichte darüber, wie es wäre, wenn es eine Person gäbe, die so ist wie wir und die in einer Situation ist, die wir Gegenwart nennen.
Und wir konstruieren, während wir den sensorischen Input über die Gegenwart bekommen, diese Person und stellen uns vor, wie es wäre, so eine Person zu sein.
Wir simulieren das.
Das ist das, was das Gehirn macht.
Deswegen sagt er, nur eine Simulation kann überhaupt Bewusstsein haben.
Nur eine Simulation ist fähig, diese emergente Struktur zu haben, die dann wieder, also die emergente Struktur, die sozusagen das Bewusstsein als Nebenprodukt hat.
Und das ist krass.
Das ist ziemlich heftig.
Also wenn ihr, wenn ihr das nicht kennt, diese Joscha Bach Talks, ihr müsst euch die reinziehen.
Ich verlinke die beiden von Lex Friedman.
Es gibt aber noch viele mehr, die sozusagen ins Detail gehen, wenn Joscha Bach seine Meinung zu GPT-3 erzählt.
Das ist super krass oder generell.
Es gibt, glaube ich, auch zwei, drei deutsche Talks, von denen einer mindestens schon mal ziemlich gut ist für Einsteiger.
Die anderen sind zu abgefahren, absolute Nord-Talks.
Aber wie gesagt, der Typ ist ein Ostdeutscher, der kann also auch fließend Deutsch, ist gar kein Problem.
Man findet bloß nicht so viel von dem auf Deutsch.
Aber hammermäßig.
Also wirklich alles andere, alle anderen Talks, alle anderen Podcasts, die es auf dieser Welt gibt, sind, meiner Meinung nach, Zeitverschwendung,
bevor man nicht vollständig durchdrungen hat, was Joscha Bach einen in drei Stunden reinquetscht an Wissen.
Das ist so viel.
Ich habe den Talk jetzt bestimmt vier, fünf Mal schon durchgeknallt und ich komme immer wieder auf neue Erkenntnisse, weil der Typ in einem Satz so viel Informationen und so viel Verständnis
reinsteckt, dass man das wirklich erst nach einem Jahr nochmal dann checkt oder so.
So und in Deep Learning ist es jetzt nur so.
Man muss dazu wissen, das habe ich auch noch nie so erwähnt, aber das ist quasi bekannt.
Das ist wahrscheinlich erste Vorlesung, Deep Learning im Informatikstudium.
Der sogenannte universelle Funktions-Approximator, das ist das Relevante.
Der sagt Folgendes aus, wenn ihr ein neuronales Netz macht mit N-Input, N-dimensionalen Input und ihr wollt nur ein Output haben, also sozusagen eine Funktion mit beliebigem Input und die soll was ausgeben.
Und ihr habt ein Layer dazwischen, der hat beliebig viele, also auch beliebig viele Knoten.
Dann könnt ihr jede mathematische Funktion damit approximieren.
Das ist erstmal irgendwie klar, aber es wurde sozusagen bewiesen, dass das so ist.
Und der Witz ist jetzt Folgendes.
In der Informatik geht es jetzt darum, wir nehmen an, dass unsere Welt determiniert ist und deswegen kann man alles mit einer Funktion quasi hinschreiben.
Die kann beliebig kompliziert sein, aber es muss durch eine Funktion approximierbar sein.
Das bedeutet, dass alles mit einem Deep Learning Netz, also mit einem neuronalen Netz beschreibbar ist.
Das ist die Voraussetzung.
Und jetzt ist nur die Frage, wenn wir beliebig viele Knoten haben, dann ist das klar.
Was man dann einfach macht, ist Overfitting.
Also ihr könnt euch quasi vorstellen, ich habe eine Aufgabenstellung und ich verstehe die Aufgabenstellung nicht, sondern ich lerne sie einfach auswendig.
Sagen wir mal, mein Konfigurationsraum hat 10 hoch 32 viele Möglichkeiten und 10 hoch 32 viele Outputs zu einem gegebenen Problem, eins aus diesen 10 hoch 32.
Dann kann ich doch, wenn ich genug Knoten, also Speicherpunkte habe, kann ich die einfach auswendig lernen.
Ich kann alle Antworten auf alle Fragen auswendig lernen.
Also stellt euch einfach nur vor, ihr wollt eine Software schreiben, die Bilder erkennt und ihr gebt der Software vor.
Man gibt ein Bild rein, das ist 256 mal 256 Pixel groß.
Und jetzt macht ihr eine feine Abschätzung und steckt sozusagen einfach alle möglichen Bilder, die überhaupt existieren können im Konfigurationsraum.
Also alle Kombinationen von Pixelwerten, die 256 mal 256 Bilder haben können überhaupt, die steckt ihr rein und lernt sie auswendig mit dem Satz darunter, was sieht man auf dem Bild.
Das lernt ihr auswendig.
Wenn ihr unendlich viel Speicherplatz habt und unendlich groß sozusagen das Lehr machen könnt, ist das natürlich kein Problem.
Dabei habt ihr aber sozusagen, ihr habt das Problem nur gelernt, aber ihr habt es nicht verstanden.
Und die Idee ist sozusagen, kann man das runter kochen auf irgendetwas, was weniger ist als Overfitting und sozusagen die Datenmenge besser abbildet,
sozusagen eine sehr große Datenmenge, zum Beispiel dieser riesige Konfigurationsraum von allen möglichen Bildern, die 256 Quadratviele Pixel haben,
irgendwie abzubilden auf irgendwas, wo wir trotzdem das Problem lösen können, nämlich eine Software, die uns am Ende sagt, was sieht man auf dem Bild oder so.
Und das ist quasi das, was ich hier sozusagen jetzt mit Overfitting auch erklären wollte, aber wie gesagt, das Video ist ein bisschen heftig, ich weiß schon.
Das nennt man Overfitting.
Viel besser wäre es doch, wenn ich runter gehe mit meiner Komplexität in meinem Deep Learning Netzwerk, also in diesem Zwischenlayer,
auf viel weniger Dimension und trotzdem noch eine sehr hohe Approximationsgüte kriege, also 99,999 Prozent oder so.
Denn dann habe ich ja Folgendes geschafft.
Ich habe mein Problem komprimiert, was konkret, ich habe aus dem Auswendiglernen Verstehen gemacht.
Ich habe sozusagen, und das ist ja das, was grundsätzlich irgendwie nie jemand mal rafft, was ist jetzt der Unterschied zwischen lehnen und lernen und verstehen?
Verstehen bedeutet, mit dem minimalen Satz an Handlungsanweisungen das Problem vollständig zu lösen und aus verschiedensten Wissenssachen, aus Kombinationen von Wissen, neues Wissen zu erzeugen.
Ja, eine Anwendung zu finden, die sozusagen nur darauf basiert, dass ich hier das eine schon mal verstanden habe und ich direkt auf das andere anwenden kann.
So, und das ist auch da der Fall.
Wenn man also den minimalen Satz quasi die beste Architektur von Layern erzeugen kann,
um zum Beispiel Energie zu sparen, Speicher zu sparen, dann komprimiert das sozusagen. Ich mache eine Kompression dabei.
Und da kommen dann sozusagen die mehreren Layer dann typischerweise im Deep Learning dazu. Es ist nicht einer, sondern es sind viele verschachtelte Layer, die runter und hoch gehen in ihrer Dimension.
Da gibt es sozusagen Konvolutiones und was auch immer. Es gibt übelst viele krasse Architekturen mittlerweile, die alle sehr tricky sind.
Aber das ist sozusagen erstmal die Idee. Es gibt diesen universellen Funktions-Approximator und man kann mit einem Neuronalen jetzt jede beliebige Funktion, insbesondere alles, was wir in unserer Realität beobachten, wenn es dem geht.
Das ist die Annahme. Und warum sollte man also nicht das Gehirn damit beschreiben können? Und warum sollte man nicht die gesamte Realität und das gesamte Universum damit beschreiben können?
Ich habe jetzt schon erklärt in meinem anderen Video, was das Bewusstsein ist.
Und Joshua Bach hat es ziemlich kompakt nochmal ausgedrückt und hat gesagt, das Bewusstsein ist ein Modell für den Inhalt unseres Aufmerksamkeitsmodells.
Und was meint ihr damit? Na ja, es ist so eine Art Meta-Aufmerksamkeit. Ihr müsst euch vorstellen, es ist so eine Art Meta-Learning.
Was meint jetzt eigentlich Aufmerksamkeit? Na ja, also erstmal gibt es ja mittlerweile schon Transformatoren.
Also es gibt schon Attention-Networks im Deep Learning. Diese Sprache wurde schon etabliert und das macht auch ziemlich genau das, was man sich eigentlich unter dem Konzept von Aufmerksamkeit vorstellt.
Also erstmal Aufmerksamkeit und Bewusstheit, das hängt schon miteinander zusammen, auch vom Wort, sozusagen von der wörtlichen Bedeutung.
Und im Moment ist es so, normale Deep Learning-Netzwerke machen Folgendes. Die haben einen Fehler-Signal, also sagen wir mal, wir haben eine Beobachtung und eine Prediktion von unserem Modell und das ist falsch.
Und dieses Fehler-Signal, die Differenz davon, die versuchen wir zurückzuführen, in unser Modell wegzutrecken. Wo kommt sozusagen der Fehler her?
Und dabei sozusagen bei vielen Daten entstehen natürlich eine ganze Menge in diesen statistischen Gewichten, wo irgendwas sich ändert.
Wenn man jetzt mit vielen Daten lernt, mitteln sich sozusagen die unwichtigen Gewichte raus und was überbleibt ist das, wo der wirkliche Fehler herkommt, also das sind dann meistens nur noch weniger Gewichte.
So, das ist aber ein Prozess, der super ineffizient ist und langsam, der ist super langsam, weil man immer wieder den kompletten Backpropagating-Step durchmachen muss.
Viel geiler wäre, wenn man ein Netzwerk hat, was oben da bei diesem Lernprozess draufguckt und feststellt, wo sind die größten Gewichte im Gradienten, also quasi in dem Backpropagating und kann ich das beobachten, wenn ich das sozusagen öfter mache.
Und dann kann man Statistiken betreiben und sozusagen das abkürzen. Man kann diesen Lernprozess abkürzen, weil man sozusagen den Shortcut geht.
Das hat so ein bisschen was von, wenn ihr euch mit iterativen Lösungsverfahren von algebraischen Gleichungen auskennt, das hat ein bisschen was von Order-Zapsets, finde ich.
Aber das ist wirklich nur meine Physiker-Intubation, da bin ich sozusagen mit gefährlichem Halbwissen hier unterwegs.
Jedenfalls, das kürzt den Lernprozess ab und das erklärt natürlich auch, warum sozusagen heutzutage so ein Alpha Star, also die KI, die StarCraft gewinnt, die hat ja so was wie umgerechnet 200 Jahre StarCraft gespielt, bevor sie auf einem Level ist, wie ein normaler Master-Spieler im High MMR Blizzard Elo.
Und ein Mensch braucht natürlich viel weniger Daten. Warum? Na ja, weil unsere Hirnarchitektur krasser ist. Wir leben schon auf dem nächsten Level von Deep Learning.
Was sozusagen die State of the Art ist im Moment, das erste Level war quasi, wir bringen ein Programm bei Schach zu spielen und das kriegen wir einfach hin.
Das nächste Level war, wir schreiben eine Architektur, zum Beispiel bei Go, da geht das nicht mehr, das Spiel ist zu kompliziert, man kann nicht in einem Programm einfach schreiben, was das kann.
Sondern wir schreiben ein Netzwerk, was selber lernt, sich Go beizubringen.
Und Joshua Bach sagt jetzt, das ist aber immer noch nicht das, was wir können, wir Menschen sind noch ein Level krasser.
Wir können Meta-Learning machen, wir können also ein Programm schreiben, was ein Programm findet, um ein Problem zu lernen.
Das ist sozusagen das, von dem er sagt, was wir als nächsten Schritt brauchen. Und ich nehme an, das passiert erst nach dem nächsten KI-Winter.
Also wenn sozusagen nur Slow reinkickt und wir noch mehr Rechnerkapazitäten haben, um das zu machen.
Weil ihr dürft mich vergessen, wie unfassbar viele Neuronen wir in unserem Kopf drin haben.
Also die Komplexität unseres Gehirns ist schon ziemlich krass.
Und man kann sozusagen sagen, da ist eine ganze Menge krasser, universeller Funktions-Approximator mit drin.
Und das Gehirn hat halt wirklich jetzt, das beobachtet halt, wo die meiste Performance herkommt beim Lernen.
Und speichert quasi diese Aufmerksamkeit, das speichert es zusammen mit dem Kontext, in dem es gelernt hat, ab.
Und das ist sozusagen der Inhalt der Aufmerksamkeit.
Also das ist der Inhalt der Aufmerksamkeit, wo haben wir wann, was, wie am besten gelernt.
Was sozusagen hat die meisten Performance Boost in unserer Performance gebracht, wenn wir an dem einen statistischen Gewicht oder an dem einen Neuronen wackeln.
Und der Witz ist, das ist so eine Art Meta-Learning, weil es sozusagen eine Aufmerksamkeit über die Aufmerksamkeit macht.
Es speichert sozusagen den Kontext und wo die Aufmerksamkeit war.
Und das muss es beobachten, das Gehirn. Und das tut es.
Das ist sozusagen Meta-Learning, weil Aufmerksamkeit über die Aufmerksamkeit quasi oder der Inhalt der Aufmerksamkeit zusammen mit dem Kontext.
So ungefähr muss man sich das vorstellen.
Und ich finde, an diesem Punkt ist sozusagen diese maximale Selbstbezüglichkeit auch klar.
Und das ist auch das, was die Leute so schizophren finden an der Frage, habe ich einen freien Willen oder nicht.
Oder was ist das Bewusstsein?
Das ist halt sozusagen, das ist das, was Douglas Hofstadter wahrscheinlich meinte, mit einem Estrange Loop.
Und das Buch habe ich bis jetzt noch nicht gelesen, aber das steht auch auf meinem Pile of Shame.
Und das Hören muss sozusagen auch genau darauf achten, also es muss ich selbst beobachten, worauf ich jetzt genau Aufmerksamkeit lege.
Also was gucke ich mir gerade an?
Und der Punkt ist irgendwie diese maximale Selbstbezüglichkeit, die macht es halt.
Und falls ihr das kennt, also bei mir war es so, wenn ich mal, ich hatte mal so einen Moment, ich war auf einer LAN-Party und war wirklich komplett im Tunnel.
Also ich hatte das nicht oft in meinem Leben, aber manchmal war ich vollständig im Tunnel, zum Beispiel beim Zocken oder auch mal beim Schlagzeugspielen.
Und wenn man einmal so vollständig in diesem Modus drin ist, dass man seine eigene Aufmerksamkeit overfittet,
wenn man irgendwie so krass sich selber dabei beobachtet, wie heftig man unterwegs ist, dann ist man wie bei Matrix, wie bei Neo und sieht alles in Slow-Motion.
Man ist auf einmal superschnell.
Und ich hatte das, ich war normalerweise so ein Spieler, ich hatte so 250 APM vielleicht, wenn es hochkommt.
Und ich hatte mal auf einer LAN-Party so 320 bis 350.
Und ich kann mich auch im Nachhinein noch erinnern, das ging runter wie Butter.
Meine Finger, das hat sich angefühlt wie das geschmeidigste, konstante Tippen der Welt.
Ich konnte nie wieder diese Performance erlangen wie in diesem einen Game, was ich mal hatte in meinem Leben.
Und ich glaube, das war so ein Zustand, der hat sich schon fast so ein bisschen transcendent angefühlt.
Und ich glaube, das war, wo meine Aufmerksamkeit diesen Zustand erreicht hat,
dass sie sich sozusagen selber vollständig beobachtet und jederzeit eingreifen kann, völlig problemlos.
Ich glaube, so einen Zustand kann man auch durch Meditation erreichen, wenn man irgendwie, wenn man das lang genug macht.
Jedenfalls, das ist irgendwie krass und das merkt ihr, wenn ihr irgendwann mal, wenn ihr irgendwas habt, wo ihr euch krass konzentrieren müsst.
Und das genaue Gegenteil ist sowas wie mit dem Fahrrad irgendwo langfahren, zur Arbeit oder so.
Da denkt man gar nicht mehr drüber nach, muss ich jetzt hier abbiegen, muss ich hier meinen rechten Fuß nach unten drücken,
muss ich jetzt hier die Bremse drücken, muss ich hier irgendwie lenken.
Das ist alles Autopilot, ne?
Da ist genau das Gegenteil, keine Aufmerksamkeit mehr quasi.
Und übrigens das wichtige, meilensteinartige Paper dazu zu den Transformers heißt Attention is all you need.
Das ist schon so ein geiler Titel.
Ich glaube, das war auch von so Boys, die bei Google in der AI-Abteilung sitzen.
Das ist auch cool geschrieben, das kann man sich wirklich mal reinziehen.
Also wenn ihr euch damit auskennt, wenn ihr euch damit auskennt, kennt ihr das Paper eh, was erzähle ich hier.
Ich bin ja sozusagen der Laie, weil ich hab mir nur mal so einen wöchentlichen Crashkurs bei uns in der Informatikfakultät mal reingegönnt dazu.
Ja und da wird dann sozusagen auch klar, dass diese Sache mit dem Attention so geil ist,
weil wenn man jetzt zum Beispiel Textübersetzung macht und man geht Brutforce von damals vor und übersetzt Wort für Wort oder so,
dann geht das immer krachen, was man braucht, das Kontext.
Und Attention ist richtig gut dafür, weil Attention kann sozusagen den Finger auf ein Wort legen und sagen,
also dieses Wort jetzt hier, zum Beispiel der Arzt oder der Künstler, zum Beispiel Cain West.
Später in einem anderen Satz steht dann nur noch R und dieses R muss bezüglich auf Cain West sein.
Dieser Kontext, das kann Attention richtig gut lernen.
Und das konnten sozusagen die Learning-Strukturen vor den Transformern nicht so gut.
Und das ist sozusagen der erste Schritt in Sachen jetzt mal Attention machen und das ist halt krass.
Der nächste Schritt, also das ist jetzt sozusagen State of the Art, das ist das, was alle mittlerweile können
und das ist auch das, was GPT-3 maximal krass macht.
Und man, also Ben Gürtel hat den Tag auch so was gesagt wie, naja, GPT-3 hat halt auch so unendlich viele Knoten,
dass wahrscheinlich auch Overfitting schon dabei ist.
Das ist einfach nur ein völlig übertrieben großes neuronales Netzwerk, was das komplette Internet gelernt hat einmal
und deswegen mit dir reden kann wie ein Mensch, kurz mal.
Das habe ich in meinem Live-Talk dann über Künstliche Intelligenz auch schon mal gezeigt, so ein Beispiel.
Und jetzt ist es halt so, die normalen Transformer-Networks, die haben halt einen begrenzten Arbeitsspeicher,
das heißt, sie kriegen auch nur einen begrenzten Text in sich rein.
Was wir aber machen ist, wir haben sozusagen eine besseren Komprimierungsalgorithmus
und können deswegen viel mehr Daten in Attention, also in Kontext zueinandersetzen.
Und das, was jetzt sozusagen Cain West und er und sozusagen der Kontext für so ein Deep Learning Netzwerk ist,
ist für uns das gesamte Universum.
Das heißt erst, wenn wir auf diesem Level sind, quasi ein Level höher in der Attention,
dann können wir auch so was wie künstliches Bewusstsein konstruieren.
Also das ist zumindest das, was Joshua Bach sagt und was soll ich sagen,
alles, was Joshua Bach sagt, klingt extrem plausibel und hier muss ich auf jeden Fall eingestehen,
dass ich nicht so krass bin wie Stanislav Lemb und ich finde im Prinzip fast alles, was Joshua Bach sagt,
ist des Todes legit des Todes.
Der Typ ist einfach nur zu geil.
Und auf der Ebene der Neuronen übrigens kann man das Bewusstsein auch noch mal genauso erklären,
nämlich mit Emergenz, da kann man einfach sagen, naja, so ein Neuron muss jetzt sozusagen eine Funktion lernen,
wann es feuert.
Ein Neuron hat sozusagen, kann eine nicht-linearer Funktion approximieren.
Es hat ja ein multidimensionales Input, die ganzen Daten, die reinkommen.
Wann feuert es? Das ist der Output.
Und das Neuron muss jetzt sozusagen das Output an das Universum liefern.
Also es hat ja nur diesen Ausgang, es weiß ja nichts von der äußeren Welt.
Irgendwann kommt wieder Input rein und dieser Input füttert das Neuron ja.
Wenn kein Input mehr kommt, dann stirbt das Neuron ja ab.
Das heißt, Neuronen haben ein Interesse daran, diese Funktion sehr gut zu approximieren,
um lange zu leben und fetter zu werden.
Und das ist genau das, was wir haben.
Und in unserem Hirn gibt es sozusagen diese goldene Regel,
Wires Together, Fires Together oder so.
Das ist so eine Grundregel, die wird um Deep Learning sozusagen, diese Intuition wird da auch verwendet,
weil sozusagen die ganze Struktur der neuronalen Netze auf dieser Analogie funktionieren,
von den Axionen und den Neuronen und so.
Dem Scheiß, den wir sozusagen auf der biologischen Ebene schon sehen können,
wie unser Gehirn im Prinzip funktionieren muss.
Wir sehen sozusagen nur diese unendlich komplizierten Netzwerke und checken nicht, wie die gehen, so ungefähr.
So und nur die Neuronen, die das richtig machen, die überleben und die anderen sterben halt aus,
die das nicht machen, also da ist sozusagen wieder evolutionärer Selektionsdruck.
Und Joshua Bach sagt halt jetzt, und das finde ich auch schon wieder so geil,
ein Neuron ist halt einfach nur ein normaler kleiner Reinforcement Learning Agent.
Das ist ein kleines Reinforcement Agent Konzept, der sozusagen sich selbst immer verbessert.
Und ja, es sendet halt einfach diese Signale in das Universum, also nach draußen.
Das ist zum Beispiel das, was wir hier machen.
Das beeinflusst unsere Handlung und den Willen und den freien Willen und diesen ganzen Scheiß,
nur um eine positive Antwort zu bekommen.
Und das Konglomerat von den ganzen Neuronen, die wir halt im Kopf haben, ist halt so angelegt,
von der Architektur her auch, aber auch von räumlich getrennten Kostenfunktionen,
also bestimmte Hirnareale machen bestimmte Sachen, dass es robust wächst in der meisten,
bei fast allen Menschen, die geboren werden.
Und die Gesamtheit davon nennen wir halt Gehirn.
Das ist das.
Und das ist krass.
Das ist wirklich erstaunlich, dass die Evolution das herausgebracht hat.
Aber der Gehirn, habe ich ja auch glaube ich schon gesagt in dem anderen Video,
was für krasse Sprünge da dazu gehören.
Weil es ein super schlechter Trade-off war, für so eine Spezies wie den Menschenaffen
mehr in seinen Gehirn zu investieren und dafür mehr Ressourcen irgendwo anders einzubüßen.
Zum Beispiel war er nicht mehr so stark.
Das musste sozusagen in einer Zeit der Erbgeschichte auch entstehen, wo das gerade so ging,
damit wir über diesen Potenzialwald rüberkommen
und dann uns als Menschen überhaupt als Homo sapiens etablieren konnten.
Das war ein super Heft, da sind mehrere Sachen zusammengefallen,
dass das durch Selektionsdruck dann passieren konnte und der Mensch daraus entstehen konnte.
Weil sowas wie Augen zum Beispiel, das wurde glaube ich drei, viermal separat voneinander
in der Evolution festgestellt, dass sich Augen gebildet haben.
Zufällig.
Durch Evolutionsdruck.
Das ist zum Beispiel was, was man öfter beobachtet, aber so ein Shit wie krasses Gehirn
und dafür natürlich weniger Robustheit, körperliche, physische Robustheit, das ist selten.
Und ja, was soll ich dazu sagen?
Die emergente Struktur von dem, was ich sozusagen gerade als Gehirn beschrieben habe,
das ist das Bewusstsein.
So kann man es auch artikulieren.
Und ich wollte jetzt wirklich nur mal dieses Video machen, weil ich finde das so krass.
Immer wenn ich mir wieder was von Erscha Bach einziehe, denke ich mir so, ja,
Dieser Typ, den jeder muss wissen, wer das ist.
Ich finde, das ist der krasseste Dude, den es gibt.
Der basht halt auch die anderen Leute, also er basht die natürlich nicht weg,
macht kein Reaction-Video oder ratet irgendwie auf irgendwen.
Aber er macht sie alle platt, er macht, also meiner Meinung nach ist er völlig überlegen
gegenüber zum Beispiel Roger Penrose oder so anderen Leuten, die sich natürlich auch den ganzen Tag,
auch Douglas Hofstadter, die sich den ganzen Tag mit Bewusstsein und diesen Fragen beschäftigen.
Ich finde, Erscha Bach hat die perfekte, sozusagen die bestmögliche verfügbare Komprimierung
schon da in seiner Sprache.
Seine Sprache ist so kompakt, da steckt so viel drin, weil er sozusagen diese ganze Terminologie
von den Deep Learning Netzwerken so krass gefressen hat und diese ganzen Konzepte auch
problemlos auf alles Mögliche anwenden kann, weil er die Intelligenz da hat,
um sozusagen die Analogien zu bilden, um das zu tun.
Es ist einfach nur ein Genuss, dem Typen zuzuhören, auch wenn er extrem schnell redet,
so wie Sheldon Cooper übrigens auch.
Aber ist kein Problem, man kann es einfach mehrmals hören und super.
Und Lex Friedman macht auch immer einen guten Job, wenn er nochmal nachfragt und so.
Also, ich wollte einfach ein Video darüber machen.
Reingehauen, YouTube.
Das war's für heute.
Vielen Dank für's Zuschauen.
Bis zum nächsten Mal.
Der Kanal ist wie eine schöne Vorlesung aufgebaut.
Wenn ich unten Videos verlinke, dann wäre es angebracht, sich die auch reinzuziehen,
weil das aufeinander aufbaut.
Bestimmte Begriffe werden definiert, viele Beispiele werden genannt.
Und ja, ich denke mir schon was dabei, weil es sozusagen meinen eigenen Erkenntnisprozess
abbildet, die Reihenfolge, in denen ich die Videos hier hochlade.
