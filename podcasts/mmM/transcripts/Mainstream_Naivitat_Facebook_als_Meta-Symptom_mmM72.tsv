start	end	text
0	17720	Es ist absolut symptomatisch, dass Zuckerberg den Missbrauch beim User verortet, aber nie
17720	18720	wirklich im Unternehmen.
18720	23840	Und selbst wenn das Unternehmen, was ja jetzt häufiger wieder passiert, dann doch verantworten
23840	24840	die Zugehörungen.
24840	25840	Ein Literaturwissenschaftler.
25840	29040	Dass dann eher gesagt wird, ja wir haben es falsch, wir haben die Technologie falsch
29040	32880	bedient oder wir haben uns die falschen Fragen gestellt und so weiter und so weiter.
32880	34840	Das System an sich ist nie daran schuld.
34840	38800	Stanford im Herzen des Silicon Valley.
38800	42600	Hier bekommen Tech-Pioniere ihr intellektuelles Rüstzeug.
42600	45880	Hier lehrt Adrian Daub Literaturwissenschaft.
45880	50760	In seinem Buch Was das Valley Denken nennt, nimmt er DenkerInnen in den Blick, derer
50760	52440	sich die Tech-Branche bedient.
53400	59160	Ich glaube, dass sich in den letzten 50 bis 60 Jahren in Nordkalifornien eine Art Denke
59160	69440	etabliert hat, die ganz stark Profit und technologische Innovationen über Sicherheit und über Werte
69440	70440	gestellt hat.
70440	77920	Die sozusagen die Kommunikation und den Individualismus als Wert an sich entdeckt hat.
77920	81200	Das Medium ist die Botschaft.
81640	87080	Der kanadische Medientheoretiker Marshall McLuhan wurde durch diesen Satz in den 1960er
87080	88080	Jahren berühmt.
88080	92040	Für ihn formen Medien und nicht Inhalte unsere Wahrnehmung.
92040	99160	So greift das Medium Facebook heute tief in die Psyche seiner User ein, indem es bestimmt,
99160	100480	wie wir Informationen teilen.
100480	105040	Die Inhalte werden überwunden.
105040	106520	Inhalte Nebensache.
106520	107520	Kannte.
107520	112480	Ein solches Denken ermögliche Mark Zuckerberg einen skrupellosen Expansionskurs.
112480	118360	Die Tatsache, dass möglicherweise da ein Kommunikationsbegriff dahinter steckt, der
118360	126320	nicht ganz durchdacht ist und dass es wirklich schwierig ist zu sagen, wir bringen Menschen
126320	130880	miteinander in Verbindung und wir stellen aber keine ethischen Maßstäbe bereit, wie dort
130880	134640	zu kommunizieren wäre, das ist eine Frage, die man sich bei Facebook sehr wenig zu stellen
134640	135640	scheint.
136400	142160	Welche Folgen ein solches Denken haben kann, zeigen Ken und Frankl in ihrem Buch.
142160	148920	2017 startete das Militär in Myanmar auf Facebook eine Desinformationskampagne.
148920	154040	Facebooks Algorithmus verbreitete Hass gegen die muslimische Rohingya-Minderheit.
154040	155520	Die Gewalt eskalierte.
155520	159560	25.000 Menschen starben, hunderttausende flohen.
159560	164320	Die Zentrale in Kalifornien habe jahrelang Warnungen von Menschenrechtsorganisationen
164320	165600	ignoriert.
165640	171960	Bis 2018 gab es nur fünf Burmesisch sprechende Mitarbeiterinnen für einen Markt von 18 Millionen
171960	172960	Usern.
172960	178080	Das Unternehmen habe ein Streichholz in einen ethnischen Konflikt geworfen und sich dann
178080	181960	abgewandt, so die Autorinnen.
181960	186760	Mark Zuckerberg setzte auch im Wachstumsmarkt Myanmar auf sein zentrales Geschäftsmodell.
190760	193720	Das ist eine der hässlichen Wahrheiten.
193840	198840	Facebook benötigt unbedingt die Beteiligung seiner User, um zu wachsen.
198840	201840	Wachstum ist das Wichtigste für das Unternehmen.
201840	207480	Der Newsfeed-Algorithmus zielt darauf ab, User zu binden, spült Aufsehen Erregendes nach
207480	208480	oben.
208480	212000	Er priorisiert Inhalte, die Emotionen erzeugen.
212000	215680	Egal ob Wut, Traurigkeit, Leid oder Empöhrung.
215680	222080	Oftmals Dinge, die einen in die Irre führen oder desinformieren.
224080	226800	Die algorithmische Verstärkung von Emotionen.
226800	229400	Die zentrale DNA von Facebook.
229400	234240	Für Daub steckt hinter diesem Geschäftsmodell ein zutiefst pessimistisches Menschenbild.
234240	243480	So findet das Denken des französischen Kulturanthropologen und Stanford-Professors René Girard großen
243480	248360	Anklang bei Gründern und Investoren im Silicon Valley.
248360	252680	Laut Girard begehren Menschen immer das, was andere auch wollen.
252680	255520	Mimetisches Begehren, so nennt er das.
255520	257760	Und so funktioniert auch Facebook.
257760	263680	Das Begehren wird durch den ständigen Vergleich mit anderen und die Jagd nach Likes geschürt.
263680	267160	Konflikte und Gewalt sind laut Girard Folge dieser Dynamik.
267160	272160	Und doch wird uns dieses Geschäftsmodell als geniale Idee verkauft, die die Welt näher
272160	273160	zusammenbringt.
273160	279160	Am 6.
279160	284840	Januar entlud sich der Hass, der in Facebook-Gruppen über Monate hinweg den Ton angegeben hatte.
284840	292240	Vor der Attacke auf das Kapitol empfahl Facebooks Algorithmus Trump-Followern hunderttausendfach
292240	295680	Gruppen, in denen sich gewaltbereite Demonstranten organisierten.
295680	300600	Trump selbst befeuerte den Mythos der gestohlenen Wahl.
300600	301600	Klar.
302600	309400	Zu seinen 28 Millionen Followern hatte ihn Zuckerberg noch im Herbst 2019 gratuliert.
309400	312600	Erst nach dem Sturm aufs Kapitol ließ ihn Facebook sperren.
312600	315600	Die Autorinnen kommen zu einem erstaunlichen Ergebnis.
317600	319800	Facebook wusste bereits vor dem 6.
319800	321200	Januar, was sie planten.
321200	325400	Sie waren alarmiert, bemerkten, dass Personen davon sprachen, Waffen mitzubringen.
325400	331400	Fotos posteten und in Gruppen schrieben, ich bringe dieses Sturmgewehr mit nach Washington.
332400	335400	Trump solle sich für seine Worte verantwortlich fühlen.
335400	338400	Die Menschen, die das Gesetz brachen für ihre Taten.
338400	341400	So wie Zuckerberg jegliche Verantwortung von sich.
341400	345400	Einige Leute behaupten, dass soziale Netzwerke polarisieren.
345400	349400	Unseren Forschungen zufolge ist das alles andere als klar.
349400	353400	Immer wieder betont er, dass er an einer Gemeinschaft für alle arbeite.
353400	356400	Genau darin liegt das Dilemma von Facebook.
357200	360200	Die Wirklichkeit eines Algorithmus, der Hass und Gewalt befördert.
360200	364200	Und der Anspruch, die Welt zu einem besseren Ort zu machen.
364200	367200	Das ist glaube ich unglaublich wichtig für diese Unternehmen.
367200	370200	Während sie eben diese enorme Macht anhäufen.
370200	374200	Sozusagen vor dieser Macht auch zu einem gewissen Grad die Augen verschließen zu können.
374200	377200	Und das ist wichtig für die Unternehmenschefs.
377200	379200	Das ist wichtig für diesen Expansionskurs.
379200	382200	Es ist aber auch einfach eine Art, in der man sich selber belügen kann.
382200	384200	Sondern kognitive Dissonanz abbauen kann.
385000	387000	Er belügt nur dich.
387000	390000	Der Unternehmer als Held, der sich von niemanden befreundet.
390000	392000	Er weiß ganz genau, was er da macht.
392000	395000	Diese weit verbreitete Denkart in der Technologiebranche.
397000	400000	Also alle, die jetzt sich hier an meinen Channel reinziehen.
400000	404000	Haben sich wahrscheinlich das Video zu Facebook schon reingezogen.
404000	408000	Aus der Reihe Digitalisierung verstehen lernen.
408800	415800	Und ihr dürft euch alle sehr erhaben fühlen über den durchschnittlichen GEZ-Medienkonsumenten.
415800	424800	Weil da wurde jetzt offensichtlich ein Literaturwissenschaftler nach seiner Meinung befragt zu Facebook.
424800	428800	Und natürlich macht er das, was alle machen.
428800	431800	Er identifiziert ein Symptom.
431800	435800	Und jetzt haltet euch fest, sie werfen Facebook vor.
436600	443600	Dass sie das pure Böse sind und vor allem unwissentlich das falsche tun.
443600	445600	Das ist natürlich totaler Spaß.
445600	447600	Erstens wissen sie ganz genau, was sie tun.
447600	449600	Sie tun es absichtlich.
449600	451600	Und ja, der Sturm aufs Kapitol ist für Facebook super gewesen.
451600	456600	Natürlich wäre es noch viel geiler, wenn noch mehr hinterher Facebook-Traffic entstanden wäre.
456600	458600	Aber wahrscheinlich war es schon unendlich viel Traffic.
458600	460600	Und sie haben es immer noch nicht verstanden.
460600	461600	Natürlich.
461600	464600	Auch so ein Gemetzel in Myanmar ist super für Facebook.
464600	468600	Alles ist super für Facebook, solange es Traffic im Facebook erzeugt.
468600	472600	Facebook braucht Daten und Facebook braucht mehr Traffic.
472600	474600	Das ist ihr Geschäftsmodell.
474600	479600	Und ihnen Wachstum, Wachstumszwang vorzuwerfen, das ist Schwachsinn.
479600	482600	Weil das ist immanent, das ist im System drin.
482600	487600	Und ich habe ja schon erklärt, Facebook und naja, eigentlich auch Fake News.
487600	489600	Fake News entstehen aus Wettbewerb.
489600	497600	Aus der ganz simplen Tatsache, dass da um die Aufmerksamkeit der User gekämpft wird.
497600	500600	Aber da sieht man, was dabei rumkommt.
500600	505600	Da gibt es jetzt hier so einen 10-Minuten-Beitrag mit dem super Enthüllungsbuch zu Facebook.
505600	509600	Und da steht mit Sicherheit nichts drin, was nicht schon längst bekannt ist.
509600	511600	Garantiert.
511600	513600	Ich will es gar nicht lesen. Will ich auch nicht.
513600	517600	Aber offensichtlich macht Kulturzeit einfach nur Werbung für irgendwelche Bücher.
517600	521600	Für irgendwelche Boomer, die keine Ahnung haben von dem Neuland Internet.
521600	525600	Und deswegen mal ein Buch lesen müssen darüber und sich dann aber nur noch über Symptome aufregen.
525600	527600	Herrlich. Find ich richtig geil.
527600	529600	Kann man eigentlich nichts mehr zu sagen.
530600	531600	Super Beitrag.
531600	533600	Herrliches Ding.
547600	550600	Super Beitrag.
577600	579600	Super Beitrag.
607600	609600	Super Beitrag.
616600	620600	Übrigens, der Kanal ist wie eine schöne Vorlesung aufgebaut.
620600	627600	Wenn ich unten Videos verlinke, dann wäre es angebracht, sich die auch reinzuziehen, weil das aufeinander aufbaut.
627600	630600	Bestimmte Begriffe werden definiert, viele Beispiele werden genannt.
630600	638600	Und ja, ich denke mir schon was dabei, weil es sozusagen meinen eigenen Erkenntnisprozess abbildet, die Reihenfolge, in denen ich die Videos hier hochlade.
