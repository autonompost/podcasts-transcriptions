Es ist absolut symptomatisch, dass Zuckerberg den Missbrauch beim User verortet, aber nie
wirklich im Unternehmen.
Und selbst wenn das Unternehmen, was ja jetzt häufiger wieder passiert, dann doch verantworten
die Zugehörungen.
Ein Literaturwissenschaftler.
Dass dann eher gesagt wird, ja wir haben es falsch, wir haben die Technologie falsch
bedient oder wir haben uns die falschen Fragen gestellt und so weiter und so weiter.
Das System an sich ist nie daran schuld.
Stanford im Herzen des Silicon Valley.
Hier bekommen Tech-Pioniere ihr intellektuelles Rüstzeug.
Hier lehrt Adrian Daub Literaturwissenschaft.
In seinem Buch Was das Valley Denken nennt, nimmt er DenkerInnen in den Blick, derer
sich die Tech-Branche bedient.
Ich glaube, dass sich in den letzten 50 bis 60 Jahren in Nordkalifornien eine Art Denke
etabliert hat, die ganz stark Profit und technologische Innovationen über Sicherheit und über Werte
gestellt hat.
Die sozusagen die Kommunikation und den Individualismus als Wert an sich entdeckt hat.
Das Medium ist die Botschaft.
Der kanadische Medientheoretiker Marshall McLuhan wurde durch diesen Satz in den 1960er
Jahren berühmt.
Für ihn formen Medien und nicht Inhalte unsere Wahrnehmung.
So greift das Medium Facebook heute tief in die Psyche seiner User ein, indem es bestimmt,
wie wir Informationen teilen.
Die Inhalte werden überwunden.
Inhalte Nebensache.
Kannte.
Ein solches Denken ermögliche Mark Zuckerberg einen skrupellosen Expansionskurs.
Die Tatsache, dass möglicherweise da ein Kommunikationsbegriff dahinter steckt, der
nicht ganz durchdacht ist und dass es wirklich schwierig ist zu sagen, wir bringen Menschen
miteinander in Verbindung und wir stellen aber keine ethischen Maßstäbe bereit, wie dort
zu kommunizieren wäre, das ist eine Frage, die man sich bei Facebook sehr wenig zu stellen
scheint.
Welche Folgen ein solches Denken haben kann, zeigen Ken und Frankl in ihrem Buch.
2017 startete das Militär in Myanmar auf Facebook eine Desinformationskampagne.
Facebooks Algorithmus verbreitete Hass gegen die muslimische Rohingya-Minderheit.
Die Gewalt eskalierte.
25.000 Menschen starben, hunderttausende flohen.
Die Zentrale in Kalifornien habe jahrelang Warnungen von Menschenrechtsorganisationen
ignoriert.
Bis 2018 gab es nur fünf Burmesisch sprechende Mitarbeiterinnen für einen Markt von 18 Millionen
Usern.
Das Unternehmen habe ein Streichholz in einen ethnischen Konflikt geworfen und sich dann
abgewandt, so die Autorinnen.
Mark Zuckerberg setzte auch im Wachstumsmarkt Myanmar auf sein zentrales Geschäftsmodell.
Das ist eine der hässlichen Wahrheiten.
Facebook benötigt unbedingt die Beteiligung seiner User, um zu wachsen.
Wachstum ist das Wichtigste für das Unternehmen.
Der Newsfeed-Algorithmus zielt darauf ab, User zu binden, spült Aufsehen Erregendes nach
oben.
Er priorisiert Inhalte, die Emotionen erzeugen.
Egal ob Wut, Traurigkeit, Leid oder Empöhrung.
Oftmals Dinge, die einen in die Irre führen oder desinformieren.
Die algorithmische Verstärkung von Emotionen.
Die zentrale DNA von Facebook.
Für Daub steckt hinter diesem Geschäftsmodell ein zutiefst pessimistisches Menschenbild.
So findet das Denken des französischen Kulturanthropologen und Stanford-Professors René Girard großen
Anklang bei Gründern und Investoren im Silicon Valley.
Laut Girard begehren Menschen immer das, was andere auch wollen.
Mimetisches Begehren, so nennt er das.
Und so funktioniert auch Facebook.
Das Begehren wird durch den ständigen Vergleich mit anderen und die Jagd nach Likes geschürt.
Konflikte und Gewalt sind laut Girard Folge dieser Dynamik.
Und doch wird uns dieses Geschäftsmodell als geniale Idee verkauft, die die Welt näher
zusammenbringt.
Am 6.
Januar entlud sich der Hass, der in Facebook-Gruppen über Monate hinweg den Ton angegeben hatte.
Vor der Attacke auf das Kapitol empfahl Facebooks Algorithmus Trump-Followern hunderttausendfach
Gruppen, in denen sich gewaltbereite Demonstranten organisierten.
Trump selbst befeuerte den Mythos der gestohlenen Wahl.
Klar.
Zu seinen 28 Millionen Followern hatte ihn Zuckerberg noch im Herbst 2019 gratuliert.
Erst nach dem Sturm aufs Kapitol ließ ihn Facebook sperren.
Die Autorinnen kommen zu einem erstaunlichen Ergebnis.
Facebook wusste bereits vor dem 6.
Januar, was sie planten.
Sie waren alarmiert, bemerkten, dass Personen davon sprachen, Waffen mitzubringen.
Fotos posteten und in Gruppen schrieben, ich bringe dieses Sturmgewehr mit nach Washington.
Trump solle sich für seine Worte verantwortlich fühlen.
Die Menschen, die das Gesetz brachen für ihre Taten.
So wie Zuckerberg jegliche Verantwortung von sich.
Einige Leute behaupten, dass soziale Netzwerke polarisieren.
Unseren Forschungen zufolge ist das alles andere als klar.
Immer wieder betont er, dass er an einer Gemeinschaft für alle arbeite.
Genau darin liegt das Dilemma von Facebook.
Die Wirklichkeit eines Algorithmus, der Hass und Gewalt befördert.
Und der Anspruch, die Welt zu einem besseren Ort zu machen.
Das ist glaube ich unglaublich wichtig für diese Unternehmen.
Während sie eben diese enorme Macht anhäufen.
Sozusagen vor dieser Macht auch zu einem gewissen Grad die Augen verschließen zu können.
Und das ist wichtig für die Unternehmenschefs.
Das ist wichtig für diesen Expansionskurs.
Es ist aber auch einfach eine Art, in der man sich selber belügen kann.
Sondern kognitive Dissonanz abbauen kann.
Er belügt nur dich.
Der Unternehmer als Held, der sich von niemanden befreundet.
Er weiß ganz genau, was er da macht.
Diese weit verbreitete Denkart in der Technologiebranche.
Also alle, die jetzt sich hier an meinen Channel reinziehen.
Haben sich wahrscheinlich das Video zu Facebook schon reingezogen.
Aus der Reihe Digitalisierung verstehen lernen.
Und ihr dürft euch alle sehr erhaben fühlen über den durchschnittlichen GEZ-Medienkonsumenten.
Weil da wurde jetzt offensichtlich ein Literaturwissenschaftler nach seiner Meinung befragt zu Facebook.
Und natürlich macht er das, was alle machen.
Er identifiziert ein Symptom.
Und jetzt haltet euch fest, sie werfen Facebook vor.
Dass sie das pure Böse sind und vor allem unwissentlich das falsche tun.
Das ist natürlich totaler Spaß.
Erstens wissen sie ganz genau, was sie tun.
Sie tun es absichtlich.
Und ja, der Sturm aufs Kapitol ist für Facebook super gewesen.
Natürlich wäre es noch viel geiler, wenn noch mehr hinterher Facebook-Traffic entstanden wäre.
Aber wahrscheinlich war es schon unendlich viel Traffic.
Und sie haben es immer noch nicht verstanden.
Natürlich.
Auch so ein Gemetzel in Myanmar ist super für Facebook.
Alles ist super für Facebook, solange es Traffic im Facebook erzeugt.
Facebook braucht Daten und Facebook braucht mehr Traffic.
Das ist ihr Geschäftsmodell.
Und ihnen Wachstum, Wachstumszwang vorzuwerfen, das ist Schwachsinn.
Weil das ist immanent, das ist im System drin.
Und ich habe ja schon erklärt, Facebook und naja, eigentlich auch Fake News.
Fake News entstehen aus Wettbewerb.
Aus der ganz simplen Tatsache, dass da um die Aufmerksamkeit der User gekämpft wird.
Aber da sieht man, was dabei rumkommt.
Da gibt es jetzt hier so einen 10-Minuten-Beitrag mit dem super Enthüllungsbuch zu Facebook.
Und da steht mit Sicherheit nichts drin, was nicht schon längst bekannt ist.
Garantiert.
Ich will es gar nicht lesen. Will ich auch nicht.
Aber offensichtlich macht Kulturzeit einfach nur Werbung für irgendwelche Bücher.
Für irgendwelche Boomer, die keine Ahnung haben von dem Neuland Internet.
Und deswegen mal ein Buch lesen müssen darüber und sich dann aber nur noch über Symptome aufregen.
Herrlich. Find ich richtig geil.
Kann man eigentlich nichts mehr zu sagen.
Super Beitrag.
Herrliches Ding.
Super Beitrag.
Super Beitrag.
Super Beitrag.
Übrigens, der Kanal ist wie eine schöne Vorlesung aufgebaut.
Wenn ich unten Videos verlinke, dann wäre es angebracht, sich die auch reinzuziehen, weil das aufeinander aufbaut.
Bestimmte Begriffe werden definiert, viele Beispiele werden genannt.
Und ja, ich denke mir schon was dabei, weil es sozusagen meinen eigenen Erkenntnisprozess abbildet, die Reihenfolge, in denen ich die Videos hier hochlade.
