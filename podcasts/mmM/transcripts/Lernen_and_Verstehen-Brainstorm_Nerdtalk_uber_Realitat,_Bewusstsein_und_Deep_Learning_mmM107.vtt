WEBVTT

00:00.000 --> 00:06.680
Das Gehirn erzählt sich ja selber eine Geschichte darüber, wie es wäre, wenn es eine Person gäbe,

00:06.680 --> 00:12.880
von die so ist wie wir und die in einer Situation ist, die wir Gegenwart nennen.

00:12.880 --> 00:18.120
Und wir konstruieren, während wir den sensorischen Input über die Gegenwart bekommen,

00:18.120 --> 00:22.720
diese Person und stellen uns vor, wie es wäre, so eine Person zu sein.

00:22.720 --> 00:25.120
Wir simulieren das.

00:25.120 --> 00:26.760
Das ist das, was das Gehirn macht.

00:26.760 --> 00:30.920
Deswegen sagt er, nur eine Simulation kann überhaupt Bewusstsein haben.

00:30.920 --> 00:35.600
Riesen Sorry schonmal an alle, die sich dieses Video jetzt hier rein gönnen.

00:35.600 --> 00:40.640
Ich glaube, es ist absolut unmöglich zu verstehen, was ich jetzt hier in diesem Video quatsche,

00:40.640 --> 00:44.800
wenn ihr mein Video zum Bewusstsein nicht zuerst gesehen habt.

00:44.800 --> 00:50.640
Das baut er halt darauf auf und ich benutze viele komische Fremdworte.

00:50.640 --> 00:56.040
Ich glaube, die ergeben alle überhaupt keinen Sinn, wenn ihr das Video mit dem Bewusstsein nicht vorher geguckt habt.

00:56.040 --> 00:58.560
Das ist nur so schon mal als Warnung.

00:58.560 --> 01:00.680
Das ist ein absolutes Nerd-Video.

01:00.680 --> 01:04.440
Ich habe das gestern aufgenommen und da hatte ich auch schon einen im Tee.

01:04.440 --> 01:07.720
Und jetzt habe ich mir halt angeguckt und dachte mir so, ja, okay, schon klar.

01:07.720 --> 01:11.960
Aber das kann glaube ich keiner verstehen, wenn man nicht irgendwie das mindset dafür hat.

01:11.960 --> 01:15.120
Und dafür ist das andere Video auch gut geeignet.

01:15.120 --> 01:17.320
Also guckt euch vorher an, bevor ihr jetzt hier weiter guckt.

01:26.040 --> 01:47.200
So Leute, jetzt mal wieder eins von diesen Deep Philosophical U-Bow-Videos des Todes und der Vorläufer zu diesem Video, würde ich sagen, ist das Video zum Bewusstsein.

01:47.200 --> 01:53.240
Und ich möchte hier erst mal mit euch über Emergenz reden, weil das braucht man irgendwie ständig.

01:54.200 --> 01:58.760
Und dann so ein bisschen mehr über, naja, was ist die Realität?

01:58.760 --> 02:00.840
Was ist das Bewusstsein?

02:00.840 --> 02:03.240
Und was soll das alles?

02:03.240 --> 02:17.000
Einfach mal ein bisschen euch mal ein bisschen mal was rein knallen an krasser Erkenntnis, die ich so in den letzten Jahren, ich würde sagen im letzten Jahr so ungefähr hatte.

02:17.000 --> 02:19.160
Und ja, also was ist jetzt Emergenz?

02:19.160 --> 02:22.040
Ich habe schon ein paar Mal verwendet das Wort.

02:22.040 --> 02:32.600
Emergenz ist immer dann etwas, wenn ihr etwas beobachtet, was erstmal total kompliziert wirkt, wenn ihr da reingucken wollt.

02:32.600 --> 02:41.880
Von außen sieht es irgendwie krass aus und ihr denkt, okay, das hat irgendwie einen Mechanismus, das ist heftig, aber wenn man reinguckt, steht man fest, es besteht aus ganz vielen simplen Teilen.

02:41.880 --> 02:54.520
Und irgendwie ist die Summe dieser Teile mehr als einfach nur, also die Summe der Teile ergibt mehr als einfach nur das, was man sich vorstellen würde, wenn man die Summe der Teile tatsächlich addieren würde.

02:54.520 --> 02:55.320
Was meine ich damit?

02:55.320 --> 02:56.600
Na ja, zum Beispiel ein Ameisenhaufen.

02:56.600 --> 02:59.800
Die kleinen Ameisen, die sind alle sehr einfach, wie die funktionieren.

02:59.800 --> 03:10.040
Trotzdem ist die Gesamtheit der Ameisen, das Konglomerat, so eine Art komplizierter Lebens, ein komplizierter Metabolismus, der sich verhält wie ein Lebewesen.

03:10.120 --> 03:21.080
Und wenn das Objekt, was ihr seht, nur aus Verbindungen besteht, die irgendwie auch rein virtuell dadurch sind, die sind ja nicht anfassbar.

03:21.080 --> 03:26.280
Man kann ja nicht sagen, ach, diese Wechselwirkung zwischen den Ameisen, die macht das erst so interessant.

03:26.280 --> 03:27.160
Aber genau darum geht es.

03:27.160 --> 03:28.040
Das ist die Emergenz.

03:28.040 --> 03:38.440
Das ist etwas, was man nicht so greifen kann, sondern es entsteht als ein Prozess höherer Ordnung zwischen Wechselwirkungen von einfacheren Mechanismen, die man sehr wohl verstehen kann.

03:38.440 --> 03:41.000
Und darum ist Emergenz nicht greifbar.

03:41.000 --> 03:42.360
Und das ist immer das Problem.

03:42.360 --> 03:43.240
Das seht ihr ganz oft.

03:43.240 --> 03:45.880
Das ist immer, wenn es um gesellschaftliche Themen geht.

03:45.880 --> 03:48.200
Gesellschaft ist zum Beispiel eine emergente Struktur.

03:48.200 --> 03:53.000
Sie entsteht aus den ganz vielen Interaktionen zwischen Menschen.

03:53.000 --> 03:55.480
Wenn wir die alle addieren, kriegen wir die Gesellschaft raus.

03:55.480 --> 03:57.960
Und Evolution ist auch so was.

03:57.960 --> 04:07.640
Evolution entsteht ja nur dadurch, dass wir einen Selektionsdruck haben, der nur dadurch entsteht, dass es sozusagen eine äußere Umgebung gibt, die sozusagen dazu führt,

04:07.720 --> 04:21.880
dass bestimmte Lebensformen, die besser, ich würde mal sagen, negative Entropie farmen können oder besser den Gradienten in die Entropie runtergehen können als andere und dadurch sozusagen einen Wettbewerbsvorteil gegeneinander haben und sich dann durchsetzen.

04:21.880 --> 04:26.600
Und Schwarmintelligenz ist auch so was wie Emergenz.

04:26.600 --> 04:31.480
Und der Markt, das ist das, was die FDP-Menschen nicht verstehen.

04:31.480 --> 04:32.760
Die raffen es ja nicht.

04:32.760 --> 04:34.440
Aber der Markt ist eine emergente Struktur.

04:34.440 --> 04:43.160
Und weil das so unbegreifbar ist, dachte damals Hayek auch, und das ist sozusagen so eine Art Gott für ihn und versteht mich da nicht falsch.

04:43.160 --> 04:48.360
Es ist natürlich eine emergente Struktur und es ist natürlich interessant, darüber nachzudenken.

04:48.360 --> 04:56.920
Aber nur weil es kompliziert ist oder irgendwie geil aussieht oder man ein bisschen Mathematik damit machen kann, heißt es ja nicht, dass das sozusagen die Lösung aller Probleme ist.

04:57.000 --> 04:58.520
Aber genau so geht Hayek daran.

04:58.520 --> 05:04.120
Das habe ich auch schon mal in einem anderen Video erklärt, von wegen welches Problem lösen die Märkte eigentlich.

05:07.000 --> 05:17.240
So und was soll ich sagen, wenn es etwas in den letzten Jahren gab, was ich mir sehr gerne reingezogen habe, dann sind das Videos von Joscha Bach.

05:17.240 --> 05:21.800
Und ich kann euch wirklich nur empfehlen, schmeißt alles in die Ecke.

05:22.120 --> 05:28.920
Jo Roggen Podcasts oder alle möglichen Lex Friedman Interviews oder sonst welche Sachen, die ihr im englischen YouTube drin gesehen habt.

05:28.920 --> 05:34.680
Das nächste, was ihr bei euch auf die Watchlist drauf tut, ist der erste Talk von Joscha Bach.

05:34.680 --> 05:36.840
Und der zweite, den könnt ihr gleich noch hinten dran hängen.

05:36.840 --> 05:41.880
Dann habt ihr sechs Stunden lang komprimierteste Todesweisheit des Todes.

05:41.880 --> 05:44.360
Der Typ ist der lebende Sheldon Cooper.

05:44.360 --> 05:48.600
Das ist der krasseste Wichser, den ich je irgendwo gehört habe.

05:48.600 --> 05:51.960
Ich glaube, das ist so ein verdammtes Genie.

05:51.960 --> 05:58.760
Und der lebt heutzutage und ich habe ihn schon auf Twitter vollgequatscht, er soll mal mit mir reden, aber natürlich, warum sollte der das tun?

05:58.760 --> 06:02.200
Der hat einfach eine volle Inbox, der hat keine Zeit mit einem scheiß Ossi zu reden.

06:02.200 --> 06:04.440
By the way, Joscha Bach ist selber ein Ossi.

06:04.440 --> 06:06.680
Aber ihr müsst euch den Typen reinziehen.

06:06.680 --> 06:11.400
Der alles, was er jemals in seinem Leben gelesen hat, hat er hier oben drin und kann sofort abrufen.

06:11.400 --> 06:12.920
Der ist krass, der Typ.

06:13.880 --> 06:21.880
Und ich bin übrigens nur auf den gestoßen, weil jemand mir den empfohlen hat unter einem englischen Matrix-Video.

06:21.880 --> 06:23.400
Hat mir jemand Joscha Bach empfohlen.

06:23.400 --> 06:25.560
Dafür hat sich der englische Kanal schon gelohnt.

06:25.560 --> 06:27.240
Das ist super.

06:27.240 --> 06:32.600
Und jetzt wollte ich ein bisschen, jetzt haben wir das geklärt mit der Emergenz, ich habe jetzt dieses Wort etabliert.

06:32.600 --> 06:41.080
Jetzt will ich ein anderes wichtiges Wort für euch etablieren, weil das ist natürlich auch so ein Ding, wo die Leute immer rumschlavieren.

06:41.080 --> 06:44.280
Und irgendwie so so eine Krämer-Laber-Attitüde haben.

06:44.280 --> 06:46.520
Was ist jetzt eigentlich Intelligenz?

06:46.520 --> 06:52.920
Also guter Freund von mir hat damals zu mir gesagt, Intelligenz ist die Fähigkeit, Analogien zu bilden.

06:52.920 --> 06:59.000
Und das ist eine ziemlich gute Definition, wenn man da mal drüber nachdenkt, weil damit kann man eine ganze Menge erschlagen.

06:59.000 --> 07:02.360
Quasi ich habe hier, sagen wir mal, verstanden, wie das eine Ding funktioniert.

07:02.360 --> 07:05.160
Und jetzt habe ich hier ein anderes Ding, das heißt anders.

07:05.160 --> 07:10.680
Aber der Mechanismus, der hier abläuft, ist genau derselbe Mechanismus wie in dem Ding, was ich schon verstanden habe.

07:10.680 --> 07:17.480
Wenn ich also die Analogie bilden kann und feststellen kann, dass abgesehen von den Bezeichnungen, dass da was da passiert, dasselbe oder das gleiche ist,

07:17.480 --> 07:20.280
dann habe ich eine Analogie gebildet und dann bin ich krass.

07:20.280 --> 07:23.080
Und der King der Analogien, meiner Meinung nach, ist Slavoj G. Jack.

07:23.080 --> 07:25.240
Der hat die witzigsten Analogien.

07:25.240 --> 07:30.200
So und Joscha Bach jetzt, der sagt, Intelligenz ist die Fähigkeit, Modelle zu bauen.

07:30.200 --> 07:32.920
Also Modelle über das, was man sieht.

07:32.920 --> 07:34.600
Und was meint man jetzt damit?

07:34.680 --> 07:41.640
Ein mathematisches Modell typischerweise hat was damit zu tun, dass man eine Komprimierung macht.

07:41.640 --> 07:49.880
Man kompressiert, man komprimiert irgendwie etwas, was man sieht, auf das Wesentliche herunter.

07:49.880 --> 07:52.040
Das ist das, was beim Komprimieren passiert.

07:52.040 --> 07:59.800
Und da muss man natürlich sich genau fragen, in welcher Sprache habe ich es auf das Wesentliche, auf das Minimum runtergekocht?

07:59.800 --> 08:03.400
Und das ist genau die Fragestellung, die man beim Archivieren von Dateien auch hat.

08:03.400 --> 08:08.680
Kann man sozusagen ein Muster finden, auf die man es runterbrechen kann?

08:08.680 --> 08:14.680
Kann ich das Muster sozusagen einmal abspeichern und dann nur noch sagen, jetzt kommt das Muster und dann spare ich mir 500 Bits oder so?

08:14.680 --> 08:16.680
So eine Idee ist das.

08:16.680 --> 08:20.360
Und darauf basieren dann sozusagen die ganzen modernen Komprimierungsverfahren auch.

08:20.360 --> 08:27.640
Im Wesentlichen, in der Mathematik würde man sagen, man findet eine Vektorbasis oder im Kompress-Censing würde man sagen, man findet eine Basis,

08:27.720 --> 08:39.960
die irgendwie im Sinne der L2-Norm oder beziehungsweise in der L1-Norm, eigentlich in der L0-Norm, ich glaube es ist tatsächlich die L0-Norm oder die L1-Norm, da wo das sozusagen ein Minimum annimmt.

08:39.960 --> 08:44.040
Das ist quasi Kompress-Censing, aber nur für die Geeks und Nerds, die sich damit auskennen.

08:44.040 --> 08:50.600
Ansonsten, ihr könnt euch einfach vorstellen, wann kann ich sozusagen etwas aufs Wesentliche so weit runterbrechen, bis es nicht mehr weiter runtergeht?

08:50.600 --> 08:53.880
Bis ich es sozusagen auf die Einsen und Nullen runtergebrochen habe.

08:53.960 --> 09:04.760
Und Sprache ist sozusagen in diesem Kontext sozusagen eine High-Level-Abstraktion, weil sie ist sehr schwammig und Mathematik ist quasi Low-Level.

09:04.760 --> 09:10.040
Man kann sozusagen das eine in das andere überführen, aber es ist sehr langwierig.

09:10.040 --> 09:18.360
Bestimmte Sachverhalte lassen sich mit Sprache in ein, zwei Sätzen erklären und man müsste einen riesen Apparat Mathematik drauf werfen, um dasselbe in Mathematik auszudrücken.

09:18.680 --> 09:24.440
Joscha Bach sagte, Mathematik ist die Domäne aller Sprachen und mittlerweile glaube ich, da hat er natürlich recht.

09:24.440 --> 09:34.840
Das ist ziemlich krass, denn es ist so, Sprache in diesem Sinne, das Kompress-Censing zum Beispiel, ist eine Projektion von Inhalt.

09:36.680 --> 09:43.720
Wir haben hier dieses Ding, wir haben diese echten Inhalte, die sind kompliziert und mit Sprache vereinfachen wir die.

09:43.720 --> 09:51.640
Wir machen schon so eine Art Komprimierung, wir komprimieren schon den Inhalt, sodass wir ihn rüberreichen können und natürlich ist dann sozusagen Informationsverlust.

09:51.640 --> 09:57.960
Und das ist bei jeder Projektion, jeder der lineare Algebra schon mal gehört hat, weiß, Projektionen verlieren Informationen und das ist da auch der Fall.

09:57.960 --> 10:06.840
Und das ist ja klar, Sprache kann beim Empfänger anders ankommen, als wir es eigentlich als der Empfänger, als der Aussender der Sprache es eigentlich sagen wollte.

10:06.840 --> 10:13.800
Und ja, Wittgenstein zum Beispiel dachte, dass man alles mit Sprache aufbauen kann und das war sozusagen sein Fail.

10:13.800 --> 10:20.280
Er hat sozusagen nicht runterbrechen können auf Mathematik, sondern er dachte Sprache ist sozusagen der Shit.

10:20.280 --> 10:27.160
Und deswegen sage ich ja auch, Wittgenstein hätte die Sache mit dem Word Embeddings in Deep Learning auch richtig gut gefallen.

10:27.160 --> 10:32.280
Ja, aber so Sachen wie Bilder oder Geometrie mit Sprache zu beschreiben, ist halt völlig Fail.

10:32.520 --> 10:37.640
Da ist völlig klar, dass die etabliert, also die bessere Variante irgendwie Mathematik sein muss.

10:37.640 --> 10:45.560
Und jetzt wollte ich mal erklären, was nennen wir eigentlich Realität bzw. was nennen wir unser Universum?

10:45.560 --> 10:57.080
Na ja, wir bezeichnen mit Realität typischerweise das, was unser Modell als Ursache angibt für den sensorischen Input, den wir erfahren.

10:57.080 --> 11:03.240
Das einzige, was unser Gehirn bekommt, ist der sensorische Input über unsere Augen, unsere Sinnesvornehmungen und so.

11:03.240 --> 11:10.840
Wir wissen nichts über die Welt da draußen, außer wir sind nur beschränkt darauf auf den sensorischen Input, den wir haben und daraus schlussfolgern wir alles.

11:10.840 --> 11:19.320
Und das Gehirn, das habe ich ja in meinem Bewusstheitsvideo schon erklärt, versucht sozusagen das mathematische schlechtgestellte inverse Problem zu lösen.

11:19.320 --> 11:24.520
Was hat die Inputdaten verursacht? Wir wissen ja nicht, was die verursacht haben.

11:24.600 --> 11:31.720
Unser Gehirn, quasi unser Verstand, unser was auch immer, unser Gehirn versucht zu beschreiben und zu erklären, was diese Inputdaten verursacht hat.

11:31.720 --> 11:35.400
Und dabei konstruieren wir das, was wir Realität nennen.

11:35.400 --> 11:47.960
Und das beste, was Urscha Bachter immer sagt, ist, es gibt in dieser, also die beste Sprache, die wir im Moment dafür haben, ist sozusagen die Physik, die physikalischen Gesetze.

11:47.960 --> 11:51.960
Und in dieser Sprache gibt es keine Geräusche und es gibt auch keine Farben.

11:52.600 --> 12:01.320
Das sind einfach nur höhere Ordnung von Strukturen, denen wir diese Bedeutung zuweisen im Sinne von einer Komprimierung.

12:06.680 --> 12:09.000
Und jetzt ist es so...

12:11.000 --> 12:17.720
Übrigens, das ist der Grund, wenn man jetzt irgendwie, sagen wir mal, ich nehme mir jetzt das Lineal, tue das hier auf den Tisch und knall hiergegen, dann hör ich so ein Brrrrrrr.

12:18.280 --> 12:25.240
Und diese höheren Schwingungsmoden und so, diese ganzen Sachen mit den Schwingungen, Sounds sind auch fraktale.

12:25.240 --> 12:28.760
Da gibt es ein ziemlich geiles Video von Adam Neely, falls ihr den kennt.

12:28.760 --> 12:30.760
Das ist ein sehr witziges Video, das werde ich verlinken.

12:30.760 --> 12:38.840
Dass sozusagen sich auch da durch die höheren Schwingungsmoden, Sounds wie, also Geräusche und Töne wie fraktale verhalten.

12:38.840 --> 12:43.400
Also man kann da immer weiter reinzoomen und die werden dann immer wieder selbst ähnlich.

12:43.400 --> 12:50.040
Und das ist super geil, denn das bedeutet im Prinzip, dass man alles auf eine Ringstruktur abbilden kann.

12:50.040 --> 12:55.800
Deswegen kann man Farben auch in einem Ring anordnen und bei Tönen kann man die sozusagen auf diese Oktaven abbilden.

12:55.800 --> 12:59.160
Und das hat damit zu tun, dass sie sozusagen fraktale darstellen.

12:59.160 --> 13:01.000
Und in echt existiert das nicht.

13:01.000 --> 13:08.360
Das ist was, was unser Gehirn konstruiert, genauso wie, was weiß ich, wenn wir irgendwie rumgucken mit unseren Augen,

13:08.360 --> 13:14.120
dann wird der Hauptinput, der wird interpoliert und auch extrapoliert hier am Rand und so.

13:14.120 --> 13:22.120
Unser Gehirn kann sozusagen die Daten, die eigentlich aufgenommen werden müssten, um das, was wir hier sehen, zu konstruieren, kann es gar nicht verarbeiten.

13:22.120 --> 13:23.640
Das braucht das Gehirn nicht.

13:23.640 --> 13:27.880
Unser Gehirn ist so krass, dass es übelst Rechenleistung investiert, um das alles zu interpolieren.

13:27.880 --> 13:30.600
Und in dem Sinne ist es halt so,

13:30.600 --> 13:43.560
Unser Gehirn leistet diese Komprimierungsarbeit schon für uns und diese periodischen Eigenschaften von zum Beispiel Geräuschen und Farben machen, dass man die auf einem Ring anordnen kann.

13:43.560 --> 13:56.920
Und wir existieren jetzt, also das, was wir als wir bezeichnen, wir existieren in dieser virtuellen Realität, die unser Gehirn konstruiert, um zu erklären, was die Messdaten verursacht hat.

13:56.920 --> 14:00.040
Und das habe ich ja in dem Video über das Bewusstsein schon erklärt.

14:00.120 --> 14:09.640
Also unser Gehirn konstruiert diese virtuelle Realität und auf diesem, weil das Ding ist, auf diesem Level von diesem äußerst merkwürdigen Quantengraf,

14:09.640 --> 14:16.120
den wir jetzt, von dem wir annehmen, dass es, dass der existiert durch unsere mathematischen Modelle und unsere Physik und so,

14:16.120 --> 14:19.000
da existiert wirklich nur kalte Algebra.

14:19.000 --> 14:29.960
Von einem Zustand des Universums zum nächsten transformieren die physikalischen Gesetze diesen Quantengraf und wir können nur einen ganz kleinen Auschnitt davon messen.

14:30.920 --> 14:32.920
Durch unseren sensorischen Input.

14:32.920 --> 14:40.040
Und das, was die Philosophen dann sozusagen als Qualia bezeichnen, das ist genauso eine Illusion wie der Freie Wille.

14:40.040 --> 14:45.640
Das ist einfach nur eine emergente Struktur, die auf unserem Gehirn entsteht, Qualia.

14:45.640 --> 14:53.240
Und Joscha Bach nimmt jetzt als Beispiel für Realität, ziemlich geiles Beispiel, wie ich finde, das Mandelbrot-Fraktal.

14:53.240 --> 14:58.520
Vielleicht binde ich das jetzt hier auch in das Video ein, da gibt es bestimmt ein cooles Gift oder so.

14:58.520 --> 15:05.560
Das ist so ein Fraktal, das entsteht im Wesentlichen, wenn man eine iterative Abbildung lösen will.

15:05.560 --> 15:15.000
Ja genau, man hat eine quadratische iterative Abbildung in einer komplexen Ebene und guckt für welche Werte von einer konstanten komplexen Zahl die konvergiert oder nicht.

15:15.000 --> 15:24.280
Und wenn man das sozusagen macht für die komplexe Zahlenebene und alles was divergiert mit schwarz abbildet, dann kriegt man dieses Fraktal und so baut man das.

15:24.360 --> 15:28.840
Das ist relativ einfach das zu bauen tatsächlich, aber das Muster was rauskommt, das sieht halt super krass aus.

15:28.840 --> 15:43.480
Und wenn man sich jetzt vorstellt, wir leben auf so einer fraktalen Oberfläche von dem Mandelbrot-Fraktal, dann würden wir sehen, okay, da gibt es so eine rechtsdrehende Spirale.

15:43.480 --> 15:48.120
Wenn man die jetzt reingeht, würde man irgendwann an einer Singularität ankommen.

15:48.200 --> 15:58.120
Und wenn man die sozusagen, wenn man darüber hinweg guckt, gibt es quasi Periodenverdopplung oder ich weiß gar nicht mehr wie dieser Effekt heißt, auf jeden Fall, dann beginnt diese Spirale von vorne.

15:58.120 --> 16:04.760
Dann beginnt sozusagen die Oberfläche von vorne zu wachsen, dann kommt diese Selbstähnlichkeit, die kickt rein bei dem Fraktal und dann sieht es wieder von vorne so aus.

16:04.760 --> 16:10.760
Und man müsste wieder die Spirale weiter reingehen, bis man wieder zur Singularität kommt und dann wieder reingehen und so weiter.

16:10.760 --> 16:19.080
Und wenn man so mehrere Layers bauen würde von seiner eigenen Realität, weil wir leben ja auf diesem Fraktal, dann wäre das eine gute Approximation für die Realität.

16:19.080 --> 16:24.360
Was wir niemals sehen würden, ist sozusagen das komplette Picture, weil das Fraktal ist.

16:24.360 --> 16:28.760
Es ist ein unendlich großes und selbstähnliches periodisches Muster.

16:28.760 --> 16:31.080
So und so ist es mit unserem Universum auch.

16:31.080 --> 16:36.920
Wir haben halt diese physikalischen Gesetze, sie sind nicht perfekt, sie sind aber eine gute Beschreibung für das, was wir haben, was wir sehen und so.

16:36.920 --> 16:41.080
Und je näher wir uns ran tasten an die Realität, desto besser werden wir.

16:41.080 --> 16:51.000
Irgendwann würden wir, wenn wir auf diesem Fraktal leben, in der Mandelbrotmenge, irgendwann würden wir diese paar Zeilen Code, die das braucht, um das zu generieren, vielleicht bauen können.

16:51.000 --> 16:54.280
Und dann hätten wir es gekickt, dann hätten wir die Realität vollständig beschrieben.

16:54.280 --> 17:00.040
Das heißt, was man machen muss, um die Realität zu beschreiben, ist man muss sich aus First Principles Schluss folgern.

17:00.040 --> 17:04.280
Und das geht natürlich nicht so als Schlussfolgerung, sondern das ist im Prinzip zwar ein Error.

17:04.280 --> 17:18.520
Also man muss Mathematik machen, betreiben und man muss es solange mit 3 in Error machen, bis man irgendwie auf das kommt, was sozusagen die minimale Information beinhaltet, die alles beschreibt, was wir haben.

17:18.520 --> 17:21.240
Das ist das Prinzip von Okams Racer auch.

17:21.240 --> 17:25.720
Also wir wollen so wenig wie möglich voraussetzen oder so wenig wie möglich annehmen.

17:25.720 --> 17:28.920
Und das soll maximal viel von dem, was wir beobachten, beschreiben.

17:28.920 --> 17:33.120
Und wenn wir etwas haben, was alles mit einem Formalismus beschreibt, dann sind wir fertig.

17:33.120 --> 17:38.000
Das ist die Idee. Das ist sozusagen das Ideal, an das ich sozusagen die Wissenschaft da ran tasten möchte.

17:43.840 --> 18:01.440
So und wenn wir also, Joshua Bach gibt auch noch so einen anderen coolen Spruch, nämlich er sagt, die physikalische Realität hat kein Bewusstsein und da gibt es auch kein Bewusstsein.

18:01.440 --> 18:05.200
Nur eine Simulation kann Bewusstsein haben.

18:05.200 --> 18:17.160
Das ist das, was er sagt und das ist ein ziemlich cooler Spruch, weil was er damit meint ist, wenn wir jetzt ein Buch lesen und da ist ein Protagonist drin und der fühlt irgendwas oder dem geht es irgendwie scheiße.

18:17.160 --> 18:19.080
Dann empfinden wir das, während wir das lesen.

18:19.080 --> 18:30.040
Das liegt daran, dass wir in unserem Kopf uns ein Bild davon, ein Abbild dieser Person in dem Buch, die da beschrieben wird durch Sprache übrigens, bauen und dadurch wird es real.

18:30.040 --> 18:37.320
Und der Witz ist, zwischen dieser Person in dem Buch und dem, was wir uns selbst nennen, gibt es eigentlich keinen Unterschied.

18:37.320 --> 18:50.480
Denn das Gehirn erzählt sich ja selber eine Geschichte darüber, wie es wäre, wenn es eine Person gäbe, die so ist wie wir und die in einer Situation ist, die wir Gegenwart nennen.

18:50.480 --> 18:59.000
Und wir konstruieren, während wir den sensorischen Input über die Gegenwart bekommen, diese Person und stellen uns vor, wie es wäre, so eine Person zu sein.

19:00.280 --> 19:01.480
Wir simulieren das.

19:02.680 --> 19:03.960
Das ist das, was das Gehirn macht.

19:04.320 --> 19:07.520
Deswegen sagt er, nur eine Simulation kann überhaupt Bewusstsein haben.

19:07.920 --> 19:17.640
Nur eine Simulation ist fähig, diese emergente Struktur zu haben, die dann wieder, also die emergente Struktur, die sozusagen das Bewusstsein als Nebenprodukt hat.

19:18.400 --> 19:19.160
Und das ist krass.

19:19.360 --> 19:20.360
Das ist ziemlich heftig.

19:20.360 --> 19:25.600
Also wenn ihr, wenn ihr das nicht kennt, diese Joscha Bach Talks, ihr müsst euch die reinziehen.

19:25.600 --> 19:27.200
Ich verlinke die beiden von Lex Friedman.

19:27.320 --> 19:32.240
Es gibt aber noch viele mehr, die sozusagen ins Detail gehen, wenn Joscha Bach seine Meinung zu GPT-3 erzählt.

19:32.240 --> 19:34.280
Das ist super krass oder generell.

19:34.280 --> 19:39.960
Es gibt, glaube ich, auch zwei, drei deutsche Talks, von denen einer mindestens schon mal ziemlich gut ist für Einsteiger.

19:39.960 --> 19:42.360
Die anderen sind zu abgefahren, absolute Nord-Talks.

19:42.880 --> 19:47.360
Aber wie gesagt, der Typ ist ein Ostdeutscher, der kann also auch fließend Deutsch, ist gar kein Problem.

19:47.360 --> 19:49.040
Man findet bloß nicht so viel von dem auf Deutsch.

19:50.440 --> 19:51.240
Aber hammermäßig.

19:52.320 --> 19:58.960
Also wirklich alles andere, alle anderen Talks, alle anderen Podcasts, die es auf dieser Welt gibt, sind, meiner Meinung nach, Zeitverschwendung,

19:58.960 --> 20:04.520
bevor man nicht vollständig durchdrungen hat, was Joscha Bach einen in drei Stunden reinquetscht an Wissen.

20:04.600 --> 20:05.440
Das ist so viel.

20:05.480 --> 20:16.040
Ich habe den Talk jetzt bestimmt vier, fünf Mal schon durchgeknallt und ich komme immer wieder auf neue Erkenntnisse, weil der Typ in einem Satz so viel Informationen und so viel Verständnis

20:16.040 --> 20:20.800
reinsteckt, dass man das wirklich erst nach einem Jahr nochmal dann checkt oder so.

20:21.960 --> 20:25.640
So und in Deep Learning ist es jetzt nur so.

20:26.200 --> 20:30.240
Man muss dazu wissen, das habe ich auch noch nie so erwähnt, aber das ist quasi bekannt.

20:30.240 --> 20:33.560
Das ist wahrscheinlich erste Vorlesung, Deep Learning im Informatikstudium.

20:34.240 --> 20:37.880
Der sogenannte universelle Funktions-Approximator, das ist das Relevante.

20:38.360 --> 20:52.720
Der sagt Folgendes aus, wenn ihr ein neuronales Netz macht mit N-Input, N-dimensionalen Input und ihr wollt nur ein Output haben, also sozusagen eine Funktion mit beliebigem Input und die soll was ausgeben.

20:53.160 --> 20:58.000
Und ihr habt ein Layer dazwischen, der hat beliebig viele, also auch beliebig viele Knoten.

20:59.200 --> 21:02.560
Dann könnt ihr jede mathematische Funktion damit approximieren.

21:03.120 --> 21:07.680
Das ist erstmal irgendwie klar, aber es wurde sozusagen bewiesen, dass das so ist.

21:08.560 --> 21:09.920
Und der Witz ist jetzt Folgendes.

21:10.360 --> 21:20.240
In der Informatik geht es jetzt darum, wir nehmen an, dass unsere Welt determiniert ist und deswegen kann man alles mit einer Funktion quasi hinschreiben.

21:21.320 --> 21:25.400
Die kann beliebig kompliziert sein, aber es muss durch eine Funktion approximierbar sein.

21:26.040 --> 21:31.480
Das bedeutet, dass alles mit einem Deep Learning Netz, also mit einem neuronalen Netz beschreibbar ist.

21:31.960 --> 21:33.000
Das ist die Voraussetzung.

21:33.400 --> 21:36.840
Und jetzt ist nur die Frage, wenn wir beliebig viele Knoten haben, dann ist das klar.

21:37.200 --> 21:38.800
Was man dann einfach macht, ist Overfitting.

21:38.960 --> 21:46.160
Also ihr könnt euch quasi vorstellen, ich habe eine Aufgabenstellung und ich verstehe die Aufgabenstellung nicht, sondern ich lerne sie einfach auswendig.

21:46.480 --> 21:56.600
Sagen wir mal, mein Konfigurationsraum hat 10 hoch 32 viele Möglichkeiten und 10 hoch 32 viele Outputs zu einem gegebenen Problem, eins aus diesen 10 hoch 32.

21:56.920 --> 22:02.200
Dann kann ich doch, wenn ich genug Knoten, also Speicherpunkte habe, kann ich die einfach auswendig lernen.

22:02.200 --> 22:04.880
Ich kann alle Antworten auf alle Fragen auswendig lernen.

22:06.760 --> 22:12.280
Also stellt euch einfach nur vor, ihr wollt eine Software schreiben, die Bilder erkennt und ihr gebt der Software vor.

22:12.960 --> 22:16.520
Man gibt ein Bild rein, das ist 256 mal 256 Pixel groß.

22:17.720 --> 22:27.160
Und jetzt macht ihr eine feine Abschätzung und steckt sozusagen einfach alle möglichen Bilder, die überhaupt existieren können im Konfigurationsraum.

22:27.360 --> 22:39.120
Also alle Kombinationen von Pixelwerten, die 256 mal 256 Bilder haben können überhaupt, die steckt ihr rein und lernt sie auswendig mit dem Satz darunter, was sieht man auf dem Bild.

22:39.520 --> 22:40.520
Das lernt ihr auswendig.

22:41.360 --> 22:46.080
Wenn ihr unendlich viel Speicherplatz habt und unendlich groß sozusagen das Lehr machen könnt, ist das natürlich kein Problem.

22:46.360 --> 22:51.720
Dabei habt ihr aber sozusagen, ihr habt das Problem nur gelernt, aber ihr habt es nicht verstanden.

22:52.440 --> 23:02.280
Und die Idee ist sozusagen, kann man das runter kochen auf irgendetwas, was weniger ist als Overfitting und sozusagen die Datenmenge besser abbildet,

23:02.480 --> 23:10.440
sozusagen eine sehr große Datenmenge, zum Beispiel dieser riesige Konfigurationsraum von allen möglichen Bildern, die 256 Quadratviele Pixel haben,

23:11.400 --> 23:18.040
irgendwie abzubilden auf irgendwas, wo wir trotzdem das Problem lösen können, nämlich eine Software, die uns am Ende sagt, was sieht man auf dem Bild oder so.

23:18.360 --> 23:24.960
Und das ist quasi das, was ich hier sozusagen jetzt mit Overfitting auch erklären wollte, aber wie gesagt, das Video ist ein bisschen heftig, ich weiß schon.

23:25.960 --> 23:27.040
Das nennt man Overfitting.

23:27.480 --> 23:33.800
Viel besser wäre es doch, wenn ich runter gehe mit meiner Komplexität in meinem Deep Learning Netzwerk, also in diesem Zwischenlayer,

23:35.120 --> 23:42.960
auf viel weniger Dimension und trotzdem noch eine sehr hohe Approximationsgüte kriege, also 99,999 Prozent oder so.

23:43.760 --> 23:45.280
Denn dann habe ich ja Folgendes geschafft.

23:45.680 --> 23:52.120
Ich habe mein Problem komprimiert, was konkret, ich habe aus dem Auswendiglernen Verstehen gemacht.

23:52.640 --> 23:59.720
Ich habe sozusagen, und das ist ja das, was grundsätzlich irgendwie nie jemand mal rafft, was ist jetzt der Unterschied zwischen lehnen und lernen und verstehen?

24:00.160 --> 24:11.560
Verstehen bedeutet, mit dem minimalen Satz an Handlungsanweisungen das Problem vollständig zu lösen und aus verschiedensten Wissenssachen, aus Kombinationen von Wissen, neues Wissen zu erzeugen.

24:12.360 --> 24:19.000
Ja, eine Anwendung zu finden, die sozusagen nur darauf basiert, dass ich hier das eine schon mal verstanden habe und ich direkt auf das andere anwenden kann.

24:20.080 --> 24:21.600
So, und das ist auch da der Fall.

24:21.920 --> 24:26.480
Wenn man also den minimalen Satz quasi die beste Architektur von Layern erzeugen kann,

24:27.720 --> 24:32.800
um zum Beispiel Energie zu sparen, Speicher zu sparen, dann komprimiert das sozusagen. Ich mache eine Kompression dabei.

24:33.640 --> 24:42.840
Und da kommen dann sozusagen die mehreren Layer dann typischerweise im Deep Learning dazu. Es ist nicht einer, sondern es sind viele verschachtelte Layer, die runter und hoch gehen in ihrer Dimension.

24:42.840 --> 24:48.960
Da gibt es sozusagen Konvolutiones und was auch immer. Es gibt übelst viele krasse Architekturen mittlerweile, die alle sehr tricky sind.

24:49.760 --> 25:01.920
Aber das ist sozusagen erstmal die Idee. Es gibt diesen universellen Funktions-Approximator und man kann mit einem Neuronalen jetzt jede beliebige Funktion, insbesondere alles, was wir in unserer Realität beobachten, wenn es dem geht.

25:03.760 --> 25:14.320
Das ist die Annahme. Und warum sollte man also nicht das Gehirn damit beschreiben können? Und warum sollte man nicht die gesamte Realität und das gesamte Universum damit beschreiben können?

25:21.680 --> 25:25.240
Ich habe jetzt schon erklärt in meinem anderen Video, was das Bewusstsein ist.

25:26.120 --> 25:34.680
Und Joshua Bach hat es ziemlich kompakt nochmal ausgedrückt und hat gesagt, das Bewusstsein ist ein Modell für den Inhalt unseres Aufmerksamkeitsmodells.

25:34.680 --> 25:41.840
Und was meint ihr damit? Na ja, es ist so eine Art Meta-Aufmerksamkeit. Ihr müsst euch vorstellen, es ist so eine Art Meta-Learning.

25:41.840 --> 25:47.320
Was meint jetzt eigentlich Aufmerksamkeit? Na ja, also erstmal gibt es ja mittlerweile schon Transformatoren.

25:47.320 --> 25:58.960
Also es gibt schon Attention-Networks im Deep Learning. Diese Sprache wurde schon etabliert und das macht auch ziemlich genau das, was man sich eigentlich unter dem Konzept von Aufmerksamkeit vorstellt.

25:58.960 --> 26:06.600
Also erstmal Aufmerksamkeit und Bewusstheit, das hängt schon miteinander zusammen, auch vom Wort, sozusagen von der wörtlichen Bedeutung.

26:07.080 --> 26:17.520
Und im Moment ist es so, normale Deep Learning-Netzwerke machen Folgendes. Die haben einen Fehler-Signal, also sagen wir mal, wir haben eine Beobachtung und eine Prediktion von unserem Modell und das ist falsch.

26:17.520 --> 26:24.520
Und dieses Fehler-Signal, die Differenz davon, die versuchen wir zurückzuführen, in unser Modell wegzutrecken. Wo kommt sozusagen der Fehler her?

26:24.520 --> 26:30.880
Und dabei sozusagen bei vielen Daten entstehen natürlich eine ganze Menge in diesen statistischen Gewichten, wo irgendwas sich ändert.

26:30.880 --> 26:43.440
Wenn man jetzt mit vielen Daten lernt, mitteln sich sozusagen die unwichtigen Gewichte raus und was überbleibt ist das, wo der wirkliche Fehler herkommt, also das sind dann meistens nur noch weniger Gewichte.

26:43.440 --> 26:53.160
So, das ist aber ein Prozess, der super ineffizient ist und langsam, der ist super langsam, weil man immer wieder den kompletten Backpropagating-Step durchmachen muss.

26:54.040 --> 27:09.520
Viel geiler wäre, wenn man ein Netzwerk hat, was oben da bei diesem Lernprozess draufguckt und feststellt, wo sind die größten Gewichte im Gradienten, also quasi in dem Backpropagating und kann ich das beobachten, wenn ich das sozusagen öfter mache.

27:09.520 --> 27:19.280
Und dann kann man Statistiken betreiben und sozusagen das abkürzen. Man kann diesen Lernprozess abkürzen, weil man sozusagen den Shortcut geht.

27:19.440 --> 27:28.400
Das hat so ein bisschen was von, wenn ihr euch mit iterativen Lösungsverfahren von algebraischen Gleichungen auskennt, das hat ein bisschen was von Order-Zapsets, finde ich.

27:28.400 --> 27:34.960
Aber das ist wirklich nur meine Physiker-Intubation, da bin ich sozusagen mit gefährlichem Halbwissen hier unterwegs.

27:34.960 --> 28:00.840
Jedenfalls, das kürzt den Lernprozess ab und das erklärt natürlich auch, warum sozusagen heutzutage so ein Alpha Star, also die KI, die StarCraft gewinnt, die hat ja so was wie umgerechnet 200 Jahre StarCraft gespielt, bevor sie auf einem Level ist, wie ein normaler Master-Spieler im High MMR Blizzard Elo.

28:00.840 --> 28:10.680
Und ein Mensch braucht natürlich viel weniger Daten. Warum? Na ja, weil unsere Hirnarchitektur krasser ist. Wir leben schon auf dem nächsten Level von Deep Learning.

28:10.680 --> 28:22.800
Was sozusagen die State of the Art ist im Moment, das erste Level war quasi, wir bringen ein Programm bei Schach zu spielen und das kriegen wir einfach hin.

28:22.800 --> 28:30.680
Das nächste Level war, wir schreiben eine Architektur, zum Beispiel bei Go, da geht das nicht mehr, das Spiel ist zu kompliziert, man kann nicht in einem Programm einfach schreiben, was das kann.

28:30.760 --> 28:36.120
Sondern wir schreiben ein Netzwerk, was selber lernt, sich Go beizubringen.

28:37.120 --> 28:43.040
Und Joshua Bach sagt jetzt, das ist aber immer noch nicht das, was wir können, wir Menschen sind noch ein Level krasser.

28:43.520 --> 28:51.920
Wir können Meta-Learning machen, wir können also ein Programm schreiben, was ein Programm findet, um ein Problem zu lernen.

28:52.600 --> 29:00.400
Das ist sozusagen das, von dem er sagt, was wir als nächsten Schritt brauchen. Und ich nehme an, das passiert erst nach dem nächsten KI-Winter.

29:00.400 --> 29:07.120
Also wenn sozusagen nur Slow reinkickt und wir noch mehr Rechnerkapazitäten haben, um das zu machen.

29:07.120 --> 29:12.680
Weil ihr dürft mich vergessen, wie unfassbar viele Neuronen wir in unserem Kopf drin haben.

29:12.680 --> 29:15.360
Also die Komplexität unseres Gehirns ist schon ziemlich krass.

29:16.320 --> 29:22.720
Und man kann sozusagen sagen, da ist eine ganze Menge krasser, universeller Funktions-Approximator mit drin.

29:22.720 --> 29:29.560
Und das Gehirn hat halt wirklich jetzt, das beobachtet halt, wo die meiste Performance herkommt beim Lernen.

29:29.560 --> 29:36.960
Und speichert quasi diese Aufmerksamkeit, das speichert es zusammen mit dem Kontext, in dem es gelernt hat, ab.

29:37.400 --> 29:41.720
Und das ist sozusagen der Inhalt der Aufmerksamkeit.

29:41.720 --> 29:48.600
Also das ist der Inhalt der Aufmerksamkeit, wo haben wir wann, was, wie am besten gelernt.

29:48.600 --> 29:57.000
Was sozusagen hat die meisten Performance Boost in unserer Performance gebracht, wenn wir an dem einen statistischen Gewicht oder an dem einen Neuronen wackeln.

29:57.840 --> 30:07.600
Und der Witz ist, das ist so eine Art Meta-Learning, weil es sozusagen eine Aufmerksamkeit über die Aufmerksamkeit macht.

30:07.600 --> 30:12.040
Es speichert sozusagen den Kontext und wo die Aufmerksamkeit war.

30:12.040 --> 30:15.720
Und das muss es beobachten, das Gehirn. Und das tut es.

30:15.720 --> 30:22.200
Das ist sozusagen Meta-Learning, weil Aufmerksamkeit über die Aufmerksamkeit quasi oder der Inhalt der Aufmerksamkeit zusammen mit dem Kontext.

30:22.200 --> 30:24.080
So ungefähr muss man sich das vorstellen.

30:24.080 --> 30:29.400
Und ich finde, an diesem Punkt ist sozusagen diese maximale Selbstbezüglichkeit auch klar.

30:29.400 --> 30:34.400
Und das ist auch das, was die Leute so schizophren finden an der Frage, habe ich einen freien Willen oder nicht.

30:34.400 --> 30:35.800
Oder was ist das Bewusstsein?

30:35.800 --> 30:40.040
Das ist halt sozusagen, das ist das, was Douglas Hofstadter wahrscheinlich meinte, mit einem Estrange Loop.

30:40.040 --> 30:44.600
Und das Buch habe ich bis jetzt noch nicht gelesen, aber das steht auch auf meinem Pile of Shame.

30:44.600 --> 30:57.800
Und das Hören muss sozusagen auch genau darauf achten, also es muss ich selbst beobachten, worauf ich jetzt genau Aufmerksamkeit lege.

30:57.800 --> 30:59.040
Also was gucke ich mir gerade an?

30:59.040 --> 31:03.360
Und der Punkt ist irgendwie diese maximale Selbstbezüglichkeit, die macht es halt.

31:03.360 --> 31:11.640
Und falls ihr das kennt, also bei mir war es so, wenn ich mal, ich hatte mal so einen Moment, ich war auf einer LAN-Party und war wirklich komplett im Tunnel.

31:11.640 --> 31:18.240
Also ich hatte das nicht oft in meinem Leben, aber manchmal war ich vollständig im Tunnel, zum Beispiel beim Zocken oder auch mal beim Schlagzeugspielen.

31:18.240 --> 31:25.960
Und wenn man einmal so vollständig in diesem Modus drin ist, dass man seine eigene Aufmerksamkeit overfittet,

31:25.960 --> 31:33.840
wenn man irgendwie so krass sich selber dabei beobachtet, wie heftig man unterwegs ist, dann ist man wie bei Matrix, wie bei Neo und sieht alles in Slow-Motion.

31:33.840 --> 31:35.760
Man ist auf einmal superschnell.

31:35.760 --> 31:40.720
Und ich hatte das, ich war normalerweise so ein Spieler, ich hatte so 250 APM vielleicht, wenn es hochkommt.

31:40.760 --> 31:44.240
Und ich hatte mal auf einer LAN-Party so 320 bis 350.

31:44.240 --> 31:47.400
Und ich kann mich auch im Nachhinein noch erinnern, das ging runter wie Butter.

31:47.400 --> 31:53.840
Meine Finger, das hat sich angefühlt wie das geschmeidigste, konstante Tippen der Welt.

31:53.840 --> 31:58.120
Ich konnte nie wieder diese Performance erlangen wie in diesem einen Game, was ich mal hatte in meinem Leben.

31:58.120 --> 32:02.800
Und ich glaube, das war so ein Zustand, der hat sich schon fast so ein bisschen transcendent angefühlt.

32:02.800 --> 32:06.560
Und ich glaube, das war, wo meine Aufmerksamkeit diesen Zustand erreicht hat,

32:06.560 --> 32:13.320
dass sie sich sozusagen selber vollständig beobachtet und jederzeit eingreifen kann, völlig problemlos.

32:13.320 --> 32:18.080
Ich glaube, so einen Zustand kann man auch durch Meditation erreichen, wenn man irgendwie, wenn man das lang genug macht.

32:18.080 --> 32:23.080
Jedenfalls, das ist irgendwie krass und das merkt ihr, wenn ihr irgendwann mal, wenn ihr irgendwas habt, wo ihr euch krass konzentrieren müsst.

32:23.080 --> 32:27.960
Und das genaue Gegenteil ist sowas wie mit dem Fahrrad irgendwo langfahren, zur Arbeit oder so.

32:27.960 --> 32:32.160
Da denkt man gar nicht mehr drüber nach, muss ich jetzt hier abbiegen, muss ich hier meinen rechten Fuß nach unten drücken,

32:32.160 --> 32:34.880
muss ich jetzt hier die Bremse drücken, muss ich hier irgendwie lenken.

32:34.880 --> 32:36.920
Das ist alles Autopilot, ne?

32:36.920 --> 32:39.840
Da ist genau das Gegenteil, keine Aufmerksamkeit mehr quasi.

32:39.840 --> 32:46.960
Und übrigens das wichtige, meilensteinartige Paper dazu zu den Transformers heißt Attention is all you need.

32:46.960 --> 32:48.040
Das ist schon so ein geiler Titel.

32:48.040 --> 32:52.080
Ich glaube, das war auch von so Boys, die bei Google in der AI-Abteilung sitzen.

32:52.080 --> 32:54.200
Das ist auch cool geschrieben, das kann man sich wirklich mal reinziehen.

32:54.200 --> 32:58.760
Also wenn ihr euch damit auskennt, wenn ihr euch damit auskennt, kennt ihr das Paper eh, was erzähle ich hier.

32:58.800 --> 33:06.680
Ich bin ja sozusagen der Laie, weil ich hab mir nur mal so einen wöchentlichen Crashkurs bei uns in der Informatikfakultät mal reingegönnt dazu.

33:06.680 --> 33:11.720
Ja und da wird dann sozusagen auch klar, dass diese Sache mit dem Attention so geil ist,

33:11.720 --> 33:18.720
weil wenn man jetzt zum Beispiel Textübersetzung macht und man geht Brutforce von damals vor und übersetzt Wort für Wort oder so,

33:18.720 --> 33:21.400
dann geht das immer krachen, was man braucht, das Kontext.

33:21.400 --> 33:25.800
Und Attention ist richtig gut dafür, weil Attention kann sozusagen den Finger auf ein Wort legen und sagen,

33:25.800 --> 33:33.040
also dieses Wort jetzt hier, zum Beispiel der Arzt oder der Künstler, zum Beispiel Cain West.

33:33.040 --> 33:38.560
Später in einem anderen Satz steht dann nur noch R und dieses R muss bezüglich auf Cain West sein.

33:38.560 --> 33:42.360
Dieser Kontext, das kann Attention richtig gut lernen.

33:42.360 --> 33:47.720
Und das konnten sozusagen die Learning-Strukturen vor den Transformern nicht so gut.

33:47.720 --> 33:53.960
Und das ist sozusagen der erste Schritt in Sachen jetzt mal Attention machen und das ist halt krass.

33:53.960 --> 33:57.880
Der nächste Schritt, also das ist jetzt sozusagen State of the Art, das ist das, was alle mittlerweile können

33:57.880 --> 34:00.280
und das ist auch das, was GPT-3 maximal krass macht.

34:00.280 --> 34:08.440
Und man, also Ben Gürtel hat den Tag auch so was gesagt wie, naja, GPT-3 hat halt auch so unendlich viele Knoten,

34:08.440 --> 34:10.800
dass wahrscheinlich auch Overfitting schon dabei ist.

34:10.800 --> 34:16.000
Das ist einfach nur ein völlig übertrieben großes neuronales Netzwerk, was das komplette Internet gelernt hat einmal

34:16.000 --> 34:19.120
und deswegen mit dir reden kann wie ein Mensch, kurz mal.

34:19.160 --> 34:25.000
Das habe ich in meinem Live-Talk dann über Künstliche Intelligenz auch schon mal gezeigt, so ein Beispiel.

34:25.000 --> 34:31.080
Und jetzt ist es halt so, die normalen Transformer-Networks, die haben halt einen begrenzten Arbeitsspeicher,

34:31.080 --> 34:35.120
das heißt, sie kriegen auch nur einen begrenzten Text in sich rein.

34:35.120 --> 34:40.800
Was wir aber machen ist, wir haben sozusagen eine besseren Komprimierungsalgorithmus

34:40.800 --> 34:46.600
und können deswegen viel mehr Daten in Attention, also in Kontext zueinandersetzen.

34:46.640 --> 34:52.080
Und das, was jetzt sozusagen Cain West und er und sozusagen der Kontext für so ein Deep Learning Netzwerk ist,

34:52.080 --> 34:54.280
ist für uns das gesamte Universum.

34:54.280 --> 34:58.520
Das heißt erst, wenn wir auf diesem Level sind, quasi ein Level höher in der Attention,

34:58.520 --> 35:03.000
dann können wir auch so was wie künstliches Bewusstsein konstruieren.

35:03.000 --> 35:06.280
Also das ist zumindest das, was Joshua Bach sagt und was soll ich sagen,

35:06.280 --> 35:11.240
alles, was Joshua Bach sagt, klingt extrem plausibel und hier muss ich auf jeden Fall eingestehen,

35:11.240 --> 35:17.240
dass ich nicht so krass bin wie Stanislav Lemb und ich finde im Prinzip fast alles, was Joshua Bach sagt,

35:17.240 --> 35:20.200
ist des Todes legit des Todes.

35:20.200 --> 35:22.760
Der Typ ist einfach nur zu geil.

35:22.760 --> 35:28.520
Und auf der Ebene der Neuronen übrigens kann man das Bewusstsein auch noch mal genauso erklären,

35:28.520 --> 35:33.880
nämlich mit Emergenz, da kann man einfach sagen, naja, so ein Neuron muss jetzt sozusagen eine Funktion lernen,

35:33.880 --> 35:35.120
wann es feuert.

35:35.120 --> 35:38.840
Ein Neuron hat sozusagen, kann eine nicht-linearer Funktion approximieren.

35:38.840 --> 35:43.000
Es hat ja ein multidimensionales Input, die ganzen Daten, die reinkommen.

35:43.000 --> 35:45.160
Wann feuert es? Das ist der Output.

35:45.160 --> 35:49.760
Und das Neuron muss jetzt sozusagen das Output an das Universum liefern.

35:49.760 --> 35:53.360
Also es hat ja nur diesen Ausgang, es weiß ja nichts von der äußeren Welt.

35:53.360 --> 35:57.280
Irgendwann kommt wieder Input rein und dieser Input füttert das Neuron ja.

35:57.280 --> 36:00.560
Wenn kein Input mehr kommt, dann stirbt das Neuron ja ab.

36:00.560 --> 36:05.320
Das heißt, Neuronen haben ein Interesse daran, diese Funktion sehr gut zu approximieren,

36:05.320 --> 36:08.000
um lange zu leben und fetter zu werden.

36:08.000 --> 36:09.760
Und das ist genau das, was wir haben.

36:09.760 --> 36:12.400
Und in unserem Hirn gibt es sozusagen diese goldene Regel,

36:12.400 --> 36:14.840
Wires Together, Fires Together oder so.

36:14.840 --> 36:19.560
Das ist so eine Grundregel, die wird um Deep Learning sozusagen, diese Intuition wird da auch verwendet,

36:19.560 --> 36:26.360
weil sozusagen die ganze Struktur der neuronalen Netze auf dieser Analogie funktionieren,

36:26.360 --> 36:30.160
von den Axionen und den Neuronen und so.

36:30.160 --> 36:36.720
Dem Scheiß, den wir sozusagen auf der biologischen Ebene schon sehen können,

36:36.720 --> 36:38.920
wie unser Gehirn im Prinzip funktionieren muss.

36:38.920 --> 36:43.600
Wir sehen sozusagen nur diese unendlich komplizierten Netzwerke und checken nicht, wie die gehen, so ungefähr.

36:48.680 --> 36:54.000
So und nur die Neuronen, die das richtig machen, die überleben und die anderen sterben halt aus,

36:54.000 --> 36:58.200
die das nicht machen, also da ist sozusagen wieder evolutionärer Selektionsdruck.

36:58.200 --> 37:01.720
Und Joshua Bach sagt halt jetzt, und das finde ich auch schon wieder so geil,

37:01.720 --> 37:07.600
ein Neuron ist halt einfach nur ein normaler kleiner Reinforcement Learning Agent.

37:07.600 --> 37:16.320
Das ist ein kleines Reinforcement Agent Konzept, der sozusagen sich selbst immer verbessert.

37:16.320 --> 37:20.160
Und ja, es sendet halt einfach diese Signale in das Universum, also nach draußen.

37:20.160 --> 37:22.200
Das ist zum Beispiel das, was wir hier machen.

37:22.200 --> 37:26.280
Das beeinflusst unsere Handlung und den Willen und den freien Willen und diesen ganzen Scheiß,

37:26.280 --> 37:28.360
nur um eine positive Antwort zu bekommen.

37:28.360 --> 37:33.120
Und das Konglomerat von den ganzen Neuronen, die wir halt im Kopf haben, ist halt so angelegt,

37:33.120 --> 37:37.600
von der Architektur her auch, aber auch von räumlich getrennten Kostenfunktionen,

37:37.600 --> 37:44.640
also bestimmte Hirnareale machen bestimmte Sachen, dass es robust wächst in der meisten,

37:44.640 --> 37:46.640
bei fast allen Menschen, die geboren werden.

37:46.640 --> 37:49.360
Und die Gesamtheit davon nennen wir halt Gehirn.

37:49.360 --> 37:50.760
Das ist das.

37:50.760 --> 37:52.600
Und das ist krass.

37:52.600 --> 37:56.200
Das ist wirklich erstaunlich, dass die Evolution das herausgebracht hat.

37:56.240 --> 38:00.040
Aber der Gehirn, habe ich ja auch glaube ich schon gesagt in dem anderen Video,

38:00.040 --> 38:02.960
was für krasse Sprünge da dazu gehören.

38:02.960 --> 38:08.320
Weil es ein super schlechter Trade-off war, für so eine Spezies wie den Menschenaffen

38:08.320 --> 38:13.560
mehr in seinen Gehirn zu investieren und dafür mehr Ressourcen irgendwo anders einzubüßen.

38:13.560 --> 38:16.640
Zum Beispiel war er nicht mehr so stark.

38:16.640 --> 38:21.560
Das musste sozusagen in einer Zeit der Erbgeschichte auch entstehen, wo das gerade so ging,

38:21.560 --> 38:25.360
damit wir über diesen Potenzialwald rüberkommen

38:25.360 --> 38:29.080
und dann uns als Menschen überhaupt als Homo sapiens etablieren konnten.

38:29.080 --> 38:32.640
Das war ein super Heft, da sind mehrere Sachen zusammengefallen,

38:32.640 --> 38:37.240
dass das durch Selektionsdruck dann passieren konnte und der Mensch daraus entstehen konnte.

38:37.240 --> 38:42.240
Weil sowas wie Augen zum Beispiel, das wurde glaube ich drei, viermal separat voneinander

38:42.240 --> 38:45.840
in der Evolution festgestellt, dass sich Augen gebildet haben.

38:45.840 --> 38:47.000
Zufällig.

38:47.000 --> 38:48.800
Durch Evolutionsdruck.

38:48.800 --> 38:53.200
Das ist zum Beispiel was, was man öfter beobachtet, aber so ein Shit wie krasses Gehirn

38:53.200 --> 38:59.440
und dafür natürlich weniger Robustheit, körperliche, physische Robustheit, das ist selten.

38:59.440 --> 39:02.680
Und ja, was soll ich dazu sagen?

39:02.680 --> 39:07.400
Die emergente Struktur von dem, was ich sozusagen gerade als Gehirn beschrieben habe,

39:07.400 --> 39:08.960
das ist das Bewusstsein.

39:08.960 --> 39:10.400
So kann man es auch artikulieren.

39:10.400 --> 39:16.320
Und ich wollte jetzt wirklich nur mal dieses Video machen, weil ich finde das so krass.

39:16.320 --> 39:20.200
Immer wenn ich mir wieder was von Erscha Bach einziehe, denke ich mir so, ja,

39:20.240 --> 39:23.480
Dieser Typ, den jeder muss wissen, wer das ist.

39:23.480 --> 39:26.240
Ich finde, das ist der krasseste Dude, den es gibt.

39:26.240 --> 39:29.400
Der basht halt auch die anderen Leute, also er basht die natürlich nicht weg,

39:29.400 --> 39:32.200
macht kein Reaction-Video oder ratet irgendwie auf irgendwen.

39:32.200 --> 39:36.120
Aber er macht sie alle platt, er macht, also meiner Meinung nach ist er völlig überlegen

39:36.120 --> 39:41.640
gegenüber zum Beispiel Roger Penrose oder so anderen Leuten, die sich natürlich auch den ganzen Tag,

39:41.640 --> 39:46.040
auch Douglas Hofstadter, die sich den ganzen Tag mit Bewusstsein und diesen Fragen beschäftigen.

39:46.040 --> 39:53.960
Ich finde, Erscha Bach hat die perfekte, sozusagen die bestmögliche verfügbare Komprimierung

39:53.960 --> 39:56.120
schon da in seiner Sprache.

39:56.120 --> 40:01.560
Seine Sprache ist so kompakt, da steckt so viel drin, weil er sozusagen diese ganze Terminologie

40:01.560 --> 40:06.440
von den Deep Learning Netzwerken so krass gefressen hat und diese ganzen Konzepte auch

40:06.440 --> 40:10.120
problemlos auf alles Mögliche anwenden kann, weil er die Intelligenz da hat,

40:10.120 --> 40:12.920
um sozusagen die Analogien zu bilden, um das zu tun.

40:13.000 --> 40:17.640
Es ist einfach nur ein Genuss, dem Typen zuzuhören, auch wenn er extrem schnell redet,

40:17.640 --> 40:19.160
so wie Sheldon Cooper übrigens auch.

40:19.160 --> 40:23.320
Aber ist kein Problem, man kann es einfach mehrmals hören und super.

40:23.320 --> 40:27.160
Und Lex Friedman macht auch immer einen guten Job, wenn er nochmal nachfragt und so.

40:27.160 --> 40:31.320
Also, ich wollte einfach ein Video darüber machen.

40:31.320 --> 40:33.320
Reingehauen, YouTube.

43:42.920 --> 43:44.920
Das war's für heute.

43:44.920 --> 43:46.920
Vielen Dank für's Zuschauen.

43:46.920 --> 43:48.920
Bis zum nächsten Mal.

44:12.920 --> 44:14.920
Der Kanal ist wie eine schöne Vorlesung aufgebaut.

44:14.920 --> 44:20.920
Wenn ich unten Videos verlinke, dann wäre es angebracht, sich die auch reinzuziehen,

44:20.920 --> 44:22.440
weil das aufeinander aufbaut.

44:22.440 --> 44:24.920
Bestimmte Begriffe werden definiert, viele Beispiele werden genannt.

44:24.920 --> 44:30.200
Und ja, ich denke mir schon was dabei, weil es sozusagen meinen eigenen Erkenntnisprozess

44:30.200 --> 44:32.920
abbildet, die Reihenfolge, in denen ich die Videos hier hochlade.

