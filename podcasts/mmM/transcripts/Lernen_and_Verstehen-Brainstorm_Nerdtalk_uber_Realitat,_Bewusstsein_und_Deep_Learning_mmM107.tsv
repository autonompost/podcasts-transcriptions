start	end	text
0	6680	Das Gehirn erzählt sich ja selber eine Geschichte darüber, wie es wäre, wenn es eine Person gäbe,
6680	12880	von die so ist wie wir und die in einer Situation ist, die wir Gegenwart nennen.
12880	18120	Und wir konstruieren, während wir den sensorischen Input über die Gegenwart bekommen,
18120	22720	diese Person und stellen uns vor, wie es wäre, so eine Person zu sein.
22720	25120	Wir simulieren das.
25120	26760	Das ist das, was das Gehirn macht.
26760	30920	Deswegen sagt er, nur eine Simulation kann überhaupt Bewusstsein haben.
30920	35600	Riesen Sorry schonmal an alle, die sich dieses Video jetzt hier rein gönnen.
35600	40640	Ich glaube, es ist absolut unmöglich zu verstehen, was ich jetzt hier in diesem Video quatsche,
40640	44800	wenn ihr mein Video zum Bewusstsein nicht zuerst gesehen habt.
44800	50640	Das baut er halt darauf auf und ich benutze viele komische Fremdworte.
50640	56040	Ich glaube, die ergeben alle überhaupt keinen Sinn, wenn ihr das Video mit dem Bewusstsein nicht vorher geguckt habt.
56040	58560	Das ist nur so schon mal als Warnung.
58560	60680	Das ist ein absolutes Nerd-Video.
60680	64440	Ich habe das gestern aufgenommen und da hatte ich auch schon einen im Tee.
64440	67720	Und jetzt habe ich mir halt angeguckt und dachte mir so, ja, okay, schon klar.
67720	71960	Aber das kann glaube ich keiner verstehen, wenn man nicht irgendwie das mindset dafür hat.
71960	75120	Und dafür ist das andere Video auch gut geeignet.
75120	77320	Also guckt euch vorher an, bevor ihr jetzt hier weiter guckt.
86040	107200	So Leute, jetzt mal wieder eins von diesen Deep Philosophical U-Bow-Videos des Todes und der Vorläufer zu diesem Video, würde ich sagen, ist das Video zum Bewusstsein.
107200	113240	Und ich möchte hier erst mal mit euch über Emergenz reden, weil das braucht man irgendwie ständig.
114200	118760	Und dann so ein bisschen mehr über, naja, was ist die Realität?
118760	120840	Was ist das Bewusstsein?
120840	123240	Und was soll das alles?
123240	137000	Einfach mal ein bisschen euch mal ein bisschen mal was rein knallen an krasser Erkenntnis, die ich so in den letzten Jahren, ich würde sagen im letzten Jahr so ungefähr hatte.
137000	139160	Und ja, also was ist jetzt Emergenz?
139160	142040	Ich habe schon ein paar Mal verwendet das Wort.
142040	152600	Emergenz ist immer dann etwas, wenn ihr etwas beobachtet, was erstmal total kompliziert wirkt, wenn ihr da reingucken wollt.
152600	161880	Von außen sieht es irgendwie krass aus und ihr denkt, okay, das hat irgendwie einen Mechanismus, das ist heftig, aber wenn man reinguckt, steht man fest, es besteht aus ganz vielen simplen Teilen.
161880	174520	Und irgendwie ist die Summe dieser Teile mehr als einfach nur, also die Summe der Teile ergibt mehr als einfach nur das, was man sich vorstellen würde, wenn man die Summe der Teile tatsächlich addieren würde.
174520	175320	Was meine ich damit?
175320	176600	Na ja, zum Beispiel ein Ameisenhaufen.
176600	179800	Die kleinen Ameisen, die sind alle sehr einfach, wie die funktionieren.
179800	190040	Trotzdem ist die Gesamtheit der Ameisen, das Konglomerat, so eine Art komplizierter Lebens, ein komplizierter Metabolismus, der sich verhält wie ein Lebewesen.
190120	201080	Und wenn das Objekt, was ihr seht, nur aus Verbindungen besteht, die irgendwie auch rein virtuell dadurch sind, die sind ja nicht anfassbar.
201080	206280	Man kann ja nicht sagen, ach, diese Wechselwirkung zwischen den Ameisen, die macht das erst so interessant.
206280	207160	Aber genau darum geht es.
207160	208040	Das ist die Emergenz.
208040	218440	Das ist etwas, was man nicht so greifen kann, sondern es entsteht als ein Prozess höherer Ordnung zwischen Wechselwirkungen von einfacheren Mechanismen, die man sehr wohl verstehen kann.
218440	221000	Und darum ist Emergenz nicht greifbar.
221000	222360	Und das ist immer das Problem.
222360	223240	Das seht ihr ganz oft.
223240	225880	Das ist immer, wenn es um gesellschaftliche Themen geht.
225880	228200	Gesellschaft ist zum Beispiel eine emergente Struktur.
228200	233000	Sie entsteht aus den ganz vielen Interaktionen zwischen Menschen.
233000	235480	Wenn wir die alle addieren, kriegen wir die Gesellschaft raus.
235480	237960	Und Evolution ist auch so was.
237960	247640	Evolution entsteht ja nur dadurch, dass wir einen Selektionsdruck haben, der nur dadurch entsteht, dass es sozusagen eine äußere Umgebung gibt, die sozusagen dazu führt,
247720	261880	dass bestimmte Lebensformen, die besser, ich würde mal sagen, negative Entropie farmen können oder besser den Gradienten in die Entropie runtergehen können als andere und dadurch sozusagen einen Wettbewerbsvorteil gegeneinander haben und sich dann durchsetzen.
261880	266600	Und Schwarmintelligenz ist auch so was wie Emergenz.
266600	271480	Und der Markt, das ist das, was die FDP-Menschen nicht verstehen.
271480	272760	Die raffen es ja nicht.
272760	274440	Aber der Markt ist eine emergente Struktur.
274440	283160	Und weil das so unbegreifbar ist, dachte damals Hayek auch, und das ist sozusagen so eine Art Gott für ihn und versteht mich da nicht falsch.
283160	288360	Es ist natürlich eine emergente Struktur und es ist natürlich interessant, darüber nachzudenken.
288360	296920	Aber nur weil es kompliziert ist oder irgendwie geil aussieht oder man ein bisschen Mathematik damit machen kann, heißt es ja nicht, dass das sozusagen die Lösung aller Probleme ist.
297000	298520	Aber genau so geht Hayek daran.
298520	304120	Das habe ich auch schon mal in einem anderen Video erklärt, von wegen welches Problem lösen die Märkte eigentlich.
307000	317240	So und was soll ich sagen, wenn es etwas in den letzten Jahren gab, was ich mir sehr gerne reingezogen habe, dann sind das Videos von Joscha Bach.
317240	321800	Und ich kann euch wirklich nur empfehlen, schmeißt alles in die Ecke.
322120	328920	Jo Roggen Podcasts oder alle möglichen Lex Friedman Interviews oder sonst welche Sachen, die ihr im englischen YouTube drin gesehen habt.
328920	334680	Das nächste, was ihr bei euch auf die Watchlist drauf tut, ist der erste Talk von Joscha Bach.
334680	336840	Und der zweite, den könnt ihr gleich noch hinten dran hängen.
336840	341880	Dann habt ihr sechs Stunden lang komprimierteste Todesweisheit des Todes.
341880	344360	Der Typ ist der lebende Sheldon Cooper.
344360	348600	Das ist der krasseste Wichser, den ich je irgendwo gehört habe.
348600	351960	Ich glaube, das ist so ein verdammtes Genie.
351960	358760	Und der lebt heutzutage und ich habe ihn schon auf Twitter vollgequatscht, er soll mal mit mir reden, aber natürlich, warum sollte der das tun?
358760	362200	Der hat einfach eine volle Inbox, der hat keine Zeit mit einem scheiß Ossi zu reden.
362200	364440	By the way, Joscha Bach ist selber ein Ossi.
364440	366680	Aber ihr müsst euch den Typen reinziehen.
366680	371400	Der alles, was er jemals in seinem Leben gelesen hat, hat er hier oben drin und kann sofort abrufen.
371400	372920	Der ist krass, der Typ.
373880	381880	Und ich bin übrigens nur auf den gestoßen, weil jemand mir den empfohlen hat unter einem englischen Matrix-Video.
381880	383400	Hat mir jemand Joscha Bach empfohlen.
383400	385560	Dafür hat sich der englische Kanal schon gelohnt.
385560	387240	Das ist super.
387240	392600	Und jetzt wollte ich ein bisschen, jetzt haben wir das geklärt mit der Emergenz, ich habe jetzt dieses Wort etabliert.
392600	401080	Jetzt will ich ein anderes wichtiges Wort für euch etablieren, weil das ist natürlich auch so ein Ding, wo die Leute immer rumschlavieren.
401080	404280	Und irgendwie so so eine Krämer-Laber-Attitüde haben.
404280	406520	Was ist jetzt eigentlich Intelligenz?
406520	412920	Also guter Freund von mir hat damals zu mir gesagt, Intelligenz ist die Fähigkeit, Analogien zu bilden.
412920	419000	Und das ist eine ziemlich gute Definition, wenn man da mal drüber nachdenkt, weil damit kann man eine ganze Menge erschlagen.
419000	422360	Quasi ich habe hier, sagen wir mal, verstanden, wie das eine Ding funktioniert.
422360	425160	Und jetzt habe ich hier ein anderes Ding, das heißt anders.
425160	430680	Aber der Mechanismus, der hier abläuft, ist genau derselbe Mechanismus wie in dem Ding, was ich schon verstanden habe.
430680	437480	Wenn ich also die Analogie bilden kann und feststellen kann, dass abgesehen von den Bezeichnungen, dass da was da passiert, dasselbe oder das gleiche ist,
437480	440280	dann habe ich eine Analogie gebildet und dann bin ich krass.
440280	443080	Und der King der Analogien, meiner Meinung nach, ist Slavoj G. Jack.
443080	445240	Der hat die witzigsten Analogien.
445240	450200	So und Joscha Bach jetzt, der sagt, Intelligenz ist die Fähigkeit, Modelle zu bauen.
450200	452920	Also Modelle über das, was man sieht.
452920	454600	Und was meint man jetzt damit?
454680	461640	Ein mathematisches Modell typischerweise hat was damit zu tun, dass man eine Komprimierung macht.
461640	469880	Man kompressiert, man komprimiert irgendwie etwas, was man sieht, auf das Wesentliche herunter.
469880	472040	Das ist das, was beim Komprimieren passiert.
472040	479800	Und da muss man natürlich sich genau fragen, in welcher Sprache habe ich es auf das Wesentliche, auf das Minimum runtergekocht?
479800	483400	Und das ist genau die Fragestellung, die man beim Archivieren von Dateien auch hat.
483400	488680	Kann man sozusagen ein Muster finden, auf die man es runterbrechen kann?
488680	494680	Kann ich das Muster sozusagen einmal abspeichern und dann nur noch sagen, jetzt kommt das Muster und dann spare ich mir 500 Bits oder so?
494680	496680	So eine Idee ist das.
496680	500360	Und darauf basieren dann sozusagen die ganzen modernen Komprimierungsverfahren auch.
500360	507640	Im Wesentlichen, in der Mathematik würde man sagen, man findet eine Vektorbasis oder im Kompress-Censing würde man sagen, man findet eine Basis,
507720	519960	die irgendwie im Sinne der L2-Norm oder beziehungsweise in der L1-Norm, eigentlich in der L0-Norm, ich glaube es ist tatsächlich die L0-Norm oder die L1-Norm, da wo das sozusagen ein Minimum annimmt.
519960	524040	Das ist quasi Kompress-Censing, aber nur für die Geeks und Nerds, die sich damit auskennen.
524040	530600	Ansonsten, ihr könnt euch einfach vorstellen, wann kann ich sozusagen etwas aufs Wesentliche so weit runterbrechen, bis es nicht mehr weiter runtergeht?
530600	533880	Bis ich es sozusagen auf die Einsen und Nullen runtergebrochen habe.
533960	544760	Und Sprache ist sozusagen in diesem Kontext sozusagen eine High-Level-Abstraktion, weil sie ist sehr schwammig und Mathematik ist quasi Low-Level.
544760	550040	Man kann sozusagen das eine in das andere überführen, aber es ist sehr langwierig.
550040	558360	Bestimmte Sachverhalte lassen sich mit Sprache in ein, zwei Sätzen erklären und man müsste einen riesen Apparat Mathematik drauf werfen, um dasselbe in Mathematik auszudrücken.
558680	564440	Joscha Bach sagte, Mathematik ist die Domäne aller Sprachen und mittlerweile glaube ich, da hat er natürlich recht.
564440	574840	Das ist ziemlich krass, denn es ist so, Sprache in diesem Sinne, das Kompress-Censing zum Beispiel, ist eine Projektion von Inhalt.
576680	583720	Wir haben hier dieses Ding, wir haben diese echten Inhalte, die sind kompliziert und mit Sprache vereinfachen wir die.
583720	591640	Wir machen schon so eine Art Komprimierung, wir komprimieren schon den Inhalt, sodass wir ihn rüberreichen können und natürlich ist dann sozusagen Informationsverlust.
591640	597960	Und das ist bei jeder Projektion, jeder der lineare Algebra schon mal gehört hat, weiß, Projektionen verlieren Informationen und das ist da auch der Fall.
597960	606840	Und das ist ja klar, Sprache kann beim Empfänger anders ankommen, als wir es eigentlich als der Empfänger, als der Aussender der Sprache es eigentlich sagen wollte.
606840	613800	Und ja, Wittgenstein zum Beispiel dachte, dass man alles mit Sprache aufbauen kann und das war sozusagen sein Fail.
613800	620280	Er hat sozusagen nicht runterbrechen können auf Mathematik, sondern er dachte Sprache ist sozusagen der Shit.
620280	627160	Und deswegen sage ich ja auch, Wittgenstein hätte die Sache mit dem Word Embeddings in Deep Learning auch richtig gut gefallen.
627160	632280	Ja, aber so Sachen wie Bilder oder Geometrie mit Sprache zu beschreiben, ist halt völlig Fail.
632520	637640	Da ist völlig klar, dass die etabliert, also die bessere Variante irgendwie Mathematik sein muss.
637640	645560	Und jetzt wollte ich mal erklären, was nennen wir eigentlich Realität bzw. was nennen wir unser Universum?
645560	657080	Na ja, wir bezeichnen mit Realität typischerweise das, was unser Modell als Ursache angibt für den sensorischen Input, den wir erfahren.
657080	663240	Das einzige, was unser Gehirn bekommt, ist der sensorische Input über unsere Augen, unsere Sinnesvornehmungen und so.
663240	670840	Wir wissen nichts über die Welt da draußen, außer wir sind nur beschränkt darauf auf den sensorischen Input, den wir haben und daraus schlussfolgern wir alles.
670840	679320	Und das Gehirn, das habe ich ja in meinem Bewusstheitsvideo schon erklärt, versucht sozusagen das mathematische schlechtgestellte inverse Problem zu lösen.
679320	684520	Was hat die Inputdaten verursacht? Wir wissen ja nicht, was die verursacht haben.
684600	691720	Unser Gehirn, quasi unser Verstand, unser was auch immer, unser Gehirn versucht zu beschreiben und zu erklären, was diese Inputdaten verursacht hat.
691720	695400	Und dabei konstruieren wir das, was wir Realität nennen.
695400	707960	Und das beste, was Urscha Bachter immer sagt, ist, es gibt in dieser, also die beste Sprache, die wir im Moment dafür haben, ist sozusagen die Physik, die physikalischen Gesetze.
707960	711960	Und in dieser Sprache gibt es keine Geräusche und es gibt auch keine Farben.
712600	721320	Das sind einfach nur höhere Ordnung von Strukturen, denen wir diese Bedeutung zuweisen im Sinne von einer Komprimierung.
726680	729000	Und jetzt ist es so...
731000	737720	Übrigens, das ist der Grund, wenn man jetzt irgendwie, sagen wir mal, ich nehme mir jetzt das Lineal, tue das hier auf den Tisch und knall hiergegen, dann hör ich so ein Brrrrrrr.
738280	745240	Und diese höheren Schwingungsmoden und so, diese ganzen Sachen mit den Schwingungen, Sounds sind auch fraktale.
745240	748760	Da gibt es ein ziemlich geiles Video von Adam Neely, falls ihr den kennt.
748760	750760	Das ist ein sehr witziges Video, das werde ich verlinken.
750760	758840	Dass sozusagen sich auch da durch die höheren Schwingungsmoden, Sounds wie, also Geräusche und Töne wie fraktale verhalten.
758840	763400	Also man kann da immer weiter reinzoomen und die werden dann immer wieder selbst ähnlich.
763400	770040	Und das ist super geil, denn das bedeutet im Prinzip, dass man alles auf eine Ringstruktur abbilden kann.
770040	775800	Deswegen kann man Farben auch in einem Ring anordnen und bei Tönen kann man die sozusagen auf diese Oktaven abbilden.
775800	779160	Und das hat damit zu tun, dass sie sozusagen fraktale darstellen.
779160	781000	Und in echt existiert das nicht.
781000	788360	Das ist was, was unser Gehirn konstruiert, genauso wie, was weiß ich, wenn wir irgendwie rumgucken mit unseren Augen,
788360	794120	dann wird der Hauptinput, der wird interpoliert und auch extrapoliert hier am Rand und so.
794120	802120	Unser Gehirn kann sozusagen die Daten, die eigentlich aufgenommen werden müssten, um das, was wir hier sehen, zu konstruieren, kann es gar nicht verarbeiten.
802120	803640	Das braucht das Gehirn nicht.
803640	807880	Unser Gehirn ist so krass, dass es übelst Rechenleistung investiert, um das alles zu interpolieren.
807880	810600	Und in dem Sinne ist es halt so,
810600	823560	Unser Gehirn leistet diese Komprimierungsarbeit schon für uns und diese periodischen Eigenschaften von zum Beispiel Geräuschen und Farben machen, dass man die auf einem Ring anordnen kann.
823560	836920	Und wir existieren jetzt, also das, was wir als wir bezeichnen, wir existieren in dieser virtuellen Realität, die unser Gehirn konstruiert, um zu erklären, was die Messdaten verursacht hat.
836920	840040	Und das habe ich ja in dem Video über das Bewusstsein schon erklärt.
840120	849640	Also unser Gehirn konstruiert diese virtuelle Realität und auf diesem, weil das Ding ist, auf diesem Level von diesem äußerst merkwürdigen Quantengraf,
849640	856120	den wir jetzt, von dem wir annehmen, dass es, dass der existiert durch unsere mathematischen Modelle und unsere Physik und so,
856120	859000	da existiert wirklich nur kalte Algebra.
859000	869960	Von einem Zustand des Universums zum nächsten transformieren die physikalischen Gesetze diesen Quantengraf und wir können nur einen ganz kleinen Auschnitt davon messen.
870920	872920	Durch unseren sensorischen Input.
872920	880040	Und das, was die Philosophen dann sozusagen als Qualia bezeichnen, das ist genauso eine Illusion wie der Freie Wille.
880040	885640	Das ist einfach nur eine emergente Struktur, die auf unserem Gehirn entsteht, Qualia.
885640	893240	Und Joscha Bach nimmt jetzt als Beispiel für Realität, ziemlich geiles Beispiel, wie ich finde, das Mandelbrot-Fraktal.
893240	898520	Vielleicht binde ich das jetzt hier auch in das Video ein, da gibt es bestimmt ein cooles Gift oder so.
898520	905560	Das ist so ein Fraktal, das entsteht im Wesentlichen, wenn man eine iterative Abbildung lösen will.
905560	915000	Ja genau, man hat eine quadratische iterative Abbildung in einer komplexen Ebene und guckt für welche Werte von einer konstanten komplexen Zahl die konvergiert oder nicht.
915000	924280	Und wenn man das sozusagen macht für die komplexe Zahlenebene und alles was divergiert mit schwarz abbildet, dann kriegt man dieses Fraktal und so baut man das.
924360	928840	Das ist relativ einfach das zu bauen tatsächlich, aber das Muster was rauskommt, das sieht halt super krass aus.
928840	943480	Und wenn man sich jetzt vorstellt, wir leben auf so einer fraktalen Oberfläche von dem Mandelbrot-Fraktal, dann würden wir sehen, okay, da gibt es so eine rechtsdrehende Spirale.
943480	948120	Wenn man die jetzt reingeht, würde man irgendwann an einer Singularität ankommen.
948200	958120	Und wenn man die sozusagen, wenn man darüber hinweg guckt, gibt es quasi Periodenverdopplung oder ich weiß gar nicht mehr wie dieser Effekt heißt, auf jeden Fall, dann beginnt diese Spirale von vorne.
958120	964760	Dann beginnt sozusagen die Oberfläche von vorne zu wachsen, dann kommt diese Selbstähnlichkeit, die kickt rein bei dem Fraktal und dann sieht es wieder von vorne so aus.
964760	970760	Und man müsste wieder die Spirale weiter reingehen, bis man wieder zur Singularität kommt und dann wieder reingehen und so weiter.
970760	979080	Und wenn man so mehrere Layers bauen würde von seiner eigenen Realität, weil wir leben ja auf diesem Fraktal, dann wäre das eine gute Approximation für die Realität.
979080	984360	Was wir niemals sehen würden, ist sozusagen das komplette Picture, weil das Fraktal ist.
984360	988760	Es ist ein unendlich großes und selbstähnliches periodisches Muster.
988760	991080	So und so ist es mit unserem Universum auch.
991080	996920	Wir haben halt diese physikalischen Gesetze, sie sind nicht perfekt, sie sind aber eine gute Beschreibung für das, was wir haben, was wir sehen und so.
996920	1001080	Und je näher wir uns ran tasten an die Realität, desto besser werden wir.
1001080	1011000	Irgendwann würden wir, wenn wir auf diesem Fraktal leben, in der Mandelbrotmenge, irgendwann würden wir diese paar Zeilen Code, die das braucht, um das zu generieren, vielleicht bauen können.
1011000	1014280	Und dann hätten wir es gekickt, dann hätten wir die Realität vollständig beschrieben.
1014280	1020040	Das heißt, was man machen muss, um die Realität zu beschreiben, ist man muss sich aus First Principles Schluss folgern.
1020040	1024280	Und das geht natürlich nicht so als Schlussfolgerung, sondern das ist im Prinzip zwar ein Error.
1024280	1038520	Also man muss Mathematik machen, betreiben und man muss es solange mit 3 in Error machen, bis man irgendwie auf das kommt, was sozusagen die minimale Information beinhaltet, die alles beschreibt, was wir haben.
1038520	1041240	Das ist das Prinzip von Okams Racer auch.
1041240	1045720	Also wir wollen so wenig wie möglich voraussetzen oder so wenig wie möglich annehmen.
1045720	1048920	Und das soll maximal viel von dem, was wir beobachten, beschreiben.
1048920	1053120	Und wenn wir etwas haben, was alles mit einem Formalismus beschreibt, dann sind wir fertig.
1053120	1058000	Das ist die Idee. Das ist sozusagen das Ideal, an das ich sozusagen die Wissenschaft da ran tasten möchte.
1063840	1081440	So und wenn wir also, Joshua Bach gibt auch noch so einen anderen coolen Spruch, nämlich er sagt, die physikalische Realität hat kein Bewusstsein und da gibt es auch kein Bewusstsein.
1081440	1085200	Nur eine Simulation kann Bewusstsein haben.
1085200	1097160	Das ist das, was er sagt und das ist ein ziemlich cooler Spruch, weil was er damit meint ist, wenn wir jetzt ein Buch lesen und da ist ein Protagonist drin und der fühlt irgendwas oder dem geht es irgendwie scheiße.
1097160	1099080	Dann empfinden wir das, während wir das lesen.
1099080	1110040	Das liegt daran, dass wir in unserem Kopf uns ein Bild davon, ein Abbild dieser Person in dem Buch, die da beschrieben wird durch Sprache übrigens, bauen und dadurch wird es real.
1110040	1117320	Und der Witz ist, zwischen dieser Person in dem Buch und dem, was wir uns selbst nennen, gibt es eigentlich keinen Unterschied.
1117320	1130480	Denn das Gehirn erzählt sich ja selber eine Geschichte darüber, wie es wäre, wenn es eine Person gäbe, die so ist wie wir und die in einer Situation ist, die wir Gegenwart nennen.
1130480	1139000	Und wir konstruieren, während wir den sensorischen Input über die Gegenwart bekommen, diese Person und stellen uns vor, wie es wäre, so eine Person zu sein.
1140280	1141480	Wir simulieren das.
1142680	1143960	Das ist das, was das Gehirn macht.
1144320	1147520	Deswegen sagt er, nur eine Simulation kann überhaupt Bewusstsein haben.
1147920	1157640	Nur eine Simulation ist fähig, diese emergente Struktur zu haben, die dann wieder, also die emergente Struktur, die sozusagen das Bewusstsein als Nebenprodukt hat.
1158400	1159160	Und das ist krass.
1159360	1160360	Das ist ziemlich heftig.
1160360	1165600	Also wenn ihr, wenn ihr das nicht kennt, diese Joscha Bach Talks, ihr müsst euch die reinziehen.
1165600	1167200	Ich verlinke die beiden von Lex Friedman.
1167320	1172240	Es gibt aber noch viele mehr, die sozusagen ins Detail gehen, wenn Joscha Bach seine Meinung zu GPT-3 erzählt.
1172240	1174280	Das ist super krass oder generell.
1174280	1179960	Es gibt, glaube ich, auch zwei, drei deutsche Talks, von denen einer mindestens schon mal ziemlich gut ist für Einsteiger.
1179960	1182360	Die anderen sind zu abgefahren, absolute Nord-Talks.
1182880	1187360	Aber wie gesagt, der Typ ist ein Ostdeutscher, der kann also auch fließend Deutsch, ist gar kein Problem.
1187360	1189040	Man findet bloß nicht so viel von dem auf Deutsch.
1190440	1191240	Aber hammermäßig.
1192320	1198960	Also wirklich alles andere, alle anderen Talks, alle anderen Podcasts, die es auf dieser Welt gibt, sind, meiner Meinung nach, Zeitverschwendung,
1198960	1204520	bevor man nicht vollständig durchdrungen hat, was Joscha Bach einen in drei Stunden reinquetscht an Wissen.
1204600	1205440	Das ist so viel.
1205480	1216040	Ich habe den Talk jetzt bestimmt vier, fünf Mal schon durchgeknallt und ich komme immer wieder auf neue Erkenntnisse, weil der Typ in einem Satz so viel Informationen und so viel Verständnis
1216040	1220800	reinsteckt, dass man das wirklich erst nach einem Jahr nochmal dann checkt oder so.
1221960	1225640	So und in Deep Learning ist es jetzt nur so.
1226200	1230240	Man muss dazu wissen, das habe ich auch noch nie so erwähnt, aber das ist quasi bekannt.
1230240	1233560	Das ist wahrscheinlich erste Vorlesung, Deep Learning im Informatikstudium.
1234240	1237880	Der sogenannte universelle Funktions-Approximator, das ist das Relevante.
1238360	1252720	Der sagt Folgendes aus, wenn ihr ein neuronales Netz macht mit N-Input, N-dimensionalen Input und ihr wollt nur ein Output haben, also sozusagen eine Funktion mit beliebigem Input und die soll was ausgeben.
1253160	1258000	Und ihr habt ein Layer dazwischen, der hat beliebig viele, also auch beliebig viele Knoten.
1259200	1262560	Dann könnt ihr jede mathematische Funktion damit approximieren.
1263120	1267680	Das ist erstmal irgendwie klar, aber es wurde sozusagen bewiesen, dass das so ist.
1268560	1269920	Und der Witz ist jetzt Folgendes.
1270360	1280240	In der Informatik geht es jetzt darum, wir nehmen an, dass unsere Welt determiniert ist und deswegen kann man alles mit einer Funktion quasi hinschreiben.
1281320	1285400	Die kann beliebig kompliziert sein, aber es muss durch eine Funktion approximierbar sein.
1286040	1291480	Das bedeutet, dass alles mit einem Deep Learning Netz, also mit einem neuronalen Netz beschreibbar ist.
1291960	1293000	Das ist die Voraussetzung.
1293400	1296840	Und jetzt ist nur die Frage, wenn wir beliebig viele Knoten haben, dann ist das klar.
1297200	1298800	Was man dann einfach macht, ist Overfitting.
1298960	1306160	Also ihr könnt euch quasi vorstellen, ich habe eine Aufgabenstellung und ich verstehe die Aufgabenstellung nicht, sondern ich lerne sie einfach auswendig.
1306480	1316600	Sagen wir mal, mein Konfigurationsraum hat 10 hoch 32 viele Möglichkeiten und 10 hoch 32 viele Outputs zu einem gegebenen Problem, eins aus diesen 10 hoch 32.
1316920	1322200	Dann kann ich doch, wenn ich genug Knoten, also Speicherpunkte habe, kann ich die einfach auswendig lernen.
1322200	1324880	Ich kann alle Antworten auf alle Fragen auswendig lernen.
1326760	1332280	Also stellt euch einfach nur vor, ihr wollt eine Software schreiben, die Bilder erkennt und ihr gebt der Software vor.
1332960	1336520	Man gibt ein Bild rein, das ist 256 mal 256 Pixel groß.
1337720	1347160	Und jetzt macht ihr eine feine Abschätzung und steckt sozusagen einfach alle möglichen Bilder, die überhaupt existieren können im Konfigurationsraum.
1347360	1359120	Also alle Kombinationen von Pixelwerten, die 256 mal 256 Bilder haben können überhaupt, die steckt ihr rein und lernt sie auswendig mit dem Satz darunter, was sieht man auf dem Bild.
1359520	1360520	Das lernt ihr auswendig.
1361360	1366080	Wenn ihr unendlich viel Speicherplatz habt und unendlich groß sozusagen das Lehr machen könnt, ist das natürlich kein Problem.
1366360	1371720	Dabei habt ihr aber sozusagen, ihr habt das Problem nur gelernt, aber ihr habt es nicht verstanden.
1372440	1382280	Und die Idee ist sozusagen, kann man das runter kochen auf irgendetwas, was weniger ist als Overfitting und sozusagen die Datenmenge besser abbildet,
1382480	1390440	sozusagen eine sehr große Datenmenge, zum Beispiel dieser riesige Konfigurationsraum von allen möglichen Bildern, die 256 Quadratviele Pixel haben,
1391400	1398040	irgendwie abzubilden auf irgendwas, wo wir trotzdem das Problem lösen können, nämlich eine Software, die uns am Ende sagt, was sieht man auf dem Bild oder so.
1398360	1404960	Und das ist quasi das, was ich hier sozusagen jetzt mit Overfitting auch erklären wollte, aber wie gesagt, das Video ist ein bisschen heftig, ich weiß schon.
1405960	1407040	Das nennt man Overfitting.
1407480	1413800	Viel besser wäre es doch, wenn ich runter gehe mit meiner Komplexität in meinem Deep Learning Netzwerk, also in diesem Zwischenlayer,
1415120	1422960	auf viel weniger Dimension und trotzdem noch eine sehr hohe Approximationsgüte kriege, also 99,999 Prozent oder so.
1423760	1425280	Denn dann habe ich ja Folgendes geschafft.
1425680	1432120	Ich habe mein Problem komprimiert, was konkret, ich habe aus dem Auswendiglernen Verstehen gemacht.
1432640	1439720	Ich habe sozusagen, und das ist ja das, was grundsätzlich irgendwie nie jemand mal rafft, was ist jetzt der Unterschied zwischen lehnen und lernen und verstehen?
1440160	1451560	Verstehen bedeutet, mit dem minimalen Satz an Handlungsanweisungen das Problem vollständig zu lösen und aus verschiedensten Wissenssachen, aus Kombinationen von Wissen, neues Wissen zu erzeugen.
1452360	1459000	Ja, eine Anwendung zu finden, die sozusagen nur darauf basiert, dass ich hier das eine schon mal verstanden habe und ich direkt auf das andere anwenden kann.
1460080	1461600	So, und das ist auch da der Fall.
1461920	1466480	Wenn man also den minimalen Satz quasi die beste Architektur von Layern erzeugen kann,
1467720	1472800	um zum Beispiel Energie zu sparen, Speicher zu sparen, dann komprimiert das sozusagen. Ich mache eine Kompression dabei.
1473640	1482840	Und da kommen dann sozusagen die mehreren Layer dann typischerweise im Deep Learning dazu. Es ist nicht einer, sondern es sind viele verschachtelte Layer, die runter und hoch gehen in ihrer Dimension.
1482840	1488960	Da gibt es sozusagen Konvolutiones und was auch immer. Es gibt übelst viele krasse Architekturen mittlerweile, die alle sehr tricky sind.
1489760	1501920	Aber das ist sozusagen erstmal die Idee. Es gibt diesen universellen Funktions-Approximator und man kann mit einem Neuronalen jetzt jede beliebige Funktion, insbesondere alles, was wir in unserer Realität beobachten, wenn es dem geht.
1503760	1514320	Das ist die Annahme. Und warum sollte man also nicht das Gehirn damit beschreiben können? Und warum sollte man nicht die gesamte Realität und das gesamte Universum damit beschreiben können?
1521680	1525240	Ich habe jetzt schon erklärt in meinem anderen Video, was das Bewusstsein ist.
1526120	1534680	Und Joshua Bach hat es ziemlich kompakt nochmal ausgedrückt und hat gesagt, das Bewusstsein ist ein Modell für den Inhalt unseres Aufmerksamkeitsmodells.
1534680	1541840	Und was meint ihr damit? Na ja, es ist so eine Art Meta-Aufmerksamkeit. Ihr müsst euch vorstellen, es ist so eine Art Meta-Learning.
1541840	1547320	Was meint jetzt eigentlich Aufmerksamkeit? Na ja, also erstmal gibt es ja mittlerweile schon Transformatoren.
1547320	1558960	Also es gibt schon Attention-Networks im Deep Learning. Diese Sprache wurde schon etabliert und das macht auch ziemlich genau das, was man sich eigentlich unter dem Konzept von Aufmerksamkeit vorstellt.
1558960	1566600	Also erstmal Aufmerksamkeit und Bewusstheit, das hängt schon miteinander zusammen, auch vom Wort, sozusagen von der wörtlichen Bedeutung.
1567080	1577520	Und im Moment ist es so, normale Deep Learning-Netzwerke machen Folgendes. Die haben einen Fehler-Signal, also sagen wir mal, wir haben eine Beobachtung und eine Prediktion von unserem Modell und das ist falsch.
1577520	1584520	Und dieses Fehler-Signal, die Differenz davon, die versuchen wir zurückzuführen, in unser Modell wegzutrecken. Wo kommt sozusagen der Fehler her?
1584520	1590880	Und dabei sozusagen bei vielen Daten entstehen natürlich eine ganze Menge in diesen statistischen Gewichten, wo irgendwas sich ändert.
1590880	1603440	Wenn man jetzt mit vielen Daten lernt, mitteln sich sozusagen die unwichtigen Gewichte raus und was überbleibt ist das, wo der wirkliche Fehler herkommt, also das sind dann meistens nur noch weniger Gewichte.
1603440	1613160	So, das ist aber ein Prozess, der super ineffizient ist und langsam, der ist super langsam, weil man immer wieder den kompletten Backpropagating-Step durchmachen muss.
1614040	1629520	Viel geiler wäre, wenn man ein Netzwerk hat, was oben da bei diesem Lernprozess draufguckt und feststellt, wo sind die größten Gewichte im Gradienten, also quasi in dem Backpropagating und kann ich das beobachten, wenn ich das sozusagen öfter mache.
1629520	1639280	Und dann kann man Statistiken betreiben und sozusagen das abkürzen. Man kann diesen Lernprozess abkürzen, weil man sozusagen den Shortcut geht.
1639440	1648400	Das hat so ein bisschen was von, wenn ihr euch mit iterativen Lösungsverfahren von algebraischen Gleichungen auskennt, das hat ein bisschen was von Order-Zapsets, finde ich.
1648400	1654960	Aber das ist wirklich nur meine Physiker-Intubation, da bin ich sozusagen mit gefährlichem Halbwissen hier unterwegs.
1654960	1680840	Jedenfalls, das kürzt den Lernprozess ab und das erklärt natürlich auch, warum sozusagen heutzutage so ein Alpha Star, also die KI, die StarCraft gewinnt, die hat ja so was wie umgerechnet 200 Jahre StarCraft gespielt, bevor sie auf einem Level ist, wie ein normaler Master-Spieler im High MMR Blizzard Elo.
1680840	1690680	Und ein Mensch braucht natürlich viel weniger Daten. Warum? Na ja, weil unsere Hirnarchitektur krasser ist. Wir leben schon auf dem nächsten Level von Deep Learning.
1690680	1702800	Was sozusagen die State of the Art ist im Moment, das erste Level war quasi, wir bringen ein Programm bei Schach zu spielen und das kriegen wir einfach hin.
1702800	1710680	Das nächste Level war, wir schreiben eine Architektur, zum Beispiel bei Go, da geht das nicht mehr, das Spiel ist zu kompliziert, man kann nicht in einem Programm einfach schreiben, was das kann.
1710760	1716120	Sondern wir schreiben ein Netzwerk, was selber lernt, sich Go beizubringen.
1717120	1723040	Und Joshua Bach sagt jetzt, das ist aber immer noch nicht das, was wir können, wir Menschen sind noch ein Level krasser.
1723520	1731920	Wir können Meta-Learning machen, wir können also ein Programm schreiben, was ein Programm findet, um ein Problem zu lernen.
1732600	1740400	Das ist sozusagen das, von dem er sagt, was wir als nächsten Schritt brauchen. Und ich nehme an, das passiert erst nach dem nächsten KI-Winter.
1740400	1747120	Also wenn sozusagen nur Slow reinkickt und wir noch mehr Rechnerkapazitäten haben, um das zu machen.
1747120	1752680	Weil ihr dürft mich vergessen, wie unfassbar viele Neuronen wir in unserem Kopf drin haben.
1752680	1755360	Also die Komplexität unseres Gehirns ist schon ziemlich krass.
1756320	1762720	Und man kann sozusagen sagen, da ist eine ganze Menge krasser, universeller Funktions-Approximator mit drin.
1762720	1769560	Und das Gehirn hat halt wirklich jetzt, das beobachtet halt, wo die meiste Performance herkommt beim Lernen.
1769560	1776960	Und speichert quasi diese Aufmerksamkeit, das speichert es zusammen mit dem Kontext, in dem es gelernt hat, ab.
1777400	1781720	Und das ist sozusagen der Inhalt der Aufmerksamkeit.
1781720	1788600	Also das ist der Inhalt der Aufmerksamkeit, wo haben wir wann, was, wie am besten gelernt.
1788600	1797000	Was sozusagen hat die meisten Performance Boost in unserer Performance gebracht, wenn wir an dem einen statistischen Gewicht oder an dem einen Neuronen wackeln.
1797840	1807600	Und der Witz ist, das ist so eine Art Meta-Learning, weil es sozusagen eine Aufmerksamkeit über die Aufmerksamkeit macht.
1807600	1812040	Es speichert sozusagen den Kontext und wo die Aufmerksamkeit war.
1812040	1815720	Und das muss es beobachten, das Gehirn. Und das tut es.
1815720	1822200	Das ist sozusagen Meta-Learning, weil Aufmerksamkeit über die Aufmerksamkeit quasi oder der Inhalt der Aufmerksamkeit zusammen mit dem Kontext.
1822200	1824080	So ungefähr muss man sich das vorstellen.
1824080	1829400	Und ich finde, an diesem Punkt ist sozusagen diese maximale Selbstbezüglichkeit auch klar.
1829400	1834400	Und das ist auch das, was die Leute so schizophren finden an der Frage, habe ich einen freien Willen oder nicht.
1834400	1835800	Oder was ist das Bewusstsein?
1835800	1840040	Das ist halt sozusagen, das ist das, was Douglas Hofstadter wahrscheinlich meinte, mit einem Estrange Loop.
1840040	1844600	Und das Buch habe ich bis jetzt noch nicht gelesen, aber das steht auch auf meinem Pile of Shame.
1844600	1857800	Und das Hören muss sozusagen auch genau darauf achten, also es muss ich selbst beobachten, worauf ich jetzt genau Aufmerksamkeit lege.
1857800	1859040	Also was gucke ich mir gerade an?
1859040	1863360	Und der Punkt ist irgendwie diese maximale Selbstbezüglichkeit, die macht es halt.
1863360	1871640	Und falls ihr das kennt, also bei mir war es so, wenn ich mal, ich hatte mal so einen Moment, ich war auf einer LAN-Party und war wirklich komplett im Tunnel.
1871640	1878240	Also ich hatte das nicht oft in meinem Leben, aber manchmal war ich vollständig im Tunnel, zum Beispiel beim Zocken oder auch mal beim Schlagzeugspielen.
1878240	1885960	Und wenn man einmal so vollständig in diesem Modus drin ist, dass man seine eigene Aufmerksamkeit overfittet,
1885960	1893840	wenn man irgendwie so krass sich selber dabei beobachtet, wie heftig man unterwegs ist, dann ist man wie bei Matrix, wie bei Neo und sieht alles in Slow-Motion.
1893840	1895760	Man ist auf einmal superschnell.
1895760	1900720	Und ich hatte das, ich war normalerweise so ein Spieler, ich hatte so 250 APM vielleicht, wenn es hochkommt.
1900760	1904240	Und ich hatte mal auf einer LAN-Party so 320 bis 350.
1904240	1907400	Und ich kann mich auch im Nachhinein noch erinnern, das ging runter wie Butter.
1907400	1913840	Meine Finger, das hat sich angefühlt wie das geschmeidigste, konstante Tippen der Welt.
1913840	1918120	Ich konnte nie wieder diese Performance erlangen wie in diesem einen Game, was ich mal hatte in meinem Leben.
1918120	1922800	Und ich glaube, das war so ein Zustand, der hat sich schon fast so ein bisschen transcendent angefühlt.
1922800	1926560	Und ich glaube, das war, wo meine Aufmerksamkeit diesen Zustand erreicht hat,
1926560	1933320	dass sie sich sozusagen selber vollständig beobachtet und jederzeit eingreifen kann, völlig problemlos.
1933320	1938080	Ich glaube, so einen Zustand kann man auch durch Meditation erreichen, wenn man irgendwie, wenn man das lang genug macht.
1938080	1943080	Jedenfalls, das ist irgendwie krass und das merkt ihr, wenn ihr irgendwann mal, wenn ihr irgendwas habt, wo ihr euch krass konzentrieren müsst.
1943080	1947960	Und das genaue Gegenteil ist sowas wie mit dem Fahrrad irgendwo langfahren, zur Arbeit oder so.
1947960	1952160	Da denkt man gar nicht mehr drüber nach, muss ich jetzt hier abbiegen, muss ich hier meinen rechten Fuß nach unten drücken,
1952160	1954880	muss ich jetzt hier die Bremse drücken, muss ich hier irgendwie lenken.
1954880	1956920	Das ist alles Autopilot, ne?
1956920	1959840	Da ist genau das Gegenteil, keine Aufmerksamkeit mehr quasi.
1959840	1966960	Und übrigens das wichtige, meilensteinartige Paper dazu zu den Transformers heißt Attention is all you need.
1966960	1968040	Das ist schon so ein geiler Titel.
1968040	1972080	Ich glaube, das war auch von so Boys, die bei Google in der AI-Abteilung sitzen.
1972080	1974200	Das ist auch cool geschrieben, das kann man sich wirklich mal reinziehen.
1974200	1978760	Also wenn ihr euch damit auskennt, wenn ihr euch damit auskennt, kennt ihr das Paper eh, was erzähle ich hier.
1978800	1986680	Ich bin ja sozusagen der Laie, weil ich hab mir nur mal so einen wöchentlichen Crashkurs bei uns in der Informatikfakultät mal reingegönnt dazu.
1986680	1991720	Ja und da wird dann sozusagen auch klar, dass diese Sache mit dem Attention so geil ist,
1991720	1998720	weil wenn man jetzt zum Beispiel Textübersetzung macht und man geht Brutforce von damals vor und übersetzt Wort für Wort oder so,
1998720	2001400	dann geht das immer krachen, was man braucht, das Kontext.
2001400	2005800	Und Attention ist richtig gut dafür, weil Attention kann sozusagen den Finger auf ein Wort legen und sagen,
2005800	2013040	also dieses Wort jetzt hier, zum Beispiel der Arzt oder der Künstler, zum Beispiel Cain West.
2013040	2018560	Später in einem anderen Satz steht dann nur noch R und dieses R muss bezüglich auf Cain West sein.
2018560	2022360	Dieser Kontext, das kann Attention richtig gut lernen.
2022360	2027720	Und das konnten sozusagen die Learning-Strukturen vor den Transformern nicht so gut.
2027720	2033960	Und das ist sozusagen der erste Schritt in Sachen jetzt mal Attention machen und das ist halt krass.
2033960	2037880	Der nächste Schritt, also das ist jetzt sozusagen State of the Art, das ist das, was alle mittlerweile können
2037880	2040280	und das ist auch das, was GPT-3 maximal krass macht.
2040280	2048440	Und man, also Ben Gürtel hat den Tag auch so was gesagt wie, naja, GPT-3 hat halt auch so unendlich viele Knoten,
2048440	2050800	dass wahrscheinlich auch Overfitting schon dabei ist.
2050800	2056000	Das ist einfach nur ein völlig übertrieben großes neuronales Netzwerk, was das komplette Internet gelernt hat einmal
2056000	2059120	und deswegen mit dir reden kann wie ein Mensch, kurz mal.
2059160	2065000	Das habe ich in meinem Live-Talk dann über Künstliche Intelligenz auch schon mal gezeigt, so ein Beispiel.
2065000	2071080	Und jetzt ist es halt so, die normalen Transformer-Networks, die haben halt einen begrenzten Arbeitsspeicher,
2071080	2075120	das heißt, sie kriegen auch nur einen begrenzten Text in sich rein.
2075120	2080800	Was wir aber machen ist, wir haben sozusagen eine besseren Komprimierungsalgorithmus
2080800	2086600	und können deswegen viel mehr Daten in Attention, also in Kontext zueinandersetzen.
2086640	2092080	Und das, was jetzt sozusagen Cain West und er und sozusagen der Kontext für so ein Deep Learning Netzwerk ist,
2092080	2094280	ist für uns das gesamte Universum.
2094280	2098520	Das heißt erst, wenn wir auf diesem Level sind, quasi ein Level höher in der Attention,
2098520	2103000	dann können wir auch so was wie künstliches Bewusstsein konstruieren.
2103000	2106280	Also das ist zumindest das, was Joshua Bach sagt und was soll ich sagen,
2106280	2111240	alles, was Joshua Bach sagt, klingt extrem plausibel und hier muss ich auf jeden Fall eingestehen,
2111240	2117240	dass ich nicht so krass bin wie Stanislav Lemb und ich finde im Prinzip fast alles, was Joshua Bach sagt,
2117240	2120200	ist des Todes legit des Todes.
2120200	2122760	Der Typ ist einfach nur zu geil.
2122760	2128520	Und auf der Ebene der Neuronen übrigens kann man das Bewusstsein auch noch mal genauso erklären,
2128520	2133880	nämlich mit Emergenz, da kann man einfach sagen, naja, so ein Neuron muss jetzt sozusagen eine Funktion lernen,
2133880	2135120	wann es feuert.
2135120	2138840	Ein Neuron hat sozusagen, kann eine nicht-linearer Funktion approximieren.
2138840	2143000	Es hat ja ein multidimensionales Input, die ganzen Daten, die reinkommen.
2143000	2145160	Wann feuert es? Das ist der Output.
2145160	2149760	Und das Neuron muss jetzt sozusagen das Output an das Universum liefern.
2149760	2153360	Also es hat ja nur diesen Ausgang, es weiß ja nichts von der äußeren Welt.
2153360	2157280	Irgendwann kommt wieder Input rein und dieser Input füttert das Neuron ja.
2157280	2160560	Wenn kein Input mehr kommt, dann stirbt das Neuron ja ab.
2160560	2165320	Das heißt, Neuronen haben ein Interesse daran, diese Funktion sehr gut zu approximieren,
2165320	2168000	um lange zu leben und fetter zu werden.
2168000	2169760	Und das ist genau das, was wir haben.
2169760	2172400	Und in unserem Hirn gibt es sozusagen diese goldene Regel,
2172400	2174840	Wires Together, Fires Together oder so.
2174840	2179560	Das ist so eine Grundregel, die wird um Deep Learning sozusagen, diese Intuition wird da auch verwendet,
2179560	2186360	weil sozusagen die ganze Struktur der neuronalen Netze auf dieser Analogie funktionieren,
2186360	2190160	von den Axionen und den Neuronen und so.
2190160	2196720	Dem Scheiß, den wir sozusagen auf der biologischen Ebene schon sehen können,
2196720	2198920	wie unser Gehirn im Prinzip funktionieren muss.
2198920	2203600	Wir sehen sozusagen nur diese unendlich komplizierten Netzwerke und checken nicht, wie die gehen, so ungefähr.
2208680	2214000	So und nur die Neuronen, die das richtig machen, die überleben und die anderen sterben halt aus,
2214000	2218200	die das nicht machen, also da ist sozusagen wieder evolutionärer Selektionsdruck.
2218200	2221720	Und Joshua Bach sagt halt jetzt, und das finde ich auch schon wieder so geil,
2221720	2227600	ein Neuron ist halt einfach nur ein normaler kleiner Reinforcement Learning Agent.
2227600	2236320	Das ist ein kleines Reinforcement Agent Konzept, der sozusagen sich selbst immer verbessert.
2236320	2240160	Und ja, es sendet halt einfach diese Signale in das Universum, also nach draußen.
2240160	2242200	Das ist zum Beispiel das, was wir hier machen.
2242200	2246280	Das beeinflusst unsere Handlung und den Willen und den freien Willen und diesen ganzen Scheiß,
2246280	2248360	nur um eine positive Antwort zu bekommen.
2248360	2253120	Und das Konglomerat von den ganzen Neuronen, die wir halt im Kopf haben, ist halt so angelegt,
2253120	2257600	von der Architektur her auch, aber auch von räumlich getrennten Kostenfunktionen,
2257600	2264640	also bestimmte Hirnareale machen bestimmte Sachen, dass es robust wächst in der meisten,
2264640	2266640	bei fast allen Menschen, die geboren werden.
2266640	2269360	Und die Gesamtheit davon nennen wir halt Gehirn.
2269360	2270760	Das ist das.
2270760	2272600	Und das ist krass.
2272600	2276200	Das ist wirklich erstaunlich, dass die Evolution das herausgebracht hat.
2276240	2280040	Aber der Gehirn, habe ich ja auch glaube ich schon gesagt in dem anderen Video,
2280040	2282960	was für krasse Sprünge da dazu gehören.
2282960	2288320	Weil es ein super schlechter Trade-off war, für so eine Spezies wie den Menschenaffen
2288320	2293560	mehr in seinen Gehirn zu investieren und dafür mehr Ressourcen irgendwo anders einzubüßen.
2293560	2296640	Zum Beispiel war er nicht mehr so stark.
2296640	2301560	Das musste sozusagen in einer Zeit der Erbgeschichte auch entstehen, wo das gerade so ging,
2301560	2305360	damit wir über diesen Potenzialwald rüberkommen
2305360	2309080	und dann uns als Menschen überhaupt als Homo sapiens etablieren konnten.
2309080	2312640	Das war ein super Heft, da sind mehrere Sachen zusammengefallen,
2312640	2317240	dass das durch Selektionsdruck dann passieren konnte und der Mensch daraus entstehen konnte.
2317240	2322240	Weil sowas wie Augen zum Beispiel, das wurde glaube ich drei, viermal separat voneinander
2322240	2325840	in der Evolution festgestellt, dass sich Augen gebildet haben.
2325840	2327000	Zufällig.
2327000	2328800	Durch Evolutionsdruck.
2328800	2333200	Das ist zum Beispiel was, was man öfter beobachtet, aber so ein Shit wie krasses Gehirn
2333200	2339440	und dafür natürlich weniger Robustheit, körperliche, physische Robustheit, das ist selten.
2339440	2342680	Und ja, was soll ich dazu sagen?
2342680	2347400	Die emergente Struktur von dem, was ich sozusagen gerade als Gehirn beschrieben habe,
2347400	2348960	das ist das Bewusstsein.
2348960	2350400	So kann man es auch artikulieren.
2350400	2356320	Und ich wollte jetzt wirklich nur mal dieses Video machen, weil ich finde das so krass.
2356320	2360200	Immer wenn ich mir wieder was von Erscha Bach einziehe, denke ich mir so, ja,
2360240	2363480	Dieser Typ, den jeder muss wissen, wer das ist.
2363480	2366240	Ich finde, das ist der krasseste Dude, den es gibt.
2366240	2369400	Der basht halt auch die anderen Leute, also er basht die natürlich nicht weg,
2369400	2372200	macht kein Reaction-Video oder ratet irgendwie auf irgendwen.
2372200	2376120	Aber er macht sie alle platt, er macht, also meiner Meinung nach ist er völlig überlegen
2376120	2381640	gegenüber zum Beispiel Roger Penrose oder so anderen Leuten, die sich natürlich auch den ganzen Tag,
2381640	2386040	auch Douglas Hofstadter, die sich den ganzen Tag mit Bewusstsein und diesen Fragen beschäftigen.
2386040	2393960	Ich finde, Erscha Bach hat die perfekte, sozusagen die bestmögliche verfügbare Komprimierung
2393960	2396120	schon da in seiner Sprache.
2396120	2401560	Seine Sprache ist so kompakt, da steckt so viel drin, weil er sozusagen diese ganze Terminologie
2401560	2406440	von den Deep Learning Netzwerken so krass gefressen hat und diese ganzen Konzepte auch
2406440	2410120	problemlos auf alles Mögliche anwenden kann, weil er die Intelligenz da hat,
2410120	2412920	um sozusagen die Analogien zu bilden, um das zu tun.
2413000	2417640	Es ist einfach nur ein Genuss, dem Typen zuzuhören, auch wenn er extrem schnell redet,
2417640	2419160	so wie Sheldon Cooper übrigens auch.
2419160	2423320	Aber ist kein Problem, man kann es einfach mehrmals hören und super.
2423320	2427160	Und Lex Friedman macht auch immer einen guten Job, wenn er nochmal nachfragt und so.
2427160	2431320	Also, ich wollte einfach ein Video darüber machen.
2431320	2433320	Reingehauen, YouTube.
2622920	2624920	Das war's für heute.
2624920	2626920	Vielen Dank für's Zuschauen.
2626920	2628920	Bis zum nächsten Mal.
2652920	2654920	Der Kanal ist wie eine schöne Vorlesung aufgebaut.
2654920	2660920	Wenn ich unten Videos verlinke, dann wäre es angebracht, sich die auch reinzuziehen,
2660920	2662440	weil das aufeinander aufbaut.
2662440	2664920	Bestimmte Begriffe werden definiert, viele Beispiele werden genannt.
2664920	2670200	Und ja, ich denke mir schon was dabei, weil es sozusagen meinen eigenen Erkenntnisprozess
2670200	2672920	abbildet, die Reihenfolge, in denen ich die Videos hier hochlade.
