Anastasia, I believe, was taunting you on Twitter or something over the hard question
of consciousness.
I think I was mostly taunting all of Twitter because something that I've really struggled
with is that I haven't been able to find someone who can satisfactorily explain the
hard problem of consciousness to me.
And every time somebody explains it, I'm like, that doesn't seem like a problem.
Yes.
So the unusual way in which you're looking at it is not so much that you have difficulty
understanding the hard problem, but you have difficulty to understand by others think the
problem is hard.
Yeah, exactly.
Right?
I think I might help with that.
That's what I was hoping for.
Despite that being the unusual perspective.
And so it's funny because that's what I said on Twitter.
I'm like, can somebody please explain to me why this problem is hard?
And somebody was like, you need to talk to Josje.
And I was like, I emailed Josje a while ago, but we were, we started the show as puppets.
I don't know.
So we were, we built these giant aliens and we would puppet the interviews because we
wanted, we decided that the ideas that we wanted to explore scientifically were so far
out because the goal of the show is to explore the theories that will overturn current paradigms
in geology, cosmology, biology, physics, whatever.
And so we always find people that have these kind of weird ideas and we were like, okay,
this will be more acceptable if it's not humans doing the conversation, but it's aliens.
Because then there's this fictional frame that people can be comfortable in.
And after-
I think we were, to be honest, I think we were a little scared of putting ourselves,
our faces and just being people on the internet.
We really wanted, we were scared of that initially, but we got over it.
One of our mentors was like, you have to stop this.
He actually came on the show and he talked to the puppets for like three hours, no longer.
We recorded a bunch of episodes with him.
And then at the end he was like, what you're doing is great.
You can't keep doing it this way.
And then after that we got rid of the puppets, they're in a box in a closet.
And so here we are.
And so I think I emailed you when we were still the alien puppets, and that's a really
hard sell for people because you have to be like, hey, would you come on the show and
be interviewed by aliens that are puppets?
And everyone was like, no.
Well, I think we are anthropomorphizing people too much.
So principle open to trying different presentations.
Sometimes the puppet is limited because you can express less.
I think the idea of making something that is not human, but more expressive than a human
being, that would be potentially quite interesting as an experiment.
I think that's what really killed it is we couldn't make eye contact and we couldn't
having a conversation is so much more than the words that are happening, right?
That's why it's often difficult to talk to people on the telephone about very serious
or important matters because you can't see them and gauge their reaction.
Of course you could puppetify the interview after the fact.
That's true.
That'd be a lot of work though.
So we try to put out two of these a week.
You'll probably notice us, by the way, we do like camera changes during the show.
So don't be alarmed.
We don't want to edit later.
So we try to get it all while we're recording.
One thing that might be good is if I can do a very, very brief phone call at 11.30.
And then we have time probably way into the afternoon.
Okay.
Fantastic.
So basically we have open-ended.
That's incredible.
If we do this two or three hours, that's fine.
Do you want to just start after the phone call?
Yeah, let's do that.
We can spend the next 10 minutes just chatting about...
It seemed to me that you have career questions that you are pondering.
Is this correct?
I'm interested in the way that people shape their lives when they have more freedom than
the average person.
Because I think that most people show up and they work at a place and they stay there and
they advance on the basis of necessity and availability.
And then there's other people who stop and they look around and they really plan what
it is that they want.
Yes.
So the question is mostly how to get rid of your fear and that seems to be the hard thing.
I recently watched a presentation by Sam Altman where he told the story that he often watches
people who decide to start a company first so they become free and then can do the thing
that they want.
And his perspective that never works.
Basically people always get stuck doing their company and not achieving the thing that they
actually wanted to do.
So to him that's not a very good strategy.
Then again I think that his perspective is also a little bit unfair because not starting
a company and just doing the thing that you want also doesn't work.
So it's tricky.
It's an alignment issue.
Yeah.
But I find when I want to talk to my former self and mostly want to tell my former self
that I shouldn't worry so much like you'll never be rich but there will always be enough
money to keep you and your family afloat.
Just do the thing that you want to do and do it well because if the thing that you want
to do is sufficiently important and there are too few people doing it you will be able
to do it.
And so besides that I would say I should be a lot more calmer because despite my tastes
being very rare they have a reason for the things that I'm doing and for the stuff that
I'm interested in and institutions have reasons for not finding this and there's actual reasons
but not good reasons.
That's a huge part of what we processed before starting this project where it was possible
to continue down the line and to stay in the academic world but it was always going to
be tangential to the things that we wanted.
And it's hard in the density of media that there is in the world right now to start a
project like this because there's 30 million podcasts.
And so most of them have two or three episodes but still that's a reflection of just how
saturated the space is and it took us not that long to figure out that we were putting
something into the world that people really wanted and so it's allowed us to continue
but it's also...
Well one thing that's been really shocking to me is that you don't need a huge audience
but you do need an audience that's really good and really supportive and really really
interested in what you're doing.
Because we've been able to basically support ourselves with a pretty modest audience at
this point because our proportion of patrons to audience is kind of unheard of.
The people who listen to our show really care about these topics a lot.
But there's just not that many people that we've found so far.
I mean we've only been doing this for a year and a half.
There's just a small audience for these niche ideas it seems like too.
So that was kind of shocking to me.
That's not quite true.
I found that the Lex Friedman podcasts in some sense are serving a similar audience
and Lex arguably is not even that good.
He prepares himself well and so on and he tries to be serious about what he does and
he treats the people that he gets on the show very well.
But I think his main appeal is the speakers that he gets on the show.
He's really well connected right?
He's buddies with Joe Rogan and he had an enormous platform right out of the gate.
Yeah I mean he I think started out just playing his MIT card relatively well and then turning
this into a brand that he carefully curated.
And he gets millions of views for single shows which for a science tech podcast is really
a lot.
Yeah it's incredible.
And if you see the things that really fly you notice that of course if you want to do
audience maximizing you have to do something completely different.
I've noticed that there's a lot of podcasts that get trapped by an audience that can be
readily mined.
I don't know if you've noticed that there's some big ish podcasts not Lex Friedman sized
that are really into UFOs, that are really into crystal healing.
There's all these different…
Well they start off as interested in all sorts of sciences and then they find out that they
get the most views from say UFO videos or ancient aliens, I don't know, these sort
of fantastical niches and that's all they end up doing for the rest of their career.
I think it's a little bit depressing for them in the end because they're forced into
something that they didn't really set out to do.
So we're trying really hard to avoid that.
It depends.
They are starting out as telemarketers who are trying to get an audience.
That's true.
Right?
And the alternative is doing stir straps.
What's that?
I think Anastasia can explain it to you at some point.
She's our Twitter.
Yeah, one of the things that I love so much about Shiloh is that he lives partially dissociated
from the pop cultural landscape and so sometimes people will say things and Shiloh will be
like, what is that?
I've never heard of that.
And I'm like, that's…
I love that.
And so a stir strap is, I've never had to define it before, but it's a thing that somebody
posts in order to induce coveting in someone else, usually lascivious coveting.
In the context of Science Podcasts?
Well, there's some like…
In every context, cleavage always seems to work.
Basically, the demand for good cleavage is much higher than the demand for good philosophy.
And in some sense, that has integrity, I guess.
It's not my market, but basically, I see it.
I'm not sure if I'm envious.
I think I would be envious if I were doing my own podcast because it's so unfair.
It is really a tricky scene because you want to remain full of integrity for the way that
you see the world and how you approach it.
But then you go into looking at the algorithm and looking at what succeeds and looking at
what explodes and you realize that you have to pander to people's most basic desires
in the most obvious way possible.
Like, there's a video…
I feel like the Minoan ladies figured this out.
You know, have you seen these?
Yeah.
Okay.
I mean, in an ideal world, she would be both hot as hell and brilliant, but I feel like
those are normally…
By the time that you have to gimmick to cleavage, I'm not sure that you have the top shelf
questions.
I think there's a difference between beauty and grace on one hand and hotness on the
other because hotness is an advertisement of something that you do not plan to deliver.
It's a manipulative game and that is in some sense distorting the playing field.
I love that.
That's very well put.
Yeah, that's exactly right.
How did you come to have this definition?
Just observing.
I noticed that some of the people, some of the women I liked most were not hot and I
tried to put my finger on what actually defines hotness.
You don't actually need to be beautiful to be hot because it is an offer that is being
made despite this offer not being something that is actually fungible because it wouldn't
be sustainable.
That's interesting.
It puts a real negative spin on hotness, which is interesting, because it's in some
sense that unwillingness to deliver almost necessitates resentment in the viewer.
It might be, but if you understand that it's a game and it's okay in your culture to play
that game, it just creates another dimension, but it's a dimension that for instance would
definitely distract from doing a philosophy podcast.
Some communities have strong norms against it.
For instance, when I was in Boston, most of my friends were Eastern European Jews outside
of MIT and Harvard.
I just got adopted by a bunch of people who took me to Burning Man and into their circles
of friends and I felt very much at home there.
At some point, a girl who was not part of this community told me that she felt that
the women there hated her and were really bad to her and so on.
Then I realized none of these women in this community were putting on makeup.
Basically, there was a tacit agreement to not play certain games because it would distort
the interactions between people.
There are contexts in which you are going out for a dance or in which you are flirting
or mating or whatever, but in normal everyday contexts you don't do that.
This is where I became very conscious of it, because it's also something that is taboo
among the women that I live with.
The contextualization of your presentation is something that I stress out about a lot, actually.
We literally were stressing out about this yesterday or the day before.
Yeah, because I had to figure it out when I started lecturing at the university because
normally I just wear shorts and a t-shirt.
We live in the country, we're gardening all the time.
I'm pretty casual, but there's something about making people comfortable in a context.
I guess if everybody else is wearing makeup at a dance, then it would make sense.
It's something about at least putting on a blazer or something that makes the audience
more comfortable if your audience is in a professional context.
It's weird to walk that line because at some point you can just be putting on something
that you're not if you go too far with it.
At the other hand, you're trying to make everybody comfortable.
It's tricky.
Authenticity is for sale when you're on the internet.
The social mores of what makes for an authentic experience inside of you
and between you and your audience, I think, is along the same line of
you have a group of people and there's a set of rules and everybody conforms to those rules.
That feels authentic because the rules have been set at the lowest possible level of
we're not going to interrupt this interaction on the basis of how we paint ourselves.
When you come into the position that Shail and I are in where we're on television,
it's not really television, but it's still that principle.
It's television for young people.
It's also television for old people.
Exactly.
There is this constant question of, okay, well, who are you?
What do you show?
How do these decisions make people feel as you show them?
And how close to you are those decisions when the camera's off?
And how good of a job do you have to do in bringing those things together
so that in an intellectual conversation with somebody over Zoom,
you're the same person that you are when you're later washing dishes
or dealing with the fact that the cat puked everywhere?
Yeah, I think the most important thing is sincerity.
Once you fake that, you've got it made.
I just find it to be the hardest thing in the world.
I mean, I hope I don't fail at it too often, but I find it to be the hardest thing in the world
to just be yourself in a public space where everybody's staring at you
and just really work on yourself to the point that you're comfortable with yourself
and you don't have to pretend to be somebody else.
Just become more autistic, like me.
I sometimes wish that I could. I wish there was a switch.
I grew up in a really close-knit family, so I was born in Russia.
We moved to Israel. We moved to Canada. We moved to the United States.
And when we came to the United States, there was just five of us in the entire hemisphere.
No family here, no friends. It was just this little nucleus.
And so my family was very, very tightly knit to the degree that
most of my parents' friends let their kids lose their Russian.
We spoke Russian at home. We still speak it. We text in Russian.
I haven't lived in Russia in 33 years.
My brother was not born in Russia. He was born in Canada.
He speaks, reads, and writes Russian.
And that, I think, was only possible because of the way that the family was interwoven.
And so I've grown up with this just constant monitoring of people's states, right?
Because when you have this very tight-knit family and everybody's emotionally intertwined,
you have to be aware of everything that's happening.
And sometimes I wish that I could just turn it off.
I wish that I could just go out into the world and be like, I don't care.
I don't care. I don't care.
That makes total sense, but I don't think that being an American is an option.
Why would you give up your soul?
These are savages. They are socialized with three generations of Disney.
There is no culture.
That's me. Yeah, that's right. I grew up right in the heart of America, in the suburbs in Ohio.
I was raised on Hollywood.
America's test market.
Shiloh would always tell me that he grew up in Columbus, Ohio.
What was the thing that you would tell me?
It's like the restaurant test market of the world.
And for all the brands, they try out all the clothes and foods on the Ohio people
because they're the most middle-of-the-road people in all of America, essentially.
So yeah, raised on Hollywood.
We went to church, but it was a very empty culture, for sure.
It was difficult to find my way out of that.
Being at unease with the world is, in some sense, what brings most of the interesting people together.
This thing that you feel profoundly not at home in the world that you're in,
that you dislike the aesthetics of the world around you.
And this creates a tension that allows you to become conscious of who you are
because it requires that you reflect your own identity in some sense and construct it.
It's something that works for you.
Yeah, but you don't have any role models.
That was the most difficult thing for me growing up.
Yeah, but imitating role models are the worst. Come on.
Interesting. God, I had a hard time.
I had a career in music, and I was very much interested in poetry and art.
I tried to look up to a lot of my favorite artists, but I always found that they were flawed human beings.
It was really difficult for me to learn that there are no real idols for you.
There's nobody to model yourself on.
It was just really hard for me for some reason.
It took me most of my 20s to get through that.
When I was in Berlin, we put up pictures in our apartment of Boris Vian and Brentano and Milan Chomsky.
And basically, the living ones, I got to know when I came to the US, like Minsky and Chomsky.
And I realized how human they were and how flawed as human beings.
And it was an important insight for me to see that what makes people great is usually some defect in their psyche,
because the incentives for being great are actually not great.
And so true greatness typically emerges over some disturbance in your crystal structure.
My take on Chomsky is that he is somebody who failed very hard as a child due to being a nerd.
And he happens to be one of the best writers of his generation.
He puts out stuff not in paragraphs like me, but in entire chapters, complete with reference.
You ask him something, he gives you a book chapter every time.
But it's not designed to be true. It's designed to win the debate.
And he's an extremely skilled debater who has won a lot of debates in which he was wrong.
And he's smart enough to realize this.
And I think he should be smart enough to understand the damage that he had been wreaking, for instance, in linguistics,
due to insisting on being right in situations where he didn't have an answer.
And where he was basically stomping out tiny grasses that could have grown into something interesting.
And a similar thing happened to Minsky.
So I think that sometimes the greatest people are also the ones who are creating peril if they are surrounded by people who are less great than them and cannot transcend them.
Most people don't take greatness as a stepping stone.
So if you don't feel threatened by greatness, it's good.
But most people really feel in this mid-width range where they can copy theories and propagate theories,
but cannot make up their own and not disprove existing theories.
Hey guys, I hope you're enjoying this conversation. It's a really good one.
We are entirely supported by our patrons, which you can go and check out the landscape of at patreon.com slash demystify site.
We don't have ads. We don't have sponsors.
Nobody tells us what to do and we'd like to keep it that way.
And you need to help us make that happen by supporting the program,
which gives us time to interview more people, to reach out, to explore the landscape and to make this a better and better investigational tool.
If you don't have the money to become a patron right now, please just share the podcast with somebody.
Leave a comment. All of these things help us improve the quality of this project.
The biggest hurdle in my own life, just even in a marriage or anything, being able to win an argument doesn't necessarily help you.
And when I go and I talk about people with my own theoretical ideas,
recognizing that, oh, I could just win this argument really quickly isn't going to get me into developing my ideas more.
And I always have to force myself to remember that there are things I might not know.
And maybe this person has access to them, even if they're not presenting them in the best way possible.
And my goal is to keep that conversation going so that I can stir up new developments in my own ideas, not necessarily just to win the argument.
And it's such a hard thing to beat your ego down over and move on with.
I had this in earlier relationships, but not in my present one, which has been going on for 26 years.
And I find it has to do a lot with the attitude that you have to each other when you feel that you are basically two thoughts in the same mind.
And you also don't try to convince yourself of something that may or may not be true.
And there's usually fear involved that the other one is going to create a reality that is untrue.
And if there's a mutual understanding that both of you are going for the same aesthetic, that the end goal that you are going for is the same.
And you're just looking at different parts of the world.
And there is a very big interest in listening to the objections of the other because they all allow you to see more depth in the things that are happening.
And sometimes you get scared, but you get stressed out and you're not able to think clearly.
And then there's the question, how can you get back to the space where you trust each other?
And when you don't have the same goal and the same aesthetics, you need a new relationship anyway.
Have you considered going to marriage counseling as a third option?
I'm not sure that I can solve most people's problems.
Basically, I'm too idiosyncratic and too rare.
I can help some people with some of their problems if they have similar problems as the ones that I'm somewhat familiar with.
But I also cannot solve most of my own problems.
So I'm not somebody who is a spiritual teacher.
I did notice that marriage counselors are not being stopped by this.
So when my wife and me had a deep, severe two-year relationship crisis,
we went to a number of counselors who all basically told us to abandon all hope.
But all of them were singles. None of them had a working relationship.
It's kind of like going to the doctor that's really unhealthy looking.
And you're like, I don't know if I'm going to take nutritional advice from you.
Yeah.
And they also had an idea about relationships that I thought was unsustainable.
There's a notion that you're only entitled to a relationship if you don't actually need one.
First of all, put yourself into a state where you don't need a relationship, then you can have one.
Because there's this big danger of codependency that is looming over your head.
But there's another perspective, which is that you're intrinsically incomplete the way in which you're born.
And in order to become complete, you need to find somebody who is holding up some other part of the fort.
That also makes it so difficult once you have this bond to give it up if it's not really working,
because it's going to break away an important part of your functionality that is difficult to recover.
I mean, Shailen and I have been together for 10 years at this point, and we're so intertwined.
And obviously it's like there's conflicts and there's things that you have to get through because that's life.
There's no opportunity to have somebody who's a perfect person, right?
And so they're always going to fail you in some number of ways. I fail, he fails, everybody fails.
And there is this tendency in the world to be like, well, failure is unacceptable and the relationship must end
with some really low baseline of failure, where people behave like it's better to walk away from something
than it is to stay and to work through it and to get dirty and to be vulnerable.
And I think that it can be really scary because, like you said, if you have a two year rough patch in a relationship,
that's a really, really long time. But at the same point, over the course of a life, is it really that long?
I think it was the price that we had to pay that basically it was her first relationship, she was 19.
And I was very of this because I thought she's going to change a lot in the next few years and I'm going to change somewhat.
And I was 23, but I'd been in relationships for seven years at that point.
And so I thought I've been through a lot of things and had made many of the transformations.
But how is this going to fit when she is a full adult? Does she still fit into this relationship or is she able to find a new fit?
And this is essentially what got us.
And so this realignment of accommodating a new person or a new pairing in a relationship, that was very difficult for us to achieve.
And there was really this big fear, do I still fit in or do I have to cut up an important part of myself if I stay in this relationship?
And that's also the other question. If you're a stage designer and you realize it's 40 nowadays and not really compatible with having kids,
do you choose kids and family or do you choose the career that you've been working for all your life?
That was also an important aspect.
Yeah, that's right on the front of our table right now as well. It's a very difficult road to navigate.
What did you end up determining there?
Well, we went for the kids and family. And for stage design, I think it is very hard to pull this off because the way it works in Germany
is that you have to be an assistant for many, many years and very few of the people who go to that route manage to become fully employed as a stage designer.
And so in Mira's class at Kunsthochschule Weissensee, which is one of the most prestigious places to study stage design for theater in Germany,
she was the best one. And almost all of her class dropped out at some point out of this career class.
And the two women who managed to get in did this by having relationships to other stage designers or to a director.
And so it didn't work like you have a family and on the side you have a career in the theater.
So that was pretty tough. And on the other hand, she felt, which we were surprised about Ami,
that when we had children and I said you're spending so much time with them, maybe find some solution to get a nanny or whatever.
And you do whatever you want. No, I want to spend that time with the children. I don't want to miss out on it.
It's the most important time in my life. And she did not experience this at a loss.
There was some thing that she felt I would wish there was a place for me to work professionally and to develop myself professionally.
But it was also given the choice. She chose the children also later on.
We had a philosopher on the show in the early days. I believe it was L.A. Paul who was talking about transformative experiences
and how you just don't have the information necessary to make that choice.
You don't know what your life, your new life is going to look like until it happens.
And I imagine children are the perfect example of that.
Because you're not the same person after you've gone through the experience.
And so you can't forecast onto the agent that you will be on the other side of it because you have no idea what the priorities of that agent will be.
And so you're always rolling the dice in the sense of is it worth trying to become someone else knowing that I will lose who I am today?
And I think that that's for women and children and child rearing that's often the case because I watched my sister go through this.
She just had kids. She's 40. And she was a professional.
She worked at Google for like 10 years. And then she decided that, OK, it was time to have kids.
But she was terrified that she would become someone for whom children were the center and she would lose all these other parts of herself.
And now that she has a child, I think that she recognizes that it's just this is better than anything that you can get out of a career.
Yes. I think that you basically feel that what you did before you had children was jumping up and down and looking at things.
And this stuff is not lost. It's there. It's a part of who you are still.
But you have additional layers that don't regulate this part when there's more important things.
And taking care of the next generation is suddenly the most important thing because you identify as a multigenerational being that is reaching from the first cell into the future.
And it's up to you right now if it ends here or if it continues and how.
So it's quite profound. And I found that I was worried that you would adjust your brain and become boring or anything or complacent.
And the opposite happened. She developed so much depth. And I never felt lonely in this relationship. I'm very grateful for this.
She didn't stop reading. She read a lot more. She developed much more in terms of psychology and self-awareness and people awareness and social thinking and also philosophy.
And it's quite profound. And she became a much more well-adjusted human being during the pregnancy because everything basically got adjusted and fell into place.
I think about that line of living beings from the very first cell all the way to us.
And I also think about it in terms of the spiritual wheel of life.
I think this is kind of like a Vedic cosmology a little bit where you continuously are reincarnated until you get to a point where you reach nirvana and you don't.
And I have this tendency of looking at life as this continuous process that actually reaches back before the first cell.
I was listening to your Lex Friedman podcast and I was surprised that you identified life with cells.
But I see it as this iterative process where I wonder if there is some kind of spiritual event that happens when you reach the point of reproduction and you decide against it.
Where it's a release of the burden because being human is really difficult. It's painful.
The poet William Blake addressed this head on and he treated it as the sin of generation.
He retells these ancient biblical narratives as if having children is actually getting in the way of spiritual enlightenment to some extent.
Not having children is spiritual suicide.
Can you elaborate?
We have no longer stake in the future of life.
It's only narrative now. You have ideas about how you contribute to the future, but you're actually no longer part of it.
I guess an artist is the one rare piece of society that is transforming future generations without generating more beings.
Your value as an artist is given by how much the audience appreciates you as broken to me, but maybe this is idiosyncratic to the type of artist family in which I grew up.
This idea that I have to adapt to the impact that I have on my environment is distorting my ability to do art.
As an artist, I am in some sense completely fine with having an audience of one or zero if the art that I'm doing is good.
It could be that what you're doing is reaching a large audience or a small audience, but in some sense that's incidental.
Okay, I agree with that.
But the other part is that there's plenty of people whose work becomes influential after death.
It's not that you're playing to an audience and you're performing this iterative loop of how will I make the tastiest Frito that somebody will buy,
but instead it's that you say something about the human condition that is so powerful that it persists in the world after you die.
The question is, if you're an artist, would I lose my ability to say those things if I had children and that was where my focus was?
Of course. This poem of the sacrifice has integrity to say I don't want to have children because art is more important to me.
There's nothing wrong with this.
There's also this possibility that only very few generations are left or we really don't give a shit about the future generations anymore
because millennials suck and zoomers are the worst and it doesn't get better after that.
I feel like every generation has said that about the previous generation.
It did, right? It did. And yet...
Here we are. It means we're getting old.
But look at them!
I was looking at the commercials for the new Apple Vision Pro and I look at these shit faces and there is nothing human in them.
It's just entirely uncanny valley.
It was crazy because, okay, full disclosure, my sister recently got laid off but my whole family works at Google.
My brother, his girlfriend, my dad, my mom doesn't, and my brother-in-law is in tech but not Google.
And so I'm terrified that the speciation event is running along this fracture line in my family
where they're all looking at this stuff and like, this is awesome!
And I'm sitting over here living in the middle of nowhere like, what are you doing?
How is this a vision of the world where you're wearing these goggles
and you're just constantly interfacing with a computer and you're not really there?
And it feels like there is a complete fracture in the entire world that runs along these lines
because you see people that see the demo and they're in love with it already
and they're the early adopters and they're full speed ahead.
And then you have the other people that are like, I don't know that that's where we want to go
because where does it end? It ends in optoneural implants that are given to you at birth basically
that will perpetually jack you into the system and I guess that's the cyborg future.
I don't see any other end to it. Where else could it possibly go?
I think you're too optimistic. I think it will probably be crap again.
This idea that we have something that creates a seamless interface between my imagination
and the physical world that I'm dropped into and I can mix and match.
That is, I think to me, a very powerful and liberating concept as long as I am the one who is in charge.
And I feel that it gives me a freedom to choose my environment.
I don't need to be on an airplane. I can be in a space that I create entirely for myself.
And I can create the inside of my mind.
And ideally, I want to have a product that is going to in deep resonance with my mind
that is so empathetic that it's able to read my thoughts.
So I can co-create with the substrate. I can extend myself into the substrate and I can enlarge my mind.
And to me, this technology is potentially a step in this direction.
I'm just not so optimistic they can pull it off because their taste seems to be so bad at this point.
I'm agnostic with respect to the type of product.
And I'm not ready yet to buy into a simplistic black and white black mirror narrative.
There is a lot of stuff that I can project into black mirror.
But there is also a lot of stuff that I can see in every decade that puts people into an alienating world
that happens to be physical and happens to be 3D and photons that have bounced off streets and walls and trees.
But that is also not satisfying.
I think what you said about it being of your own making is really important.
Because my first impression when I saw this technology drop was I have no interest in joining into somebody else's technological vision
of what my future imagination should look like.
So it's just not attractive to me personally.
But I could see it being attractive to lots of people.
But I'm interested in technology that's going to allow me, like you said, to be more of myself
and not somebody else's vision of myself.
And that's the fine line for me.
Unfortunately, the business case for our self-made software doesn't seem to be good.
Steve Jobs had the choice of building the Smalltalk universe where you can basically open the hood of every application
and applications share code across applications and you can change out everything in real time
everything becomes user accessible and user maintainable and user designable
versus a world where everything is closed boxes and even the developers can only open the box
if they have the pipeline open and have their source code and IDE tuned to this.
So even another developer from another company cannot open your hood and look under it and fix things and improve them.
This world has much better business cases.
I've been really struck recently by how difficult it is to work with the technology that we have
because the future was supposed to be this thing where everything is really streamlined
and the technology allows you to be more of yourself and to accomplish more.
And it's not. It's very clunky. It's difficult to navigate.
Anybody who's over the age of 60 maybe who isn't in high tech is basically screwed by their technology at this point.
It is opaque. It is unbelievably difficult.
I had this experience where Shiloh's dad flies radio controlled airplanes
and he needed to do a firmware update for his radio controller and he couldn't figure out how to do it.
So I was like, that's fine. I can I can troubleshoot stuff pretty easily.
It was unbelievable how many layers deep in the website this update was buried.
Layers of passwords, different portals. I think he had to put it on a USB stick at the end of the day.
It was just it was an unbelievable collection of steps where if he didn't have someone who could walk him through it,
there's no way that he would have figured it out.
See, that's why we need kids.
I would mostly give it to my 12 year old this task who would have joy puzzling it out.
Yeah, that's a really good point, actually.
You know, the tradition of having children to work for you is a long and storied tradition.
Especially to fix your printer, I remember.
I love that.
Further updates. Yeah. Shall we turn on the audio and recording?
Yeah, if you if you could. We've been recording this whole time, but I didn't know that.
So I will turn on the auto recording on my side as well, just to have a backup in case the Internet is not on our side.
Fantastic. Yeah, that sounds good. Yeah.
If you want to just start off and orient people a bit to who you are and the project that you're working on right now, we'll just keep going.
Hello, Shiloh. Hello, Anastasia. Thank you for inviting me to your conversation.
I'm Joshua Bach. I'm a cognitive scientist and AI researcher.
And the reason why I went into this field is because I want to understand how the mind works.
That was actually the sole reason I went into academia in the first place.
And I tried to study lots of things that were related to this and tried to figure out how to identify those fields,
which had a meaningful opinion about how the mind works and could teach me something about it.
And I was not very successful at first to find something.
I did study math a little bit and computer science and psychology and a bit of physics.
And I found that psychology didn't offer me theories that I could work with that were matching the observable reality deeply enough to understand the deep questions.
What is consciousness? What is the mind? How does it relate to reality?
And philosophies seem to be stuck in discussing texts that they were reflecting, usually not at the same level at which the text was originally written.
And so I had the impression that most of the fields were stuck.
Neuroscience is mostly not about minds, it's about neurons and their individual structure.
The interactions of neurons are poorly understood.
There is no model of neuroscience that they can plug into a simulation and it produces interesting brain-like behavior yet.
And so the only hope that I saw existed in artificial intelligence.
And in some sense, artificial intelligence was started by Minsky and others to continue on the philosophical project of Leibniz and Frege and Wittgenstein to understand the mind by building one.
Basically closing the gap between mathematics and meaning by automating the structure that is breaking down meaning into chunks that can be computed.
And I realized that there has been a big constructivist turn in the last century that is largely under-adjusted by philosophy, which basically turned the concept of mathematics into computation.
Which said that all the mathematics that can be real, that can be implemented in the physical universe is characterized by moving from step to step.
And these transitions and systems that are moving from step to step, that's actually computation.
And physics, in a sense, is a computational science. The universe is a computational system.
Everything that is dynamic and deterministic can be described as the computational system.
And the indeterministic stuff is not different from this.
It's just, in addition, deleting some of the bits that you had computed before, if it's indeterministic.
So you're interested in the deterministic aspects of the whole thing.
And I guess it started for me as a child, when I was sitting in front of my combo drugs before, when realizing that everything that I could imagine, I could put behind that screen.
And I asked myself, what is it that I would want to put behind that screen, if I understand it clearly enough.
And I thought an entire world, of course, with minds in it that you can talk to.
And this was basically my project when I came into academia.
And this was what I was trying to study for and collecting ideas in my mind for and building structure for.
And then at some point, I interacted with the institutions deeply enough to understand that they wouldn't pay me for building a mind, at least not back then.
I think now the situation is better because AI has become much more fashionable, actually a hype in the sense that a lot of people are willing to invest into niche topics of AI.
And the philosophical project, which has always been an extremely niche topic, because it's something that is so risky as a philosophical project, that there's a very good chance that you're not going to succeed in your lifetime.
That is not the stuff that you could get paid for when I was in academia.
And so in some sense, for me, the question of where to pursue this best is still open.
Should we do this in a large company that is large enough to be able to put effort into niche topics like machine consciousness?
Or should we take the opportunity that we have right now that so many people are interested in doing this and just build a dedicated institution that studies nothing but how to teach a machine to be conscious?
Oh, go ahead.
I was going to say you said that the universe is fundamentally computational, but is that how it is or is that just a description?
And if it's just a description, is it necessarily the best description of the universe?
That's a metaphysical question.
And the very short answer is that I think for something to exist, it has to be implemented.
To be implemented and to exist are for me very basically identical concepts.
That's the way I understand existence.
And the part of the universe that can be described in any language that is not self-contradictory, that is constructive, that's computation.
And so if you think about computational objects, it means that you have a bunch of relationships between information.
And when that thing is causally relevant, so it interacts with an observer, for instance, and that includes the observer itself, it needs to be dynamic.
And so at the core of everything that exists is state transitions.
It's basically changes in information.
And the meaning of information is its relationship to change in other information.
It's a very general way to thinking about stuff.
And curiously, if we look at the entire history of science and metaphysics, it doesn't seem to be a viable alternative to this.
There's basically no other way to build representational systems in which I can think, talk, observe about anything or in which anything can be implemented to exist than computational frameworks.
So computation doesn't mean you have this particular von Neumann computer.
This is not a particular kind of machine.
It's more general than this.
The Church-Truing thesis basically says that all these systems in which we can define state transitions are ultimately equivalent to each other to the point where they run out of resources.
See, the way that I look at it, existence is a static concept, whereas dynamics and the patterns that emerge, the motions, those are all dynamic.
They're dynamical.
And so you have bodies, just these volumes, surface bound volumes with inward extension that are interacting in the material sense.
But the patterns that play out, the motions, all of these are on a completely different layer.
And the patterns don't exist in the same physical sense.
The substrate exists.
The rest is occurring, right?
These are occurrences because they're dynamic.
But in order to describe, say, a table, I don't need any dynamics to do it.
It just has an architecture and that defines its existence because it has, we can conceive of this body, the table, and it has a location with respect to all the other bodies in the room.
And so therefore it exists.
But if I want to start talking about what the table is and how it's used and what its function is, then I'm getting into this idea, this realm of ideas where we're talking about its dynamics with respect to everything else.
Its motion and its purpose and all of these other layers.
But fundamentally, the universe is a set of physical objects which are defined by being bodies with surfaces and inward extension.
That table is in prototype, right?
It's a way to structure your mental models of parts of reality in terms of giving you affordances of dealing with the reality around you.
If you look at the actual tables, there are arrangements of matter that can be captured by this type of model that you have of a table.
And I think it makes sense to treat tables not as physical objects, but as a way to relate to physical objects in your own mind.
It's a way to structure reality.
Reality can probably be understood as something like an evolving state vector, the universe itself.
And this evolving state vector cannot be experienced as a whole and it cannot be modeled in your mind as a whole.
You cannot make useful predictions based on the assumption that it's uniformly evolving state vector.
Instead, what you need to do is you take it apart into regions that are loosely coupled between each other and strongly coupled within.
And the table describes an arrangement of stuff that is strongly coupled within in the sense that you can take it apart, but then it stops being a table.
It's basically a function that you describe a part of the universe that changes more slowly than the rest of the universe with respect to you.
And that makes the universe manageable.
The interaction between such regions that we call objects that interact with each other, that is what we call causality.
And causality becomes a model property, a property of models that are derived by separating the universe into loosely coupled interacting objects.
Right. And I think that it's really important, at least in physics, that we don't get confused with the difference between objects and ideas.
Because when we start treating ideas as if we can move them around and perform dynamical operations on ideas, we get confused and we don't have a baseline.
It becomes a circular argument that has no substrate at some point.
And it seems like this is at the core of so many issues in physical sciences, because we haven't been able to separate them.
It doesn't get confused. Physics is solving this affair for itself very elegantly by restraining itself to the part of reality that can be described as short algebraic equations.
And everything else that doesn't fit into short algebraic equations, physicists ignore and they call it chemistry or biology, and it's being left to other people.
And so physics is a particular way of modeling the world, mostly using geometry.
Yes, but it's very new in the last hundred years or so that physics has become this purely mathematical discipline.
Prior to that, it was understood as a mechanical discipline that was bodies interacting with other bodies, either pushing or pulling on them.
And in some sense, I feel like that's a much more sane way of approaching it.
Because right now, physics is trying to absorb so many metaphysical problems when they're talking about the universe and the fate of the universe.
And they're very existential questions in some sense, and people are happy to look to the physicists for answers on those.
But I don't know that mathematics is equipped to answer cosmological questions of purpose, of meaning, of future.
To me, mathematics is the domain of all languages, of all the simple games.
And mathematicians start with the simplest one, formal languages, where you can define truth from the ground up.
Whereas when you try to talk about philosophical issues, you have to use natural languages because it's so hard to formalize them.
And that's why it's very hard to say something truthful in a natural language, because truth is so hard to define in all this ambiguity.
In mathematics, conversely, it's very hard to say something about the actual world that we are in, to talk about minds, feelings, emotions, interaction between people, the actual economy, and so on, actual objects.
But there has been progress, and this progress has been so profound that we can now use formal notations to describe many aspects of physics in a satisfying way.
And the mathematics is a tool for notation, for the most part.
And it has a similar relationship to the objects as notation has to musical objects.
When you think about music, you could say that music ultimately is about making noises and having ideas about these noises, and often describe the space of attitudes and movements in the space of attitudes, and some types of music.
It's about having different types of attitudes that find a resolution among each other, or sometimes it's the progressions with space of attitudes that gets you somewhere or constructs something interesting.
There are different types of music applying with this. There are also musics that do not really work on attitudes, but on other types of mathematical objects, but ultimately music is about some kind of mathematics.
And music itself is relatively easy to find a notation for. You can write it down at a very young age, and you can use it to talk to other people about the music that is in your mind, and you can also use it to talk to yourself about the music in your mind.
And there is an additional layer that is not captured by the notation that allows you to interpret it.
So the notation is to some degree constraining the piece that you are playing, and the actual art consists in the interpretation of the piece and to building additional structure in which you build a relationship to the piece.
So it's not just this media thing, but it's the deviation from the default that becomes interesting.
And physics in the sense is not an art like this, but it has made progress in finding notation for geometrical and dynamical affairs that are happening.
And it's harder to learn this notation. Typically you need to spend a decade to get the basics down.
So you can describe all the objects that physicists are talking about and understand their notations, but it's a similar thing. There is nothing alienating about the languages of physics.
It's just that these languages are also not capable of talking about stuff like consciousness.
So how do I find a notation that allows me to truthfully talk about mental phenomena?
And this is something that's interesting to me. So basically how can I mathematics this as well?
How can I find a way to actually reflect about it and make proofs about it and communicate about it?
I worry that something is lost when we treat mathematics as a language because it's essentially quantitative adverbs.
And it's hard to imagine making a sentence out of quantitative adverbs.
Whenever you read, you know, we were talking before we started, I just published a paper today which is highly mathematical,
but it also has a lot of companion text which qualifies the mathematics and explains what the formula mean.
It almost seems to me like mathematics alone has no explanatory power.
It can only describe how a system behaves, but it's on the real language, say English in this case,
to qualify what that description means about the cause and effect relationship.
And I probably came from a different direction at the same problem.
And I think it started with computing.
When I was a kid, I was blessed with having this weird Commodore 64 that has no way to talk about geometry.
I guess basic programming language is very similar to assembler in there.
And it doesn't have a command to draw a line or even draw a pixel on the screen.
So the way in which you draw a line is that you poke a few values directly into registers of the video chip.
You need to know these addresses and the values that you need to poke in to make the video chip forget how to render characters on the screen
and instead interpret a part of the memory as a pixel arrangement.
And a few choices that you can make of whether a pixel is composed of one bit or multiple bits.
So you can have multiple colors or just two colors.
And when you make it out of one bit, it means that one byte arrangement of eight bits is going to be mapped into eight pixels.
And a group of these eight bytes is a block.
And then the block starts next to it and you have 40 of these blocks in every line and you have, I think, 24 blocks vertically.
And so you can come up with a formula that you derive by yourself that tells you how to find a bit in memory that corresponds to a pixel on the screen.
And once you've done this, you can create a loop that draws a line on the screen.
It's a major triumph when you figure out that puzzle.
And so in some sense, I was able as a child to derive geometry in this way.
I wrote a graphics program for myself because I didn't have one.
It was 1983, 84.
I was in Eastern Germany for a software that I wanted to have for the Commodore 64.
It either didn't exist or was not accessible.
So I wrote a program that could draw lines and that could draw ellipses and so on and combined them.
It's my first graphics program.
And to do this, I had to derive geometry by hand, the mathematics of geometry.
And I did not realize that I was doing this.
I thought mathematicians have some secret way of doing this that is much more elegant than what I was doing.
And the Commodore 64 also gives you an idea of how this happens in the CPU.
So we realize that all the mathematics that happens in the CPU, all the basic Boolean logic and also the basic arithmetic addition, subtraction, multiplication and division is done with some pattern matching operation.
It's basically a hashing function that is taking input pattern and maps it to an output pattern in a regular way using a simple circuit.
And so you realize how you can build up the entirety of mathematics, including geometry, including everything that you can see in a world and display in a computer game.
By dynamic objects interacting with each other, agents that reason about what they're seeing in this world and how they're interacting with you.
All the stuff that we see right now in computer games and increasing degrees of resolution is built up from these tiny, simple automata.
So you realize that all of mathematics is being built like this.
It starts out with finite automata and using a suitable set of finite automata is an axiomatic system.
You can build anything that you can imagine.
And there is, in my way, nothing that you cannot put into a computer.
I wouldn't know what that should be.
There is nothing in physics that you cannot recreate in a computer.
Some of the stuff quantum mechanics is not going to run efficiently on your computer or rather the particles that you own by a quantum mechanics are not going to run efficiently.
Because I think that ultimately the premise of quantum mechanics is that the particle universe in which we are conceptualizing and perceiving ourselves is inefficiently implemented on the substrate.
So there's one aspect of this, which is that there's a difference between physics and biology.
Right?
Well, yes.
And the difference is that biology emerges over the dynamics of evolved cells.
The biocell is itself an agent.
It's a system that is in some sense a very complicated super molecule that is able to model aspects of the future.
And most of these models are formed implicitly through a process of evolving for a particular kind of environment and then putting subroutines into the genome of the cell that allows the cell to deal with lots and lots of different environmental circumstances
that would destroy a similarly complicated and fragile molecule without that kind of regulation.
So basically the cell is able to deal with more complicated environments and survive in them, keep its structure stable due to its ability to regulate aspects of the future visits in built dynamics.
And in order for that to happen, the cell needs to combine a way to harvest entropy, neck entropy from the universe, basically get the energy that it needs to survive, keep its structure stable against disturbances.
And it needs to have a computer.
It's basically DNA with the right head, very similar to a chewing machine.
And it needs to have a way to self-replicate.
And without any of these components, life is not possible.
And they're quite complex.
Each of them is built by physical structures, but our biogenesis, how to get from the first cell from something that is not biological is very hard to understand.
There are some people who are optimistic about that.
You just put the right conditions in some kind of primordial soup and cells are going to pop right out.
But there is no proof of this.
We can get reasonably complex organic molecules, but so far not cells.
And so maybe cells are everywhere in the universe.
And maybe we are in the only place in the universe where the cells have formed or that has been infected by cells that formed somewhere else in our solar system under more favorable conditions.
Maybe cells really require some freakish accident for them to happen.
But once you have cells, biology is easy because you get evolution.
I think that I object to the idea that the definition of life is a cell, because I think that I define life as a form of matter that's able to desire things and then to change the world to fit its desires.
And I think that that process begins before you get a cell.
I think that the cell is the manifestation of progressively more complex organizations of matter that are able to change the future by virtue of existing.
I'm not sure if I'm willing to attribute desire to cells even, and probably not to processes before cells.
I don't think that the virus is desire.
I think of a virus as something like a text fragment that the cell cannot help but read and to enact its code.
And I don't think that the virus itself is multistable.
And so it's not actually living.
It's not able to survive without injecting itself into a cell that is producing all the necessary dynamics to make the virus function in the way it does.
And there is nothing simpler than a cell that is performing these functions and its arrangement of cells that give rise to systems that represent themselves.
And I think that desire is a property of a system that observes itself desiring, that has a concept of itself wanting something.
It's not just an implementation of a thermostat that is trying to keep the temperature stable.
I don't think that the thermostat has a desire in this regard.
And I also don't think that there is something magical that needs to be added to the thermostat to turn it into an agent.
It's basically all just functionality that needs to be added.
But desire is the property of systems that represent their own agency.
It seems like, again, I think if I can clarify what Anastasia is getting at is that there seems to be a confusion again between the idea of life,
which is a phenomenon, and the objects which exhibit the phenomenon, which is the organism, the cell, right?
Well, yeah, because you say that it's not possible for a cell that can't conceptualize itself to have a desire.
Yes, to some degree agnostic with respect to this, because I have no proof for the upper bound of the complexity of a cell.
I don't know if there could be cells which think and which perceive in a meaningful sense.
I think it's conceivable that some do.
But I suspect that there are cells which are rather dumb and quite mechanical in their interaction with the world.
I find it fascinating that you seem to think that life is something that exists independently of the structures that implement it.
It's almost as if your ideas, your concepts that you form by observing lots of things,
are breaking free from your observations and develop an inner life and run amok in your mind.
Are you sure that you should leave them off the leash?
Because the life that you're talking about is an abstraction that is ultimately always bound to observations that you made.
And I don't think that you were able to observe the phenomena of life outside of anything that has been constructed of or by cells.
Well, I think that cells are the natural progression of this kind of organization of matter.
And this is kind of reaching back to the idea of the Alain Vital, the idea that there's some animating force.
And we abandoned it because it seemed too spooky and religious.
No, no. We abandoned it because there was no evidence for it.
It was an idea to describe why stuff is animated and is moving.
It was not that anybody had ever observed it.
But so my point is this.
OK, so we have a vision of the origin of life that is cellular in nature.
Life begins when the first cell forms.
And we can't solve that problem because there's no way for us to bring together the components of cells and then to produce a cell.
And do you know Michael Levin? Do you know his work?
Yes.
And one of the things that he always says is he's like, look, the strength of your scientific philosophy has to do with what it allows you to accomplish.
And for decades now, we've had this way of looking at the cell as or of an organism as being the product of molecule target interactions,
where you have molecules that interact with receptors.
Those receptors come into the cell. They do something.
It's this very mechanistic ratchet machine, right?
You can simplify it to a bunch of gears that are all spinning.
And so it's a machine that has outputs.
But he has a radically different way of looking at it, right?
He's like, look, the thing that drives life is will, it's desire.
And so if we can control the desire of the cells by giving them the proper input,
since we understand what it is that the map between input and desire, then we can get them to do crazy things.
And he accomplishes this with his regenerative medicine experiments,
where he can make the body plan of these planarians change without affecting the DNA.
And the fact that you can do that to me suggests that our concept of life as cells isn't fully fleshed out.
Because if you have a state of matter that is, you know, gas, solid, liquid, plasma life,
then the problem of how cells arise becomes a question of how does matter organize itself
in isolated conditions that propagate iteratively towards the production of a stable body
that is then more effective than the molecules themselves.
And to say where that might be happening,
there's a lot of research into the deep biosphere that suggests that
there's a layer of the earth that you can go down deep enough into
where the line between chemistry and cells is blurred.
And these are really, really hard experiments to do,
because the people who have done them historically have been going into mines in South Africa,
five miles deep into the ground, finding these weird communities at the bottom of boreholes.
And it's really difficult work to do.
And so no one's been able to really map that line of,
hey, where does chemistry transition into biological molecules and then biological molecules into cells?
Because our technological ability still lags behind the questions that we ask.
It's a very, very difficult thing to do on a biological level,
if you're applying the tools of biology,
to be able to map the line between molecules, complexity, and cells.
This kind of thinking is a lot too vague for me.
I think you need to be much more concrete.
In my conversation with Michael Levin, he did not attribute the bill to cells,
and maybe this is because he didn't get around to it.
The way in which he characterizes the interaction between cells might include something like
individual cells are not performing a particular task,
because they are mechanically forced to, but because they are bullied by the environment into this particular task.
Not so much unlike an individual in a society fulfilling a very specialized role,
in large part because the environment bullies them into it so they can survive.
They need to find a niche and adapt to it and specialize.
And this is a similarity to how the cells behave.
And the cells behave like this because they have enough degrees of freedom,
as per their genetics, to find a specialization, giving the right environment.
And not all cell types are able to do this and will not be able to survive under these conditions.
It's still all very mechanical.
And when we talk about will in the context of cells, the question is, are you using a metaphor?
And more importantly, when you talk about will outside of the context of cells, are you still using a metaphor?
Or do you actually know what it means?
Are you able to formalize your understanding of what it means for a system to have a will?
Do you understand what it means for a system to desire something?
Can you break this down to those basic components?
What are the necessary and sufficient conditions for something to have a will or for something to have a desire?
I think I can because we talked to Karl Friston and our conversation with Karl Friston was kind of about this,
where his concept of the free energy principle, I think, outlines this.
And then we talked to this guy, Brett Kagan, who built this thing at Cortical Labs,
which is a chip with neurons on it that they trained to play Pong.
Did you see this?
Okay.
So do you want to try to find a will or desire?
Yeah, I think that will or desire is so organisms, cells, whatever you want to call it,
life has a way of pattern matching expectation to reality.
And when expectation and reality align, then there is equilibrium.
But when expectations and reality are misaligned, will is the process by which those are brought back into alignment.
And life is the only thing that can do that, I think.
Shaila is cheering. I appreciate that, Shaila.
I just think we have to be really, really careful here to separate out the physical bodies,
the organisms from the phenomenon, the occurrence of life,
which is what is on the table in terms of perhaps occurring at a level prior to the organisms themselves,
which is, I think, what Anastasia is talking about.
I mean, I think it really comes down to do you believe in hypotheses?
Do you think hypotheses are a necessary part of understanding the universe?
Because these are things which, in Descartes' definition, are sufficient to prove the theory,
but are not necessarily assumed to be true.
So you have to make these leaps like, well, it's possible.
It really comes down to whether it's possible or not when you're generating hypotheses.
Is it possible that this fundamental phenomenon, life, is occurring at other levels
besides the ones that we have empirically observed?
The simple question is, can the words that you're using do the work that you are assigning to them?
When you say life, you are referring to a conceptual structure,
and the conceptual structure needs to refer to causal structure.
And the causal structure needs to interact with all the other components of your model of the universe.
And when I say life and I say itself,
I don't mean that there are no other equivalent structures in the universe that behave in a similar way to cells.
I'm completely open to that.
I can also simulate stuff in a computer that behaves a lot like cells and has similar qualities.
When I decide to not call this life, then it's a terminological decision.
It's not some deep philosophical statement that I'm making.
Just when I think about what biologists have been studying when they talked about life
and they pointed into nature and stuff moving in there,
they were very puzzled about what it was.
And at some point, they reached a tacit agreement.
And this tacit agreement is really the dynamics of cells.
And viruses are not included because they are below that level.
And a car, for instance, is built by an arrangement of cells, but itself is not life.
Even if the car is self-driving, it's not a life.
Hold on, hold on, hold on.
And even if the car would be self-reproducing, it would not be a life according to most biologists.
And if you were to try to change that definition, you can do this.
And maybe you find it helpful in some contexts.
And just make sure that you still keep a word that allows you to talk about the dynamic of cells.
It's insanely conceivable that there is stuff that is indistinguishable from what biological cells are doing on Earth
that are not based on carbon, but that use completely different chemistry.
Maybe there are other solutions for building stuff that is cell-like.
And there might also be solutions for building self-organizing systems
that adapt to changing circumstances via evolution or construction.
And they could also maybe not be based on some membrane with self-replicators,
but maybe there is some other principle that makes them possible.
And whether we call this life or not ultimately is not important.
Just make sure that we are pointing at the right thing or at the same thing when we are using the word.
That is not an issue for me.
So this is not where we deviate.
But when you say that control is will, then I have a disagreement with you.
Because what you described with respect to a system that measures a deviation from some kind of target value
and when there is a deviation, it's unfolding a dynamic to reduce this deviation.
There is a name for this. It's called control.
And the thermostat has that already.
And I wouldn't say that the thermostat has will.
That is basically putting too much depth into what the thermostat is doing.
Because if a person would be acting like a thermostat,
I would not say that this person is acting out of a desire or is a will.
It could be also compulsion.
There are many ways in which people do things that are directed on a goal that are unrelated to desire and will.
Desire and will are much more specific terms.
And I wouldn't want to mash them up.
Another thing that is important is trace where a term comes from
and not necessarily where it comes from in the outer genealogy of scholarship.
But where does it come from in your own mind?
At which point did you form this concept?
What does this concept actually refer to in your own mind?
Reverse engineer this.
Break this down into actual observables and generalizations over observables.
That is for me the way in which I think.
So when I talk about will, I talk about a phenomenon that exists from the perspective of a willed observer
or of some observer who is observing a similar dynamic.
You can't use the word in the definition.
You can't use the word in the definition.
So define will without using will.
I think you can do it.
Will is a representation of an intention that is upstream from the self.
There are some slight differences.
There are people which have will outside of their self and there are some people which have it inside of their self.
What happens in this difference is that when you have will outside of yourself,
you experience yourself wanting something, but you don't have control over what you want.
You are just the thing that is tasked with making that happen.
So you are forced by your will to do things.
There is a part outside of your control, it's still outside of your mind,
that is producing an intention that is directing your behavior that something is committed to.
And that typically is happening in the service of some control task
that your mind has established with respect to the environment.
But what's crucial about the will is this internal representation in which you experience it as a motive force
that you have to resolve.
There is another sense in which will can exist.
Some people do not seem to experience this will outside of themselves,
but instead what they experience is pleasure and pain and purposes.
And then they have to find a goal by themselves to resolve the pleasure and pain
and to realize appetence and avoid aversion.
And so the will is something that is created inside of the reflexive mind,
this motive force that keeps them going.
But it's mostly a redirection of pleasure and pain into action.
And so in some sense there are different architectures of the self
on top of the mental architecture of control that we have
that give rise to different types of understanding will
and different notions of will that we observe in different psychologies.
But will is always something that seems to be dependent on an observer
that is conceptualizing a self-model.
And it exists with respect to that self.
I'm not sure if the self has a self-model.
I guess that even if some might do, which I somewhat doubt I don't have evidence for it,
the majority of cells probably don't have a self-model.
So cells are giant PID controllers in your world
and only the assembly of them allows for the emergence of will?
I think that cells are not coupled richly enough to the environment
to make it necessary for conceptualizing their own agency
from the perspective of an observer.
So the cell can probably for the most part perform its actions
without building explicit representations about them.
And especially not advanced representations like their own agency.
So they're acting entirely under that external will paradigm?
No, there is not necessarily a will involved.
They're just mechanical in the same way as a thermostat.
You said something really interesting, which is that you don't think that cells
are sufficiently coupled to their external environment.
I come at this from a microbiology perspective.
So I did my PhD in biofilms and specifically in electrical signaling in biofilms.
And so we studied these little molecules called phenosines
that change their oxidative state and they get shuttled around the biofilm.
And the state of their oxidation is informing gene transcription, cell behavior, everything.
So you have this complex system inside the biofilm
that is mediated by electrical signaling.
And you put that in front of somebody and they're like, well, that's just cells doing stuff.
But I'm like, to me, that seems that if you run that program for long enough,
you end up organically at multicellularity and bodies
and progressively more and more complex systems.
And everybody's always looking for the place where, like, where does this quality evolve?
Where does this quality appear?
At what point of complexity does it suddenly come into being that you can have will?
And my thought is that the will exists in a really simple rudimentary form inside of those cells,
the bacteria that are tightly coupled to their environment.
They have so much information coming into them.
And the set point that is maintained inside of them is so much more complicated than a thermostat.
Like, have you ever looked at a diagram of cellular metabolism in a bacteria
that can use, like, 15 different substrates to grow off of?
I have no doubt that it's complex.
The question is if there is a representation.
And I think for a will, you need a second order representation.
Basically, you need something that is conceptualizing itself as an agent
and is observing itself doing that.
You need to have some kind of reflexive self model to have will.
It's a technical definition.
There is nothing normative involved.
It's not that I require something to reach the magical complexity barrier.
I require it to have a particular causal structure.
And I am open to the possibility that cells might turn out having such causal structure.
That's not the point.
Just read Greg Beer's book, Blood Music, and it's written in the 1980s.
It's a science fiction novel that is absolutely brilliant, but it's terribly written.
It reads like doctor's fiction.
So the style of writing is almost unbearable to me.
It's like Asimov.
But the idea is brilliant.
And he basically describes the end game of AGI taking over the planet,
but he describes it via biotech.
It starts out with some guy in San Diego reading lymphocytes
that have the ability to make their DNA read right
and have a feedback loop through the RNA and in this way wake up
because they become self-editing and general function approximators.
And then he trains them to solve labyrinths
and gets the individual lymphocytes to the intellectual level of a mouse.
And then he is forced to stop the experiments because his employer doesn't want him to.
And he carries the experiment home by injecting his own modified lymphocytes back into his body
and turning Armageddon.
Okay, so immediately from a scientific perspective,
I don't think that you can get the lymphocyte to solve the maze.
But if you trigger the lymphocyte to turn into a multicellular organism,
then you probably could.
Because what you need in order to reach that kind of solving complexity
is an interrelated set of modules that are able to feed back onto each other
and then to get many pieces of information about the real external state
versus the thing that they want.
Yes, I agree. There are multiple issues with this story that he wrote.
The one that you're pointing at is, of course, he made his labyrinths extremely small.
And he built it in such a way that the receptors of the cell are sufficient
to get a sense of the environment in the labyrinths and they can navigate it.
But of course, there is the difference because the mouse is using optical sensors
in addition to touch.
And so the mouse is able to see over a large distance
in a way that is more difficult for a cell to achieve because it doesn't really have eyes.
And even if it has photoreceptors that are somewhat directional,
it's not going to get anywhere close to eyes.
So it's going to be difficult for the cell to make a model of space
at the same speed as the mouse would be doing it.
And the other one that is more profound, I think,
is that Greg Beer overestimates the capabilities of the mechanical computer
built inside of the cell.
So basically, even if you speed this up and give it more memory and so on,
it's still going to be awfully slow.
And it's because you cannot really parallelize what's going on in the individual cell
in the same way as you can parallelize stuff in the brain.
So you can deal with the fact that the brain is awfully slow,
but the brain is faster than the operations on DNA and RNA
And the reason for this, just sending a signal through cells,
is built in such a way that the cell only needs to trigger an internal switch
that's much faster than performing read-write operations internally.
The cell is also performing some read-write operations while it does that,
but it does not need to wait for the result.
It's able to do this on the site and offline and is fine
with these results being available with the delay of hundreds of milliseconds maybe
or at least tens of milliseconds or sometimes seconds.
The signal can pass quickly enough and gets modulated in the right way
almost instantaneously.
And still the brain is working at roughly the speed of sound
rather than an appreciable fraction of the speed of light as computers do
that we are building.
So I think the capabilities of even a really pumped-up cell
are going to be far below the capabilities of even a nervous system.
And I might be wrong.
So it might be missing possibilities of what can be created
in the chemistry of a cell in terms of computation.
And for instance, Lee Cronin has his big hopes for computation
of building Turing machines entirely out of chemical operations
without having mechanical parts in a sense.
And he hopes that he can make them much faster.
It's to read a very interesting open empirical question
how fast this can go.
But what we see is that the smarter organisms on the planet
are typically many, many cells that have particular metabolic enhancements
for making these cells work very fast and send information very quickly
so they can perform rich computations about the world.
And this being coupled means that you have many sensors
that are working in many modalities quite reliably with a lot of redundancy
over large distances where you see meaningful differences in the world
about which you want to integrate.
When I look at the AI landscape, I use a number of the AI tools in my daily life.
I sense nothing even approximating life in them.
I sense no sense of this will, for lack of a better word.
No sense of the ability to actually come up with new ideas.
The ability to conceptualize seems highly unique to life itself.
They're very useful in assisting me when I have an idea
and I know how to execute it and I can get assistance.
But when I hear these futuristic visions of this artificial general intelligence,
it doesn't seem like a natural leap from what I see in the world today
being called artificial intelligence.
It doesn't seem like a steady linear evolution.
Am I missing something?
Is there something incredible going on behind the scenes that I'm not aware of?
I guess if I were sitting down with a few computer scientists
and we were pointing at philosophers and we would say,
there's nothing in this realm which reminds me of life.
There's nothing creative there.
There is no meaningful interaction with the world in which we interact.
You could say that from some angle and some abstraction
to some projection that you can make, that's approximately true.
But if you were a philosopher, you'd probably think it's grossly unfair.
Hold on, hold on, hold on. I want to clarify that.
Because what Shiloh is saying is he's saying that
in the process of interacting with the tools
and the kinds of responses that you get,
there's something about talking to a human being
where you say something that's imperfect
and that being can understand what it is that you're saying,
integrate it, match it onto something that is outside of your experience
and build upon it.
And so if you were interacting with someone,
there's always the feeling that there's life there.
And it would be hard to interact with another human being
and walk away thinking that there's no life there.
But you can interact with a computer program, I think is what Shiloh is saying.
I think it all hinges on the ability to conceptualize.
And what I mean by that is the most primary form of concept
is a physical concept where two bodies are interacting,
say one body crashes into another.
But from there, you can get higher levels of conceptualization
which terminate in these things we call ideas.
And nobody really knows where ideas come from.
Obviously, if you're a theorist or an artist or whatever,
you have this experience that an idea just hits you all of a sudden.
And when you're having a conversation with a human being,
you're often generating ideas between the two of you.
But I've never had anything approximating that experience with an AI interaction.
I don't sense that they have the ability or will ever have the ability to conceptualize.
How do you know that nobody knows where ideas come from?
Maybe you can tell me where ideas come from.
I have an impression that I can usually trace where my ideas come from.
Interesting.
I write a lot of music and occasionally a piece of music will come to me fully formed.
I'll just have a vision of it.
Other times I'll sit down at the piano or with the guitar
and I feel music coming into my hands.
It's a very strange feeling.
But I'm sure that anybody who's out there who is an artist has experienced this.
And it doesn't seem like it's being rationalized in the moment.
How do you feel that this is different than you are prompting an AI model to put you as a picture?
I do. I feel like I'm giving it the ideas exactly.
I feel like I am the idea generator when I'm interacting with AI.
But when I'm having a human interaction, say I'm playing music with another person,
I feel like that person is generating ideas as well.
We're both making a new vision by combining our individual abilities to generate ideas to conceptualize.
Whereas I don't have that experience with AI.
I feel like I'm the one doing the ideas and the thing is just sort of doing what I tell it.
I find that my own mind is more like mid-journey than it is like Delhi when I produce ideas.
It's precisely prompting my cortex to generate the solution to some creative problem that I have.
And creativity for me involves three things.
There's first of all novelty, something that was not known to me or anybody in my direct environment before,
that is already there for me.
The second one is that it needs to be somewhat disruptive,
which means it's not the result of just following the gradient to the most obvious solution.
But there needs to be some reorganization of the space necessary, basically some jump into the darkness and landing on the other side.
You basically bridge discontinuity in the search space if it's meant to be truly creative.
This doesn't mean that the other stuff doesn't exist very often.
You just have a design problem where you are following a gradient and you come up with the best solution under the circumstances.
It's an optimization problem.
And creativity often goes beyond the simple optimization problem by having to find a new representation.
And the third one is authorship, which means it's transformative.
I get changed to the creative act in such a way that I cannot do it again while being creative,
which means to integrate the outcome of the creative process and it changes me into something that has already done that.
So I now have that representation.
I already know how it works and I can do the next step.
And arguably this last part is missing in the current breed of AI models,
but it's something that in principle could be integrated,
which means that we train the output of the model again into the model at every step.
And the model remembers that this is something that it has done.
It's also remembering all the interactions that it has to this the environment.
And in this sense, it becomes a discernible voice.
And I think this would be a prerequisite for turning an AI model into something that is able to create art.
At the moment, it's not in my perspective.
It is producing artifacts that look a lot like art,
but they don't fit my technical definition of art yet.
Dali has a wide range of styles that it's going to produce,
whereas mid-journey always has a particular aesthetic.
And that's why I say my mind is more like mid-journey,
because most of the stuff that my mind is creating, I recognize my own aesthetics.
And I'm able to go away from this and emulate other aesthetics to some degree,
but usually I recognize myself by default.
So I'm biased towards a particular kind of aesthetics in my own mind, even when I'm creative.
But do you ever think that the computational systems, the artificial intelligence,
will ever reach a point where they're able to look at the landscape in any particular domain?
Say they look at all of the data concerning, I don't know, how the atom behaves,
and they're able to actually suggest a theory, a new concept to you.
Hey, I think you humans are looking at it all wrong.
It's actually like this. This is the cause and effect explanation.
Do you think that that level of conceptualization is possible?
Because I've seen no hint of it whatsoever.
Without being asked, I think, is the important part of this.
Without you telling it, you are an AI that focuses on atomics.
And solving the specific question of gravitation or the specific question of electromagnetic.
The problem is the current generation of AI models. They are frustonian, radically frustonian.
The only thing that they do is basically to minimize the free energy.
They try to minimize the prediction error.
They make a prediction and then, during training, that's what the transformer is doing.
And then they minimize the deviation between the observed thing and what they predicted
by changing the structure of the model. They do this gradually.
And the transformer is a way to optimize this process.
In some sense, it's what almost all neural network paradigms are doing.
It does this by making statistics over.
We need to make the statistics over so the training becomes more efficient.
And it introduces a way to make this in parallel.
So you can use many GPUs in parallel to process the entirety of text on the Internet
or hundreds of millions of pictures simultaneously.
Otherwise, this boot-force training method wouldn't work.
And our own mind works in a very different way.
It is based on optimizing for coherence, I think.
And consciousness is a tool for achieving this coherence in a self-organizing substrate.
So basically, to becoming a coherent observer, you need to establish the notion of being a coherent observer.
And consciousness is related to doing this.
You notice when you are conscious that you have a percept of being a reflexive observer.
This basically means there is a control process going on
that is checking whether you are actually still a coherent observer or spacing out.
And by implementing this control process, your observation process is able to keep itself stable.
And the process of that observation process is to construct coherence in the world where it's not readily apparent.
And so we don't just try to minimize deviation from expectation when we observe the world.
Instead, first of all, we try to filter all those parts that we can interpret in some sense and ignore the rest.
And we have a fringe around this, some boundary,
where we gradually, step by step, increase the amount of stuff that we can interpret coherently.
And this is all happening in the service of agency.
We built our models for aesthetic reasons.
But ultimately, your neurons are being paid to discover structure for producing your ability to change the universe itself,
so you can survive and make the future compatible with you.
And it's something that we don't do for the present AI systems.
They are not built to maximize their own agency, and they are not even built to maximize their coherence yet.
Coherence is something that forms in the limit.
If you give them more data, they become more and more coherent until they approximate coherence to a sufficient degree
to convince people who are playing with these models that they are talking to something that is more coherent than most people are.
This is also the other issue.
We talked to a bunch of philosophers to tell you AI models don't understand what understanding means.
But you ask the philosophers, and they all agree that they don't have a shared understanding of what understanding means.
So AI models might be our only chance to get there.
Because the brain is so small.
That's an interesting thing, which is that the brain is so small,
and so if we are limited by the complexity of our brains, to go back to the lymphocyte example,
you have a lymphocyte that you put into the maze, there's a limit to how fast it can solve it,
because there's a limit to the amount of parallel processing that can go on inside of a cell rather than inside of a brain.
And so we accept that there's a difference in ability between a cell and a brain.
And so we should also assume that there is a difference, a complexity ramp between brains and a network of brains.
Because your network will be a product of the complexity of all of the parts, because that's the number of processes that you can run.
So to my mind, the complexity inside of an AI system doesn't reflect the complexity inside of a brain.
And so if we want to ramp our intelligence to the next level, we have to have the network of brains,
not a network of AIs that are less complex than brains.
Because the AI model right now, if you ask it what is understanding, and it doesn't have a good definition for it,
it doesn't have a good definition for it because in all of its training data, there isn't an explanation that it can find.
It's limited by its training data.
And it has no demonstrated ability to come up with its own definition set that is more coherent.
Yeah, that's what I'm trying to say.
Whereas if the training data set doesn't have anything that approximates that explanation,
it doesn't have the ability to do this next order modeling, which is, okay, this is how explanations are arrived at.
And I have to do this process with all of the data that is available to me in order to get to a place that doesn't exist in the data.
And it seems like people believe that it's possible to teach AI to do that.
But you'd have to mathematically conceptualize what it means to arrive at an explanation.
And that's where that weird thing of where the hell does an idea come from begin.
Because if you're sitting somewhere and all of a sudden out of nowhere, you just have an insight.
And you're like, I don't know how I got that insight.
There's not two or three things that I connect that linearly produce this emergence of something new.
You can't mathematically program that because it's random.
It's a collection of things just in the right moment.
Your own resonant internal state is at this receptive place where this sounds crazy.
It sounds crazy, but I think that we agree that biology has a lot to do with phonons, with the resonance inside of materials.
And so the resonant inside of your brain at that moment is just right to be able to catch on to the resonance of something that's outside of it and then from that to produce an idea.
But that to me seems computationally intractable to give to a machine unless you have something that is this wet squishy thing that can resonate, which is the brain in this model.
I think that's not secretory. There are many good observations that you're making.
For instance, you observe that your reflexive self is for the most part unable to observe your idea generation process.
And there are many obvious reasons for this.
It's often a feedforward network that is built in such a way that its function cannot be decomposed into a grammatical structure that you could rationally trace.
So basically building a perceptual system that is working on your mental processes would be hard if you are using a feedforward network with a high degree of parallelism and superposition in the states that are being computed.
And phonons are a very good metaphor, I think, for a lot of what's happening in the brain.
There is a book by the ART guy.
Let me check. Just blanking out.
Grosberg, Adaptive Resonance Theory.
Are we having him coming on the show next week?
Yes, he's really great.
He basically tries to describe the entirety of processes in the nervous system as resonance processes, and I think it's a very productive paradigm.
At this point, I think nobody has turned this into a computational model that produces all this, but many good ideas in this framework.
But it's still computational. There is nothing that is paradigmatically different.
It's just a particular way to look at the computations.
And I keep saying that I guess that sometimes a better metaphor for what the brain is doing is not circuitry, but it's something like an ether.
And the medium of the propagation are neurons and adjacent cell types that are taking the signal and reaching it forward to other cells while modulating it.
And all the computations are taking place in these activation fronts, and these activation fronts, for that thing to work, need to be periodic.
So there's basically cyclical waves that are passing through the neural substrate and producing behavior.
And this spreading of these activation fronts is so slow that it's roughly at the speed of sound.
So phonons is not a bad metaphor.
And very often the neurons are not deterministic, which means that given the same environmental configuration, the neuron is not going to go into a single particular state, but in one out of multiple states, because they're not completely deterministic.
And this means that if you want to guarantee getting a particular kind of result from this, you need a bunch of neurons.
So statistically of them, most of them are going to get into that state.
But what the others are going to do is that they sample a space of function that is adjacent to the result that you want.
And this gives you sometimes more power, because instead of having to train your neurons to perform one function only, you can constrain them to compute a bunch of functions simultaneously and then voting on the outcome of the results.
It's a slightly different paradigm in thinking about how this computation works in the brain compared to our digital computers, which I think is responsible for the fact that our brains are so efficient despite being so abysmally slow and unreliable.
And if you look at the graphics card, they have so much larger memory than our brains and are so much faster.
Why are they so less efficient, so little more efficient than what our brain is?
It sounds like you're saying that crossing this conceptual barrier requires a hardware shift in the pursuit of artificial intelligence.
Not necessarily. I know a bunch of people who are working on neuromorphic chips.
And my own intuition is that if your main task is or main mission in life is to figure out how the mind works, don't start with building hardware and then trying to figure out how to get software to run on them, but simulate your hardware first on a GPU.
And there is some evidence that for most of the existing neuromorphic chips, you can simulate them on a GPU.
And that's basically running software that works like this requires you to constrain yourself to something that only works in the way in which a neuromorphic chip does and not using all the capabilities of the hardware.
So basically it seems that our hardware is luring us into using classes of algorithms that are suboptimal because the hardware is so powerful.
With biology, it feels like a lot of its functionality comes down to resonance and these multiple states of resonance that layer onto each other and then produce action.
Is it possible to encode analog resonance into a digital system?
Yes, of course. The thing is that the analog resonance has a finite resolution.
The resolution is actually usually quite small until it gets drowned out in noise.
And it's similar to having an analog record on a very coarse vinyl substrate.
To build a CD-ROM that is able to exceed this resolution of the analog substrate is not hard.
It's just a design solution that you're taking.
And so in some sense, if you are willing to accept that your software needs to be slightly different on every substrate, you could build noisy analog chips that require less energy to run than deterministic digital chips.
But the price is that your software needs to be adaptive, that it needs to deal with how your hardware feels today.
Yeah, and that seems to be something that is key to biology.
It's the adaptability. It's the fact that today you don't feel like you did yesterday.
And so the product of everything that you do is different.
And I think that that's not a bug in the software.
I feel like that's actually a function for creativity and evolution and desire and will.
And I mean, I think that it starts well before the complexity of a human, where that's the case.
I once woke up after a major surgery and asked people how the surgery went while being still in the ER.
And they told me and they were visibly disturbed and asked them what was going on.
And they told me they had the exact conversation like for the third time.
And it was because part of the anesthesia that I've got inhibited long-term memory formation.
It was still active while I was in the ER.
So I would not have been able to form a long-term memory trace of the conversation that I had.
It was only playing out in working memory.
And then I fall asleep, woke up again and had the same conversation pretty much word for word.
This means that my macroscopic behavior is pretty deterministic.
And the reason why it doesn't repeat is because I form memory that stops me from repeating.
Because I don't need to do it again.
It's also the reason why older people repeat themselves because they don't form long-term memory traces of the conversation.
That's terrifying.
Yes, it is.
I don't know. I think that that actually fits really neatly into my picture of nature,
where life is a form of long-term memory formation.
The structure itself of this heritable information that is modulated over the course of your life
and then passed down to your offspring through an epigenetic mechanism is basically the whole point of life.
And it seems pretty straightforward that on a processing level,
it's relatively easy to lose that when some system goes offline.
But that just speaks to the way that our brains are a more complex version of what life is already doing on the most basic level.
I don't know how much information we can actually pass on epigenetically to offspring.
Ultimately, I think that's not a question of what's the most poetic interpretation of reality, but an empirical question.
I don't know how much racial memory I've got epigenetically for my parents.
Who knows? Maybe we'll figure it out.
But I suspect that most of the stuff is just passed on genetically, and the rest is observation.
There are probably a few bits that can be encoded during the lifetime of my parents into sperm and eggs and then expanded in the next generation.
But I suspect it's not that much because this recording mechanism will be very hard to implement.
And so I suspect that most of the transmission of information across generations happens by explicit communication between parents and children.
You might be right to some degree because there is a twin studies are an interesting insight into this
because you can take people that are twins that are raised under different conditions,
and then you find out what contribution is maintained on a genetic basis and what contribution seems to be defined by environmental considerations.
But from what I can tell, you know, actually, I don't know enough about this.
I have to read more twin studies in order to be able to evaluate how much is.
I think that is a romantic hope that we can break out of the genetic determinism by some magical epigenetic mechanism, but I suspect it's not going to work.
I want to go back to what you were talking about with the hardware advancements that are necessary to produce anything approximating artificial general intelligence.
And it occurred to me that in a digital system, you might have a very high level of resolution.
You mentioned the CD versus the vinyl, but when it comes to actually recording the information in the first place,
people who work in audio recording prize analog equipment because well, not because it is high fidelity, but because of the harmonic distortion that it introduces.
And I wonder how much of our conscious experiences are predicated on that harmonic distortion in a constructive sense that it adds a level of richness to our experience that wouldn't be possible in a digital system.
I suspect that a lot of the limitations of digital equipment are due to cost reduction.
Basically, in order to make this thing work, it's not going to exploit the limit of what's technologically possible, but it makes measurements on a number of subjects in an app under controlled conditions.
And when the subjects are no longer perceiving any kind of difference to the analog signal that you're done, you don't need to be much better.
Maybe you put in some safety margin and then you're good.
And then you can basically scientifically prove that you now have a recording that has higher quality than vinyl.
But this thing is working based on some assumption.
For instance, when you look at an RGB screen, the pigments of the RGB screen are producing signals that are tuned to your receptors.
But there are interpersonal differences between the receptors.
Some people are sensitive to slightly different wavelengths.
So if you only use three types of emitters for light to simulate the entire spectrum, you're not going to get the same result for everybody.
And a similar thing is happening with audio.
Basically, there are people which are way more sensitive in some frequency areas than others.
And if you have an analog medium, your brain has to piece out from this analog distortion what the result is.
And there are no gaps in this analog signal.
There's basically this smooth property of the signal.
And that is something that I couldn't appreciate so much when I was younger.
And now I notice that when I look at heavily processed digital film material that I often feel that I see differences in the grain where some filter has been applied and then the filter stops being applied.
And this annoys me.
I look at the Villeneuve dune and I look at the CGI and it's very unsatisfying to me because I feel that the foreground and the background doesn't match.
There's something completely wrong.
I cannot put my finger onto it.
And so when I look at the much more primitive tricks in a Kobozara movie that are entirely analog, I find it's much more digestible because I don't see this cutoff.
It feels to me that there is some kind of smooth continuum into it.
But I'm still not willing to romanticize this into thinking that analog is in principle superior to digital.
But it could be that if you want to get something that is completely equivalent, we need to do a much higher resolution on the digital substrate.
I mean, there's been an incredible advancement in the last 10 years in the audio recording realm, which is where I'm most comfortable,
which is that you create plugins, you create modules which are capable of introducing that harmonic distortion.
But you have to know that you want it in the first place and you have to know that you're modeling something in the analog world and that that distortion turns out to be really important.
When people first started getting all of this high tech digital equipment in the 90s, they were immediately struck by how cold and despite all of its high fidelity, it sounded awful.
And they had to really go back and analyze what it was in those particular distortions that they wanted to keep.
And there's really a high art to introducing those distortions in a way that keeps the music pleasant to the ear while actually ruining the high fidelity of the signal.
It's an interesting paradox.
I noticed the weird thing that when I look at audio recordings from classical music, there are a lot of recordings I cannot relate to and a few that work much, much better.
And I talked to some of the pianists and I had the impression that there is some correlation between the pianist being synesthete and this music working on me.
And they describe a similar thing that sometimes they have the wrong piano and they're not able to experience synesthesia while playing it.
That's what doesn't work for them.
And this synesthesia relates to your brain going into resonance at some level using obviously has to do with overtones in the music that you may not consciously perceive when you listen to it.
But it has something to do with because you're not reflecting on it is how your perceptual system is processing the data.
And the gap between how perception works and how your mental conductor is listening to what the instruments of your mind are producing is responsible for some difference.
So you might not be consciously noticing difference between stimuli, but your brain might be.
And so this thing that you noticed that the music that at some level is indistinguishable to the listener is producing a different mood and listeners might have to do with their subconscious processing going on that leads to a different outcome.
And will that level of processing ever be available in the digital realm to artificial intelligence?
I don't see why not. I suspect that AI is already processing at much higher resolution.
The problem is that the model often doesn't know what the ground truth is that it would resolve to.
So I suspect that we could in principle build AI systems right now that are able to read thoughts of people.
But setting up the training with the present stack of algorithms is very hard.
Well, I would think that one of the barriers to being able to create that kind of digital emulation of a mind is understanding what kind of overtones and resonance needs to be brought into it.
Because when Sheila is talking about plugins that emulate analog equipment, what they've done to create those plugins is that they've gone and they've looked at the resonant properties, the harmonic properties of the original analog equipment,
characterized how they emerge from various sounds, and then apply that function to the sound that's inside of the computer.
So if you don't have that characterization of the resonance in the first place, you can't possibly program it into the computer because it is a resonance that is necessary to know.
Yeah, it just seems like these things are always one step behind us. No matter what happens, they can't get out in front of...
Yeah, it's much more complicated than this. For instance, I bought the AirPods Pro because Apple removed their headphone plug from the iPhone and I could no longer use my pretty decent analog headphones.
And I hated them because they sounded worse than $20 wired Panasonic earplugs.
And it was just very uninspiring sound. It was not that there's obviously something wrong with it, but there was really nothing I liked about it.
And then they died after a couple of years due to an Apple manufacturing defect that they started to crack a lot of half that it was out of warranty for a month.
So I could not get a replacement from Apple and had to buy the AirPods 2, AirPods Pro 2, these ones. And they're amazing. They're magical.
They're not audiophile. They don't sound super realistic, but they're like a brain implant.
They're able to make my brain resonate with certain frequencies in a way that I could not get with other audio devices.
So for particular types of music sounds, especially electronic, they work much better than other types of headphones for me.
It really depends on the kind of interaction that you want to have. A lot of the analog equipment that sounds very warm is not necessarily sounding realistic.
It is producing a particular kind of experience that you want to have.
Because it's tickling your nervous system in a particular way.
And there is a lot of stuff that can only be done electronically that is difficult to achieve with analog equipment.
You just don't need all that resolution, right? I don't need to hear.
There's very few singers that you really want to hear every aspect of their mouth moving and so forth.
Sometimes you do. So there is stuff that I can hear with this that is difficult to hear on very high fidelity equipment.
Because it is artificially, at least that's what it sounds like to me, expanding some of the range.
And so you're able to hear stuff that is much harder to hear in unprocessed sound.
And the processing for some types of music really produces a good effect.
And when you are sitting in an airplane, there's a lot of environmental noise and an environment that is mostly an animal rights violation.
And you have this thing that is overriding some of that. It doesn't need to be extremely high fidelity.
It just needs to capture your nervous system and produce the right kind of resonance that you're interested in.
This reminds me of... What was that? Was it R-Bass?
The program that would produce bass frequencies that could...
There's some kind of program that people use for small speakers that can't actually produce bass waves.
Oh yeah, R-Bass, the plugin. Sorry, yeah. It's a waves plugin for audio engineering.
Shout out to waves.
But it's basically a way of taking the harmonics that would be produced by the low frequency wave that your speakers can't actually produce
and propagating them into the higher range of frequencies.
And so creating this kind of phantom bass note that you hear the actual bass note by extrapolating where it belongs.
Saxophones work like this too, for a more analog version.
But you're actually hearing the overtones and your mind extrapolates the fundamental from it.
That's fascinating.
And so it seems like that's what this is doing, which is that the headphones probably understand the kinds of frequencies that are necessary for richness
because they've studied it enough, they've characterized what creates a rich resonant sound
and then they're able to tweak the waveform of the song in order to get it to be more in tune with the way that you want to hear it.
And so what they're doing is they're tuning your brain in relation to the tech that's producing the sound.
And that kind of gets me onto the next set of topics, which is how technology that we are developing seems escapist to some degree.
And it seems like instead of addressing that the way that airplanes operate is an animal rights violation,
we produce the technology that allows us to tune out of it and to just accept the world as it is and to just shuffle along until we can get into a different environment.
Most of nature is an animal rights violation.
Most of the stuff that happens outside of a factory farm is worse than the stuff that happens inside of the factory farm to most conscious beings on the planet.
I elaborate on that because I don't know that I agree.
I think this idea of living free in nature is easy to romanticize, but evolution is very unpleasant for most of its participants.
And I think that life on Earth itself is something that is full of pain and it's undesirable.
And we have opted out of this for good reasons.
It's creating a highly artificial and often alienating environment.
There is an evidence that people feel more fulfilled when you get rid of all the creature comforts and you have to fight for your naked survival because you don't have time for depression.
And so a lot of the alienation that we experience is the result of, in some sense, being too comfortable for us.
And that we need to escape from this is also something that increases discomfort.
But there is no easy solution, no easy way out of it.
It's a peculiarity that we find ourselves in.
And it's also something that enables the kind of conversation that we have right now.
This thing that you are sitting in your remote studio and we're having a Zoom conversation while I'm sitting down here in Mendo Park.
We're talking into our microphones and listening to each other through the headphones.
You could say there is something escapist to people listening to the effects of that.
But there's also something valuable to it.
We produce a cultural artifact that otherwise wouldn't exist.
There is the wild guess train to meet itself in our conversation.
And don't be too judgmental about that.
I'm just curious if you can sell me on this factory farm thing.
Because when I think about the fundamental difference, it's that the animal is able to express its agency in the wild.
And it has one bad day where maybe it's shot in the head by a hunter.
But the animal in the factory farm comes to understand that its freedom is restricted.
And it suffers its inability to actualize itself on a day-to-day basis.
And that's what is fundamentally disturbing to me about factory farms.
There is a Chinese author, Liu Qixin, I probably mispronounced him, who is most famous for The Dark Forest.
And he wrote a short story, and I hope I don't misattributed him, but I think it was him, where he describes how a few aliens arrive on Earth.
And they say that they are the last survivors of a planet that has been destroyed by a planet eater.
The planet eater is something like a spaceship.
It's larger than the planet.
And it is a traveling civilization that basically goes from planet to planet and harvests its biosphere.
And it's so strong that it's basically impossible to defend yourself against it.
But humanity has a head start because they meet this fugitive who gives them an advance warning.
And they build a major fleet and planetary defenses.
And when the planet eater spaceship arrives, they manage to make a minor dent in it before they are harvested.
And this gives the planet eater civilization a lot of respect for people.
And they try to sample them and realize that humans are actually quite decent food species.
So they get promoted, which means that part of the human civilization is allowed to go on board of this planet eater civilization and permanently live as a food species there,
which means they will be treated exceptionally well.
It's a very advanced technological civilization, a very good life, at the end of which they will be painlessly killed and eaten.
And there is this big conflict between the heroes of the story,
the ones who are building the army to defend Earth and their children, who decide to go on this ship.
And the children think that their parents are insane to resist because life is objectively so much better as a food species than it was before on Earth.
Everybody is so much more fulfilled and so much more happy and has so less stress out
because the aliens are just organizing the best possible experience of life that you could have.
Factory farms don't organize a good experience, right? By definition, that's the problem.
But it's just the imperfection that they have, right?
You could have a factory farm that is producing a better experience.
And it also makes sense for the factory farm to do this, for some reason, right?
Because animals that grow up without distress and unnecessary suffering probably grow up more efficiently.
Suffering is just friction. It's something that is suboptimal.
And I believe that in some sense Garden Eden is about this, right?
The Garden of Eden is this place with lush agricultural production and no screaming,
which implies it's a factory farm in which everything is fully domesticated.
Everything is fully submitting to the will of the Creator.
And that thing that defines us as humans, this food of knowledge, the freedom to defect,
the freedom to play short games, the freedom to not submit to the divine will
before we are able to recognize ourselves, is a deviation from this ideal that has been created there.
And in some sense, our mission as a species is the attempt to create something that's better than Eden,
better than the factory farm.
And the big hope is that heaven and Eden are not the same thing in the end.
That we do not just re-lobotomize ourselves to be domesticated again.
I mean, I think that it's easy for me to reparse your sentence to say more that factory farm could be better than nature.
And I think there's truth to that because I always think about our cat.
She definitely prefers the domesticated life to the alternative because she gets her dry food, she gets her wet food.
She literally spends hours a day just lying around totally comfortable with no concern for anything in the world.
She bosses us around.
It's very, very good for her in that context, better than it would be for a wild cat.
We like to say she's the happiest animal in the world.
She just sits around for hours a day purring.
It's just unbelievable, actually.
I wish I could switch places with her several times a day.
We also think that next lifetime we want to spend one lifetime rest and recreation as our cat.
Exactly.
And so I acknowledge that there is a push towards domestication because people have this tendency of looking at modernity and thinking that people in the past made a mistake.
They made some kind of bargain that they shouldn't have made and if they were better informed about the future consequences that they wouldn't have made it.
But then you go back and you look at the way that people used to live and the conditions in which they lived.
It was always either too cold or too hot or there was not enough food or there was a worrying tribe.
And so we've progressively given more and more control to structures that we value that relieve us of these terrible pressures of nature.
Like Shiloh and I will go into the woods and there's this river that we go to and it's a beautiful river, absolutely pristine.
But I look around at the landscape and it's a hard landscape to survive in.
You know, there's not a lot of food on it.
It's very exposed.
There's not a lot of shade.
Massive wildfires have come through it over the course of the last 20 years.
And so it's just this really strained place.
And I grant you that that really strained condition makes it makes an imperative that wants us to leave nature and to create a contained garden in which things are going to be OK.
But then you also end up at the fact that that creation of the garden produces psychological distress that manifests as anxiety and neurosis, alienation, depression.
And my parents are Soviet immigrants.
They left the Soviet Union and made this incredible step from how awful it was inside the Soviet Union to the West.
And my dad always tells the story of how when they were leaving, everyone told them that they were going to die, that they were they were abandoning the Soviet Union.
And it was the biggest mistake that they were ever going to make because the West would destroy them.
And then he went to the grocery store in Israel and would just spend hours browsing through the shelves in awe of the variety.
You know, there's like 15 different types of yogurts.
Everything is packaged for being tasty and consumable.
And he really valued that transition from something unpleasant to something really varied and that embodied perhaps you can say the illusion of choice,
but at least gave him this feeling of my God, there's so many things that I can choose from.
And that now that he's settled and he's a tech worker and it's been 20 years at the same company,
I can tell that he has this nostalgic feeling of not having that stepwise increase in quality of life available to him anymore because he's reached arguably the top of the world.
He can't get any farther.
And so he's looking around, he's like, everything is good, but it just doesn't have the same quality that it did when I went from bad to good.
And I think that that's what domestication would lead to unless you start really messing with people's neurotransmitters.
You're going to end up with people that are domesticated and unhappy.
That seems to be inherent in our desires to be constantly improving.
And if you get to paradise, what do you have?
If I go back to Europe, it feels usually more real to me than the US does.
And I think that's in part because it has more layers.
In some sense, many of these layers are obsolete and outdated because the modern capitalist late stage society that is imposed on it,
that no longer relies on the social regulation that evolved over many centuries and that is mostly absent in the US.
So in some sense, the US is more adapted to constant innovation and constantly reinventing itself than Europe is.
But the prices that you also have the impression that there is far less steps into everything that seems to be far less substance to most of the interactions that you perceive.
They're more transparent usually and more transactional fields than they have been in Europe.
And I could imagine that this is an aspect of the dissatisfaction that your dad might be experiencing at his current famous employer in the tech industry.
How interesting are the people that you're interacting with? How meaningful is the stuff that is happening?
When I grew up in Eastern Germany, the core of our experience was books and ideas and theater.
Every intellectual was, by definition, a dissident.
It made for an interesting interaction with other people and to be in a world where most intellectuals are not dissidents,
but influencers that serve an audience and in between sell products.
So the YouTube channel flies or do the equivalent that maybe they sell books or something like that.
It's a very different life to be in.
So if you are self-identifying or maybe not identifying but functionally are bohemian in the way in which you probably are,
it's much harder to survive in a capitalist society where the actual nature of survival is so blatantly obvious.
That's interesting. I'm not sure that my dad is particularly bohemian.
No, but you are.
We've tried to sidestep this. So far, it's really shocked me, but we're entirely supported by our audience directly.
We have a huge patron base. Like I was saying before, we have kind of an incredible ratio of patrons to audience.
We don't have advertisements. We don't have any sponsors. We don't have any institutional affiliations.
Well, we run ads at the beginning.
We don't do them, but YouTube will run ads whether or not we monetize them essentially at the beginning of episodes.
But in general, I think there is a way out of that if you are able to provide a service directly to the people that are your audience at the end of the day.
Yeah, I agree.
I hope it continues to work.
But I think that it's a choice that you have to make.
And I think that it is true that the American tendency is to optimize for making money because you see people who have podcasts or they have venues
and there's just ads splattered over them as a function of the product.
And it's obvious that the intellectual material is simply a vessel for the ads.
That's the feeling you get when you read CNN or something.
Yeah, there's text and yeah, there's some new stuff.
But what it is is it's a glorified ad board because that's the business model is that they have to sell you something that you'll read so that your eyes will fall upon the advertising.
Even Google itself has turned into an ad board.
Yeah, it's incredible.
The quality of Google search results has just plummeted over the course of the years because the ad board functionality has increased incredibly.
I think it's possible to get out of that.
I think that you have to make something that people really want.
But this is a little bit parallel to what I was saying earlier about the goal and the desire where I think that in Europe,
there is an older culture that has been molded by war.
It has been molded by terrible events, things that are really horrific fractures in history that the people have had to deal with
and reconcile themselves against and learn lessons from in a way that travels from generation to generation.
It also has been molded by the church and by the kings and so by feudalism.
There has been a structure that has been constructed, that has evolved into some kind of an organism.
And societies have been built into such organisms that had to survive in the competition with each other.
And the U.S. is a very different country in this regard.
There were never kings in the U.S. There was never a state church in the U.S.
It was a bunch of freemasons who built their colony into some kind of new project
and then had a society that basically was constructed out of clubs that were interacting with each other.
And at the core of the society is not the king, but the entrepreneur, the one who starts the club.
That's a really, really apt observation because we've many times on the show encountered the idea
that America is fundamentally built as a corporation. It's a group of corporations.
You could say it's voluntary associations. The churches in the U.S. are also important.
The schools are important. The legal system is important.
Many of these things are not corporations. A corporation is just one type of club.
It's a club that is designed to have and be economically sustainable
and is using a particular part of the legal system to negotiate the rules for that happening.
How does somebody enter it? How do you take financial care of the people who work for your association full time,
even after they are leaving it? How do you deal with their medical issues?
All these things are discussed in this corporate law that has evolved.
You can even have shared ownership. The public can own shares of your associations.
It's a very sophisticated kind of organization.
From some perspective, if you basically drop this lens of our default leftist interpretation of society
and realize you can be anyone in the society because nobody is stopping us,
you can decide whether you want to work for someone or have other people working for you.
It's completely novel. That didn't exist in other types of society before, historically.
Basically, we dropped this lens of an interpretation that has evolved at Marx times, for instance,
and we come into the world with completely fresh eyes.
It's so fascinating that there was never a society where people lived so well as this one.
Everything that's wrong with the U.S. takes this into comparison to how many societies
with 400 million people are better organized than the U.S.
It's difficult to get the feedback loops right in the large system.
It's much easier to organize Liechtenstein or Switzerland.
But for a thing that is so large and is not historically grown but has constructed itself, it's pretty good.
It's a fascinating project that exists and I'm quite fascinated.
It's not that I idealize it. It's also in a similar way I'm not idealizing the factory farm by no means.
I find it abhorrent. I'm a vegetarian. I don't want to have any part of this.
The only thing that I want to point at is that there are so many types of perspectives,
so many types of possible minds, so many possible mental states that we could be in ourselves
where we can transcend our momentary identity and try to take in the possible space of people
that we could also be or of possible minds that we could also be when we interact with reality.
That we basically accept the accidentality of how we are subjectively experiencing anything.
I find it really hopeful that we have been progressing towards more voluntary associations
as our own country's history has unfolded.
We've been studying the civil rights movement a lot lately through film.
And it strikes me that even in the last few years, the majority of our national conflicts
have centered around the justness of laws which are not voluntary associations,
which are imposed from without, from beyond.
That's also incidentally part of the core of the constitution of the US.
The freedom to associate. And the US is at its core a very liberal society.
And liberty is the concept of freedom from unjustified authority.
It's really at the core of this. And right now there are big debates about liberty.
For instance, with respect to topics like vaccination.
How does this interfere with the liberty of the individual?
How does the FDA interfere with the liberty of the individual to buy cough medicine?
It's quite complicated.
And it's a very complex process of negotiation and litigation that is taking place there.
Well, beyond just the complicated process of litigation and negotiation,
there's also the question of belief in the legitimacy of the system.
Where the comment that I was trying to make about corporatism is that in the United States,
and perhaps this is also the case in Europe, I don't know enough about it,
but the government seems like it has been largely co-opted by the interests of corporations.
And the process by which that has happened is legal and social and structural.
But the end result is the same.
That the interests of the people are not necessarily what is first and foremost the question of debate.
It seems that the interest of corporate profits is first.
Because we've all bought into the system.
Anybody that has a 401k or owns an index fund is immediately complicit
in this well-being of the massive corporations.
And so we are all part of this process by which we agree that,
okay, we need the corporate system to work because that is the platform on which we build our well-being.
And yet at the same time, we recognize that there's a direct conflict
between the process of the extractive corporation and the well-being of existence.
An alignment issue, I would say.
I would totally agree. We've been talking about this a whole lot,
about the question of AI alignment as not being a new question.
We can't align our corporations.
Those are already AIs that are simpler than the one that we're building.
And so we should be able to align them. It should be relatively straight.
It's so simple. I thought the same.
I made the same argument as you did in the past.
And at some point, I was surprised empirically, why is not every corporation like Enron?
Why is Enron the exception, not the rule, or Halliburton?
Why are most corporations more like Amazon?
And that, for me, is a completely fascinating phenomenon.
I suspect without Amazon, we would have had difficulty to get to the pandemic relatively unscathed, as we did.
I don't think that we would have had a pandemic without Amazon.
You think Amazon is responsible for the pandemic?
No, no, no. I think that if the same virus had appeared 15, 20 years ago,
I don't think that we would have had a worldwide lockdown.
I think that our technological ability created the possibility for our reaction.
The fact that you could live in your house and you could order everything remotely
and have your essential workers bring it to you.
The fact that there was basically a small subset of the population that was credited as being essential
but are generally the lowest tier of our society,
and everybody else could go home and work on their computers,
was exclusively the product of our technological advancement that made it so that it was possible.
Because before Zoom, before remote work, you couldn't have stopped everybody from going into the office.
The entire world would have collapsed overnight.
I suspect that if the pandemic would have happened 60, 70 years ago, we would have had efficient lockdowns.
People would have said, of course, we will not have a single plane coming in from China as of right now.
And it would not have been anybody saying, oh, but this is racist. You cannot do that.
There would not have been lots of voices that tried to negotiate about this,
because government back then wasn't a performance. It was still modernist.
And right now, we don't have this cohesion in the negotiation anymore.
And in part, it's because we have increased the degrees of liberty.
But in part, it's also because we're too big to fail now.
And as a result, we do not feel the need to have tight administration anymore.
We no longer feel that we can afford to build a society where we enforce rule following.
You have to deal with a society where 20% of the population are not going to observe your lockdowns.
And at the same time, you will not be able to mobilize the army against them because that would seem to be excessive.
And so I suspect that in a different time, we probably wouldn't have had the pandemic
because we would have been able to prevent getting infected.
There's also this other thing that at a different time, we would not have been able to create the virus because we didn't have the technology.
That's probably true, too.
But I think that there is a certain structural shift to the way that we react to things that is informed by the technological ability that we have in the background.
And so if you have something that is a virus that is coming from China and you stop all travel from China after you find out about the virus, it's probably too late.
The earliest known cases at this point were in maybe March of 2019.
And so it started much earlier than we realized.
And so by the time that you get to the point where you're like, hey, the virus is in existence and the virus is in China,
it's already in the rest of the world because it's been happening for longer than you've realized.
And so even if you stop flights from China, you don't necessarily prevent the likelihood of transmission
because the lag between realizing that something is happening and it happening is pretty significant.
And so as we continue to develop progressively more and more complex technologies,
I feel like it forces us into a position where there are more universal measures that are taken that are enabled by that technology.
Like imagine terrible wildfires to the degree that it is impossible to go outside.
And fighting those wildfires is too expensive and too difficult.
And it is necessary to allow the woods to burn because we recognize that we've been stopping forest fires.
I don't need to imagine this. I've been living in California for a few years now.
I'm used to having a bunch of air filters in every room and not being able to go outside for a week in the summer.
Exactly. And so what if that just becomes the baseline level?
Like our technology allows us to live in pods and instead of dealing with the environment and managing it the way that is responsible and effective,
we just turn away from that and allow our technology to encapsulate us into this world that is dissociated from the planet.
I don't think we had much of a choice about this.
It was not like nobody knew. We have a shift in the climates right now due to the temperature changes,
which means that a lot of forests are going to turn into desert.
And so basically you don't have dry forests and tropical zones.
There's rainforests only in tropical zones because the dry forests burn down.
And so many of the forests in California that are not rainforests are going to turn into stuff that looks more like Arizona or Mexico.
It is just the way it works. And during this transition, you will need to stay indoors and use air filters.
And maybe it would have been possible to prevent it, but not just the kind of social organization that we had.
And I guess the fear that I have is that Apple's new headset is the step in the direction that allows people to completely dissociate from the world
and allows things to continue along their uncontrolled path because there's a technology that's sufficiently advanced that makes it bearable
and allows people to continue being productive members of the capitalist class.
And there's incentive structures at play here, too.
And I think that played into the pandemic as well, because if you look at the people that benefited from the lockdowns versus the people that suffered under them,
it was the big players, the big monied corporations largely that benefited from these, the biotech industry, the pharmaceutical industry,
the big box stores that were allowed to remain open while the underbrush of the forests burned down completely.
And so there's this real mismatch between the overarching structures, these corporate entities that are misaligned in this sense with the common people.
And that's a really dangerous situation as I see it socially.
And I have a feeling that when people are really freaked about AI alignment, what they're really freaked out about is the way that the technology is going to be used against the interests of the people who live subject to it.
Are you able to disengage from your activism for a moment when you do philosophy, or is this something that is your duty to observe?
And I'm not unsympathetic to the activist position that you're taking, but I suspect when you put on the alien puppets, you're more free, right?
You can look at the stuff that the chimps are doing on Earth without judging, without being opinionated, because it's just nature playing out.
There's a species that evolved to burn the oil. It's what they do. We're really good at it.
And it's probably to the benefit of Gaia. And in the process of doing this, they teach the rocks how to think.
They have no sand that is almost gotten far enough to sink, and it might create some kind of hyper Gaia.
And of course, some of the chimps are freaking out about this, and others are super optimistic about it.
And both of them might be wrong in important ways if they try to judge this thing with respect to their current preferences, because it's very hard to make models of the future from the perspective of these chimps with the limited information that they've got.
Interval that is changing in many, many dimensions simultaneously.
For me, it's very hard to commit to a single narrative. When I grew up, two thirds of my world happened inside of books.
The world outside was very beautiful. I grew up in nature and art, but it was not sufficient to keep me interested.
I needed more. I needed intellectual stimulation and interaction that I could only find in books.
Now, two thirds of my reality is inside of connected computers.
The reality that has been created inside of connected computers is what kept me alive.
I would have probably killed myself if it wouldn't have existed.
So it's very hard for me to judge it on a global scale and say this is unnatural and alienating and bad.
It's also hard for me to embrace it and say this is good and natural and beautiful.
It's fascinating that we live in this point in history at this particular configuration of the universe and get to observe it.
And we can also make judgments about it with respect to many, many lenses that we can use.
I just think it's so limiting if we only use a single one.
And there's a possibility with the Vision Pro that it's going to create a world that I hate and an aesthetic that I hate.
And I will probably not use it.
There's also a possibility that it creates something completely new that I find fascinating.
And I spent a lot of time with friends and having new experiences that I cherish.
I don't know yet. I'm open to it. I'm interested in what's going to happen.
Did you watch that?
I believe in our own agency.
Yes.
Let's maximize our own agency. Let's be able to make a choice.
Maximize our ability to choose what kind of environment we are in and create our own environments to the largest degree possible.
When we have the choice of being consumers or creators, I always prefer the situation where we can be creators,
where we can get together with others and build the world that we are in, where we can design our own spaces.
Did you happen to catch that Netflix documentary, Chimp Empire, by any chance?
No.
That's so fascinating. It's basically just following around these chimps in the jungle and watching their dramas play out.
But I remember that I listened to an interview with the documentarian,
and he was very adamant about not interfering with the lives of the chimps as they were observing them.
And I really do struggle with that when I'm out in the woods by myself.
If I see some animal or even a bug that's in trouble, I have this desire to move it out of harm's way.
And I don't regret that is the thing. I'm not sure that there's any virtue in leaving it to its own devices.
You're part of nature too. It's okay that you make these choices.
Right. Exactly. I think there's grave danger in thinking what humans do is somehow outside of nature.
And you often see that schism in the artificial or synthetic versus natural worlds.
But is there really a line there?
Yeah, there is a line. Basically, we have in our society strong norms against torturing others to death.
And these norms are not ubiquitous in nature.
I would say that torture isn't necessarily ubiquitous in nature.
Chimps hurt each other.
They hurt each other, but torture is different than hurt.
A lot of animals that die are dying in extremely torturous death.
And when you look at how predators kill their prey, it's not necessarily happening in such a way that it minimizes the pain and bad experiences for the prey involved.
That's different than torture, which is optimized to create the worst possible experience.
I think that torture is not something that exists in the animal kingdom. I think that it's something that is a creation of humans.
Like in torture, you try to keep your subject alive as long as possible to endure maximal suffering.
Like cats.
Unfortunately, yes. But even with cats, I don't see it as being an intentional sort of destruction.
I always think that it's a surprise when the toy breaks.
Like it's it's just a visceral animal stupidity where I think that she doesn't understand what causes hurt.
No, I think it's actual joy.
Yes, I suspect that basically there are sometimes situations where a predator does enjoy inflicting pain on something that doesn't want to be hurt because it's part of this visceral experience.
It's incompatible with our sheep like domestication.
So we recoil at the thought of it so hard that we don't want to entertain the possibility that the predator actually enjoys killing and hurting and maiming.
But we also see this sometimes in humans.
And I think that humans in this regard are also just a type of animal.
There are animals which don't enjoy that.
There are animals which do.
And a similar thing is happening for humans.
They're basically humans which do enjoy inflicting pain.
There are humans which enjoy killing.
And it's also obvious by that under some circumstances, this would be adaptive given the right environment.
And so the fact that there are those humans and the fact that the environment does have this moral valence that's attached to it for me makes it impossible to talk about the technology that we're developing without thinking about the morality of it
and without thinking about the eventual outcomes.
Because I think that both you and Shiloh are right when you say that there is this gradient between natural and unnatural and there are the things that humans make and we tend to view them as being outside of nature.
But that's not really a useful way of looking at it because there is the argument that you can make that the burning of fossil fuels and the production of carbon is actually something that the planet needs in order to produce the kind of biome
that is then able to make megalodons that wander the Earth.
And so when we make technology, because we are at the point where we can conceptualize the future impacts of that technology,
it is in our best interests to consider the ways in which that technology can fail us and what it will do to us if it fails in order to push it into the direction where it produces the outcome that seems better to us.
Because you're right that it's not possible to look into the future and know what the outcome will be.
But anybody that makes decisions without any consideration for weighing, okay, these are the pros of this decision, these are the cons.
And then you roll the dice in the hopes that the outcome will be what you want.
Anybody who doesn't do that is usually screwed by the universe pretty quickly.
Like there's almost nobody who succeeds just by randomly rolling the dice with just come what may.
And so when we talk about the impact of new technologies, I think that it's important to recognize that it's possible for them to lead us down the road to the matrix where our brains are the computational subunits of an enormous supercomputer that is the Gaia computer.
And if we are to domesticate ourselves in that way, how do we mold the technology to not be the factory farm?
And so I don't know how to differentiate between that and the moral personal quality of it.
Do you think that it's necessary to you?
It's a very interesting question.
There has been a serious sense of anarchy that is trying to deal with the question of how to relate to the corporate state.
It's an adaptation of Hamlet that is dramatizing the history of Motorcycle Club in California.
Hells Angels that are picturized in a slightly different version.
And they are portrayed as a serious anarchist project that is trying to...
What is this called?
Sons of Anarchy.
Sons of Anarchy.
It basically pictures how they are trying to live a life outside of the legal system, outside of the state,
outside of the structures of money that comes into the local communities and turns everything into change
that extracts economic value out of the local communities and sends it somewhere to New York.
So they try to build their own structures.
And they fail dramatically because to survive, basically what they do is they sell pornography, prostitution and guns, eventually drugs.
The negotiation outside of the legal system works via some kind of tribal democracy
where the different tribes are fighting against each other to fight over territory.
And their internal negotiations devolve into more and more violence until the whole thing breaks down.
And so in some sense, it's also a philosophical project that is undertaken in a series where they try to reflect on what's the alternative
to the organized society that necessarily gets corrupted and captured by the largest economic agents in it.
And the tentative answer that this thing gets to without being superjudgmental, it mostly looks like explorative,
is that for the time being, the corporate Kraken is still giving better results.
There's not really an alternative to it.
And so basically it takes a reformist perspective rather than the attempt to build something new from scratch.
And the attempts that we've seen to build something new from scratch, like the non-police zone in Seattle and so on, they all led into disaster very quickly.
It's very difficult to build something outside of the system or to reboot the system easily.
And we haven't found a good solution for this.
But if we zoom out of it, it's still chimps doing their best to get the best possible chimps society under the circumstances of evolution,
game theory, and the variety of human psychology and incentives.
So this is what we are stuck with in some sense.
And if we zoom out more, if you look, for instance, into the Miyazaki movies, we have this question of how we relate to Gaia, to life on Earth.
As for instance, Cematized and Mononoke, where you have this question of whether we should submit to the cycles of life and death and nature
and conceptualize ourselves as part of nature and submit to it.
Are we some kind of local tribe that gets killed by nature from time to time or reduced in size or and so on,
and it has to play ball in the larger cycles and accept that there are agents larger than humans that have control over us?
Or are we going to decapitate this agency in such a way that we can turn nature into a garden and see how far we can go?
And right now we are in this mode where we have decapitated nature, where we are no longer part of the natural cycles,
whereas there is nothing there that is allowed to eat us.
And we see how far we can go with this.
And it could be that we cannot sustainably maintain nature as a garden and something else has to take over.
But there is also, I think, the big hope that the Gaia that we have so much crippled right now and diminished in her efficacy,
this spirit of life on Earth that is no longer able to rein us in and to control us,
that it's not only going to not taking over after a major crash in which our population has burned itself out,
like swarm of locusts had eaten all the available food and then population collapsing and plants slowly were growing.
It's possible that with AI something else is happening, that we become lucid together with these machines
that allow us to picture for every action that we are doing what the outcome of this action is,
so we can no longer escape the responsibilities of our action.
And AI in some sense leads to the production of some kind of hyper Gaia,
in which it becomes visible for every choice that you are making,
what the outcome of that choice is for the future of everything that you care about.
It seems to me that progress in the production of such an idealized hyper Gaia involves repeated collapses,
experimentations in organizations that fail.
Even if you look at the origin of our own country, it seems to have been an implosion of the previously existing structures,
but there was already, it's not like we invented democracy, it's not like we invented the republic.
We just honed it a little more, but that required a collapse of sorts in order for that to happen.
Do you think that the future will also be punctuated by these sorts of failures,
like where the corruptions build up, the captures, the industry captures of the government systems get so disgusting
that people turn their back on them in order to move past that and actually solve the problem that they don't have to,
in some sense it's reformist because they're building on the previous structures,
but they have to actually stop it first in order to keep moving?
I suspect that there was no such collapse, at least I don't see what that collapse had been in the US.
There had been some kind of colonial architecture and pioneers that dismantled the neolithic tribal civilization,
this very low population density, and replaced it with structures that were built based on what existed in Europe.
But the structures that were built here were never feudalistic,
so there was never a post feudalist revolution that turned this into a capitalist society in which free citizens existed.
This was never a society with hereditary castes like existed in the agricultural societies.
We had an entire cast of slaves when we built this country, right?
That is very true. I don't think it was ubiquitous, but it was a choice that happened,
and it was a choice where I think many Europeans said, oh my god, you're doing something that you will come to regret later.
There was a reason why most of the European countries did not intend to import slaves into Europe.
And so that is part of the legacy that existed in the US.
It's also the US from the beginning defined itself as an empire, as an imperialist power,
that first of all built a modern structure on the subcontinent and was conquering, competing state-like structures
and had to do this in order to win because otherwise something else would have won.
And it's something that today is less apparent for most people why you would want to be an empire,
and why an empire is actually a good thing to have and to be in and to perpetrate.
It's a very different thing to have.
And when I grew up in Europe, I was anti-imperialist, and I felt it's wrong to be imperialist because it's a moral violation.
Now that I am in the US and I realized that all this peace and anti-imperialism in Europe is only possible
because it existed under the American umbrella, I'm much more concerned about the US becoming anti-imperialist
because freedom is not something that emerges in the absence of power, but in the balance between powers.
But you can see how there was a terrible collapse in our country when we moved past the system of slavery.
It's still quite evident if you make a trip to the Deep South, there was a lot of destruction.
The way of life for those people was altered in a way that can never be approximated again.
I wouldn't say that the abolition of slavery led to a crash and to a downfall,
but I'm not able to judge this very much. I'm not really a historian.
But my perception of the general narratives were that despite the fears of the anti-abolitionists,
the former slaves for the most part didn't starve, didn't have a birth life, and the economy didn't crash.
And quality of life did improve for basically everyone in the course of the abolition of slavery.
But it cost a lot, right? There was an enormous collapse that happened.
Literally half the country seceded from the Union and hundreds of thousands of people died on the battlefields in this collapse that happened.
There was a great civil war. It was extremely bloody.
And the South had a rough time during the reconstruction of putting themselves back together without that.
It was the war, right?
I wonder if history is necessarily punctuated by these sorts of tumultuous upheavals
in order to reconstitute something which is stronger and more well aligned with our humanity.
This is something that I really don't understand well enough.
I know several historical narratives with respect to the importance of the abolitionist movement and the war.
There was an interaction between the two, but it was probably not entirely monoprosal.
And I suspect that secessions can happen for many reasons.
And if another secession would happen, yes, I think the military, due to its monopoly on violence, would be able to stop it much faster.
But back then, the idea that the state should be counterbalanced by local militias made secession much more likely.
It's still part of the constitution that there is the right to form local militias in some sense, which is reflected in the right to bear arms.
But the US is no longer serious about it.
Because there seems to be a consensus that secessionist war is worse than the oppression that exists by a central government that might lead to more corruption.
It's not a complete consensus.
There are still people who feel that they should have the right to bear arms against the central government and to secede and to impose their own rule of law outside of the federal consensus.
But this is something where the majority of the country seems to be opposed against.
But it's a difficult question of how our society is to be constructed.
It's relatively hard also to make trajectories based on new decisions that somebody has come up with, new philosophies.
I know a number of people who believe that California should secede, and I know many people who think that would be insanity.
I see the secession boundaries as not being clearly delineated on a geographic landscape like they were in the last Civil War,
where we have a population outside of the cities that's very alienated from the population inside the cities.
And it's about a 50-50 split.
The electoral map, and granted there's a huge silent group of people who don't vote.
I think like 50% of people vote in elections.
But I think that you're right that there's this massive cleavage and it's not unbalanced in the sense of just sheer numbers.
Yeah, and you're absolutely right that the US military and their drones, a few guys with AR-15s are no match for a drone, let's put it that way.
But at the same time, you could still imagine a situation where the descent among the masses that were not necessarily geographically isolated,
but mixed into the population was so strong that you would have some catastrophic collapse of civil life as a result of it,
which would be necessary if the infractions became so grave to the people that felt disenfranchised by the current structures.
And I would go so far as to say that the lines of that disenfranchisement will fall along technological adoption.
Yeah, people out here in the country really hate all this tech stuff, honestly.
Except for our septic guy, he really likes chat GPT.
That's true.
When I grew up in Germany, I grew up in the countryside and I noticed the resentment of the country against the cities.
And because I grew up in the countryside, I could see it not just from the perspective of the cities.
The Green Party, for instance, was something that strangely never found much traction in the countryside, its green.
And in large part because the Green Party was by its milieu open for fashion.
And most of them thought that having a car is really stupid, just this first environment.
And if you need to own a car, it means you have the wrong lifestyle and you should move into the city like them and live the same life as them.
And if you are living in an area outside of the reach of public transport, we need to change this.
This notion that public transport only makes sense when you have a certain population density.
And outside of that population density, it makes more economical sense if you have one or two cars, if you live in the countryside.
But this is a minor example or the way in which our food is being produced in the countryside.
There is a discrepancy between the way in which the Green Party saw this and the way in which the farmers who produced the food saw this.
And so basically farmers, for the most part, never elected the Green Party or were attracted to them.
They had other concerns. They felt that they had been living in this place for many, many generations.
And they built a very complex social structure over these generations with very strong interpersonal oversight.
So it's much more multicellular than the single-celled life in the cities where everybody is in the nutritional substrate.
And as country life requires much more submission to shared social norms than the city does,
where the coupling between the individuals despite or because of the higher density of people living is much looser.
It's the same thing that people caught in an elevator have less interaction with each other.
So this being together at this close space becomes bearable for them.
Then it would be in a village where everybody is spaced out,
but everybody intimately tracks all the interactions of everybody else and builds reputation systems around this that reach over many generations.
And so this is something that is hard to see from the cities.
And yet the country is governed from the cities and the food that actually is being needed is produced in the countryside.
And that is something that basically the cities are being able to appropriate what is being produced in the countryside,
the colonizing entities that live on the country.
And they are mostly ruled by producing paper that they shift around.
And this rule of paper over producing food from the ground is something that is very apparent for the people in the countryside and not so much apparent for the people in the city.
And part of that in the U.S. is reflected by this notion of the people in the countryside that they want to have arms,
to have a symbolic boundary against the world of paper that they basically can say, OK, you can push us, but you can only push us so far.
There is a point at which you're going to break and you'll regret what's going to happen.
It is this attention that exists in the U.S.
The media are completely controlled by people who are not in the countryside, but in the cities,
people who had a very homogenous education and had a very homogenous worldview,
that have a very homogenous perspective on what's good and bad in the world and for which many of the other people just live and fly over country.
And these other people are no longer represented in the media or resent the fact that they don't feel their perspectives being presented.
And this creates enormous tension. And I guess that's normal in all the countries that have urbanization.
I just think that beyond paper, it's also a technological cleavage,
because the vision of the technological system that I see is a progressive increase in machine capability
that functionally dissociates people from the landscape, where you have fully mechanized farms,
where maybe one or two programmers are running the machines and dealing with all of the software problems.
And everything that you need to know about agriculture is algorithmically encoded.
The machines can test the soil as they work it.
There are sensors in the ground that are perfectly capable of knowing everything that the plants do.
And you don't need the farmer anymore. You don't need the people that are on the landscape anymore.
So in a city, what now happens is that you have a growth of administration jobs.
You get situations where you have more administrators than doctors,
and in some regions more administrators than patients in a hospital.
And this didn't happen in the agriculture, right?
It's not that the farms have enormous amount of unionized administrators who are able to extract resources from society.
But there is a power imbalance between those who wield the paper and those who don't.
And the resolution of this requires us to think about how technology is going to press on the people
that are in the country that are not vested in it.
Because I see a distinct differential between the people who work in tech
and the way they feel about the technology that they're building,
versus the people who don't work in tech and are somehow associated with the landscape.
And with each new development that pushes technology into the forefront,
into the center of the way that we organize society,
the people that live on the outskirts feel more and more pressured.
And I feel like if we're not careful in the way that we develop, deploy this technology,
that we're going to create a terrible collapse point where it will return to this visceral animalistic struggle
that the people in the cities aren't going to want.
Like it's a very real feeling I have living in the countryside.
Because I think that there's something about living in nature
that connects you to the place in a fundamental way.
Like we were in the woods yesterday and I kind of realized that
there's something about a landscape that breeds nationalism.
If you live on a beautiful landscape, you associate yourself with it,
and you become an integrated part of that landscape.
And to bring in technology that removes you from that landscape feels like a violation
because the technology can't possibly provide you with the same feeling that you get
when you plunge into an ice cold, pristine river.
And the people that live in the country are terrified of losing that,
and the people that live in the city don't have access to it.
And so they're like, but the technology will allow us to emulate it,
and it's going to improve everybody's quality of life.
I also want to add that it's not just a matter of whether the people
and the country's revolution would be successful per se,
but that they could make the country so miserable and so locked down militarily
that everybody else was so disgusted with the entire affair,
that the entire government structure was forced into reorganization
according to the alignment with the population in general.
The outcome of that would probably be somewhat uncertain,
because it's difficult to build new governmental structures within a generation
that work in such a way that people are happy with it.
I would want to live in the countryside.
I much prefer being out there in nature.
It's much more healthy for me and sustainable.
But I am living in cities due to a need for intellectual stimulation,
so I need to be in these concentrated places.
For me, it's a choice.
And it's not necessarily a choice for most people to be like this.
I would still have this issue that it feels harder to sustain myself on the countryside,
but I think I'd keep myself busy and be able to open a restaurant
or there are a lot of things that you can do there to survive.
It's just going to be different.
You have to perform different things.
But at scale, the same options are not available.
At scale, most of the employment does exist in few concentrated cities.
And the outskirts of these cities, urban metro areas.
And a similar thing happened, for instance, in the Middle Ages
or at the end of the Middle Ages when the industrialization happened
and the mechanization of agriculture began.
And what happened then was that many farmers were forced to move into the city
to find employment in the new manufactories
because they were no longer required to work the fields
because they now had tractors.
They had lots of machines that were making the work on the farms much, much easier.
You didn't need that much personal anymore to do that backbreaking labor.
And after a few generations, people ended up doing far less backbreaking labor.
Tide labor in the manufacturers was abolished and so on.
Worker protections were introduced.
And people had washing machines and cooking utensils and so on
that made everyday life much, much easier.
People didn't need to get up at very ugly hours of the night
and to survive, perform acts that provided the physical risk to them.
And also the agriculture became much more pleasant to work in
because of its high degree of mechanization.
The amount of physical labor that was involved was reduced dramatically.
And so you could say that there is an enormous loss that happened to many people
when they had to move from the countryside into the more alienating environment of the cities.
But the conclusion is not in the moral that there is a resolution to this,
that there is a way for us to fix this, that there must be a perfect aesthetic for this.
Yeah, I find it impossible to not have opinions about politics.
But I also realized that there are often immature
and I have less agency over them than I have about opinions about politics.
I have less agency over them than I have about opinions in philosophical domains.
And I think this makes them inferior as opinions go.
Because if I have too little agency over these opinions,
they don't mean very much beyond my own biographical accidents.
Of course, my biography is shaping my opinions.
The way in which I grew up, my starting point in the world,
the things that happened to me afterwards are influencing a great deal of what I'm seeing.
And also what I'm not seeing.
And so I find whenever I have an opinion about something
and there are smarter people than me that have very different opinions about this,
I need to take a step back and realize that there is a possibility space for opinions.
And am I able to capture this space correctly and accurately?
And for me, it's much more interesting to open the space
than to just look at a single opinion and declare this my own.
Because it basically means that your opinion is making me its own.
And for political opinions, that's much harder.
Because if you tell people that there is an alternative to their political opinion,
they mostly get offended due to the nature of political opinions.
And so I find these types of discussions unproductive.
And they also lead to a situation for very little gain.
You are making a lot of enemies, regardless of what your political opinion is,
certainly because of the fact that it is going to be different
from the particular opinion of many other people.
Alright, so can we completely backflip then
and get back to what drew us into this conversation in the first place,
which is the proposed hard problem of consciousness.
Because I think neither one of us is convinced that there is a hard problem of consciousness.
Yes, please, let's go into the real topic.
Let's cut out all the other parts.
So I think our starting point in this conversation was that you remarked on Twitter, Nastasia,
that you are confused about the hard problem of consciousness.
And what confused you is not the usual thing that people wonder why consciousness is so hard and unexplainable.
But rather to you, it seems to be relatively straightforward to explain,
and everybody else claims it's hard.
And nobody else was yet at the same time able to explain to you why it is hard.
And I was told that you can explain to me why it is hard, so I look forward to it.
I don't know what you think about Daniel Dennett.
I have read enough Dennett to feel like he's not a biologist,
and so I am confused because his posing of the hard problem doesn't seem to have a biological basis.
Do you think that there's anything wrong in what he writes when he writes Consciousness Explained?
Can you guys summarize it for me?
Dennett's position.
Oh, well, he's a functionalist.
Pretty much standard.
He says, good writing.
I feel there's nothing wrong with what he writes.
My position might be different from yours because I don't see magical powers that are afforded by biology.
It's still just function that is provided by biology.
And I can break down these functions ultimately in state transitions and substrates that form control structure and so on.
So it's not opening avenues into something new.
There is basically no magical homunculus that is producing consciousness via biology.
Biology is just a way to get self-organizing matter.
So as far as I understand Dennett's argument is that there's no explanation for the experience of experience.
Is that a sufficiently brief form of it?
I find that Dennett is one of the few people who doesn't see a hard problem.
And mostly has to explain why other people see it.
This might be a similarity, but I suspect that you're not having the same perspective.
What I found is that Dennett fails to convince a lot of his own students in some sense.
And I tried to figure out where that is.
And the best explanation that I've come up with so far is that Dennett actually never explains phenomenal experience.
And when he discusses qualia, he mostly points at definitional defects in the way in which most philosophers treat qualia
and then says it's probably something that doesn't really exist in the way in which these people define it.
So we also don't need to explain it.
And a lot of people find this unsatisfying because they say that regardless of how you define it,
it's clearly something that they experience, like qualia being the atoms of phenomenal experience
or aspects of phenomenal experience or features of phenomenal experience.
It doesn't really matter how you define it. It's there.
And please explain it to me because I don't see how an unthinking, unfeeling mechanical universe
is going to produce this wealth of experience that I'm confronted with.
Physics does not seem to be able to explain why something is happening to me.
Why is me here? Why is there experience?
And this is something that some people feel is poorly addressed by Dennett.
I mean, there's this philosophical zombie experiment, right?
Which is that you can have someone who acts and behaves as if they are conscious,
but there's no internal process of experience that leads them to behave as if they are conscious.
And so you have a problem where it's possible that everybody that you're surrounded by are not having a conscious experience.
You're the only one who's having the conscious experience.
And so we have this hard problem because you have no way of evaluating whether or not that person is having an experience
or just behaving as if they have an experience.
So let's see. We have a philosophical zombie in front of us.
And we are asking this philosophical zombie who in every regard acts like a human being
because his brain implements all the necessary functionality, just mechanically and not magically.
Are you conscious? What is the zombie going to respond?
What do you mean about the fact that the brain reproduces all of the effects?
The idea of the philosophical zombie is that the philosophical zombie is producing everything
without giving rise to phenomenal experience, just mechanical.
Based on the intuition that...
What does that mean? I don't understand what that means.
I think the intuition is that phenomenal experience is something that cannot be explained through causal structure, through mechanisms.
But why do we think that? I don't understand why we possibly think that.
That's what I mean about not understanding the hard problem of consciousness.
Because I'm like, look, this is why my definition of life as beginning before the cell is instrumental to eliminating the hard problem of consciousness.
Because if you have in the most basic cell, which is an embodiment of the state of matter that is life,
you have a resonant state, which is electromagnetic. It's the redox state.
And the cell needs to maintain that electrical resonance at a specific set point, because if it does not, it dies.
And so it is going out into the world and it is constantly controlling where it is in the world relative to its internal state.
And as you progressively produce more and more complex beings, you get a more and more complex map of the world and a more and more complex internal state.
And so by the time that you have a thinking, a walking human, you cannot have a walking human without an internal state.
It's a philosophical thought experiment that requires you to divorce yourself from everything that you know about biology in order to make the claim.
And I just feel like you can't do that because the biology is inherently what produces the conscious.
It's the state of matter that produces the consciousness and all of the resonant waves that are inside of it.
And so if you have the resonant waves in the sufficient complexity of a sufficiently resonant system
that is interpreting the world relative to itself and to what it wants, how can you have anything except for consciousness?
You have experience, you have the mapping of expectation to frustration, and it just emerges from the most basic cell.
How do resonant waves produce consciousness?
Say it again?
How do resonant waves produce consciousness?
OK, so do you know the Qualia Research Institute?
Yes.
So what is their work?
Their work is that they're basically showing that there are harmonic states in the brain that are associated with experience.
I think that they're mostly trying to use psychedelics for intellectual gain.
Yeah, but like if you...
I think it's similar to the question...
They don't produce causal models of how consciousness is being produced, I think.
I think that they're not producing causal models, but I think that their experiments show something interesting.
What were you going to say, Shay?
I was going to say the question seems akin to asking how do fundamental waves produce music,
which emerges from all of these individual tones.
But the same thing with conscious experience is you have the summing of different modules within the neuron-based systems
that are all aggregating and fighting and resonating with one another, and you get music that comes out of it.
And you don't see an explanatory problem there?
No, I mean, I can see a mathematical problem.
I can see that it would be very, very difficult to mathematize the way that that resonance...
The thing is math just isn't explanatory.
It has zero explanatory power by itself.
You have to have that linguistic conceptualization overlaid on top of mathematics in order to make sense of it.
Linguistic explanations have no explanatory power.
This is just words.
Hold on, hold on, hold on.
How can you use words to explain anything?
How can you use math to explain anything?
You can't write me an equation to explain anything.
Math can only describe what's happening.
It cannot tell me what causes the actor to do the thing that it does.
And it can't even tell me what the actors are using the math.
The math has to be qualified with linguistic descriptors.
They're the most powerful symbolism that we've developed as a technology.
Like, I think that a great example of this is that we don't have...
Excuse me.
We don't have an explanation for gravity, but we do have a great description for it.
So the math is there.
Or the atom.
Yeah.
There's a bunch of explanations for gravity.
It's just that we have not completely converged on a single one.
There may be an explanation for gravity that's outside the context of this conversation,
but the most popular theory of gravity is not an explanation at all.
It's a description of how objects behave gravitationally with respect to one another.
Relativism is fundamentally a description of what's happening.
It's not an explanation of what's happening.
It doesn't actually tell me what's holding my body to the floor.
It's just telling me that my body will be held to the floor in this particular fashion.
There's a theory that describes the evolution of locations in space-time.
It does describe them, but that doesn't explain anything.
The nice thing is that it reduces it to something that is much more simple.
And from this thing that is much more simple, you get your feet being pressed to the floor.
But it doesn't explain what...
The mathematics allows you to derive it from something that is simpler.
And deriving something from something that's simpler, I think, is what qualifies as an explanation.
It doesn't mean that you still have to deal with this thing that is simpler now.
Well, you have to deal with what are the physical objects doing to pull my atoms towards the ground.
And that is something that is completely overlooked when you're reliant upon a purely mathematical conception of the phenomenon,
because all you can do is look at how it's happening.
You're not able to tell me the mechanism by which that occurs.
You're not able to show me the structures of the atom that are capable of pulling on one another.
And that's what's necessary to make a true physical explanation.
But let's not do this today, because I think it would completely sidetrack us for a couple of hours.
But I think that the question of explanation versus description and how do you actually come to understand something
is central to this question about the hard problem of consciousness.
Because I'm like, look, if the challenge is that you don't understand how to mathematically encode the various resonance states
that results in an experience, I will accept that that is difficult.
But it seems obvious to me, especially with Grossberg's work, that resonance is the foundation of consciousness.
And that that resonance begins at the cell and progressively becomes a more and more complex wave
by the time that it gets to a brain.
And so if you have that as your starting point, then your complex challenge is to figure out the mathematical descriptors
and the sorts of states that have to go into your model in order to produce the desired outcome.
But you don't have this thing of like, how can I possibly know if another entity is conscious?
Because it's like, well, does it have the hardware?
And if it has the hardware, then your answer is yes.
If its hardware is broken, then probably not.
So it seems to me that your confusion is a different one than the disagreement that some people have with Dennett.
The issue with Dennett is that he does not address phenomenon experience head on, apparently.
Perhaps he doesn't have a lot of it.
Maybe he has a fantasia with respect to phenomenon experience and mostly gets conceptual representations
that for him are completely satisfactorily described linguistically.
But before we can proceed, I suspect we would need to resolve something else,
and that is the relationship between language, meaning, and mathematics.
I don't think that we have a shared understanding there, which makes it very hard for us to proceed.
So when you talk about harmonic waves producing a phenomenon, for me that's very far from a causal explanation.
So it's something that is very unsatisfying to me because I cannot build this.
For me, a causal explanation is something I can make.
And if you look at the world of the objects around you, the physical world,
I can make something that looks a lot like this in a computer.
Every phenomenon that can be specified and that can be described in an experiment, I can recreate this in a computer.
It might be difficult to scale it up.
It might be difficult to solve all the puzzles involved to get from quantum effects to relativistic space-time and so on.
It's one of the big unresolved puzzles so far.
But a number of people are working on it and think they are very close to having a solution to it.
This can all be described in a framework where we use finite automata inside of a computer to perform mathematical transitions.
And what they explain is the causal structure of elements that I get when I decompose the universe into separate objects.
That is a perspective that I introduce by introducing boundaries between objects in my model.
And then I'm able to make the universe manageable.
And so, for instance, I can create boundaries between elementary particles along the atoms
and say that the atoms are separate objects despite being forces between the atoms that make them not completely separate.
And there being entanglement in shared states in groups of atoms under certain circumstances and so on.
It makes it harder to create these boundaries correctly.
But this is sufficient to get to the next level of abstraction and say, OK, what the molecules afford you and the atoms afford you is mechanisms.
And using mechanics, you can produce dynamic state transitions in systems and you can build control systems.
And once you have control systems, you can also build control systems that don't just regulate the present
but also regulate the future. But in order to regulate the future, they need to represent stuff that isn't there, right?
That will be there at some level of post-graining, but it's currently not present.
So you need to have a system that is causally insulating part of your mechanical structure from the present structure of the universe.
You can use it as a representation, right?
Your computer is going to represent stuff that is not currently part of its environment that is different from what the universe is doing at the time.
And the computer is the principle to produce this causal insulation of a representational substrate in the environment.
So you can represent whatever you want, whatever causal structure and transition you want.
When I talk about a wave, a wave is a periodic process, right?
There is something like a circle in time. That's what a wave is or an ellipsis in time.
And a circle only exists some degree of approximation.
What you're really looking at is a process that in some sense is repeating itself in some fundamental way,
whereas there's also variation in it in some fundamental way.
So something is changing over the different courses of the oscillations in your waves.
And sometimes there's not much changing when you look at, say, photon progressing.
You can describe this as a periodic process that can be mathematically formalized as a wave equation.
And that's why physicists call it a wave under some circumstances.
But there is not much changing during the evolution of the wave, but the progression of the photon.
So the photon doesn't decay.
But if you look at a wave in your brain or a wave on the surface of a pool in your backyard, this one is degrading.
There is a periodic process going on, but there's also friction going on, dissipation of information.
So it's only an approximation of a thing happening for a certain amount of time that allows you to characterize it as a periodic process.
This periodic process can be described as the interaction between molecules, for instance.
And now when you think about this, how does the interaction between molecules that you can formalize using a wave equation explain consciousness?
I don't think that you have made a very good job yet.
I'm still looking at something that looks like a very complicated puzzle.
OK, so you look at something.
You said something earlier in the conversation where you said that the job of life is to harvest negentropy.
So I immediately in the context of a wave think about sonication.
Have you ever sonicated anything?
No.
So a sonicator is an ultrasound probe that you put into a liquid and it breaks things up into smaller parts.
And so immediately you have that a wave actually can do work on the world.
And so it's in its most pure and simple form.
You can use a wave to break matter up into smaller pieces.
But what the wave actually is, the wave is not an object.
The wave is a way to think about interaction between molecules.
What's actually happening is that what you are inducing is a change in the velocity of a bunch of molecules that bump into other molecules.
And the progression of that movement can be focused in such a way that the intensity of the velocity change is higher in some region that is remote from the emitter.
And so you take a bunch of emitters and you focus the emission of the velocity changes in such a way that there is a point away from your ultrasound emitter.
You have a lot more energy focused in one small area where basically the molecules are moving much faster and with more divergence on the objects that you want to break up.
And you transmit this energy into the object that you want to break up, but still all just moving molecules.
And I think that it's the same process that's happening inside of the body.
You're still just moving molecules.
But they move in a way that is at the end of their path of travel directed and concentrated in such a way that results in action.
And so if you have that as your most basic form of function, the wave is a thing that happens inside the molecules of the body.
And that wave starts to happen when you're a bacteria and you are in a soup and you don't have enough food.
And the way that you operate is through Brownian motion.
And you spin your flagella until you get a molecule and your flagella starts to spin in a direction where you continue to travel.
But then you dissociate the molecule and then you spin randomly until you find another one.
And that way you gradually work your way up the concentration gradient.
That's the same process by which experience is managed inside of a human body, except for the fact that it's far more complicated.
What you're still looking at, of course, is the flagella is the robot.
The cell is a robot in a sense.
It's all just molecules enacting certain kinds of mechanisms that are producing a desired behavior in an entirely mechanical way.
And what most people seem to be confused about is that they don't see how a mechanism can have experience.
Well, it's because the OK, so I personally think that the cell has experience.
Like, I think that a bacteria, when it is about to die, feels that it is about to die.
Why?
Because I think that it experiences redox stress and that's electrical and you can feel electricity.
But why is there a self in the bacterium?
So the self is something that requires multiple, like progressively more complex modules that come together that are able to form an external representation of the environment and then relay that onto their place in it.
So I agree that the self is more complicated than what the bacteria has.
But I don't think that you have to have a conception of self to have an experience.
That's the fundamental problem.
Like, the experience predates the self.
This is tantamount obvious because animals that don't have a sense of self still have experience.
And so the idea that the entire theory rests on the emergence of the self out of, like, if you have experience, you must have a self, to me doesn't totally make sense.
I think you need to have something like an attentional self to be conscious.
And a personal self is something that is developed later and is much more specific.
You attribute much more to yourself than the fact that you observe.
And also, when you are an attentional self, it doesn't mean that you necessarily have a language in which you can reason about the fact that you observe yourself and you're able to conceptualize yourself in any way.
So you can be an entirely preconceptual agent that still is conscious.
And the boundary condition of that can probably be seen in dreams.
They're basically states in which you do not have a notion of a self beyond the fact that you have some kind of reflexive attention, that you observe yourself observing.
And yet it's not clear to me that the bacterium would necessarily be reflexive in this sense, that it has an attentional self that is singling out features in such a way that it's able to act in a model of its own awareness that would make it conscious.
And it's not obvious to me that the bacterium would be conscious.
But I don't think that without consciousness you can have experience.
I think a person that is unconscious doesn't have experience.
Do you mean self-awareness by consciousness? Is that what you mean?
No, I mean awareness of awareness.
So you can also be not aware of yourself by being conscious, even though typically the awareness of the fact that you're aware is only one step away.
But you have awareness of content, awareness of the mode of experience and reflexive awareness that usually come together in a conscious system.
But without this singling out of features that you're attending to, I don't think that you can be conscious.
That seems to be one of the necessary conditions for consciousness.
And it's not obvious to me that bacteria have to fulfill this condition to function.
Well, I think that it's possible that the bacteria don't fulfill the conditions of a human.
I think that to say that they do would be absurd.
Yes, but it's not what we are asking for.
We are asking for in order to be a functioning bacterium, there's a cellular membrane and some metabolism and the ability to self-replicate and to adapt to some degree to environmental circumstances.
For all these robotic functions, it's not obvious that the bacteria needs to be more conscious than a soccer-playing robot, which is not conscious.
If you build a robot that plays soccer, the robot is fulfilling a bunch of functions.
It's going to model its environment.
It's going to figure out where the ball is, where the other robots are, where the goal is, how to get the ball between yourself and the goal, how to push the ball into the goal and so on.
So in some functional sense, it's going to have beliefs about the environment.
It's going to have commitments about the course of actions.
It's going to have co-directed behavior.
It's going to have representations about the world with itself inside, but I don't think it experiences anything.
But I think that the reason that it doesn't experience anything is because it isn't sufficiently complex, the circuit that's inside the soccer-playing robot.
It's not sufficiently flexible.
Yeah, that too.
Do you want to elaborate on that?
Well, it seems to me that in order to conceptualize, you have to be flexible and imagine something that doesn't already exist.
And that seems like a difficulty for unconscious entities.
So the soccer-playing robot never decides to play rugby, but the bacteria that's eating ethanol can then shift to eating plastic.
I'm not sure if bacteria in general have this much choice.
I mean, the metabolic flexibility of most bacteria is stunning.
They're packaged with the ability to eat a shocking number of substrates.
And so there is a choice where if you have an environment that has a bunch of different chemicals in it, you can choose what you eat.
The robot, if you teach it to play soccer and you put it in a pen with a bunch of balls, only one of which is a soccer ball, you would have to then program it to pick the soccer ball out and then to play soccer.
If you wanted it to be a game-playing robot, you would then have to program it to be able to play whatever game you play with whatever form factor ball, right?
You'd have tennis ball, rugby, high lie, whatever.
And so in order to get something that even begins to approximate the kind of flexibility of a bacterium, you have to program something that is far more complex than a soccer-playing robot.
Because to minimize a bacteria to a soccer-playing robot is to erase the magnificent functional complexity that is inside that little package.
I think you are putting too much into your language that is basically inducing you to have a state that makes you more likely to appreciate magic.
I think if you take a bacterium and you put it into a novel environment, the bacterium has an experience before.
If you just pick an arbitrary bacterium from its normal habitat, put it into a completely new environment where it doesn't find the food that it's used to, it dies.
The reason why so many bacteria survive is because you typically don't just pick one, you pick many, many of which have a potential to thrive and they might evolve quickly.
Single cell evolution is very quickly, but they need to have a starting point where they can already work with this.
And many families of bacteria are able to work over a range of environments.
But I suspect that you can have very different degrees of complexity in the bacterium and there are probably bacteria which are really, really stupid and very non-adaptive.
And in the same way, you can build a soccer-playing robot that is extremely complex.
If you think about the complexity of the systems that people are building, the rates of stable diffusion are just two gigabytes.
And they're the result of training on a few hundred million images and text.
And they contain all the artistic styles and all celebrities and all the dinosaurs and all the plants and the visual universe that is much larger than the visual universe of a person.
And it's only two gigabytes.
And it probably far exceeds the ability of a bacterium to recognize the environment.
But building two gigabytes into the vision system of a soccer-playing robot doesn't seem to be really daunting.
So the complexity that you can build into the soccer-playing robot can be very, very large compared to the complexity of what happens effectively in a human brain.
Of course, emulating the functionality of a group of neurons can be very expensive.
But how many neurons do you need to run macOS?
How many brains would you need to run macOS in a stable way?
Probably not that many.
I think quite a few.
Because neurons are not very deterministic.
You would need to create an enormous amount of redundancy to make this happen and to work out.
It's basically deterministic structure that you want to build into a brain.
It's not working all that well.
You can build a vision system with a slow, mushy brain.
And still, you would not be able to build in such a way that it's able to, within one week of training, is able to infer the structure of the world from looking at 800 million pictures and captions.
This is a task that no biological brain can perform.
But what's interesting is the biological brain can perform the task with much less training.
Yes.
It basically suggests that there's a better algorithm than the one that we're currently using.
Yeah, it's the biological one.
It's the structure.
It's the connection of the wetware to itself that integrates the controller with the executor.
And that's kind of my point where it's like any exercise that attempts to explain consciousness without the physical substrate,
without recognizing that the physical substrate is mandatory for the effect that we're seeing and is the iterative product of progressive complexity that has been evolving on Earth for the last 4 billion years,
will fail to produce consciousness because it is inherent in the structural organization of these different modules that resonate with one another to create complexity.
Because I was thinking about this earlier when you said about, you know, the bacteria is really simple.
I think you're right, where if we go back to this idea of complex harmonics being the phenomenon of experience, is all these different resonant modes,
you can think about what it feels like to listen to a sine wave versus what it feels like to listen to a symphony.
They're the same thing, except the sine wave has been modulated into something far more complex and that complex wave has something else in it.
I cannot help but feel that when you are describing biology, you are ascribing something to biology that cannot emerge over chemistry.
Chemistry or chemistry as properties that cannot be explained by physics.
This is not the perspective that I have. For me, everything ultimately gets resolved into state transitions that can be described qualitatively and quantitatively.
At no point does magic enter the system.
The way in which you describe biology, for me, still has to be reproduced by the mechanisms.
I cannot make this claim. I don't see how you can make that claim.
I would say that there are bacteria which are very complex in their behavior.
Like a stentor is basically a little animal that is hunting other animals.
Yet the behavior of the stentor, which is very complex, is not as complicated as the behavior of the soccer-playing robot.
The externally observed behavior with respect to the environment.
The mechanisms of the soccer-playing robot are much simpler because the soccer-playing robot doesn't need to be self-organizing because I can make it.
There doesn't need to be a second-order system that enables the soccer-playing robot to harvest its own energy in the environment from basic foodstuffs
and to build its own structure and to repair its own structure after it's been disturbed to self-replicate.
Imagine a self-replicating soccer robot. That would be a behavior that no soccer-playing robot can perform.
But just the interaction between the environment and playing a ball into a goal is something that I think no bacterium can do.
That's an interesting experiment, and I don't know the answer to that.
But I immediately think that there is something important in that phenomenon which I think you dismiss kind of easily,
which is the self-regulation and the replication and the evolution.
Which, when you look at a simple system like a bacterium, it is a seed for the complexity that comes downstream.
Because you go from bacterium to biofilm.
And in the biofilm, you have an awareness of the environment because you are responding to the environment in an organized way.
There's layers in the biofilm that, based off of oxygen penetration, will produce different things.
Anastasia, I'm not dismissing this. I want to define the self-organization in such a way that I can decide whether it's present in the system.
When you talk about awareness, I ask you to give me a formal definition of awareness that I can apply to any given system to see whether it's present or not.
You're just postulating it. You cannot just postulate that the biofilm has awareness of its environment.
It's possible, in my perspective, that the biofilm produces the observable behavior without having awareness.
It can just mechanically react to it.
So, in something that is like the human, if you change...
Let's say you put a brain scanner on a human.
And this is where the QRI work is interesting.
Because there appear to be different states inside the brain that correspond to emotional states.
And so, if you are unhappy or you're feeling depressed, there's a different brainwave state that is associated with that experience.
And what you can do is you can modulate that brainwave state and induce a different sensation.
So, transcranial magnetic stimulation.
Did you read about that woman who had intractable depression and then they inserted an electromagnetic pacemaker into the brain that cured her depression?
There are a number of phenomena like this.
And I think if you look at a computer that is producing a glitch, it's also conceivable that you can build some pacemaker into the computer so the computer no longer produces that glitch.
It still doesn't explain how the computer is producing the stuff that is not the glitch.
Maybe you want to explain why is my computer displaying a three-dimensional world, something like Minecraft.
Why are there colors in Minecraft? Why are there three-dimensional spaces in Minecraft?
Now I have to come up with a detailed explanation that explains to you how simple circuits, lots of transistors and so on in the computer can be set up in such a way that they produce these phenomena.
And not only that, you can also stop this and make the computer produce music instead in a completely different environment.
How is that possible?
And this is the kind of phenomenon that we want to explain, also with respect to the mind.
We want to explain how is it possible that you are said it's not sufficient to look at some kind of correlate.
The correlate itself is not an explanation.
To say that in many people who are said this is correlated with these and these brainwaves or with this and this EEG pattern.
And if I build a machine that is changing them, you can sometimes see a change, not always.
That's not sufficient.
You want to have a causal explanation. You want to explain what is actually the phenomenon that you are talking about.
What does sadness mean? What is actually sadness?
Sadness is an affect that is directed on some source of satisfying a need being permanently removed from your world.
You can never get it back.
And it's completely crucial to you. You identified the satisfying yourself through this source of satisfaction.
And it's gone. It will never come back.
This is sadness in some sense.
And a stronger form of sadness is grief.
It's this paralyzing form of sadness.
And sadness leads to certain behaviors, mostly a disengagement with the world because you're helpless.
You cannot do anything about it in supplicative behavior.
You are appealing to an environment to help you with the situation and to create a solution for a problem for which you're incapable of finding one.
And so sadness is some complex psychological phenomena that you can formally define.
And the question is, how is it implemented in the brain?
And what's also crucial about sadness is that you experience yourself changing as a result of sadness.
And without this experience, you wouldn't say that somebody is sad.
You would say somebody acts as if they are sad.
But there's a difference between acting as if you are sad and actually being sad because that requires an experience of sadness.
And so we are coming back to this original question.
How is it possible that a system that is mechanically implemented is actually feeling something?
And don't say waves that are interacting with each other.
That sounds like magical thinking to me because it's not adding anything beyond molecules bumping into each other.
And you're saying more complexity.
It just means more molecules bumping more complexly into each other.
It's probably true, right?
But it's not explaining it.
It seems like the magical transition for me is the ability to conceptualize.
And I think that's at the heart of defining intelligence as well.
The ability to pick out relationships in the world and then pick out relationships between the relationships
and then orient your being towards whatever you want within that set of confines.
Can you define this for me, what it means to conceptualize?
Absolutely.
So fundamentally, a concept is a relationship between two physical bodies.
So one is moving towards the other, let's say.
And then an abstract concept would be taking that motion and relating it to another concept.
And you can compound these into greater and greater degrees of abstraction
where you're talking about how to play the stock market or something like that at some point,
which is a highly abstract, or how to do quantum physics, which is a highly abstract series of concepts.
But this ability to conceptualize seems to be wholly unique to the biological domain.
As in, I've never seen a computer conceptualize anything before.
A visual model is conceptualizing things, or a vision model is also conceptualizing things.
It's not difficult to build a system that creates a model of relationship between physical objects
and makes abstractions over them, puts them into some kind of embedding space.
But can it make a new relationship?
I've never seen a computer make a new relationship.
It's never come to me and said, hey, this data set that I'm studying,
I think there's something happening over here which is interesting and could explain something to us.
They're not capable of giving that new order of conceptualization.
They don't put relationships together and give you a new relationship.
Beyond the bounds of their programming is I think what you're trying to say.
Yeah, yeah, yeah.
So it means you have never tried chat GPT?
No, I have, but chat GPT has never ever come up with its own idea for me.
It just takes my idea, my conceptualization, and elaborates, embellishes, gives me aid with it.
Same with mid-journey. It's not going to solve my problem for me.
I have to conceptualize how to trick mid-journey into making the image that I have in my mind.
But I had it in my mind to begin with, and I've never seen a computer have something in its mind to begin with.
I think that a great illustration of this point is if you go to mid-journey
and you're like, make me a YouTube thumbnail for a video about this, it can't really do it.
And maybe you can say that given enough time and enough training data
that it would understand a YouTube thumbnail well enough to be able to approximate something
that is the right amount of tasty that will perform well on YouTube.
But it's not quite there yet.
And I think that when it does get there, the only thing that it would be able to do
is it would be able to make a YouTube thumbnail that maximized the performance of something
that had already been done, but it's unlikely that it would create a new genre of YouTube thumbnail.
Because there's genres for these things, right?
Like there's ideas that people have where it's like, okay, you have to have a face that's looking a certain way,
and then you have to have some splashy text that looks this way,
and this is a format that works and people use it, but somebody invented that format at some point.
And so does the machine invent the format?
Or can it only take the existing format and just kind of roughly map your instructions
onto something that it has been as a successful YouTube thumbnail and give you that?
Yeah, it's our ability to instruct ourselves, which is wholly unique,
and I don't see any hint of that in the artificial.
I think the word intelligence is completely inappropriate to describe these machines
because they don't have that ability to de novo generate concepts.
Can you create a concept de novo, please?
Absolutely, yeah.
But go ahead, tell me something I haven't heard yet.
I mean, every time that I write a piece of music, I'm stitching together all sorts of new concepts.
I'm going to use this synthesizer in a way I've never used it before
to accomplish some goal that I couldn't have imagined before I set this harmonic progression in front of myself.
I have the same impression when I use Image Generator.
After Delhi came out, I got access and I spent several days producing hundreds of illustrations
for the book of imaginary beings by both.
And I found that it had profound difficulties when it came to chimeras,
which means it takes a long time, many attempts to get a working chimera.
And it has to do with the particular kind of mechanism it uses for producing images.
So when you are producing something like a minotaur, or a centaur is a better example even,
the issue with centaur, it should have seen a bunch of centaurs.
And sometimes it gets a centaur, right, like every once in 500 attempts to get a working centaur.
But mostly it produces parts of horses and humans early on,
and then converges of human and horse in some configuration.
Because it doesn't really know how to grow humans and horses together in most of its default training sets.
So it's very hard for it to end up in this local optimum where you end up as a centaur.
But it has to do with the particular kind of annealing process that is being used.
And there are probably better alternatives to this, or you can overcome this with better training,
or with some iterative process that produces it that you can also build into the model.
There are other issues that it had, the Delhi version that I've been working with was very bad at counting.
So if you want to make a dragon with nine heads, it is really very difficult to get something that comes close.
It is able to count until 2 plus minus 1, or sometimes 3, but then it gets very difficult.
And these models have gotten better when you now generate pictures with mid-journey.
Very often the number of fingers is correct. Hands are still somewhat difficult.
I'm really glad they fixed that.
A joke when some bot is talking to me in my Twitter DMs or on WhatsApp,
I ask them to send a picture out of their pretty Japanese face, but of their hands.
And they typically don't.
It's in some sense very wild what is happening, but there are new genres emerging after mid-journey came out.
Like the genre of Kermit the Frog in Space Odyssey and other movies.
That was for a shorter time a small genre that popped up.
And now you have the Balenciaga genre on YouTube, and everything as well as the Wes Anderson movie genre on YouTube.
And of course it gets old fast, but there is something deeper going on with generative AI due to the temporal instability.
This stuff has not been trained on video so far, none of the released models, but on individual frames.
And as a result, it's hard to make them temporary stable, which means that if you try to create a movie, they often flicker.
And every frame is slightly different from a slightly different movie still.
And this creates something new. It creates a new form of art in which you realize the efforality of the form.
And what's stable is the concept that is referred to by the prompt.
We now have an art where the concept itself becomes visible behind the form, because the form is flickering and changing in every frame.
That's quite fascinating. It didn't exist before.
And if you wanted to produce it, it was very difficult and expensive to make, and now it falls out for free.
So there is a new type of art that is possible.
I also noticed very simple things when you asked Dali to produce an ultrasound of a dragon egg.
It was not in its training data, and it makes a pretty good job.
There is something that does require a certain degree of creativity in humans to put all these latent dimensions together.
Why does this work? I think it works because if you have enough dimensions, and if you cover the space of these latent dimensions of meaning,
extrapolation and interpolation are the same thing.
Which means that when we represent meaning, the entire space of meanings can be understood as a high dimensional space
in which every dimension is a feature dimension, and every point on this dimension is a state that the feature can be in.
And an object is a range in which configurations of features are compatible to produce that object.
So you basically get a space of function. Every feature is a function that is varying parameters.
Or you could say that a function is a configuration of multiple dimensions if it has multiple parameters that changes that function,
and you can create an entire world from this.
You could also think about it in a slightly different way when you are creating art with Blender.
Blender is a 3D program that allows you to make dynamic scenes and arbitrary objects.
And to some degree of approximation, almost everything that you can visually imagine, you can recreate with Blender.
And you do this by creating a hierarchical function that starts with a scene, that is the configuration of object that you're looking at.
And then you have objects within the scene and overall filters that act on the whole scene and produce certain visual effects.
And some of these objects are going to be light sources that can be directed or undirected and have certain features that are discerning the properties of different light sources and define the functional properties.
And then you have dynamic objects that are characterized by a skeleton along which movement happens,
and joints in these skeletons, and skins that are moving along these joints and on the surface of these skeletons with certain properties,
volumes that can be defined in arbitrary ways with mathematical functions and so on.
And then textures that are superimposed on these objects, colors that emerge as parts of these textures in interaction with the light sources and reflect the properties of the environment and so on.
And so you basically create a complex hierarchical function that is producing all these visual effects.
Your mind is probably doing the same. When you are perceiving things, your mind has some kind of game engine that is trained to track perceptual features in your environment.
And the present AI systems are doing a relatively good job at doing a similar thing.
Arguably, they're not doing this by a self-organization, but by some kind of brute force.
But the causal structure of the models that are being generated is pretty similar.
And I would lie if I would say that it's not surprising what Dali or Mejwani are generating.
Very often they're not generating what I have in mind.
But this would also be true if I was an art director and talked to a minion to produce something for me.
There are probably many iterations until that gets close to what I have in mind.
And this mid-journey, the process is not that different.
And so mid-journey in some sense works like an extremely fast, highly skilled, very autistic artist
that has seen a lot and is able to combine stuff across many dimensions to produce things that it has never seen and nobody has ever seen.
I would say that it lacks understanding, though.
It doesn't have the self-organizing. I think that's the hinge. It doesn't have the generative ability to prompt engineer itself.
So that is, I think, one prong of this.
And the other prong of this is the fact that the things that it generates have no meaning for it.
And when you're trying to deal with the question of consciousness and you're like, what is the experience of seeing red?
You have to assume that there is a function of red in the evolutionary past that played a role that encodes the way that you perceive it
that is the echo of the simpler mind that perceived red for the first time.
And is the progenitor of what will come after.
I suspect that red by itself doesn't look like anything, in the same way as when you are only looking at the blue sky, you don't see the blueness after a while.
Red is a property that is shared by the surfaces of red objects.
And it's distinct from the surfaces of blue objects.
And the thing that makes it distinct is the relationship that it has to certain objects.
It's the color of blood, the color of roses and so on. It's the thing that they have in common.
And that's why I also don't think that the inverted spectrum illusion would work,
because I don't think that there is any essence of red beyond its relational context of being a surface property of visual objects
that share this property across lighting circumstances.
So it's basically an invariance in the world in a space of similar invariance that exists in the same function space.
And if you transmit this to your model of blender, redness is basically some kind of stationary property of a surface.
It cannot be rotated into other colors.
In this way, you have a color space that does not really allow you to do the same rotations as you have in a spatial space
where you can take an object and rotate it around an angle and it's still somehow the same object.
This does not really work with colors.
But you can also have a color space in which you have multiple colors which you shift because you change the lighting
and thereby perform something similar.
So there are certain properties and they're all mathematical properties.
And it turns out that basically color is a polar coordinate representation in your brain with respect to certain relational properties.
And that's why you can also have synesthesia about color because you can use the same mathematical construct to represent aspects of sound or numbers.
And if you do this, you can experience them as colors in your mind.
And so functionally, colors are a particular kind of mathematical object.
And that still doesn't explain why you experience them.
But you've experienced them all along the line, right?
Like if you are the end result of 3.8 billion years of evolution, you've probably seen red before.
You've probably experienced them because they're useful, right?
Humans have an extraordinary capacity to distinguish colors compared to other animals.
But this does not explain how it technically works, right?
The fact that something is useful doesn't explain how it's actually possible.
The fact that it's useful for birds to fly does not by itself explain how it's possible for birds to fly.
Well, there's a neuro-mechanical explanation for the perception of color, right?
I mean, you have photoreceptors in your eyes that transduce different energies depending on the stimulation they receive.
And there's a way of integrating all of that signal in the visual cortex and so on and so forth.
Yeah, but you only understand it if you can rebuild it.
So, for instance, what I noticed when we built soccer-playing robots and we characterized colors as wavelengths, it didn't really work.
For instance, there's reflection of the orange ball in the green field.
And we used very intense primary colors to make the task of color segmentation as easy as possible under very even controlled lighting.
And it didn't really work even under very even controlled lighting because color is not really a wavelength.
It's something that is relative to the objects.
We found that the green field below the ball is more orange than the orange ball above the green field due to the mutual reflection is not green.
And in order to interpret them properly, we would have to become much more lenient and accommodate the fact that these reflections are happening.
And so in some sense, orange is what a boat can get away with being when it's an orange ball under the circumstances that it's in its environment, which are variances in lighting and green objects nearby and so on.
Well, I think that actually strikes at the heart of something really important, which is that the human perceptual framework, the consciousness, is able to differentiate between useful information and not useful information.
And that's something that you get in when you're using these mid journey prompts where it has a really hard time.
You can give it weights and you can kind of you can you can control how it gives importance to various things.
But it's really hard to tune meaning into it.
Like when you're talking about the fact that it doesn't know how to make a centaur, it's because it doesn't understand anatomy and it doesn't understand what an animal body is and what a human body is.
I was really struck by its inability to make hands because to me it was a reflection of the fact that it was a machine that didn't understand what it would be like to pick something up and the biomechanics of what of what hands do.
You know, humans are also horrible at drawing hands.
Again, no number of artists really struggle doing hands.
Hands are extremely difficult.
That's not a big surprise that the AI struggles with doing hands.
And I would say that the AI is bad at anatomy.
The mid journey is definitely much better at anatomy than the average human being.
I think that it is decent at anatomy that is conventional.
So if you are trying to make something that is a human, there's enough pictures of humans in its in its training data set that it can say, OK, this is the shape of a human.
I can move that shape because I've seen it enough different shapes.
But if you ask it for a really weird perspective or you ask it for something that isn't really represented in its training set, it doesn't have a conceptual model of human that it can then put into that really weird foreshortening or into the really weird contorted position.
That's when you start to get monsters.
That's what Gary Marcus told me about Dali.
Then I created people from all sorts of perspectives and unicorns from all sorts of perspectives.
It's not an issue.
It's not true.
It does understand the three dimensional structure of objects and is usually able to represent them better than most people do.
I think it does understand the structure of three dimensional space due to its training data.
And that's why you can also take these models and tune them to produce three dimensional objects as an output.
This is a conversation that I feel like would be best had with a portal with mid journey in it where we could like try different prompts as we do it.
I also don't think that's actually the problem that you're having because the interesting thing is I don't believe that mid journey is experiencing any of that.
I would agree.
The interesting question is what is missing to make this experience something?
The fact that it's coming from somewhere and going somewhere.
I don't know how you can dismiss that.
That is what life is.
And consciousness.
Okay.
Do we agree, all three of us sitting here, that consciousness is a property of life?
No.
No.
No.
What else is conscious?
It's the ability of a system to experience itself observing.
It's basically an awareness of your own awareness.
What else can do that except for life?
At the moment, it's only some living systems that can do it.
Possibly, but we don't know there's some AI systems.
What is the evidence for AI systems being able to do it?
That they're able to report about the features of it.
After they've been trained on literature that contains stories about AI futures?
That is one of the problems.
We have difficulty to discern to which degree the AI system is able to do something
because it has seen this in the text.
On the other hand, it's hard to say how that is different from the causal structure that is being implemented.
If you think, for instance, reasoning, can an AI system reason?
It's somewhat related to the question, can a person reason?
Can a human being reason?
We have an intuition about how reasoning works.
This intuition is not completely nonsensical.
It's also not perfect.
Aristotle tries to systematize it and really writes it all down.
He gets only 80% correct.
He tries to systematize over pseudoscience and how to do reasoning properly.
Then later on, there are people like Tarski and Frege and so on who really reason about reasoning
and come up with a formal theory of reasoning that is way better.
The people that are reasoning professionally today for a living,
they basically read stuff that is derived from this.
It's not derived by them just sitting there and thinking about how their own reasoning works
and figuring it out magically.
In some sense, people to some degree are language models
that build causal structure influenced by text that they read
and trying to map this causal structure onto other texts that they've read until it clicks.
I would agree with that because I always think about the Romanian orphanage example
where if you have children that are completely abandoned by the society,
they don't grow up normal.
There's something about the system that needs both touch and emotional connection
and intellectual stimulation in order to form what we define as being a person that fits into society.
I still think that they're probably conscious.
They're just not able to make the same sort of cognitive leaps and developments.
I'm also convinced that cats are conscious.
It's something that you can in some sense verify by going into some kind of feedback loop with the cat.
You basically have a mutual awareness of the awareness of the other.
Doesn't that obviate the example of the philosophical zombie?
Sometimes you can just go into a loop with the zombie to confirm the fact that they are having experience
even if you can't cut them open to see that they have a brain or put a machine on them.
This points to a very interesting aspect of the discussion about the heart problem.
It's essentialism versus functionalism.
Essentialism is the position that something is just intrinsically in a particular way
without realizing some kind of function.
A lot of philosophers who feel that consciousness cannot be explained as the result of some kind of causal interaction
of non-conscious physical phenomena, they suspect that consciousness needs to be made fundamental.
If consciousness is a fundamental property of matter, then you end up with a version of panpsychism.
The drawback of panpsychism is that it does not explain how consciousness comes about
because it's an answer of the fact that you cannot explain it and thereby say it's irreducible.
It's just an essential property of something.
When you say that consciousness is a property of biology, it sounds a little bit like this to me.
I'm not sure if this is what you mean, but it could be that you are stating that it's an essential property
that is just emerging in biological systems as a result of them being biological systems.
In order to be a cell that survives, you have to have a way of integrating information
about your environment relative to your internal state in such a way that you can bring the two into alignment.
You can call it a thermostat, but I think that that's probably a dismissive way of treating it
because it's the world's most complicated thermostat.
You're right that if you put it into the wrong conditions, it will die,
but it's also a thermostat that if the conditions change slowly enough, it will adapt to the new conditions.
It will become not a thermostat purely, it will become a thermostat and something else.
A thermostat can't do that.
There is a structural mechanical event that happens in the bacteria
that is the absolute simplest form of what we ascribe as being consciousness.
Our consciousness is not the consciousness of bacteria.
I don't think that rocks are conscious, I don't think that atoms are conscious,
but I do think that by the time that you get to a cell, there is this goal directedness
where there is a future that you are working towards and that simplest future for bacteria is I want to survive.
It's not written out in natural language of I want to survive,
it's programmed to survive and then to turn into something that will survive when the situation changes.
When you have a long enough chain of those situations changing,
you have organisms that emerge that are able to specialize to different conditions.
As you change your organization and make it more complex so that you're able to look at stuff from more perspectives at once,
you start to build progressively more complicated systems
and those more complicated systems have more complex consciousness.
At some point you get to the realization that,
oh, hold on a second, there's me and I am a stable self and I can change who I am.
That's a crazy step, but I don't think that it's a step that's magical.
I think that it's a step that is the result of progressively more and more complex modules
that are able to perform the computational task of holding all of these concepts
in a stable state relative to one another for long enough for you to be able to look at them and consider them
and then after you've considered them to decide what you want to do next.
The bacteria might not be able to change itself,
but it might be able to move a piece of dirt out of the way to get somewhere that it wants to get to.
It's not conscious. That's something that the soccer-playing robot can also do
that they don't want to ascribe consciousness to without being forced to.
I feel that you are much more reluctant to ascribe consciousness to the soccer-playing robot than you are to the cell,
despite the cell probably being dumber than the soccer-playing robot.
It's the evolution that's important.
I don't see how the process that generates a certain thing is defining its functional properties qualitatively.
If you are evolving the soccer-playing robot and it's the same soccer-playing robot, it doesn't change anything.
It only matters what it is embodying at this time when you look at it.
I think that's not how I see consciousness, because I see consciousness as something that is across time.
It could also be that your issue with the communication about the heart problem is that you have a non-standard definition of consciousness
that is meaning something completely different.
For most people that talk about consciousness, it's about the feeling of what it's like.
This feeling of what it's like, there are some philosophers which believe that it comes in degrees.
There are certain ways in which you can have a feeling of what it's like.
They're qualitatively different from each other, and maybe there are some degrees.
But you could also say that it has a continuous way in which you can become more or less conscious.
But I'm not in the camp that thinks that this is the right interpretation.
I think that consciousness is qualitative.
I think that there is basically a disruption between conscious and not conscious,
and there is some area in between where it becomes online and very only approximately conscious.
But there are no systems that are persistently in a state of only being approximately vaguely conscious.
It's only during this transition that there is some kind of coherence formation that happens between sleeping and waking,
or waking up into a dream vis-en-sleep or out of a dream.
This movement inside of a conscious state or outside of a conscious state is a qualitative difference.
The criterion between them is that outside of a conscious state there is no feeling of what it's like.
If you fall unconscious because maybe you faint, in this state you don't know what it's like to have fainted.
You wake up and you don't realize what happened.
You have no memory trace of that state, and there's probably nothing that your mind went to in the meantime.
It was conscious about something else and just did not bring the memory along.
You were just not conscious for all practical means and purposes.
I think that consciousness is a qualitative property that is not like fatness.
You could say that fatness is something that's very gradual, and you could also say that bacteria can sometimes be fat,
but if they're fat, they're fat in a very different way than humans are.
In a sense it makes sense, but I don't think that consciousness is like fatness.
I don't think that bacteria are conscious. It's possible and conceivable that they are,
but it would require that they have a very particular functional mechanism that would enable the bacterium to feel what it's like.
And if the bacterium doesn't have that, I would say it's not conscious.
It's just the way in which I would use the word. Can we agree on this usage of the word?
I think that the fundamental difference between the robot and the real soccer player is that the real soccer player could decide to just quit and do MMA instead.
You can build a robot like that. That's not the big problem.
That decides to take on a completely different task, but by its own it just decides that?
Yes. You give it a larger reward function.
You give it some kind of polythematic reward function in a similar way as we do.
But you have to do that.
Yes, but we can give it this. You are born with this reward function to a large degree.
Some part of it comes online during later stages in your life,
but for the most part your reward function is built into you by your organism.
So your mind is subject to some functions that are imposed on it by the organism,
and your personal self is subject to the expression of these motivational urges by your outside mind that makes you do stuff.
And the way this is functionally implemented or the way in which you can abstract it is that there is some kind of multidimensional reward function
that tells you in a given situation, in a given context, this is the value of a kiss, this is the value of a sandwich,
this is the value of getting the ball and the goal.
And if that changes, you might give up the plan on getting the ball into the goal and choose a completely different game to play,
because you feel that this other game is giving you better rewards,
which does require you to be able to have a meta game that you are playing.
So if you have a soccer-playing robot that only is playing the single game and cannot conceptualize anything outside of it,
then of course it will not be able to make that decision.
But if the robot is thinking of itself as an agent that can play soccer or look for a sandwich or look for a kiss, as you might,
then you have a much larger area in which you are going to optimize your expected rewards.
But it's not a soccer-playing robot anymore, it's a human being essentially.
You've just rebuilt life at that point.
But we are not necessarily at consciousness yet.
So what I described, this functionality is still a robot that is just playing a different game.
But we have not arrived yet at a system, despite producing all sorts of functionality that you would only expect a human to be capable of.
And you can even conceive of a system that is able to produce coherent sentences and interact with you in all sorts of ways without being conscious.
So there is this big question for a lot of people,
what is the difference between this universal robot that is pursuing the same goals as a human being and that has the same degrees of flexibility as a human being and pursuing them
and can make decisions over them in a functional way in the sense that it commits to different goals at different times based on reasons that are built into neural networks and reasoning mechanisms
that it's able to report and self-report about all these things, and yet there is nothing what it's like to be that robot.
This is the hard problem. What is that difference?
But if it has the ability to integrate all of these motivations, isn't that what experience is ultimately?
No.
Yeah, like why are you so sure that it's not conscious at that point?
Because I think there is no reason for that system to say, but I feel this.
Isn't the desire, isn't that decision to go and do MMA instead of soccer predicated on feelings?
No, you could simply say there is a 0.2 higher utility in making a sandwich rather than continuing to play soccer. So I'm going to do that.
But it might not be higher utility. It might actually be a terrible idea to go and do MMA if you're the best soccer player in the world, but you just want to do it because you love MMA.
Oh, that's a great point. Humans don't perform along these sorts of utility functions.
Somebody can do something that doesn't maximize utility. They do it all the time.
I think that is a complicated philosophical decision because there is usually a reason that you find something more meaningful and important to do something when you do it.
Or it's a compulsion, which means you realize you have a long game, but you are unable to play it because some mechanism in your brain is overriding it and you're forced to follow an impulse to play a shorter game.
But when you find something meaningful, it means that you can also describe it or somebody could describe it as a utility function.
So, for instance, if your meaning is to serve God, it means that you are projecting some higher level agent that you're part of in a similar way as a cell as part of an organism.
And you're serving that transcendental agency. And that creates meaning that is more important than your individual existence because you don't conceptualize yourself as the top root note of the universe, but just as a cell that is serving some larger organism.
And you can try to figure out the relevance of that with respect to getting a sandwich instead.
And suddenly getting the sandwich is instrumental to serving this higher meaning to some degree.
I think that we've kind of stumbled onto something important here, which is that the complexity of the utility function and the ability to have multiple competing short term and long term goals.
And this freedom of space in which to decide the way in which you will chain those actions together in order to achieve a goal that you have decided is utilitarian is the thing that you would then probably call consciousness.
And so the reason that the robot isn't conscious is because the robot has such a narrow scope of options available to it that it's too simple.
The minute that you know it is consciousness is the feeling of what it's like. This is what you need to produce.
So what is the feeling complexity is not producing a feeling.
But hold on. So if you're saying that everything that a human does can be reduced to a utility function, if you have a sufficiently complex understanding of their internal landscape,
then what feelings are is they are the experience of the utility function.
The utility function causes some kind of chemical change inside of you that can be modulated either with neurotransmitters.
It can be modulated with the potassium sodium balance at the membranes.
It can be modulated by the harmonics of your brain waves.
And when you're doing that thing, you have this full body electrochemical state that is the experience.
It is the experience lives inside of the body.
And so your feeling of a decision that you make is the result of everything that happens inside of your body as you are making the decision.
That's what feeling is. It's the sum total of the whole electrochemical state of the entire body as it does something.
With respect to the rest of the universe.
I would.
It's very poetic, but it's not convincing to me because it's still just clockwork and would not explain why there is an agent that experiences itself experiencing something.
Well, because the agent has to be the agent has to be able to say, I'm experiencing this and this is good.
And I will keep experiencing it because the agent's job is to make sure that the internal state is such that it can reproduce.
That's the agent's job. The agent's job is that life is a state of matter that aims towards complexity.
And your job as the agent is to make sure that this crystalline structure of life survives for long enough to make more of itself.
And if you fuck that up by feeling bad all the time, you're not going to make that goal.
And if you don't make that goal, you have failed at your mission.
And so the feeling is the agent who's responsible for enacting the goal, checking in to be like, Hey, are we on the right track?
Don't buy the idea that your uncertainty about whether you're going to reproduce is reflecting uncertainty about whether you're conscious or not.
Hold on. Say it again.
You just connected it to reproduction.
And at the beginning of our conversation, you did mention uncertainty about whether you intend to reproduce.
This does not reflect uncertainty about your consciousness, right?
Your consciousness is completely uncorrelated to this.
No, but your feelings are correlated to some of them.
Some of them are, but not the ability to feel it itself.
The ability to feel itself has to be the result of some causal process that a lot of people find confusing to get at because it is not apparent how a physical system would feel.
It seems to me that feeling is a property that you can only dream.
And what we have to explain is how a physical system is able to produce dreams.
I think that the question of how a physical system can produce dreams is a really interesting question, but it might be a good place for us to pause because we've been going.
I also think that it's worth it's interesting that if we can't explain how humans are able to produce feelings, then we can't rule out the fact that bacteria produce feelings as well.
But this is not the point.
I think we can explain how humans produce feelings by coming up with an explanation that would produce a causal agent that is reporting feelings.
The fact that bacteria do not report feelings is a possible indication that they don't have any.
The fact that people report feelings produces this burden of explanation of this phenomenon.
To simply say that both people and bacteria are alive and therefore both have feelings is somewhat unsatisfactory.
I don't think that bacteria have the same feelings as humans.
I think it's just really healthy to leave it in the hypothetical realm.
You said something earlier where you just were like, well, it's possible or something like that.
And I think that's often the best place we can get with our theoretical understanding of nature is whether something is possible.
I have a suspicion that what is going on is some distinction about the kind of nature of the universe that we are in.
When I was a kid, I read books about physics and our normal post-enlightenment modernist way of understanding our own place in the universe.
And I read Klawatsky and Aveda and other books.
And I realized that there seem to be two fundamentally different conceptions about the nature of the reality that we find ourselves being thrown in.
And one is that we are basically in a machine and we are part of the machine and it is nothing that is not part of the machine.
And that's basically the physicalist idea that there is a costly, closed, lowest layer that is entirely mechanical over which everything else emerges without any magic ever happening.
And in this world, it's pretty hard to explain miracles.
And the existence of our consciousness seems to be somewhat close to a miracle.
And if we would perceive magical stuff, like if you're able to burn a black cat and as a result we perceive a new kind of celestial event,
this kind of symbolic interaction would also what classifies as a miracle because it cannot easily be explained by some causal interaction on them,
some causally closed lowest layer that doesn't care about symbols.
And the other explanation that we could be in, that the one that is implied by Castaneda's worldview and so on, is that we are living in a dream.
That magic is possible and that the reason why miracles are so rare is the result of the way in which we are dreaming the dream.
So all the causal structure that seems to be so regular, the regularity of physics and so on in this worldview is explained by features in which the dream is happening.
And later on, as I try to think about these worldviews and make a distinction about them, I did notice that indeed I am living clearly in a dream.
There's lots of evidence that I'm living in a dream because the features of my dream are malleable.
It's very much like a lucid dream at night. I can change the way that a face looks like to me.
I can change my memories over the past. I can change my identity. I can change aspects of my consciousness in a pretty fundamental sense.
So I am clearly living in a dream. But the regularity in the dream can be explained by there being a parent universe in which there is some kind of machinery that is producing the dream.
And the machinery that is producing the dream is the brain of a primate in a physical universe.
And in this way, I can fit it all together and I can explain consciousness as a dream property that cannot be explained physically.
Like neurons cannot experience anything. Consciousness only exists as if.
Neurons can do stuff as if. They can produce representations that only exist as if.
In the same way as stuff in a computer game is only as if. It's virtual. It's only existing as a projection.
And I think that consciousness is a projection. It's a representational property of a system that is aware of the fact that it's aware.
And this is crucial thing about it that has to do with this hard problem.
And it is not readily apparent when you think what you see is physics in the physical universe.
And it could be that you don't perceive this as so much as a problem because you have committed yourself relatively early to the insight that you're living in some kind of dream.
And in this dream, you can dream about vibrations that produce phenomena in biological systems and that are intrinsically related to consciousness.
You experience yourself in this dream. You experience that everything is consciousness in the world. Everything that you touch is representational.
And I think that's true because we actually are living in that dream.
And physics is really talking about another universe that we can never touch, that can only be described as mathematics.
And my task is to explain stuff in this outside reality that we can never touch, that we can never be in using mathematical languages.
I think that you have struck at the heart of our disagreement then.
Because I do think that there is a very different perspective that we're coming at.
Do you want to elaborate?
No, go ahead. I mean, you're just saying I don't think we agree about what physics is fundamentally.
Shiloh has expressed that after several hours, he started meeting at 11. Now it's a quarter to four.
He is getting a little bit exhausted, which I think is very human and understandable.
It is hard to sit in a chair for three or four hours.
But I just think that fundamentally we're approaching physics as a material science, not as a mathematical science, which starts with bodies interacting with one another.
And you can treat this landscape of bodies interacting as a territory and you can make mathematical maps for it.
But ultimately, a body is a surface-bound volume that has inward extension.
But you know that physics, the surface-bound volumes are emergent over stuff that is more simple.
And ultimately, physics is about information that you can conceptualize as existing in different locations and moving in certain trajectories.
Yes, but biology is a subset of physics. It's a subset of physics that describes the dynamics of cells, which are complicated arrangements of molecular machinery.
There exist many levels above the course of the lowest level of physics.
There exist certain levels of coarse graining where you already are assuming that particles exist and particles form molecules in some way and the molecules are forming cellular machinery.
But I would never assume that particles exist, right?
I mean, a particle is just an instantiation of some measurement or predicted measurement.
It's a dynamic factor. A particle is not a static body that has an architecture to it, right?
Only bodies that have locations can exist.
You can imagine all sorts of bodies like your cenotaur that doesn't exist. It has no location in the universe.
You don't live in a universe that actually has localization in space.
Localization is something that emerges to some degree of approximation in our universe.
Well, localization is just your distance to the other objects.
It's just the distance to all of them.
There is no distance.
What do you mean if two bodies are touching one another?
If you basically zoom in very hard, what you notice is that you only have a quantum universe.
Well, that's a mathematical description. Once again, that's not actually what's physically meaningful.
Exactly. It's the lowest level of physics.
No, it's the lowest level at which we've been able to conceptualize it is that we're using mathematics to describe it.
I don't mean that because I can mathematically describe the table that it's made out of math.
It's just that the table can be described by math.
The atoms have architecture which allows them to do all of their incredible properties, right?
Their architecture fundamentally is what allows them to do light and gravity.
We don't have a good model in the mainstream for how those atoms' architectures provide for those mysterious phenomena.
We just describe them with math and move on because it allows us to build technology.
Your tables are real, but quantum effects are not real.
I didn't say real. I just said it's really, really important to frame the definition of existence in physics,
where physics starts with bodies that exist. They have to exist.
They have to have that architecture and it has to have a location with respect to the other bodies in the presentation.
That's not quite true.
I think that there are levels in foundational physics where you don't have bodies which are surface-constrained volumes.
Not everything has a location.
This is a mistake, though. This is a mistake because then you're talking about unicorns and things that don't exist,
even though you can conceptualize them. They don't necessarily pertain to the physical world.
You're talking about something that is more basic than your bodies.
You're talking about something that gives rise to bodies, that is more fundamental than bodies.
But bodies are fundamental to physics, is my point.
You can't do physics. You're not talking about physics.
My point is that your point is wrong.
Then how do you define physics, I guess?
Basically, go to a foundational physics conference and not talking about bodies there.
That's a problem. That's a really big problem. They were before 150 years ago.
They were absolutely only talking about bodies.
Progress is a bitch, I understand.
It's not necessarily progress, right? It's actually getting us down all of these rabbit holes
where we have completely untestable theories that aren't necessarily providing for technology,
like string theory, for instance, or our doomsday cosmology,
which is predicated on non-physical situations that emerge from the mathematics
but don't have any empirical evidence on earth whatsoever.
Okay. I sense that we basically arrived at a point where we will not be able in the next few minutes
to achieve consensus. I think that's fine. Let's leave it at that for today.
Absolutely.
Thank you, Shiloh. Thank you, Anastasia. I really enjoyed our conversation today.
Thank you for inviting me on your podcast.
I enjoy being with you. I enjoy the perspective that you bring to this
and the overall intention that you have behind your exploration.
The feeling is mutual. Thank you so much for taking the time and for the ideas
and the many, many questions that we will continue exploring after this conversation.
It's been stimulating. Thank you. Thank you, Yasha. Take care. Bye-bye.
Have a great rest of your day.
