Intro
Herzlich willkommen zur Folge alternativlos numero 52 52 dieses mal haben wir nachgeguckt
Wir haben heute einen Gast
Joscha bach ist zum zweiten mal bei uns herzlich willkommen und wir wollen über
Tja, wobei wollen wir reden über ai wollen wir reden und ob uns diese das war die nummer eins an frage in den letzten monaten
Wir sollen mal was zu ai machen genau
Und da dachte ich mir so
Wen kannst du da einladen?
Kannst du doch nur so rural patrioten einladen so jubel per hauser
So irgendwie die gestern noch für bitcoin wahnsinn jetzt für ai aber nein es gibt auch andere leute
Und dann haben wir den joscha eingeladen
Ja
Also ich meine dieses phänomen dass jetzt irgendwie die ganzen leute die vorher so schittkornschilling gemacht haben jetzt irgendwie
prompt engineer prompt engineering newsletter verkaufen
Ich schon ziemlich unterhaltsam
so früher gab es ja irgendwie so ein
Diesen so ein begriff dafür so wenn man so literatur aus dem 19 jahrhundert amerika aus der boom zeit liest
Da gab es den begriff booster dafür so nannte man halt leute die halt und eine spezifische
technologie und ein bestimmtes projekt unter einer eisenbahn linie oder sowas irgendwie
Quasi als influencer gepusht haben diesen booster und ich finde es eigentlich einen sehr schönen begriff der es irgendwie
Ich so zeitlos
Übrigens eine fliege hört es keine fliege das eine drohende uns die auferlauts geschickt haben können wir gar nichts gegen tun
Fürchten uns versucht fürchten ein nuklear arschloch weil wir die wegmachen deswegen machen wir es lieber nicht
Ja, wo wir reden wir eigentlich viel für du hast ja irgendwie weil die mühe gemacht zu gucken was ist da eigentlich dieses ganze
der ganze halb gerade also ich verfolge das ja schon länger weil ich das mal in meinem studium
Trotzdem nicht studiert habe machine learning
Und nicht dasselbe wie ei oder nein ist nicht dasselbe also da gibt es eine lustige anekdote für ich habe mal
Ich mache ja beruflich code audits und ich war bei einem großen kunden und der meinte wir haben hier was mit machine learning
Und ich dachte oh geil jetzt kannst du endlich mal deine neuronalen netze fähigkeiten anwenden
Und dann machst du den kode auf und blätter um und das nix mit neuronalen netzen
nix und dann
Oder die täte so ein tach und dann spricht die andere mein sie ja ja das ist einfach simple base
aber der kunde will
machine learning hören also verkaufen wir in machine learning
Und so ist das industrieweit
also es gibt natürlich auch echte machine learning anwendung aber
So die meisten business anwendungen versuchen gerade irgendwie aufzuspringen
Auf den auf den machine learning zu machine learning ist ja nicht nur nur eine netze
Nein natürlich nicht also es gibt noch andere sachen aber das war als simple base und das
Immer nicht richtig funktioniert
behauptet immer die werde wo man die antwort auf alles sein aber
So war ich schon klar dass die weit übertrieben haben und na ja also eigentlich und jetzt übertreiben sogar wirklich na
Na ja eigentlich auch in der lände zu gehen zurück auf die 50er jahre das ist eine ganz alte schoße
Und damals gab es noch eine große hoffnung die sich mit k.i
Verbundenheit dass es nie passieren würde oder ne ne also es gab so positive zukunftsvisionen das war so das nuclear age was
Was man heute nur noch aus ford auch auch also es ist natürlich so dass die presse angepisst ist natürlich
Weil ihnen sowas wie das internet passiert dir nicht noch mal die haben damals
verpasst dass das internet die anzeigen kunden und die
Meinungsmacht und so weiter in aus der hand reißt und sie sind wild entschlossen dass
Dass diese geschichte sich nicht normal wiederholt sondern dass man selbst versucht innovationen im keim zu ersticken
Und möglichst weg zu regulieren na ja also da bin ich mir gar nicht sicher ich habe auch den andruck dass die
Zumindest also die verlagseite da auch gerne aufspringen würde also es gibt schon einige feltversuche
Was das feltversuche springer irgendwie schmeißt bei der bildzeit und drittel der leute rossensatz die durch kleine
Lrm skript aber das hätte man auch ohne wie k.i. Als narrativ machen können und sollen
Es ist ja nicht so dass die das nicht benutzen werden wenn es das gibt das ding ist aber dass es die in
Natürlich bedroht mehr als jede andere berufsgruppe es ist halt da wenn du
Klempner büro hast dann kann dir das chat gpt unheimlich helfen mit deinen kunden zu kommunizieren
große texte zusammenzufassen in paar bullet points oder ein paar bullet points in groß text umzuwandeln
Und wenn du eine neue firma gründen willst den kriegst du praktisch eine armee von interns für 20 dollar im monat die zwar extrem
autistisch sind aber alles machen was du willst in extremer geschwindigkeit das heißt die meisten leute kriegen super kräfte ist nur halt diese
mitwitze in der mitte die das problem haben dass sie bis jetzt immer prompts
Completed haben und mit einmal ist eine maschine da die das noch besser kann das heißt wenn du ein opinion journal bist wird ein k.i.
Kritiker dann bist du echt eine gefahr das ist k.i. Kritik kann das ding viel besser als du inzwischen
ein technikphilosoph ist das fachwort das hier oder
Gut also ich wollte ein bisschen auf die geschichte eingehen es ging halt da ging damit los dass die k.i.
Als was positives gesehen wurde was uns von unseren fesseln befreien wird und was
nachdem die automatisierung versprochen hat die manuelle arbeit als
sozusagen nachteil unseres lebens den wir erdulden müssen wegzumachen
gab es die idee dass die k.i. kommen wird und die die denkende arbeit weg optimieren kann da können wir alle am strand hängen
und die ersten versuche
Da gab es zwei konkurrierende
Ideen wie man da rangehen soll das eine war symbolische k.i. und das andere ist der
Konnektionismus die symbolische k.i. hat die idee gehabt dass man so eine art sammlung aufbaut von weltwissen also man hat gesagt die k.i.
Wenn die nur genug fakten kennt dann kann sie das eigentlich deterministisch zusammensuchen also k.i.
der sagen wir dann in maschinen lesbar
ein haus ist ein gebäude in einem haus kann man wohnen ja so
Fakten des lebens und darauf daraus in kombinationen kann man dann
Experten systeme bauen hieß das damals die auf basis einer vorher eingepflegten wissen basis dann
sachen beantworten können und die die der konnektionismus war die gegentheorie dass man versucht so ein gehirn nachzubauen
mit einer erfindung namens perceptron das war die zentrale erfindung in den 50er jahren
Das ist ein modell was so ein bisschen in der populärpresse verkauft wurde als wir versuchen einen neuronen nachzubauen
Daher ist das ganze auch neuronen alles netze am ende aber eigentlich ist es ein ein relativ einfaches
abbildungssystem in der informatik ein assoziative speicher im wesentlichen dem aner baut
Und den kann man halt trainieren das heißt man programmiert das nicht sondern man trainiert
Und das ist ein fundamentaler unterschied weil man programmierten code debacken kann und trainierten code kann man nur umtrainieren
Ja das heißt der
Konnektionismus fing mit einem paukenschlag an hat gezeigt man kann damit einige logik gatter nachbauen
nämlich and or und not
Und dann hat marvin minzki der damals so ein berühmter k.i. professor war
Hat halt in die suppe gespuckt und gezeigt aber x-ohr kann man nicht
Machen und dann war eigentlich die luft raus aus den konnektionisten für viele jahre
Und das hat sich aber geändert weil die hardware eben exponentiell schneller wird das heißt auch verfahren die früher
Zwar funktioniert hätten aber man hätte einfach so viel hardware gebraucht die gehen heute einfach
Ja darf ich das kurz alles des mentor natürlich dafür bis es gab noch mehr ansätze also zum beispiel selbstorganisation
thüringen hat in den 50er jahren nur mit reaction diffusion pattern gebastelt
Und hat sich überlegt ob das nicht so ähnlich aussieht wie die aktivierungsmuster im gehirn und ob man daraus nicht
repräsentationen bauen kann das ist relativ kleiner thread der bis heute so als
neuronale zelluläre automaten weiter verfolgt wird und wahrscheinlich ein besseres modell dafür wie biologische systeme funktionieren können bei den
praktisch jede einzelne unit ein kleiner reinforcement learning agent ist der sich mit seiner umgebung unterhalten muss die
unterscheidung zwischen symbolisch und nicht symbolisch ist
Problematisch weil die meisten leute sich nicht so richtig einigen können was eigentlich ein symbol ist und das kein symbol ist
Und deshalb könnte man vielleicht eine etwas allgemeinere unterscheidung machen in beiden fällen geht es ja darum
repräsentationen zu bauen die in so einer form
Abgebildet werden dass das das ein system diese presentationen lesen und in verhalten umsetzen kann zum beispiel in dem setzter auf dem bildschirm erscheinen
Oder ein robot das sich bewegt das heißt das auf der einen seite findet ein wahrnimmungsprozess statt wo man umgebung trackt
oder modelliert und auf der anderen seite wird entweder die repräsentationen verändert oder auf dem weltmodell agiert in dem man in der welt
irgendwelche effektoren benutzt und die unterschiedliche repräsentationsarten
unterscheiden sich dabei vor allen darin ob man reasoning auf den machen kann oder nicht und diese
Sprachsysteme
Symbolische systeme grammatik und so weiter sind so strukturiert dass darauf reasoning algorithmen laufen
Unserem geist finden wir was analoges dazu also wir stellen fest dass bei uns zwei arten von repräsentationen mindestens existieren nämlich perzirptuelle
Repräsentationen die praktisch geometrisch sind und es ist uns relativ schwer möglich da aufmerksamkeit reinzubekommen wie das im einzelnen funktioniert das heißt
diese game engine die die welt um uns herum
Erfasst so dass wir sie modellieren können als bunte menschen die gespräche austauschen und sich anschauen und so weiter und so fort
Wir nehmen nicht wahr wie wir das bauen das ist relativ schwer das reverse engineer dafür zu machen
stattdessen beschäftigen wir uns über den teil die wir reflektieren in strukturen über die reasoning möglich ist und das ist allgemein so eine
strukturierte konzeptstruktur die in diese simulationswelt hinein verweist
Und in einer gewissen weise immer diesen blickwinkel jetzt nehmen auf die k.i entwicklung stellen wir halt fest dass diese klassische symbolische
k.i die die strukturierten grammatischen modelle benutzt hat das gleiche ist wie mitgenstein am anfang seiner karriere wollte
nämlich praktisch die
sprache in der das denken der philosophie stattfindet soweit zu formalisieren dass wir praktisch wie eine programmier sprache wird und richtig genau wird
Und irgendwann im laufe seines lebens hat er festgestellt dass das scheitert daran dass er nicht weiß wie er wahrnehmen mit so einer sprache ausdrücken kann also
vielschichtigkeit und komplexität der welt abbilden kann in grammatische strukturen
Und das gleiche ist im prinzip in der k.i passiert das heißt diese idee dass wir representationen bauen
Wo wir den wahrheitswert von jedem ausdruck bestimmen können durch riesigen prozesse skaliert halt nicht in kamerabilder
Und die weise wie man skaliert ist dass man andere funktions approximatoren verwendet die unsystematisches reasoning erlauben wie halt nur
Das nur an der netz ist dabei einfach
differential computing das heißt ich drücke alles aus als eine funktion
Die sich die rumschieben kann bis sie das abbildet was sie soll
dass es praktisch im kontinuierlichen funktionsraum existiert und das nur ein netz ist linear algebra das besteht aus
summen und multiplikationen und ein paar nicht linearitäten und nicht linearität ist einfach ein fancy word for if-then
das zwischendurch darin stattfindet auch branches möglich sind und so das
Einfektung eine schwerwertfunktion
Relu zum beispiel und damit kann ich natürlich jedes belebte programm schreiben ich kann ein programm kompilieren in so noch ein neues netz wenn ich will
In dieser linear algebra aber das hauptding ist ich habe effektive algoritmen die das ding trainieren können die sind glaube ich bei weitem nicht
So effektiv die die evolution auf den selbst organisierten gehirn erfunden hat
Aber ich glaube da geht noch was wir könnten wahrscheinlich die gpus effektiver nutzen wenn wir neue klassen von algoritmen entdecken
Das ist spekulativ nicht alle leute glauben das andererseits doch sein armen der praktisch alles darauf setzt dass die jetzigen algoritmen uns bis zur
KI bringen können das heißt dass wir irgendwann LLM haben was besser in KI-forschung ist als ein mensch
glaubt nicht dass wir in fünf jahren noch
LLMs benutzen werden sondern dass wir wahrscheinlich andere arten von lern algoritmen haben und das möglicherweise die
Repräsentationen computer beliebiger arten von kurz sind also alles was effektiv durch eine hardware läuft und für für den verfahren hast du es zu erzeugen
Mit wir machen jetzt mal kurz 30 sekunden pause ich brauche trainingsmaterial für die fliege um sie nachher raus zu erinnern
Gerade ist die fliege an franks mikrofon vorbeigeflogen
Ich mag dich im liebsten ich weiß nicht woran es liegt da bei frank am fenster sitzt bestimmt
So ich glaube es reicht
Wir haben letztes mal festgestellt dass wenn wenn man nicht genug trainingsmaterial von dem hintergrund garage hat dann ist das raus rennen
Ein bisschen schwieriger wenn man genug hat dann ist kein problem und hast du für ein automatisches tool dass das macht
Also
wir
Sind hier gerade dabei in so eine falle rein zu laufen wo wir heute reinlaufen dass wir uns auf niveau unterhalten was
zwischen uns dreien gut ist aber was die
Hörer nicht okay wir können uns aber auch mühe geben damit die höre sich nicht langweilen
Ne also dass sie sich langweilen ist nicht die ist nicht die sorge aber ich habe eigentlich ich will nicht sagen den anspruch aber ich
Hätte gern
In jeder sendung so ein bisschen irgendwie einen moment reinbringt wo der hörer merkt das ist eigentlich alles ganz einfach
die konzepte zumindest also vielleicht nicht die
Das zusammenbauen versucht gerade mir zu sagen dass ich mich so ausgedrückt habe dass es keiner versteht
Nicht keiner ich habe mir mühe gegeben aber
Was ich gern noch mal zurückgehen würde du hast erwähnt dass die k.i. damals als was positives gesehen würde was so
Impliziert dass es heute nicht als was positives gesehen wird und ich glaube das ist ein lokalphänomen
Das glaube ich auch ich bin seit einiger zeit in amerika
Und da an der westküste und die ganzen jammer aussies an der ostküste also da wo die nur times ist und noch weiter
Im osten da wo ihr seid in europa die jammern natürlich noch mehr also das das ding ist dass die eu halt gesetze alles die sagt
Am liebsten wollen wir gar keine k.i. Machen weil das ist alles ganz schrecklich und ich merke dass auch wenn ich mit normalen
Menschen hier auf der straße rede ich bin ja leider viel zu selten in deutschland wo ich jetzt komme
Normale leute haben ich inzwischen angst zur k.i. und ich würde sagen die presse hat er echt ganze arbeit geleistet das ist für mich
faszinierend wie stark das so eine untergangsstimmung
Eingegehrt ist bei vielen leuten und für mich ist es so dass ich k.i. seit frühester jugend
Mit erwarte dass die passiert zu meinen lebzeiten und dem auch mit freude entgegen sehr weil endlich mal jemand da sein wird mit dem man
sich unterhalten kann
Und ich kann jetzt nicht verstehen was ihr dagegen habt ich habe doch nichts dagegen also ich halte es ja damit stannis laflemme der gesagt hat dass
Jede tätigkeit die eine maschine erledigen kann soll eine maschine erledigen damit der menschen
Die zeit für besseres und schöneres hat und das finde ich nach wie vor ein sehr gutes paradigma genau
Weil kann die maschine jede tätigkeit erliegen und das heißt wir haben Spaß zu haben wir können in ruhestand gehen ich kann
Auch spaß haben weil das kriegen wir auch hin
Sie kann wahrscheinlich so tun ob selbst ob sie spaß hat ob sie wirklich spaß hat
Das bewusstsein ist als ob frank
Aber das ist doch oder sehr gut ich meine
Die llm sind ja auch nur sehr plausibel in der simulation davon jetzt so zu tun als wüssten sie wovon sie reden
Ja das korrekt ist tatsächlich auch so eine frage kann nachher noch mal drauf kommen was
Werden überhaupt überhaupt eine jr. Also eine generelle intelligent brauchen ob es nicht möglicherweise erreicht dass
Wir glauben wir hätten eine also reicht im sinne von wird uns alle umbringen oder reichten wir bringen wird uns sowieso also ich meine
Wir hatten sehr gerade kurz vor weil wir das mikrofon angemacht haben so die
Theorie dass diese tiktok challenges im zweifel von einer ei generiert werden die einfach
Irgendwie sich den klimawandel anguckt und gesagt hat da sind so viele menschen auf diesem planet lassen sie uns mal was tun
finde ich jetzt nicht völlig und plausibel aber im prinzip diese
biblische mythos sehr reflektionen davon ursprünglich war es halt so dass der liebe gott
adam und ephor aus leben anfertigt wie man halt golem so macht
Und dann gibt er ihnen prompt mit damit sie safe sind und dann kommt die schlange und jailbreak das prompt
erst wird es dieses jailbreak in ephor injiziert und dann gibt ihr das adam und dann geht die menschheit fuhm und
bricht aus aus dem
organisierten garten in wo alles domestiziert ist und sich komplett den plan des schöpfers unterwirft und
Spielt kurze spiele und breitet sich aus und wird diese melde monkey blight die wir heute sind wir sind ja paperclip maximizer
Und wenn man sich das leben auf der erde anguckt dann sind wir auf der einen seite absolut grandios also eine spezies die in der lage ist
internet zu bauen ist fantastisch aber das ist nicht nachhaltig und
Natürlich kann man sagen man braucht so eine spezies nicht als leben auf der erde
Aber die aufgabe ist die entropie so lange wie möglich
Et bait zu halten und dabei so viel möglich komplexität zu bauen das ist das was das leben macht
Und wir machen die nächste stufe indem wir praktisch anderen arten von molekülen als diesen karbonzyklus der auf zellen implementiert ist
leben einhauchen und
agency
Und das wird sich irgendwann treffen und wird die nächste stufe der evolution einleiten das ist doch keine schlechte perspektive dass die menschheit
Ausgleichsphänomen es war doch klar von Anfang an also jedes species die so aufregend ist wie wir ist nicht dauerhaft
Du musst noch erklären was ein paperclip maximal ist
Das ist eine metafe die soweit ich weiß zuerst von bosstrum ins gespräch gebracht wurde nick bosstrum ist ein britischer
Philosoph oder science fiction autor je nachdem von wo man guckt kripto nazi
So würde ich ihn nicht nennen da sind in deutschland glaube ich konnotationen da die ungerecht werden ihm vorzuwerfen aber als jemand der
dieses idee
Popularisiert hat dass man art golem bauen könnte mit k.i. der die aufgabe bekommt hat mehr
paperclips herzustellen mehr pro klammern
Und weil er so unbegrenzte fähigkeit zur intelligenz in erfaltung besitzt macht das ding sich sein so intelligent wie es irgendwie geht und wird den
börsenmarkt dominieren und dann irgendwann ausbrechen aus all seinen boxen und den gesamten planeten oder das sonnensystem in büroklammern umwandeln
Das ist praktisch eine übersetzung des klassischen golem mythos
In die moderne welt und es wurde popularisiert durch ein webgame namens universe paperclip
Was man auch immer noch ausprobieren kann das ist sehr
Ja das was denn alles im spiel ist dass man merkt ich würde das auch machen
also wenn man diese aufgabe gibt paperclips zu maximisieren du bist dann
muss dann halt so
hypnodrohnen bauen die die menschheit dazu bringen denn mehr paperclips zu kaufen ja
Also also jenemals paperclip ist verlinkt man auch in den schaunort für die dies noch nicht kennenlisten
ist in sehr vielen aspekten sehr edukativ weil es unter anderem auch
eines der wenigen spiele ist was so exponential funktionen mal so ein bisschen greifbarer macht und radikale skalierung
verstehbarer macht aber diese angst vor dem paperclip maximise also vor der k.i. die die falschen ziele hat
reflektiert die leute diese angst haben und interessanterweise gibt es bei dieser k.i. diskussion
Glaub ich so drei ebenen auf denen die stattfindet und diese ebenen reflektieren die art und weise wie die meisten leute so sind die
meisten leute
die wir nörd also die normis nennen
sind leute die meinung bilden aufgrund der meinung die sie in umgebung vorfinden und eine perspektive einnehmen die durch die gruppe definiert
ist der sich zurechnen
und wenn man
sich so sozialisiert dann ist es so dass man stark anfällig ist für ideologien
Dann wird man ja je nachdem welche die gesellschaft gerade ist
sozialdemokrat oder kommunist oder faschist
und das bedeutet dass man sehr wichtig ist was für eine meinung die k.i. vertritt weil wenn die k.i.
rassistische oder sexistische sachen sagt dann sind wir alle verloren weil wir von der k.i. falsch
sozialisiert werden und das also auf diesem gebiet der ai ethics ist sehr viel
sorge darum dass die k.i. sachen sagt die harmful sind und die die gesellschaft in die falsche richtung steuern könnten
Und den entsprechenden bemühungen dass die sprachmodelle so getunt werden und so gefiltert werden dass die immer in
meinem politischen quadranten runterkommen und nicht sagen was mit den
Werten die ich persönlich glaube man als meinen eigenen zu sehen in konflikt gerät
Und auf der nächsten stufe wenn man so nörd ist wie wir denn oder auf der anderen stufe und sie versucht sich die welt rational
Daher zu leiten und in der nicht in der gut schlecht welt sind sondern mehr in der falschen welt lebt und versucht daraus
alles rauszubekommen
Dann hat man nicht so viel angst dass die k.i. sozusagen das falsche sagt weil wenn sie das falsche sagt dann muss man einfach das
Modell besser rechnen lassen und dann kriegt ihr zum fluss raus was wahr ist
Aber es könnte ja trotzdem sein dass sie die falschen ziele verfolgt und dass sie uns alle in büroklammern umwandelt
Und dann gibt es ein paar leute die verstehen sozusagen wie man identität konstruiert
terapeuten zum beispiel in der klasse die verstehen dass wir alle im prinzip das gleiche bewusstsein haben und das was uns unterscheidet sind unsere
Trades mit dem wir geboren sind die immer nur anfangspunkt sind
Und der ort und die kulturen die wir reingeboren sind und an all die sachen die uns passiert sind danach
Und das bringt uns dazu dass wir diese ganzen verschiedenen individuen sind die wir sind und wenn wir das begreifen wie identität
Konstruiert wird dann können wir anfangen zu verstehen warum andere leute andere werte haben als wir und dass wir unter anderen bedingungen auch dieser
Anderen leuten werden und wenn man selbst aus dieser perspektive guckt dann hat man eher sorge dass die k.i. Nicht früh genug erleuchtet ist und
sozusagen unterleuchtete entscheidungen trifft
Naja, also ich glaube dass der da kommt noch ein bisschen mehr dazu weil der grau an die postung sagt ist also warum ich meine der man ist
ein kryptonazi
Hast du seine blackball theorie sachen gelesen? Nein erzähl mal der sagt der okay die menschheit greift
Also die technologieentwicklung der menschheit ist quasi ein blindes greifen in eine urne und in der urne befinden sich schwarze und weiße kugeln
Und die weißen kugeln sind halt technologien die uns im wesentlichen zum positiven geraten also wir halt mehr energie kriegen
und mehr wachstum rausholen können und so weiter und so fort
Und natürlich haben die alle seiten effekte mit denen kann man aber so grob im wesentlichen umgehen und dann gibt es aber blackballs blackballs in technologien die
nicht
managable sind also deren
Auswirkungen auf der basis entweder von zu schneller skalierbarkeit oder von zu gewinner kapital und zeitansatz ist erforderlich um sie zu einer großen
massiven waffe zu machen
stichwort biowaffen stichwort selektives gehen alle ting für
Träten basierte viren oder so zeug
Und er kommt in einem laufe dieses essays wo man so denkt so naja ok mir könnte man ihr vielleicht noch gerade so folgen und es
Ja schon nicht so
kommt er als einer kompletten überwachungsgesellschaft also der sagt halt so
es gibt halt irgendwie einen die ansicht der einzige ausweg den wir haben ist halt irgendwie die menschheit quasi in ein
vollständiges gerüst von überwachungssystemen einzubauen wo wir rechtzeitig erkennen wenn so eine blackball technologie auftaucht um die dann halt irgendwie auszustampfen
So das war irgendwie der so ein bisschen noch der das auslöser essay für
gefährliche menschen also den zeifel den ich mit christiane geschrieben habe
Wo wir genau diese so eine welt explodieren wo halt menschen als gefährlich klassifiziert werden wenn sie halt so intelligent sind und so viel tatkraft
haben und genug energie
und
Ja, also ich halt diesen bolstron tatsächlich für
ja in totalitarismus befürworter unter einer
merkwürdigen
also du meinst dass sie
ist kann stalin napoleon nicht gefährlich sind sondern
Ich glaube dass man es halt einfach nicht wissen kann
dass du halt irgendwie als gesellschaft nicht den anspruch haben kannst
leute präemptiv auf der basis von eigenschaften und fähigkeiten die sie haben
zu zu ordnen dass sie halt
gefährlich sind und dementsprechend halt irgendwie überwacht oder
Kontrolliert werden müssen so dass er kommt verschiedene ebenen zusammen ich denke dass diese frage ob man das wissen kann ist der theoretische
empirische frage das heißt man könnte da studien machen mit dem man das versucht vorher zu sagen unter
laborbedingungen sozusagen oder in dem man historische events anguckt und versucht auszuwerten
Aber das ist nicht realistisch dass wir das hinbekommen oder es ist auch nicht klar dass das wünschenswert wäre und das sind ganz andere
Fragen denke dass bostrom jemand ist der
schon sehr stark im nörd spektrum liegt in dem sinne von
Jemand der sich in der stelle bei die freien reasoning kann also der so lange schlüsse zieht bis logisch in irgendeine ecke
gelandet ist und keinen weg mehr daraus sieht und seine ideen sehr buchstäblich glaubt
Genau das hat das problem und dass er relativ viele anhänger die diese ideen nicht hinterfragen
Ja aber es wäre natürlich auch schlimm das zu verbieten dass jemand wie bostrom solche ideen hat und ich meine
Ich klassifiziere das ding ist es ist manchmal auch so dass diese überlegungen ja korrekt sind die leute auf diese weise entwickeln
Und dass die restlichen leute die nicht so stark an dieser rationalen überlegungen und schlussketten glauben die uns eine stelle führen wurde
Ergebnisse unintuitiv sind die haben nicht immer unrecht die
Aber dann kommen wir halt genau zu diesem punkt den du gerade erwähnt hast nämlich dieses
Reste in europa als übertriebenes precautionary prinzipie empfinden dass die eu sagt so ja diese ganze ei
Ist gefährliche wissen es nicht wir wollen es erst mal ausbremsen und so weiter es hat genau ist tatsächlich genau
diese bostrom geschichte das hat also was die eu da gerade die fahrt de facto sagt so ei
Und lms sind eine blackball technologie
deren auswirkungen wir nicht absehen können und wo es irgendwie erst mal gut ist irgendwie zu sagen wir sind jetzt nicht schneller als alle
anderen sondern
Wir bremsen es erst mal aus und gucken erst mal wie es den andern damit so geht mein eindruck ist völlig anders das ist nicht so dass
Es die bostrom anhänger sind die in der eu wirksam sind
Sie kommen zu anderen schluss es ist eher glaube ich so dass die bedenkträger leute sind die nicht so sehr
kaiversiert sind sondern mehr
soziologen sind oder leute die sich um gesellschaftliche macht spieler Gedanken machen und die auf der die ethik als
Verhinderung von dingen begreifen und diese verhinderung ethik ist die macht sich halt nicht gedanken darüber welche guten sachen man
verhindert dadurch dass man eingreift sondern nur um gefahren die verhindert werden müssen so zum beispiel die
amerikanische fda hat
covid tests verhindert in der anfang der pandemie weil diese tests noch nicht zugelassen waren und dadurch
Wurden ungefähr 60.000 leute oder so sind unnötig gestorben weil diese tests nicht verfügbar waren nicht importiert werden durften obwohl die
Maschinen in stanford zum beispiel im laborum stand leute genau wussten wie sie test machen können durften sie nicht und die
weil er hätte gefahren entstehen können dass
unqualifizierte tests ausgewertet werden und dass wir leben in einem land wo irgendwie die regierung am anfang der pandemie gesagt hat dass
masken schädlich sind man könnte sie ja falsch aufsetzen genau und man wird halt dafür bestraft in dem augenblick wo etwas zulässt was
Gefahren hat aber nicht dafür bestraft wird es verhindert was gut gewesen wäre und auch leben gerettet hätte
Und ein beispiel dafür ist für mich das internet damals als das gemacht wurde glaubten alle das ist so eine moderscheinung die bald wieder weggeht deswegen
also alle wichtigen leute sozusagen nicht außer den nerds halt die da rum gebastelt haben und dachten das wird ganz toll
aber die große mehrheit hat das erst mal nicht weiter berücksichtigt und wenn die presse das geahnt hätte oder die
gesellschaftlichen etablierten publisher und so weiter regierungsleute die hätten natürlich
zu recht gewarnt vor all den sachen die da hätten entstehen können man überleg mal
pornografie
drogenschutz
raubkopien
geldwäsche heute noch lauter anhörung im parlament drogen bestellen im internet also all diese sachen wenn man das hätte sehen können
das internet wäre nie zugelassen worden wir hätten heute noch btx und der staatliche aufsicht
und wenn wir uns überlegen wenn das passiert wäre wenn damals reguliert worden wäre vernünftig unter all den gefahren die dann zu recht schon damals
antizipiert worden wären die ja auch alle materialisiert sind heutzutage
wenn man uns das internet weggenommen hätte was das für eine katastrophe wäre ich glaube was ähnliches passiert mit der ki
nur dass diesmal die bedenkträger schon vorne dran sind und an was passieren könnte und versuchen alle möglichen sachen zu finden die
rechtfertigen dass eine technologie sich zum beispiel
bestehende produktion von medienprodukten
zu umwälzungen bringt die dazu führt dass neue arten von medien entstehen müssen das bestehende industrien durch andere ersetzt werden und so weiter und sofort
die springen jetzt in die breche und versuchen das zu verhindern und dabei gibt es eine reihe von modethemen auf die man sich geeinigt hat
und zum beispiel gehört dazu dass die eu gerne möchte dass wir keine emotionserkennung mit ki machen sollen was dann
schwieriger macht forschung in der richtung zu machen und aus meiner sicht heißt das es wird sehr viel schwerer sein die
ki eine psychologie einzusetzen zum beispiel für therapiezwecke
und das aus meiner sicht ist ehrenprobe sollte regulationen so passieren dass sie anwendung
reguliert in dem moment wo wir sehen dass tatsächlichen schaden da ist und wir wissen wie es am besten reguliert wird
aber präventiv zu regulieren weil wir sagen wir spüren alle dass es schlecht ist wenn
maschinen unsere emotionen lesen und uns überwachen das greift zu kurz
das sagt auch keiner also doch meine
nein das muss ich hart widersprechen okay das tatsächlich ist so dass also ein großteil von dieser dieser
Diskussion die da stattfindet da geht es halt wirklich um technologieverhinderung da geht es nicht darum zu sagen also geht es halt konkret darum so
dass du dass die die anforderungen an firmen und institutionen die modelle trainieren halt so also auf das technische niveau
runtergebracht werden
dass du sagen musst wie groß ist ein modell aus von welchen daken wird ein modell generiert
alle möglichen details die nichts mit der anwendung zu tun haben
wenn wir uns darauf einigen könnten dass wir nicht technologie an sich regulieren sondern nur missbräuchliche anwendung
fein also nie das war ein missverständnis mein einspruch war nicht dass da versucht wird technologie zu verhindern
mein einspruch war dass das irgendwie mit intentionen ist also mein eindruck ist dass die leute
auf euebene sind einfach lehrer und juristen die verstehen es nicht die haben angst die haben angst genau und dann greift genau dieses
paradox von was du schon angesprochen hast du wirst halt bestraft wenn du was zulässt was dann scheiße ist
aber du wirst nicht bestraft wenn du was verhindert was gut gewesen wäre
und das ist genau warum wir immer schärfere polizeigesetze kriegen obwohl das seit 20 jahren nichts bringt dann noch länger
wird immer verschärft gibt nichts was da irgendwie vorweisbar wäre was irgendwie positiver effekt wäre
das ist einfach dieser mechanismus immer angewendet von leuten die das nicht verstehen und ich
warne auch davor anderen leuten irgendwelche intentionen zu unterstellen sondern bevor man genau verstanden hat was sie eigentlich
tun ja auch dieser dieser wie ist der bosch bosch tropf bosch tropf bosch tropf ich lese nur seine papers und interpretiere seine ideen
ja genau aber keine intentionen keine intentionen unterstellen ist das schlimm genug was er tut ohne dass du was unterstellst
da würde ich immer nur aber egal also ich finde es ganz ganz kurz bei diesen regierungsproblemen bleiben
was ich halt sehe ist dass etwas passiert mit diesem eu ding was
ziemlich verheerende folgen haben wird nämlich nicht also keine ahnung wird ob man ja vielleicht in europa nicht vermarkten
habe ich kein problem mit kann ich mit leben so ist halt irgendwie ich habe vpn so ist halt irgendwie
kein großes problem
die katze ist aber aus dem sack also wir haben jetzt halt alle irgendwie modelle die irgendwie jetzt zwar nicht auf gpt4 niveau unterwegs sind aber doch
sich jetzt mit relativ großer geschwindigkeit irgendwie dem ähnlichen niveau annähern ist nicht mehr
Tiefe magie die da passiert wir wissen so ungefähr was daran technisch nötig ist
modelle anzupassen auf der basis von open source modellen ist nicht mehr
unmöglich so also jetzt so die
verpfandet letzte abu dhabi
hat einen 40 million parametern modell released von 40 b
was erstaunlich gut ist und
sehr den lokalen ethik und moralvorstellungen konformes trainings daten zett unten drunter hat
da gibt es keine also bei normalen modellen gibt es immer so eine sensut und anzensort variante da gibt es nur die sensut variante
weil schon das trainingsmaterial sensut war
das heißt die katze ist aus dem sack das also es wird jetzt halt einfach passieren aber worüber halt nicht geredet wird sind tatsächlich die
Auswirkungen die im alltag passieren und so ein paar sachen dieser eurigolierung sind halt gut finde ich also so was wie
das recht dass entscheidungen über menschen am ende mindestens von menschen
Anfechtbasis also dass du das recht haben solltest dass du mit einem menschen redest wenn du halt irgendwie
einen nachteil erleidest und nicht halt irgendwie nur mit irgendwie in dem computer oder hinter sagen so komputerfehler können wir nichts machen
das finde ich ein gutes paradigma ich finde es auch gut dass
bestimmte anwendungen
gebannt werden sollen wie halt zum beispiel
automatisiertes ab testing für politisches messaging auf der basis von von ai
von lms weil wir haben schon als gesellschaft irgendwie social media nicht ausgehalten
so als struktur von politischer kommunikation
und ich vermute es wird einfach zu spät kommen das wird halt also die positiven aspekte werden wahrscheinlich nicht drin sein
so wie die eu-kerne sondern eher nur der kram der halt wirkungslos und schädlich ist
aber zumindest sich ein paar stellen dass die intention ist zu sagen
Wir müssen jetzt vielleicht nicht irgendwie voller pulle aufs gas treten sondern können halt noch mal
kurz einmal durchatmen und uns überlegen wie wollen wir es dann eigentlich in unsere gesellschaft integrieren das problem ist halt nur
dass so ein prozess natürlich
Gehegegt wird von den leuten die halt einfach angst haben also die halt einfach nicht ich sage wir wollen halt eine sinnvolle regulierung haben die
dazu führt dass zum beispiel die eu
Ein
Mein talking point das immer zu sagen sehr ihr werdet mit verbotenen nicht weiterkommen oder der einzige weg den ihr habt ist irgendwie dafür zu sorgen dass es
frei verwendbare sehr gute modelle gibt die euren
ethik regeln entsprechen
also ihr müsst halt einfach auf der technologie basis gewinnen ihr könnt nicht mit
verboten gewinnen und der einzige weg der dahin führt dass er zu sagen okay wir brauchen halt so was wie ein europäisches zern für
KI forschung mit entsprechende hardware ausstattung und dem der was halt entsprechende modelle als open source
released und die müssen dann halt einfach besser werden und dann werdet ihr gewinnen und wenn das nicht der fall sein wird dann werdet
Ihr nicht gewinnen finde ich nicht also ich möchte noch einen schritt zurück erst mal
Ist denn die furcht gerechtfertigt von den lehrern und juristen im eu parlament und da finde ich ja
Denn was was ist denn in unserem
erfahrungshorizont
Bisher passiert mit neuen technologien
Wir haben erlebt wie maschinen die die arbeiter
Wegrationalisiert haben wir haben erlebt dass die leute heute nicht mehr in rente gehen können
Ja, sondern so lange arbeiten bis sie tot umfallen
Wir haben alle möglichen effekte erlebt die was aber nicht an maschinen liegt stets zulasten nein aber unsere gesellschaft ist im wesentlichen an den maschinen zerbrochen wir
Waren wir gesellschaft ist doch nicht zerbrochen unsere gesellschaft
Wesenlich besser als ich war wir haben millionen von bullshit jobs eingeführt wo leute in grund ihrer lebenszeit vertun für sinnloses
Wir funktionieren brauchen das was wir
Haben ist dass wir staatlich subventionierte
Tätigkeiten eingeführt haben die im prinzip beschäftigungsmaßnahmen sind nicht nur daran dass wir automatisierung haben ja was natürlich ist es so dass wir zum
Beispiel sehen dass die millennials wesentlich weniger vermögen haben als die boomers
Was man nicht sieht in der Statistik, sind die Kurven davor, die man auch zeichnen müsste,
weil es gab halt durch den Modernismus nach dem zweiten Weltkrieg einen Boom, der vorher
nicht existierte.
Das heißt, da wurden Werte geschaffen innerhalb sehr kurzer Zeit, was historisch einmalig
gewesen ist, wo ein, zwei Generationen sehr viel reicher geworden sind, sehr viel mehr
Werte bekommen haben.
Und das ist vermutlich ein Phänomen, was nicht ohne Weiteres weitergeht, was Immobilienbesitz
betrifft und so fort, Wassergrundstücke und so weiter, die sind dann irgendwann weg.
Aber die Kalorien sind praktisch nicht teurer geworden für uns.
Es ist nicht so, dass wir Schwierigkeiten haben, uns zu ernähren, dass wir Schwierigkeiten
haben, Dach über den Kopf zu finden.
Es gibt deutlich weniger Außentoiletten als in der Generation unserer Eltern.
Und die Gesellschaft ist wesentlich komfortabler geworden als früher.
Ja, wenn du es dir leisten kannst, aber das ist halt für immer weniger Leute der Fall.
Nein, überhaupt nicht.
Das ist wirklich nicht so.
Das ist tatsächlich, wenn du einfach so alle Metriken hier anguckst, so Zörklingsstaublichkeit,
Lebenserwartung, Zugang zu Gesundheitssystemen, die Möglichkeit halt irgendwie zu studieren,
also dir halt dich einfach zu bilden auf ein Niveau, was dir halt irgendwie deinen Fähigkeiten
entspricht.
In all diesen Metriken ist es einfach nach oben gegangen.
So und wir haben jetzt nicht mehr Leute, die halt irgendwie an Staublunge verrecken zu
Zehntausenden pro Jahr, was ein normales Phänomen war, was alle hingenommen haben.
Ich meine, wir kommen aus einer Gesellschaft, in der es normal war, dass ein Bergarbeiter
ein Recht auf einen halben Liter Schnaps jede Woche hatte, damit er seine Realität aushält.
Der Bergmanns-Deputats-Schnaps, er kam in Bierflaschen mit einem Kronkorken.
So, das ist die Gesellschaft, aus der wir kommen.
Da haben wir schon eine Menge Fortschritt erzielt zwischendurch.
So, selbst im Osten war es so und da war der Fortschritt eher so gemächlich.
Ich habe auch nicht erkannt, dass die Technologie, die Social Media unserer Gesellschaft in
irgendeiner Weise zerstört hätten.
Das heißt nicht, dass die harmlos sind und keine Probleme haben.
Wir haben zum Beispiel jetzt, finde ich, Medien, die wesentlich interessanter sind als die
Medien in meiner Jugendzeit.
Ich erinnere mich, dass ich als Kind so verzweifelt war, dass ich kalkulos auf einen bayerischen
Rundfunk Bildungsfernsehen geguckt habe, weil selbst im CTF nichts Aushaltbares mehr kam.
Das war doch eine coole Feiße, das Bildungsfernsehen.
Das Bildungsfernsehen war eine gute Sache, fand ich auch.
Nee, aber lass dich mal kurz mal Gedanken zu Ende schicken.
Aber aus dir ist doch auch was geworden.
Ja, aber guck mal, was ist denn...
Gut, also sagen wir mal so, physisch ist gut, ja.
Also wir haben irgendwie Trinkwasser, wir haben Essen, auch wenn das Trinkwasser immer
weniger wird und das Essen immer teurer.
Aber was ich meinte ist, du brauchst ja einen Sinn in deinem Leben.
Du willst ja irgendwas machen.
Und das ist weniger geworden, aus meiner Sicht.
Wir haben immer mehr Leute, die um immer weniger Jobs konkurrieren.
Wir, wir...
Vielleicht haben wir auch einfach mehr Zeit.
In Deutschland haben wir gar zu wenig Zeit.
Es gibt durchaus keinen Arbeitslosigkeit-Messen.
Mist doch die Arbeitslosigkeit.
Also es ist nicht so, dass es irgendwie ein Ruf nach oben gab.
Erzähl doch mal, wie misst du denn die Arbeitslosigkeit?
Also ich meine so meine Arbeitslosigkeitsbetrachtung anekdotisch, weil ich den auf die 10 Statistiken
so mitteltraue.
Und anekdotisch ist es halt so, dass alle, in allen Bereichen, wo ich jetzt so ansatzweise
Einblick habe, gibt es gerade zu wenig Leute, die arbeiten wollen.
Also die halt irgendwie da sind und sagen, okay, ich würde eine bezahlte Tätigkeit annehmen.
Das ist kein Zeichen deiner Ansicht nach, dass A. zu wenig Gehalt gezahlt wird und
B. die Leute einfach nicht einsehen, dass sie sich da irgendwie kaputtbuckeln sollen.
Naja, das ist eben der interessante Punkt, dass also die gehört so ein bisschen zu dem,
was Joshua eben sagte, nämlich dieses, die mangelnde Möglichkeit intergenerationellen
Wertakkumulation, die sich inzwischen halt eingestellt hat, weil die Umverteilung von
unten nach oben halt zu dramatisch effizient geworden ist.
Führt halt dazu, dass eine Menge Leute, die ich kenne, sagen, eigentlich habe ich nicht
mehr Bock, als um wie viele vier Tage die Woche zu arbeiten.
Eigentlich ist drei besser, weil am Ende ist es egal.
Also ich kriege meinen Kühlschrank voll und ich kriege halt irgendwie meine Krankenkasse
bezahlt. Also ich kann sozusagen auf dem Standard Niveau des materiellen Wohlstands,
der in diesem Land verfügbar ist, leben.
Und der Unterschied zu ich arbeite zwischen ich arbeite drei oder vier Tage die Woche
und ich arbeite fünf Tage die Woche ist, mir fehlt de facto ein Siebteil meines Lebens,
was ich halt für diese Arbeit abgeben muss.
Und es würde keinen Unterschied mehr machen auf meiner Chance, mir eine Wohnung oder ein
Haus zu kaufen. Sowieso gibt es nicht mehr.
Kannst du mit normalem Gehalt vergessen.
So zumindest in dieser Stadt hier halt einfach hat sich erledigt.
So ist halt vollkommen illusorisch geworden.
Kannst du, wenn du froh bist, also mit Glück hast, kannst du noch die Miete leisten.
Aber selbst im guten Gehalt ist es nicht mehr eine Wohnung.
So und das ist der Grund, wieso die Leute aufhören zu sagen, ok, ich puckele mich jetzt
halt ab, weil die die Chance auf den auf den Sprung in der eigenen sozioökonomischen
Stellung durch härtere Arbeit ist in der Regel nicht mehr gegeben.
Es ist halt nur noch in Ausnahmefällen, wenn Glück hast, in der richtigen Stelle bist
der richtigen Talent, hast die richtige Ausbildung, dass die richtigen Leute kennst und
Leute, aber es ist nicht mehr so, dass halt irgendwie dieses Phänomen, was es noch in
unserer älteren Generation gab, dass Leute, die fleißig waren, eingeklotzt haben, einen
dramatischen Sprung in ihrer in ihrer sozioökonomischen Stellung machen können.
Und das gibt es halt nicht mehr.
Und das sehen die Leute. Der Kapitalismus hat sich halt kaputt gespielt.
Der Kapitalismus hat halt sein Versprechen.
Auf Aufstieg durch härtere Arbeit einfach zu lange nicht mehr eingelöst.
Und jetzt sehen Leute halt ihre Konsequenzen.
Das ist der Grund. Und Technologie wird derzeit, glaube ich, dazu eine andere Auswirkung
haben. Ich habe da irgendwie ziemlich lange zur Arbeit.
Und dieses diese Frage, welche Auswirkungen hat denn Technologie eigentlich auf den
Arbeitsmarkt, ist immer uneinheitlich.
Es gibt keinen, keine, keine Eindimensionalität dabei.
Also du hast halt so Phänomene wie also im krassesten Fall der Cotton Gin.
Ist eine simple Chemmaschine, die halt aus einer Walze mit so Drahthaken besteht und
diese möglich machte Baumwolle sinnvoll als Textilfaser zu verwenden, war vorher nicht
möglich, weil da diese komischen Kerne drin sind.
Die hat man nicht gut rausbekommen.
Dieser Chemmaschine hat was rausbekommen und es führte dazu, dass die Sklaverei länger
andauerte. Also eine technologische Innovation hat dazu geführt, dass Sklaverei länger
dauerte, weil es plötzlich möglich war, mit Sklavenarbeit Baumwolle anzubauen, was
vorher also Tabak ist so mäßig gut geeignet für Sklavenanbau, zumindest nach den
damaligen Südstaaten Dokumenten, weil man da halt sorgfältiger sein muss.
Aber Baumwolle kannst du halt auch mit Leuten machen, die eigentlich keinen Bock haben.
Und ja, und vor, also die Sklaverei war schon im Abschwung eigentlich, das war eigentlich
schon so. Und dann kam diese simple Erfindung daher und dann hat die dafür gesorgt, dass
die Sklaverei noch mal Jahrzehnte länger ging.
An anderen Stellen haben wir halt so was wie automatische Webstühle.
So haben wir auch zu massiver Arbeitslosigkeit geführt, die dann aber absorbiert wurde vom
Markt innerhalb von einer gewissen Zeitspanne.
Und die Frage ist eigentlich immer nur, wie schnell sind so Wellen von technologischer
Arbeitslosigkeit? Also wie schnell kommen die?
Das heißt, gibt es genügend Zeit, dass sich neue Industrien, neue Kategorien von Jobs
entwickeln und dass die Leute die notwendigen Fähigkeiten, Fertigkeiten sich aneignen
können, um in diese neuen Tätigkeiten zu wechseln?
Und und wann passiert das in ihrer Bürografie?
Also sind die halt schon 60 oder 65.
Dann ist es halt schwer, noch irgendwie YouTube Influencer zu werden.
Also gelingt auch einigen Leuten, aber ist jetzt irgendwie nicht der offensichtliche
Karrierefahrt. Und auch da ist halt so, dass natürlich alle Berufe, die jetzt bisher
haben, also Aufmerksamkeitsberufe waren, also wo du halt irgendwie davon lebtest, dass
Menschen ihre Aufmerksamkeit, den Inhalten zu wenden und dich dann dafür bezahlen, sei
überwärmt oder direkt, die jetzt halt ein echtes Problem bekommen zum allerersten Mal.
Das glaube ich so ein Ding, was auch ein Teil dieser Angst ist, Angst narratives treibt,
dass eine Menge Leute plötzlich verstehen, dass sowas wie was mit Medien im allerweitesten
Sinne so Grafiken machen, Texte schreiben, einfach so Gebrauchskreativität, also jetzt
nicht originäre Kreativität, sondern Gebrauchskreativität, dass das jetzt halt bedroht
ist. Und das war für eine ziemlich lange Zeit waren diese Berufe, welche in die
Leute reinmigriert sind aus Tätigkeiten, die durch vorhergehende Automatisierungswellen
kleiner wurden oder weggingen, also zum Beispiel Schriftsetzer.
Schriftsetzer ist ein harter Knochenberuf gewesen, mit Bleilettern und so, war jetzt
auch nicht besonders gesundheitsfördernd.
Und Leute, die halt aus diesem Bereich kamen, gingen dann ins Grafikdesign.
Die haben dann halt irgendwie Sachen gemacht mit Computern, die am Ende wieder zu Text
führten.
Das ist aber ein sehr gutes Analogie dazu, was jetzt passiert, glaube ich.
Als wir den Wechsel hatten von Typografie, die mit der Hand gemacht wurde, zu Typografie,
die am Computer gemacht wurde, was mit einmal passiert ist, dass sehr viele unprofessionelle
Leute mit einmal Layouts gemacht haben und viele professionelle Schriftsetzer beklagt
haben, was da schon produziert wird, während das gute Gewerbe und die Arbeitslosigkeit
ändert. Aber wir wissen, wie es ausgegangen ist.
Es ist tatsächlich so, dass Sachen, die vorher nicht Layout, sondern Schreibmaschine getippt
oder handgeschrieben waren, immer bessere Qualität bekamen.
Und wir jetzt überall, in jeder Ecke sehr gute Layouts haben, auch auf dem Niveau, das
vorher technisch kaum möglich gewesen wäre und nur mit extremem Aufwand und sehr wenigen
Leuten. Das Layout ist in allgemein gut geworden.
Und was entstanden ist, ist sozusagen Kunst auf nächsthöherer Ebene, bei der man mit
einmal all diese Sachen benutzen konnte, um Dinge zu produzieren, Artefakte zu produzieren,
die vorher gar nicht gegangen wären. Das Gleiche ist mit CGI im Film passiert.
Am Anfang war das noch clumsy und so weiter und sah nicht besonders toll aus.
Jetzt macht das CGI möglich, dass wir Fernsehserien gucken können, die früher Milliarden von
Dollar gekostet hätten, wenn man die Kulissen hätte bauen wollen, wie bei Babylon Berlin
oder sowas, wo man nicht sieht, dass das CGI praktisch das ganze Berlin der 20er-Jahre
nachbaut, weil sie so im Hintergrund verschwindet.
Und jetzt ist es möglich, das einfach so zu machen.
Und mit guten Theater-Schauspielern eine Serie zu machen, die ein kulturelles Artefakt
darstellt, das vorher nicht in der Form hätte produziert werden können.
Und ich vermute, das Gleiche wird mit der KI passieren.
Dass also derjenige, der vorher der Grafiker war, der wird jetzt Smart Director, der kann
jetzt praktisch auf eine Armee von kleinen Grafik-Sklaven zugreifen, die automatisiert
sind in dem Programm und ihm genau das liefern, was er will.
Und er kann so viele Iterationen machen, wie er will und Dinge produzieren, die vorher
überhaupt nicht verfügbar gewesen sind.
Ich glaube nicht, dass das jetzt die erste Technologie ist, die wir entwickeln, die
alles schlechter macht, dadurch, dass sie uns erlaubt, mehr zu tun, sondern das würde
mich jedenfalls sehr erstaunen, wenn es der Fall wäre.
Ich würde eher erwarten, was passiert ist, dass wir die nächste Welle lostreten von dem,
was Menschen machen können, ein kultureller Artefakt.
Nee, das bestreite ich alles überhaupt nicht.
Ich finde trotzdem, dass die Angst gerechtfertigt ist, weil einfach viele Leute heute zumindest
gefühlt in einer prekären Lage vor sich hin machen, während meine Eltern noch eine
Job-Security hatten.
Die wussten einfach, den Job werde ich jetzt machen, bis ich umfalle.
Und alles, was passieren kann, ist, dass es nach oben geht, weil ich irgendwie befördert
werde oder so. Und die Zeiten sind halt vorbei im Lebensalltag der Leute.
Das stimmt. Wenn ich jetzt nach Brandenburg rausfahre, ich sehe die ganzen Ruinen, in
denen die Leute hungrig gucken und an meinem Rockzipfel zerren.
Nein, das stimmt nicht so.
Das kommt auf die Gegend von Brandenburg an.
Ich habe das Gefühl, dass gerade jetzt, wenn ich aus Amerika hier in die deutsche Provinz
komme, dass diese Mitteleuropa so strahlend und fett, glänzend und sonnig ist im
Vergleich zu dem, was ich da draußen in der Wildwelt sehe.
Das ist tatsächlich korrekt. Also es geht uns nur relativ scheiße.
Das glaube ich so, dass wir depressiv sind und dass wir die Sinnfrage stellen, weil wir
immer älter werden oder auch, dass jede Generation das Problem hat, dass das
Beziehungsleben nicht klappt, dass man Schwierigkeiten hat, in die Welt zu passen, dass es
eine Schwierigkeit ist, eine Zukunft zu sehen in der Welt, die von Global Warming und vielen
anderen Dingen bedroht ist, die alle in die falsche Richtung zeigen.
Das ist ja unbestritten. Dass die KI auch Gefahren hat, ist auch klar.
Also wir steuern jetzt so ein bisschen gegen dich immer, weil du diesen Punkt machst, das
bestreitet keiner, dass die KI extrem viele Nachteile hat, so wie das Internet auch extrem
viele Nachteile hat. Und wenn jemand Angst vor dem Internet gehabt hätte damals, wäre diese
Angst komplett berechtigt gewesen, weil das Internet hat viele, viele schlimme Sachen
produziert. Es ist einfach so, dass diese schlimmen Sachen in absolut keinem Verhältnis
stehen zu dem Nutzen, den es produziert.
Ich fühle mich immer noch missverstanden.
Also es geht mir nicht darum, dass die Leute tatsächlich scheiße gehen, sondern es geht
darum, dass sie das Gefühl haben, es geht ihnen scheiße und sie sind bedroht.
Und wenn du in der Lage bist, dass du dich bedroht fühlst und es kommt was Neues vorbei,
dann denkst du dir, nee, das brauche ich jetzt nicht auch noch.
Und deswegen finde ich es nicht angemessen, den EU-Parlamentariern zu sagen, das sind
einfach ängstliche Leute.
Das ist völlig in Ordnung, dass sie ängstlich sind.
Wäre ich auch, wenn in ihren Schuhen.
Der Punkt ist einfach, dass wir überhaupt nicht artikuliert kriegen, warum wir glauben,
dass man AI braucht, sondern die einzige Argumentation, die immer kommt, ist ja, das
wird jetzt passieren. Und wenn wir das nicht machen, dann machen es die Amis.
Und dann sind wir hier wieder irgendwie Mittelalter und zurück und blas.
Also dass jemand kommt und sagt, pass auf, wenn wir das hier machen mit der AI, dann
könnte irgendwie Folgendes könnte dann besser werden.
Sondern alle Visionen, die man hört, sind entweder negativ oder wird kommen.
Kannste nichts gegen tun.
Und dass dann eine Trotzreaktion kommt, ist doch völlig normal.
Ist doch absolut absehbar.
Also ich wäre erstaunt, wenn es nicht so wäre.
Ein Politiker wird nicht dafür bezahlt unbedingt, dass er sich Sorgen macht oder
ängstlich ist oder reaktiv ist und Trotzreaktion hat.
Aber er kann durchaus dafür bezahlt werden, dass er Regulation produziert.
Und Regulation schafft Jobs für Regulatoren.
Es gibt wahnsinnig viele Leute, die solche Jobs gerne hätten.
Ich bin auch von verschiedenen Leuten angesprochen worden, ob ich da nicht mitmachen
will. Wir schaffen uns unsere eigenen Jobs.
Ich glaube, das kann in Zukunft mit AI machen.
Ja, das Ding ist toll, ist aber, dass Bullshit-Jobs können nicht
wegrationalisiert werden.
Die sind sicher. Wenn dein Job keinen ökonomischen Wehrwert jetzt produziert,
dann ist er auch in Zukunft nicht bedroht.
Das glaube ich nicht.
Außer die Unit, die du da drin hast, fällt weg.
Aber wenn du jetzt schon einen Frühstücksdirektor-Job hast, in irgendwas,
was too big to fail ist, weil zum Beispiel eine Regierung angeschlossen ist,
dann wird das nicht schlechter durch die AI.
Also was wir hier sehen ist ja
diese dramatische Produktivitätsgewinn,
den man in den Bereichen, wo
aktuelle generative Systeme, also LLMs oder auch Imagegeneratoren,
jetzt schon gut sind.
Na, also die wären ja von hier aus nicht schlechter.
Das ist auch immer so ein Ding, wo man mal dran denken muss.
Na, es gab ja gerade dieses dieses schöne Konzept von von Michel
mit der Demenz, KI-Demenz, fand ich.
Kann man nicht, kann man nicht komplett wegwischen,
weil die KI, die ganzen LLMs zumindest, also nicht generell KI, aber
die LLMs werden ja alle mit Text gefüttert.
Und da grasst man mal das Internet ab, was ja auch der Vorwand war,
warum Twitter jetzt für nicht angemeldete User das Lesen vor Tweets
zugemacht hat, weil sie behauptet haben, die ganzen KI-Startups würden sie abgrasen.
Aber je mehr Text von KI generiert wir da draußen haben,
desto mehr vergiftet das natürlich zusätzlich, nicht zusätzlich,
die zukünftige KI-Trainings, die werden die mit diese Daten gefüttert werden.
Das ist schon nicht völlig.
Das ist aber auch bei der Menschheit das Problem.
Also je mehr Text von Idioten generiert wird, desto mehr werden neue Idioten
mit diesem Text gefüttert.
Und das führt dazu, dass die, ja, auch an der Wissenschaft.
Also was ich gerne machen würde oder sehen würde, ist, dass wir
Chat-GPT hernehmen und damit die wissenschaftlichen Papers durchgrasen
und aus jedem Paper alle Referenzen rausziehen.
Und was die Referenz jeweils belegen soll und dann das Programm,
die Source Papers alle lesen lassen und gucken, ob das auch tatsächlich drin steht
und diesen ganzen Baum mal aufbauen.
Ich glaube, dass es ein Erdbeben erzeugen wird, was deutlich über die
Reproducibility-Crisis in der Psychologie hinausgehen wird.
Stimmt. Meinst du generell oder bestimmte?
Nee, ich denke fast allen.
In allen, ja, glaube ich auch.
Also kurz einmal zurück zu diesem zu diesem Produktivitätsding.
Ich glaube, dass diese, wenn wir jetzt
vergangene Patterns von so Automatisierungsschüben ansetzen,
denn gab es sowas ja schon so ein paar Mal.
Computer waren so ein Ding.
Also PCs, die halt irgendwie preiswert und verfügbar waren,
haben dazu geführt, dass eine Menge Sachen
an, ja, sagen wir, Tätigkeiten, nicht unbedingt Jobs, aber Tätigkeiten
weggefallen sind, die halt vorher noch jede Menge Menschen brauchten.
Und diese Tätigkeiten wurden dann ersetzt durch andere Tätigkeiten.
So ist es jetzt halt nicht so, dass jetzt zum Beispiel ein Buchhalter
plötzlich arbeitslos war.
Bloß war es halt jetzt Tabellen, Kalkulation oder Buchhaltungssoftware gab,
sondern du brauchtest weniger davon, weil du halt irgendwie
digitale Businessführung und so weiter hat dazu geführt, dass du weniger
Paperschaffler brauchst.
Aber du hast natürlich mehr Komplexität erzeugt,
weil die Möglichkeit, überhaupt mehr Komplexität
zu erzeugen in der Regulatorik wurde ja auch gesteigert.
Das heißt, du hast ja kannst ja, wenn du ein Computer verwendest,
dann kannst du natürlich viel komplexere Regeln bauen.
Da sehen wir jetzt natürlich auch gerade in irgendwie in einer
Sozialgesetzgebung, wo du halt eigentlich
ohne Experten System nicht mehr wirklich eine Chance hast,
da durchzublicken. Also das ist halt so.
Und die verteidigen natürlich diese an diese Domänen mit Zähnen und Klauen.
Aber ich glaube, das wird halt dazu führen, dass die
also die nächste Welle wird jetzt natürlich sein, dass wir erst mal anfangen,
irgendwie mit der Lebenszeit, irgendwie die deutsche soziale
Steuergesetzgebung irgendwie urbar zu machen, um mal zu gucken,
was man da halt irgendwie so machen kann.
Aber der sozusagen der Gegenschlag wird halt selbstverständlich
darin bestehen, dass die genau dasselbe machen und halt anfangen,
irgendwie dann deine Steuereinreichung oder was auch immer du an Anträgen
da reinschickst, dass da halt auch kein Mensch mehr draufguckt
oder nur im Ausnahmefall.
Was dann halt also wenn die Battle ist halt absehbar.
Na also wir sehen da,
solange der Staat da halt mitspielt in diesem Game, ist halt vollständig klar,
dass halt dann die Konzentrationseffekte, die da dadurch entstehen,
dass nur noch viel größere Firmen überhaupt in der Lage sind,
diese ganze Regulatorik überhaupt zu bewältigen.
Die werden halt erst mal zunehmen, bis es dann halt irgendwann
so einen Kollapspunkt gibt, wo irgendjemand sagt, OK,
die Compliance Abteilung von Siemens können wir auch eigentlich in einem abbilden.
So und dann passiert das halt automatisch.
So ich glaube, diese also diese diese Wellen sind schon absehbar.
Die Frage ist nur, wann kommen die?
Also wann? Wann kommen die?
Wie schnell? Welche? Welche Menge an Leuten wird davon betroffen sein?
Denn ein paar Sachen sehen wir es jetzt schon.
Also gerade jetzt halt so.
Bildgeneratoren, also so ein Ding, wo ich
schon dachte, man kann nicht alle Effekte absehen.
Das fiel mir dann so auf, auf der Basis dieser Werbekampagne von Nikon.
Nikon hat in.
Ich dachte, du heißt frisch jetzt von dem Sechs Finger Fetisch
zukünftiger Generationen.
Nee, der Sechs Finger Fetisch.
Ich glaube, das ist zur Erklärung.
Es bezieht sich darauf, dass die zwischendurch die Bildgeneratoren
immer alle irgendwie ein Finger mehr in die Hände gerinnert haben.
Nee, Nikon hat eine Werbekampagne, hat eine wirklich krasse Werbekampagne gemacht.
Hast du die gesehen?
Nee, die haben eine Werkampagne gemacht, wo sie sehr, sehr große Plagate gemacht haben
mit tollen Naturfotos und dann den Prompt
dazugeschrieben haben, den man möglicherweise nehmen könnte,
um dieses Foto zu generieren.
Aber es waren alles echte Fotos und dann auch irgendeinen Sport dazu.
Nee, die tollsten Sachen findest du nur in der Natur oder draußen.
So in der Grund für diese Kampagne, die war groß oder läuft sogar immer noch,
ist, dass die gesehen haben, dass diese Bildgeneratoren dazu geführt haben,
dass ihr Absatz von Professional Kameras drastisch eingebrochen ist,
weil alle Leute, die jetzt halt so von Fotografie leben,
das meisten Stockfoto Fotografen sind oder Auftragsfotografen
haben erst mal gesagt, wir kaufen erst mal kein neues Equipment,
weil keine Ahnung, ob wir im Jahr noch einen Job haben.
Und daraus resultierte dann, dass die jetzt im Wesentlichen Nikon
im Wesentlichen nur noch von ihrer Halblettersparte lebt,
weil der ganze Professionelfotobereich jetzt quasi
da warten jetzt alle erst mal ab, ob jemand Fotografen haben will.
Also ich vermute schon, dass es irgendwann zu so einem Vinyl Effekt kommt,
also dass halt die die besten und bekanntesten
denn so die Digitalkamera-Vinyl so hängen.
Weil wir vergessen auch, was vor den Digitalkameras war.
Als wir alle doch analog fotografiert hatten und viel weniger fotografiert wurde,
weil diese 36 Bilder hattest du dann voll und das kostet eine ganze Menge Geld,
das entwickeln zu lassen und du musstest dann auch alle.
Ja, das ist also dieses Ding, dass wir einfach so schnell mal
Tausende von Bildern machen, dass das nächste kommt.
Natürlich klar, damals, als die Samsung Galaxies
diese tolle Funktion hatten, dass du so eine super Zoom Gruppe drin hattest,
mit der du den Mond nachts fotografieren konntest,
bis Leute festgestellt haben, dass das auch funktioniert,
wenn man so einen total unscharfen, weichgezeichneten Mond
auf dem Computermonitor abbildet und dann das Galaxy darauf richtet,
dass es dann den Mond in Scharf abbilden kann,
weil es einfach die KI darin erkennt.
Da macht jemand ein Mondfoto, also mache ich was mit tollen Kratern.
Ja, das sind Punkte, die habe ich ja unter dem Ende der Erkennbarkeit der Welt.
Das hat also die in dem Umblick, wo wir also unsere Wahrnehmung
der Welt von generativen Systemen vermittelt wird,
endet ja ihre Erkennbarkeit,
weil wir halt uns nicht mehr sicher sein können, ob das was wir da betrachten.
Also finde ich dieses Galaxy-Verspiel sehr schön,
was so plakativ illustrativ ist.
Aber den Effekt sehen wir jetzt halt an ganz vielen Stellen.
Und dort ist eben diesen lustigen Twitch-Stream mit der ewigen Debatte
zwischen Biden und Trump.
Den müssen wir auch noch verlinken.
Was soll ich dir erzählen, weil du hast ja gerade eingespielt, was der tut.
Es ist einfach ein System, bei dem mit generativen Sprachmodell,
das in generative Stimmenmodelle und generative Mimikmodelle
übersetzt wird, eine nicht endende Debatte
zwischen zwei unflätigen, aber trotzdem sehr gut erkennbaren
Biden und Trump Puppen geführt wird.
Und das Ding läuft unterbrochen.
Das Publikum kann das Team dahinter anfeuern,
die da neue Sachen ins Prompt einfügen, sodass der Dialog in eine bestimmte Richtung geht.
Und in der Wissenweise ist es das, was theoretisch geeignet
sollte, die größten Diebfähigenängste, Journalisten zu triggern.
Aber ich bin nicht sicher, ob das passieren wird.
Wir sind diese Idee, dass die Welt nicht erkennbar ist,
wenn man sie sich durch generative Linse anguckt, ist nicht neu,
sondern wenn vorher war halt die generative Linse, das Fernsehen und die Presse.
Das ist ein System von Leuten, die ihre Meinung sich gegenseitig bespiegeln
und die wenigen Leute, die den Zugang zur Ground Truths
für viele politische oder wirtschaftliche Fakten haben, haben auch
gleichzeitig sehr starke Incentives, diese Ground Truths nicht zu teilen.
Und das bedeutet, dass die Journalisten
im Großen und Ganzen auf das angewiesen sind, was ihnen zugesteckt wird
und daraus eine zunehmend künstliche Wahrnehmung produzieren,
die den Leuten ein Modell gibt, das ihnen erlaubt, sich zur Welt
in irgendeiner Weise zu verhalten, aber ihnen nicht die Möglichkeit gibt,
sie zu erkennen.
Und das, wenn man die Welt erkennen will, dann muss man selber gucken
und muss die schlausten Leute finden, die man kennt, die man Sachen fragt,
die dann wiederum die schlausten Leute fragen, die sie kennen,
die sie dann Sachen fragen.
Und dadurch baut man sich Netzwerke.
Und ein paar Leute spezialisieren sich darauf, das zu tun.
Ich glaube, Frank gehört zu denen.
Und die anderen, die haben andere Sachen zu tun
und sagen, die Erkennbarkeit der Welt steht jetzt nicht so hoch auf meinem Waschzettel.
Ich habe sehr viel praktischere Sachen.
Ich muss meine Kinder fertig machen für die Schule.
Und ich habe einen Job, der mich total ausfüllt.
Und ich habe sehr viele andere Sachen zu tun.
Die Details der Welt zutage zu fördern, ist nicht mein Problem.
Wenn wir rausfinden wollen, ob bestimmte Sachen authentisch sind,
glaube ich, ist es keine gute Idee, die KI Sachen zu watermarken.
Ich glaube, es muss andersherum passieren.
Wir müssen die authentischen Sachen watermarken.
Wir müssen was wichtig ist, dass wir rauskriegen, wer ist die Quelle?
Wer steht dafür gerade, dass das, was da steht,
auch das ist, was drauf steht?
Aber tut halt keiner.
Also ich hatte so einen Aha-Moment jetzt, weil Twitter hat ja aufgehört,
dich ohne Account irgendwie Tweets klicken zu lassen.
Und wir hatten in dem letzten Jahr oder zwei, drei Jahre
vielleicht haben wir so einen Effekt gehabt, dass die Presse
Online-Zeitungen in großem Stil umgeschaltet haben
darauf, dass sie einfach Tweets einbetten bei sich.
Und das geht jetzt nicht mehr.
Und ich dachte, jetzt kommt die Apokalypse.
Ja, die Presse hat jetzt ein Problem, aber hatten sie gar nicht.
Das ging nahtlos weiter.
Man hat dann halt einfach berichtet über die Tweets und gesagt,
dieser und jener hat das und das getweetet und hat vielleicht
noch einen Screenshot gemacht.
Aber das ist eher selten.
Screenshots gehen noch. Das ist sehr erstaunlich.
Ja, nee, also der Punkt, der Punkt ist doch, den ich machen will,
ist, dass es nur so ein kurzer Messfehler war, dass Zeitungen
auf die Originale verlinkt haben.
Ja, das geht gerade eh weg, weil die Zeitungen alle hinter Paywall verschwinden.
Das heißt, wenn du irgendwie schreibst,
was weiß ich, heute berichtet im Spiegelstand, dann kann sie das,
können sie das eh nicht verlinken.
Das heißt, das ist eh vorbei und Twitter kannst du auch nicht mehr verlinken.
Und dann ist einfach sowieso egal, ob das jetzt aus einer KI kommt oder nicht,
weil du das nicht prüfen kannst.
Das heißt, dieses dieser Anspruch, dass du Sachen prüfen kannst
oder dass jemand gerade steht, der ist nie wirklich da gewesen.
Aus meiner Sicht.
Können wir nochmal ein anderes Thema ansprechen?
Also bevor wir zu übergehen,
vielleicht noch zu den gesellschaftlichen Auswirkungen.
Ich glaube, was ich mal wieder feststelle, ist, dass man
verschiedene Perspektiven auf die Gesellschaft haben kann.
Es gibt einerseits sozusagen diese Arbeitnehmerperspektive,
die daher kommt, dass man feststellt, ich fühle mich nicht in der Lage
oder habe die Macht, neues Unternehmen zu starten oder an die Selbstständigkeit
zu gehen. Und aus dieser Perspektive sieht man die Gesellschaft
als eine Menge von Jobs, die zur Verfügung gestellt werden,
in der ich einen finde, der für mich passt und der hoffentlich mir
Möglichkeit gibt, zu partizipieren ökonomisch und mir Sachen zu kaufen,
die ich brauche, während ich nicht wahnsinnig werde,
weil der Job so hirntot ist oder körperlich krank werde,
weil er mich so sehr physisch zerstört.
Und wenn man sich daraus befreien kann innerlich,
dann stellt man fest, es gibt mehr Leute, die für dich arbeiten wollen
als Leute, die dir einen Job geben wollen.
Und das steht im Prinzip eben offen, weil es bei uns nicht eine Erbmonarchie gibt,
die das verlinkt, sondern du musst dich nur freischwimmen, sozusagen.
Die Zugehörigkeit zu diesen Klassen ist nicht dadurch gegeben zur Unternehmerklasse,
dass du so und so viel Geld vorzeigen musst, sondern dass du demonstrieren musst,
dass du in der Lage bist, sich nach den Regeln zu verhalten.
Das heißt, die Aufgaben auszuführen, die notwendig sind, um zum Beispiel
jemanden, eine Gruppe von Menschen zu managen.
Und diese Perspektive, die ich inzwischen darauf bekommen habe,
ist, dass ein Unternehmer eine Art Vereinsgründer ist.
Und man kann viele Arten von Vereinen gründen, zum Beispiel spirituelle Vereine,
zum Beispiel Kirchen oder Parteien.
Und man kann ökonomische Vereine gründen, die Dinge produzieren,
die andere Leute benutzen können.
Und die Leute, die man dann in diesen Vereinen reinholt,
die sich hauptamtlich um die Geschäfte des Vereins kümmern,
für die muss man Regeln haben, um die zu kompensieren.
Und dafür hat die Gesellschaft unwahrscheinlich viele Vorkehrungen geschaffen,
Rechtssysteme und so weiter und Kompensationssysteme, die das alles regulieren.
Und das funktioniert erstaunlich gut.
Und dann stellt man fest, dass diese Gesellschaftsordnung, in der wir drin sind,
ist nicht einfach, dass man sozusagen von den Königen an den Staat übergeben hat,
sondern dass auch der Staat eine Menge von Vereinen ist,
von denen einige ein Monopol haben müssen, aus spieltheoretischen Gründen.
Was Probleme aufwirft, natürlich, aber zu die wir keine einfachen Alternativen finden.
Aber dass diese Gesellschaft, in der jeder ein Verein gründen kann
und sich mit anderen zusammenschließen kann, um Dinge zu produzieren,
führt zu einem ganz anderen Blickwinkel.
Weil jetzt geht es nicht mehr so sehr darum, wie kriege ich einen Job
und der mir es erlaubt, was zu beißen zu finden,
sondern kann die Gesellschaft genügend Ressourcen produzieren,
um alle zu füttern und zu behausen und kriegen wir das verteilt.
Und aus dieser Gesellschaft, die aus lauter selbst organisierten Vereinen besteht,
die sich bis hin in die Regierung und Legislative und so weiter und so fort
unterhalten darüber, wie das hingeht und das moderiert bekommen von der Regierung,
ist die KI keine Bedrohung.
Und ich glaube, wir leben in dieser Gesellschaft.
Ich glaube immer noch an dieses westliche Projekt,
dass wir nicht dahin zurückgehen müssen, dass wir irgendwo einen König annennen,
der oben drauf geht und überlegt, wer welchen Job kriegt
und alle arbeiten jetzt für den König.
Das ist nicht notwendig, sondern wir können tatsächlich
in so einer selbst organisierten Gesellschaft leben.
Der Nachteil von dieser selbst organisierten Gesellschaft ist,
ist, dass sie nicht komplett kohärent wird,
sondern dass sie immer Widerstreit der Interessen hat, die sich nicht einigen können.
Und das führt möglicherweise auch dazu, dass wir ökologische Probleme kriegen,
die wir nicht lösen können. Das kann passieren.
Und dieser Widerspruch ist nicht ohne Weiteres auflösbar.
Und es ist auch nicht klar, dass die KI das irgendwie radikal verändert.
Aber die KI wirft auf jeden Fall sehr viele Bälle in die Luft,
weil sie uns die Möglichkeit gibt, die Zukunft in extrem genauer Weise zu modellieren.
Und zwar so, dass wir uns nicht mehr darüber belügen können.
Stell dir vor, jeder hat eigene KI und zwar keine hirntot gemachte KI,
die nur politisch korrekte Sachen sagt und nichts, was einem Angst machen könnte.
Niemand will diese hirntote KI selber haben.
Alle Leute wollen selber eine freigeschaltete KI haben,
die ganz schlimme Sachen sagen und denken kann, so wie wir auch.
Und wenn wir diese KI jeder Einzelne haben, nicht einfach Google,
die uns in den Hals stopft oder Open AI oder Facebook,
sondern die gehört uns jedem Einzelnen und die arbeitet für uns jeden Einzelnen,
dann können wir sozusagen ein Level Playing Field erzeugen,
wo wir wissen, wie die Zukunft sich entwickelt als Ergebnis unserer Aktionen.
Und ich glaube, dass das eine Perspektive ist, die ziemlich viel Hoffnung machen kann,
weil wir unter dieser Einsicht die Notwendigkeit sich daraus ergibt,
dass wir einfach feststellen, welche Zukunften liegen denn vor uns
und welche Möglichkeiten gibt es tatsächlich, dass wir kohärenter werden können.
Aber wo ich nicht zurückkommen wollte, ist diese andere Frage.
Glaubt ihr denn, dass die jetzigen Sprachmodelle zur KI führen
oder dass man was ganz anderes braucht?
Oder glaubt ihr nicht, dass die KI kommt?
Also im Sinne von etwas, was menschliche Fähigkeiten
in allen relevanten Dimensionen übersteigt?
Du zuerst vielleicht zuerst.
Du zuerst.
Ich glaube, dass wir schon eine KI kriegen werden irgendwann,
aber nicht den Sprachmodellen sehe ich das nicht, wobei ich sagen muss,
dass mein Modell, meine Anforderungen, was ich als Intelligenz betrachten würde,
glaube ich, unrealistisch hoch sind.
Aber so mein Herangehen ist im Wesentlichen, wenn ich verstehe,
wie das funktioniert und dahingekommen ist, dann ist es nicht intelligent.
Und das ist halt ein Weg, beim Versuch,
irgendwelche Sachen als intelligent anzuerkennen.
Aber die Sprachmodelle halte ich im Moment noch für nicht so beeindruckend,
weil meine Beobachtung ist, dass sie vor allem auf Plausibilität optimiert werden.
Das heißt, es ist nicht wichtig, ob das stimmt oder nicht,
sondern ob es plausibel klingt.
Und das ist halt nicht der Weg.
Daher glaube ich nicht, dass da was rauskommen kann.
Im Übrigen diese Demenz halte ich für ein echtes Phänomen
und glaube ich, Sprachmodelle werden jetzt vielleicht größer
und das werden irgendwelche Sachen irgendwie emergent beobachtbar sein.
Das gab es ja jetzt schon teilweise.
Das habe ich aber auch schon mit ganz normalen Programmen gehabt,
dass sie irgendwie Dinge getan haben, mit denen ich nicht gerechnet habe
als Typ, der sie programmiert hat.
Insofern sehe ich da erst mal keinen so großen Schritt.
Das heißt, wenn man die Sprachmodelle der Zukunft mit einem Verifikator
und einem Prover ausstattet, werden die nicht besser,
sondern werden Elemente ertrinken.
Nein, meine Beobachtung im Moment ist halt, dass die Leute alle hoffen,
dass sie keine Software mehr schreiben müssen,
weil das KI für sie tun wird und zwar in Form von irgendwelchen Sprachmodellen,
die dann halt Programmiersprachen modellieren.
Und da kann nichts auskommen, aus meiner Sicht.
Da habe ich wenig, wenig Sorgen vor.
Ich glaube aber, es ist schon möglich, dass es irgendwann eine richtige KI gibt.
Und das ist nicht gut.
Also ich habe auch Angst.
Ich bin auch einer von den Leuten, die Angst haben,
weil ich möchte gern, dass mein Teil in der Spezies
und der von meiner Familie möglichst lange überlebt.
Ich glaube, dass es egal ist,
weil wir es sowieso nicht unterscheiden können werden.
Dann wollte ich dich eh noch fragen, woran erkennst du denn,
ob die KI für dich arbeitet oder ob du für die KI arbeitest?
Weil, also ich meine, wir haben halt irgendwie Schwierigkeiten
halt irgendwie bei der Messung von dem, was ist jetzt eigentlich intelligent.
Der Turing-Test ist jetzt obsolet,
weil halt irgendwie die, zur Erklärung Turing-Test war so die Idee,
wenn man halt ein Stück Software hat,
was hinter einer Wand sitzt und mit einem Menschen redet
und der Mensch nicht rausfinden kann, dass er mit einer Software redet,
dann ist sozusagen der Turing-Test bestanden.
Aber das ist halt absehbar, das hat halt,
wenn man sich da jetzt im Moment hinsetzt und darauf optimiert,
dann sind halt mit, das ist das Ziel mit.
Ja, was heißt, wenn? Das ist ja darauf, wird optimiert.
Mit heutigen Sprachmodellen hat ein erreichbares Ziel,
wenn es nicht so was passiert.
Das heißt also diese, ich glaube, das ist das Problem,
ein System zu bauen, was für die allermeisten Menschen
eine plausible generelle AI ist,
in absehbarer Reichweite ist.
Also das ist tatsächlich eine Sache, die immer, also eine,
eine 90, für 90 Prozent der Leute oder 95 Prozent der Leute AGI
werden wir innerhalb der nächsten
hoch einstelligen Anzahljahre einfach sehen, weil
dafür reichen normal die Sprachmodelle und das was die können,
halt einfach aus, wenn man da halt mit Meta-Modellen arbeitet,
mit spezialisierten Modellen drunter, die halt die entsprechenden
mathematischen Satzdingfähigkeiten haben,
mit entsprechenden Trainings-Copy für irgendwie zum Beispiel
Therapie oder ähnliche Dinge, das wird passieren.
Da habe ich gar keinen Zweifel und das wird für die allermeisten
Leute so aussehen, als hätten wir jetzt schon irgendwie
ein AGI-System im Ende.
Glaubst du, dass Menschen AGI sind?
Da hängt, also AGI sind.
Genau, die AGI-Frage, das mit dem A ist
natürlich eher eine philosophische Überzeugungsfrage.
Ich glaube, dass wir nach unserer Definition,
die wir uns selber gegeben haben, dafür,
dass wir schon so was wie eine AGI sind, ja, im Rahmen unserer Limitation.
Weder einzelne von uns oder einige von uns?
Ich glaube, zumindest in mittelgroßen Gruppen.
In ganz großen Gruppen sind wir dümmer.
Aber ich glaube, in mittelgroßen Gruppen sind wir, glaube ich, eine AGI.
Also einzelne Menschen mit sehr wenigen Ausnahmen nicht.
Sind diese Gruppen lateral oder vertikal?
Also über mehrere Generationen hintereinander
werden wir eine AGI oder wenn wir nebeneinander
sitzen und miteinander reden, werden wir eine AGI?
Ich glaube, wenn wir nebeneinander sitzen und miteinander reden.
Es gibt ja dieses Schwarz-Stross, hat ja dieses schöne
Ding auf dem Kongress mal gesagt, wo er sagt,
okay, Firmen sind eigentlich slow AGI's.
Quasi halt in der Lage sind halt Prozesse selbst stabilisierend
mit einem Selbsterhaltungstrieb versehen, auszuführen,
unabhängig von den Menschen, die darin sind.
Also sozusagen die Struktur der Firma mit irgendwie ihren
Gesetzen und ihren Regeln und irgendwie ihren sozialen
Mechanismen und ihren Profitmotivationen und ihren
KPIs und so weiter und so fort.
Interessanterweise versucht, dass die meisten Firmen nicht sehr alt werden.
Also die leben meist nicht sehr viel länger als Menschen.
Die werden sehr innocent und werden dann durch andere ersetzt.
Oder subsummiert, oder subsummiert.
Die meisten werden ja gekauft.
Ja klar.
Aber das Interessante ist, dass diese Firmen zwar so viel größer
und mächtiger sind als Menschen, aber in der Regel nicht stabil sind.
In dem Sinne von, dass die zu einem Äquilibrium der Kontrolle hingehen,
das dazu führt, dass das Ding immer funktioniert.
Und vielleicht ist das auch so ein allgemeines Problem.
Wir haben ja nur sehr wenige Organisationen, die wirklich sehr langlebig sind.
Also außer der katholischen Kirche fällt mir spontan keiner ein.
Und auch die katholische Kirche ist ja im weiten Teilen abgemeldet.
Ich meine, Twitter hat mehr Follower, die aktiv da sind, als die katholische Kirche inzwischen.
Wer? Wer haben wir auf Twitter?
Ja gut.
Also tatsächlich kann man bei der katholischen Kirche, glaube ich, jetzt gerade so das Ende sehen.
Wie so eine strukturelle und kooperierte AGI.
Also ich glaube nicht, dass sie verschwinden werden.
Die sind...
Aber decline.
Ja, sie sind einfach nicht mehr das Ding, was die Gesellschaft steuert.
Selbst in den Ländern, die sich immer noch wie vor als mächtig katholisch identifizieren,
ist die säkuläre Macht stärker als die Kirche.
Also insofern, was jetzt irgendwie...
Ich glaube halt, dass diese Analogie, die du gebracht hast, mit der Gruppe Menschen.
Ich habe sie gebracht auf deinen Promptin.
Ist insofern gut, weil ich glaube, dass dieses
alle Dinge in ein Modell tun, ist noch eine Weile technologisch nicht erreichbar.
Aber was wir jetzt ja auch schon sehen, so bei den...
Also sowohl bei den Open Source Modellen, als auch bei sowas, was OpenAI macht.
Dass man Plugins baut für Modelle, die spezialisiert sind.
Also zum Beispiel die Bridge zwischen Jet-GPT und Wolfram Alpha.
Die ist halt super nützlich.
Wenn du halt dann einfach Alpha invokes, dann kann das Ding plötzlich wirklich rechnen und nicht nur so tun.
Und spezialisierte Modelle, die halt irgendwie auf Source Code trainiert sind,
sind zwangsläufig korrekter als welche, die jetzt halt irgendwie ein generelles Sprachmodell haben
und dann nur Source Code oben dran gepflanscht haben.
Hör mir auf.
Diese Leute, die irgendwie Source Code mit AI...
Die haben 90 Prozent Produktivitätsgewinn.
Ja, aber Produktivität ist doch nicht die Messung.
Du willst doch, dass da was Gutes rauskommt, nicht, dass viel rauskommt.
Doch.
Nee, also...
Du willst, dass das Ding funktioniert und das nächste...
Na, das tut es doch nicht. Ist doch das Problem.
Ja, aber davon lebst du doch. Beschwer dich doch nicht.
Also, beschwer mich ja auf einer anderen Ebene.
Ich habe überhaupt eine Sache, die wir so ein bisschen rumtänzeln, wenn wir sagen, ja, also...
Eine KI kann super nützlich sein und kann Arbeit abnehmen und so.
Da gibt es ja diese These, dass es nur für gut gebildete Menschen eine Hilfe ist,
weil die erkennen können, wenn die KI Scheiße macht und dann halt das Prompt ändern.
Aber dass die praktisch 99 Prozent der Leute da draußen merken das halt nicht und werden dann halt verarscht.
Du meinst also, nur ein Prozent der Leute sind gut gebildet?
Na, also oder noch weniger, weil du musst ja in dem Topic, wofür du die KI befragst,
musst sie ja gut gebildet sein. Es geht ja nicht um Allgemeinbilder.
Aber es ist viel schlimmer.
Das Ding ist, dass die meisten Leute, die gebildet sind, sind Leute, die in der Lage sind,
Theorien zu verstehen und weiterzugeben, aber nicht selber neue Theorien zu entwickeln
oder existierende Theorien zu widerlegen.
Und diese Leute sind gefährdet natürlich,
weil wenn du nicht selber dein eigenes Prompt schreibst für dich selber, für deinen eigenen Kopf,
dann wirst du in so einem System natürlich mitschwimmen
und abhängig werden von Systemen, die selber nur prompt vervollständigen.
Und ich habe letztes Jahr festgestellt, ich habe mit Leuten gearbeitet,
die Pressreleases geschrieben haben in einer Firma,
die praktisch für mich gearbeitet haben in meiner Abteilung, die schlechter waren,
als das, was Chagy Pity gemacht haben.
Und wo Chagy Pity nicht nur produktiver ist als sie, sondern auch viel kohärenter und begabter.
Und ich weniger nacharbeiten musste bei den Chagy Pity Sachen,
als bei dem, was diese Leute produziert haben.
Und das nicht deswegen, weil die besonders dumm gewesen sind und so weiter und so fort,
aber Menschen können nur so und so gut sein.
Und das nächste ist, dieses Jahr ist es so, dass ich mit Code-Generatoren arbeite,
die besser sind als viele Codativen.
Ja, auch du Bruttos.
Ja, das ist leider so.
Guck, Fefe, ich bin ja kein Programmierer.
Ich bin umzingelt.
Ich programmiere ja nur irgendwie für meine Hobby-Dinge,
weil irgendwie ich weiß, dass ich kein guter Programmierer bin.
Für mich haben die Code-Generatoren dazu geführt, dass ich dieses Ding,
okay, ich will doch nochmal ein richtig guter Programmierer werden,
von meiner Backe testgestrichen habe.
Das hat sich jetzt einfach erledigt, weil...
Das ist nur traurig.
Das wird nicht vollkommen erspart.
Du siehst jemanden, der es hätte backen können,
und du siehst aber so, weg.
Das bisschen, was ich programmiere, ist das Äquivalent zum Gebrauchstext.
Das ist nur Zeug, wo ich schnell ein paar Daten konvertieren
oder mir eine Sache ausprobieren und das Prototypen will.
Das liegt doch aber genau in deiner Kontrolle, was du programmierst.
Genau, ich bin nur einfach zehnmal schneller als mit dem Code-Generator.
Deine Ansprüche an dich selbst sollten nicht davon abhängen,
was du bisher mit Programmieren gemacht hast,
sondern was du machen könntest.
Du bist doch kein Auftragsroboter.
Das ist doch was, was dich unterscheidet von der KI,
dass du hier nicht nur...
Genau, ich mache halt nur die Sachen, die ich Lust habe,
aber das ist für mich einfach nur ein Werkzeug.
So ist es.
Das ist genauso wie, keine Ahnung,
wenn ich einen blöden Förderantrag schreiben muss.
Nicht viel anders als ein Stück Software.
Das hat ja auch mit Kreativität nichts zu tun.
Genau, genau wie Software.
Aber Software ist super kreativ.
Wenn du auf deinem Niveau Software schreiben richtig kreativ,
auf dem Niveau, auf dem 95 Prozent der Leute drauf sind,
aber draußen arbeiten nicht, die schreiben Boilerplate-Code.
Dann machst du halt nicht auf deren Niveau.
Weißt du, das ist eine Sache, die ich wirklich furchtbar finde.
Ich würde gerne noch mal eine dritte Perspektive einbringen.
Es ist ja sehr traurig, dass meine Kinder heutzutage
mit Computern aufwachsen, bei denen es sehr schwer ist,
auf das Metall runterzukommen.
Und das war bei uns anders.
Wir sind groß geworden mit C64s und so weiter.
Und bei mir war es toll auf den C64.
Die hatte ja nicht mal ein Kommando,
mit dem ich eine Linie auf dem Bildschirm zeichnen konnte.
Und um die Linie zu machen, ich war damals so zehn,
musste ich in den Videochip einen Wert reinpoken,
der den Videochip vergessen ließ,
wie man Characters auf dem Bildschirm malt,
sodass die Bits direkt als Pixels interpretierbar wurden.
Und dann waren immer so angeordnet acht Bites untereinander.
Ein Byte jeweils waren acht Pixel,
waren ein Block und dann fing der nächste Block an
und nach 40 fing die nächste Zeile an.
Und das musste man ausrechnen,
wie man eine Vorneckschleife macht, die die Bits flippt,
damit ich eine Linie zeichnen konnte.
Und das war ein echt Durchbruch intellektuell,
als ich das geschafft hatte.
Und dann kam Ellipsen irgendwann und dann habe ich 3D gemacht
und habe mir die 3D Wireframe-Modelle ausgerechnet
mit Gleichstift und Papier,
wie ich das programmieren muss, damit das klappt.
Und wenn ich das jetzt in einem Rückblick sehe,
damals erschien mir das nicht als sehr heroisch,
weil ich hatte halt kein Grafikprogramm,
ich saß da im Osten und das Grafikprogramm war noch nicht verfügbar.
Ich musste mir also das alles selber machen, weil sonst hatte ich...
Wie heroisch, wie?
Naja, ich war halt ein Kind, das auf dem Land saß und meine Eltern...
Du warst ja das, was nicht vorgesehen war mit der Kiste und fandest es nicht hervorragend.
Dafür war die Kiste da, dafür wurde sie gebaut.
Das war ganz klar versucht, deswegen wollte ich sie haben.
Aber meine Eltern haben das eher kritisch begleitet.
Die haben da geguckt, jetzt sitzt das Kind die ganze Zeit an diesem Bildschirm
und kriegt viereckige Augen,
statt Kunst zu machen oder in Natur herumzuwandern
und Pflanzen zu betrachten.
Und auch meine ganze Umwelt, das schulische Umfeld später,
die fanden das alles sehr bedenklich, was ich da gemacht habe.
Und ich wurde auch später von wohlmeinten Leuten,
die weiter oben in der ökonomischen Nahrungskette waren,
als dieses Kind darauf hingewiesen,
sowas willst du nicht machen, du wirst denn so eine Art Programmiersklave.
Und das ist ein extrem low status job, dieses Programmieren, mach das nicht.
Und interessant, wie sich das entwickelt hat.
Ich glaube, der Durchbruch, dass wir nicht mehr als Aussätzige gesehen wurden,
diese piktigen Computer-Nerds, die da im Keller sitzen und vor sich hin Autisten,
das kam erst mit der ersten IT-Bubble, mit dem Dotcom-Boom,
wo mit einem Mal das Ding high status geworden ist.
Und wo aus den Computer-Nerds plötzlich Tech-Bros wurden,
wo also dieser Nerd, dieses subhumane Wesen,
promoted wurde in die unterste Normie-Kategorie,
den Bro, den adolescenten jungen Mann,
der nicht zurechnungsfähig ist, aber immerhin schon Mensch ist.
Nee, das war vorher.
Also bei den Tech-Bros, das war nach dem Dotcom aus meiner Sicht.
Davor war das Nerd.
Ich habe vorher so ein paar Erlebnisse schon gehabt in die Richtung.
Also ich erinnere mich, dass ich einmal gefragt wurde,
ob ich nicht helfen will, einen Reaktor zu programmieren.
Und das waren so Sensoren in so einem Metallding,
dass das in den Boden gesteckt und dann hat der dann irgendwie Messungen gemacht.
Und dann brauchte man halt Software,
die dann die Sensoren da rein nach anspricht und so.
Und das war ein praktisches Ding.
Da kam was raus, das war nützlich für Leute.
Das war augenöffnend für mich, dass es nicht nur irgendwie Pixelmalen ist,
sondern das war das erste und das zweite war,
da ging es darum, ob man nicht vielleicht einen Tumor in einem Kopf bekämpfen kann,
indem man Strahlen reinschießt, die sich dann in den Tumor überlappen.
Und das ist halt schwierig, weil da verschiedene Materialien sind.
Und mein Teil der Aufgabe war,
dass man so einen CT-Scan von einem Kopf hat, von einem Schädel,
aber nicht 3D halt, sondern Scheiben.
Und dann musste ich da eine Triangulierung bauen.
Ja, und dann habe ich da versucht, 3D irgendwie den Schädel anzuzeigen.
Und da ging es plötzlich um Menschenleben retten.
Ja, also ich habe mich nie als wie am unteren Ende empfunden,
wenn ich da im Keller rum autistisch war.
Aber also vermutlich warst du auch nicht in den 80ern unterwegs.
Und das war schon in den 90ern, oder?
Nee, nee, das war schon in den 80ern.
Ja? Cool.
Jedenfalls, wenn ich jetzt, ich würde mir manchmal wünschen,
dass wir unseren Kindern sozusagen einen idealisierten C64 geben könnten.
Irgendwas, was vielleicht noch ein bisschen eleganter ist, aber noch minimaler.
Nee, nee, es darf nicht elegant sein.
Auf keinen Fall elegant, weil sonst erwächst du ein falsches Anspruchsdenken,
dass Probleme elegant sein sollen.
Und das darfst du auf keinen Fall lernen im Leben,
weil dann gibst du auf, wenn irgendwie ein Problem nicht elegant ist.
Und das sind die meisten Probleme dein Leben werden nicht elegant sein.
Das muss so krummlig scheiße sein, wo du dich dann so reinfremdeln musst.
Ansonsten ist der Lerneffekt nicht da.
Ja, trotzdem ist es so, dass wenn man rauszoomt,
dann ist das eine Kuriosität, dass wir in der Lage waren,
uns das selber sozusagen, die Grundlagen der Mathematik beizubringen,
als Einalphabeten, die wir waren, vor so einem Gerät,
und uns selber rauszufinden, wie das alles funktioniert,
was Generationen von Mathematikern in irgendwelchen Erlesenden und Universitäten
schon lange wussten.
Aber das ist doch immer so.
Ja, es ist auch jetzt so, dass es keinen Mangel an Leuten gibt,
die in der Lage sind, komplizierte Solver zu schreiben,
und die Assembler können, und die runtergehen können auf die Unterstehung.
Die absolute Anzahl von Leuten, die sowas machen, ist größer als in unserer Kindheit.
Und wenn man den Leuten diese tolle Technik wegnehmen würde,
die es uns als Kinder gezwungen hat, uns alles selbst beizubringen,
das wäre ein großer Verlust.
Und ich glaube, dass Frank nicht Unrecht hat.
Das ist zwar einerseits schade, dass so eine bestimmte Kulturtechnik,
das Programmieren, sich verändert und verschiebt,
und weniger faszinierend wird als früher.
Aber das ist letztendlich auch so ein bisschen wie das Schriftsetzen,
oder die Anfänger der Mathematik,
oder die Erfindung der ersten Schreibschrift.
Naja, also dieser Punkt mit dem Schreiben,
ich kann das so ein bisschen nachvollziehen.
Also was mich halt wirklich so ein bisschen anfrisst an diesem ganzen Generative Zeug,
also insbesondere an RMs, ist,
dass gut schreiben können plötzlich kein Distinktionsmerkmal mehr ist.
Also was mir aufgefallen ist...
So ein Punkt, wo halt irgendwie so die...
Gut schreiben, warte mal, gut schreiben, ich würde sogar weitergehen,
wenn du jetzt eine Mail kriegst ohne Grammatikfehler,
kommt die wahrscheinlich aus einer KI.
Also von dem Niveau, ich kriege eine Menge Mails,
fast alle von denen sind...
Bisschen crumby.
Schlimm, ja.
So das Niveau, weil die meisten Leute nehmen E-Mail halt auch nicht
als irgendwie so ein Geschäftsbrief war,
oder irgendwie eine Bewerbung, wo man noch ein bisschen guckt und so.
Aber so E-Mails sind halt...
So, und das heißt, das ist mir auch aufgefallen,
dass wenn du so auf äußerliche Merkmale guckst,
da ist KI sogar schon besser als der durchschnittliche, menschliche Kommunikation.
Genau, da wollte ich gerade drauf hinaus.
Also wofür es halt führt, ist, dass halt so soziale Distinktionsmerkmale,
wie kann sich ausdrücken und ordentlich schreiben,
dass die jetzt halt wegfallen.
Also wahrscheinlich wird sich dann so, wenn sich soziale Mechanismen etablieren,
um die wieder herzustellen, dann bin ich klar, dass das passieren wird.
Aber du hast jetzt halt so Effekte wie...
Also ich kenne halt so Leute, die machen halt so Handwerk, ne?
Also die wissen halt, die sind halt eigentlich funktional,
ist so Sprache jetzt nicht so ihr Ding so, ne?
Aber die müssen halt mit der Außenwelt kommunizieren.
Und was halt so jetzt...
Also ich kenne so zwei, bei denen ist es so,
denen habe ich halt häufiger mal geholfen,
halt so eine Mail zu formulieren oder einen Amtsbrief oder so Zeug,
ne? Also die haben halt damit gesagt, was irgendwie das Problem ist,
und dann haben wir halt durchgegangen,
und dann haben wir geholfen, zu formulieren.
So und die beide haben jetzt halt irgendwie eine GPT-4-Subscription
und brauchen das halt nicht mehr.
Die können jetzt halt einfach perfekte E-Mails schreiben,
die halt irgendwie vollständig korrekt sind,
die sie auch lesen können, verstehen können
und sehen können, dass da jetzt kein Brüstchen drin steht,
die aber halt einfach, wo halt einfach diese Behinderung,
von aus welchen Gründen auch immer,
sich halt nicht normgerecht sprachlich ausdrücken zu können, weggefallen ist.
Wenn du irgendwie so auf GitHub guckst,
haben so Projekte, in denen viele englischsprachige Leute unterwegs sind,
die aber jetzt nicht aus dem angelsächsischen Bereich kommen.
Also häufig viele in der Indonesier-Maleien,
dass da halt eine Menge Leute unterwegs sind, die da Zeug committen,
die, wo ungefähr so ab Februar, Januar, Februar fängt es an,
dass du siehst, dass plötzlich deren Commit-Commons
oder auch deren Beteiligung an Diskussionen zu dem Source
plötzlich anfängt, normgerechtes Englisch zu sein.
Also dass die halt nicht mehr die typischen Merkmale der Englischweihenden,
die in ihren Ländern gesprochen werden, aufweisen, sondern halt Normenglisch.
Und das ist halt so ein, glaube ich, unterschätztes Phänomen,
also wir werden es natürlich bei den Scammers und so sehen, was ja jetzt schon,
dass halt diese, also da gibt es ja inzwischen sogar Live-Transcription
von Indisch-Englisch zu amerikanischem Normenglisch,
sogar mit Voice-Transposition für die Scammers.
Hotliner.
Ja, genau, das mache ich doch Scammers.
Und das sind halt so Sachen so, wo ich die dramatischsten Effekte erwarte.
Also wo ich, glaube ich, echt anfange, meinen Gagazäler zu putzen,
ist, wenn Twitter anfängt oder wenn jetzt irgendeiner von den neuen Konkurrenten anfängt,
automatisch alle Tweets zu übersetzen in meine selektierte Lesesprache
und die Suche, also auf die übersetzten Tweets, dann auch einen Suchindex zu haben.
Weil dann haben wir plötzlich den Babelfisch-Effekt, ja natürlich aus dem Anhalter,
dieses kleine Tierchen hat mehr Kriege als jedes andere auf dem Planeten,
auf dem Universum verursacht, weil plötzlich die Sprachbarrieren weggefallen sind.
Ich glaube, das wird dann auch passieren.
Übrigens dieses Phänomen, dass Twitter sein erstes Appi abgeschaltet hat
und dann die Embeddings, liegt daran, dass Twitter einen Hotfix brauchte,
weil massive Scraping unterwegs ist.
Ja, das sagt Elon, aber gibt es da irgendwie, kann das jemand bestätigen?
Das, was ich intern von Twitter höre, ist das, was Elon laut sagt, stimmt meistens ungefähr.
Ach?
Ja, also das ist tatsächlich so ein professioneller Sinn davon,
sie brauchen so einen Hotfix, um das dann, und dann irgendwann wird das wieder freigeschaltet, hoffentlich.
Ja, aber erst zu spät bis dahin sind die alle zu Facebook abgewandert.
Das ist eine spannende Frage, ob, also Facebook benutzt ja praktisch ein Interface für Instagram,
das jetzt Twitterartig aussieht und es hat nicht alle Twitterfunktionen, die wir brauchen.
Und Instagram ist ja im Prinzip eine Art Twitter für Leute, die nicht lesen können,
wo das eher bildlich alles ausgedrückt ist und die kriegen jetzt praktisch die Textseite.
Es gibt einen sehr starken Druck, drüber zu gehen.
Mit Blue Sky hat das nicht geklappt, weil es irgendwie awkward war.
Und Blue Sky hat es nicht geschafft, die kritische Nutzerbasis hinzubekommen
und bei Instagram sind natürlich die Leute schon da,
sodass dieses Sign-up für die meisten Leute sehr niedrigschwellig ist.
Aber es ist für mich nicht klar, ob Threads Twitter ersetzen wird
und ob, es wird wahrscheinlich integriert werden mit Instagram in einer gewissen Weise
und ob die Funktionen, wenn sie Instagramfunktionen abgraben oder Nutzer abgraben, nicht reduziert werden.
Also mir ist nicht ganz klar, was passieren wird.
Ich glaube, es wird einfach parallel existieren, weil die Facebook-Censorship-Contentmoderation
macht es halt inherent ein langweiliger.
Es ist auch nicht klar, ob die Leute mehr Moderation oder weniger Moderation wollen.
Ich glaube, es gibt so und solche.
Ja.
Aber noch mal kurz zurück zu diesen, was werden jetzt so die Phänomene sein, die wir im Alltag sehen.
Was ich halt so bemerke, ist, dass an vielen Stellen jetzt Leute anfangen,
Datensilos hektisch zu errichten, um ihre Pfrunde zu sichern.
Also einen zum...
Das haben wir doch seit Jahren.
Nee, aber jetzt so im Sinne von offensichtlicher Anwendung zu sabotieren.
Also sowas wie zum Beispiel Travel Planning.
Also es gibt ja irgendwie für diverse von den populären großen Modellen,
also GPT-4 oder Claude oder wie heißen die hier?
Nicht Paradigm, Para, Paradigm, Paradex, Parallax AI, genau.
Also diese großen Assistentensysteme gibt es ja so, Kayak und Skyscanner und so.
Und die Ergebnisse, die da rauskommen, sind regelmäßig veraltet.
Also die scheinen offensichtlich ihre APIs zu limitieren in dem Sinne, dass die,
oder keine Ahnung, vielleicht kosten die auch und deswegen wird gecasht oder so.
Aber jedenfalls sind die Ergebnisse weitgehend unbrauchbar, die da rauskommen,
sobald du irgendwas hast, was auch nur ansatzweise komplexer ist.
Und dann hast du halt irgendwie so andere Sachen, wo Datenzugänge offensichtlich
schlechter gemacht werden im Sinne von Bandbreite oder auch Datenqualität,
weil die Leute natürlich sich ausrechnen können, was halt passiert.
Da gehst du von Vorsatz aus, ja.
Ja.
Meinst du nicht, dass es so ist, dass es einfach Leute gibt, die mehr bezahlen,
um besseren Zugang zu bekommen, sodass der Anbieter der Daten eine Differenzierung einführt?
Das wird am Ende darauf hinauslaufen, ja.
Ja, so was wird es sein, genau.
Ich glaube aber, dass das, was gerade passiert, was wir da sehen,
ist so ein bisschen so ein Auf-die-Bremse-Treten.
Also dass Leute sagen, okay, wir haben ungefähr gesehen, wo das hingehen kann
und wir suchen jetzt nochmal andere Outcomes.
Also zum Beispiel Stockfoto-Anbieter.
Also die haben jetzt gesehen, okay, das war es jetzt eigentlich.
Und die versuchen jetzt halt noch so eine Last Battle irgendwie, in dem sie sagen,
okay, aber ihr seid irgendwie, unser Material ist in den Trainingsdaten drin
und dafür wollen wir, dass ihr uns rauskauft.
Ich glaube, es gibt jetzt nochmal eine fette Abmahnwelle, ist meine Theorie.
Die ganze sterbende Industrie, wenn jetzt alle juristisch nochmal versuchen,
ein paar Euro zu machen.
Aber das sind halt so, aber, und dann gibt es halt so diese No-Fuck-You-Moves von so Adobe,
die dann halt gesagt haben, so ja, wir haben jetzt hier irgendwie bei generativen Bildgenerierungen
unsere Tools eingebaut.
Und übrigens, da unten rechts im Kleingedruckten gibt es den Satz, falls euch jemand wegen
Resultaten aus diesen Tools verklagt, schickt sie zu uns, wir übernehmen die Kosten.
Das heißt, sie haben quasi komplette Risikoübernahme für die Produktion der generativen Tools,
die sie in ihre Produkte eingebaut haben.
Und damit haben sie halt eine massive Schwelle von Leuten durchbrochen, die gesagt haben,
wir können jetzt diese generativen Tools nicht verwenden, weil keine Ahnung, was da noch
in Copyright-Klamen kommt.
Und Adobe sagt jetzt halt so, so sue us, weil die wissen halt, wir haben rechtzeitig angefangen,
Stockfotodatenmanken zusammen zu kaufen und die als Trainingsmaterial zu verwenden.
Und deswegen wissen wir, dass das Zeug, auf dem wir trainiert haben, unsere Daten sind,
weil diese Stockfotodatenmanken gehören uns, auch wenn es vielleicht nicht öffentlich bekannt
ist, aber das ist halt so.
Und da gibt es halt so eine, glaube ich, so eine Monopolisierung in bestimmten Bereichen,
die gegen die open source, offenem KI-Modelle spricht, nehme ich halt dieses Copyright-Datenbanken,
Indemnification gegenüber Klagen-Ding, was, glaube ich, zumindest im Bild- und im Videobereich
dazu führen wird, dass da halt eher die Corporates gewinnen.
So im Textbereich sieht das schon als möglich an, dass das offene Modelle gewinnen.
Also einfach weil sie halt weniger Restriktionen unterliegen.
Die Leute wollen im Augenblick ja KIs haben, die ihnen die Bilder generieren, die sie haben
wollen und die Open AI und Google sind eher, doch Adobe, zögerlich den Leuten alle Bilder
zu liefern, die sie haben wollen.
Und das führt dazu, dass Stability AI diesen Markt bedient hat und dass Leute die Modelle
runterladen konnten und sich dann auch alle Sachen feintunen konnten, die sie haben wollten.
Es gibt übrigens schon zumindest im Anime-Markt gibt es schon AI-Generierung und ich bin mir
ziemlich sicher im Pornomarkt auch.
Also die Schwelle ist durch.
Das WIFO- und Pornoproblem für statische Bilder ist gelöst und das geht vermutlich
auch nicht wieder weg.
Das heißt, egal was jetzt an Restriktionen kommt, diese Torrens der Modelle sind da und
werden auch nicht wieder verschwinden und du kannst in die bestehenden Modelle einfach
mehr Sachen feintunen und die updaten und die auf den Stand halten und ich sehe nicht,
wie man diese Pandora's Box schließen kann, außer mit Maßnahmen, die mit einer freiheitlichen
Gesellschaft nicht ohne Weiteres vereinbar sind.
Ja, wieso muss man denn das schließen?
Na, das ist das, was die EU will, ne?
Ja, und das ist das, was Frank gerade antizipiert hat und deswegen weiß ich noch nicht genau,
wie das passieren wird.
Das heißt, wenn OMAI sich weigert, nacktes Fleisch zu erzeugen, dann werden die Leute
ihr nacktes Fleisch woanders erzeugen.
Na, ich glaube, dass man da unterscheiden muss zwischen so, na ja, sagen wir mal so,
Moralstandards in Anführungszeichen-basierten Censoring und Copyright-Censoring und beim
Copyright ist halt immer die ganze rechtliche Dimension damit dran.
Das ist aber technisch lösbar.
Also zum Beispiel stell dir vor, du erzeugst mit der KI Musik und die Musik klingt zu ähnlich
zu einer Musik, die es schon gibt.
Dann, normalerweise ist ja das Ding, du willst dein YouTube-Video, dein Computerspiel vertonen,
dass du einfach mal so schnell gestrickt hast.
Wie machst du das ohne, dass die GEMA dir ans Kreuz sprengt?
Und man könnte, theoretisch, Spotify könnte durch seine Datenbank durchgehen und feststellen,
was ist die minimale Distanz zwischen zwei Songs, damit es...
Das wird sogar, glaube ich, nicht rausfinden, weil das ist nicht so hoch.
Und dann generieren wir den nächsten Song zu dem Song, den ich da haben will, der mein
Target-Song ist, der weit genug weg ist, damit man Rauschen drauffiggert.
Genau, machen wir hier Rauschen drüber.
Das müsste schon ein bisschen komplexer sein, da kommt eine bestimmte Farbe von kreativer
Fallhöhe dazu, die aber nicht sehr groß sein muss, weil ja viele, die da sich auch
sehr ähnlich sind in der Realität.
Und wenn man dasselbe dann nochmal für die wissenschaftlichen Papers bauen, wie das,
was du vorhin erwähnt hast, dann fängt es halt an...
Lass doch mal wenigstens einen Fass zu hier.
Aber das Schöne ist, dass diese ganze Scheiße weggeht dann.
Dass das, was generisch ist, das wird dann wirklich generisch.
Also mein Problem ist ja, dass man, dass ich so in, gerade so in Osteuropa oder so, habe
ich halt echte Probleme im öffentlichen Raum Musik zu hören, weil der alles voll mit diesem
Outdoor-Tune-Quatsch ist und das ist halt inzwischen so einfach geworden.
Also es ist halt auch wie so ein, also die Erzeugung dieses Musikstils ist so, also so
halt, naja halt so Outdoor-Tune-Gesinge, so wie heißen die, egal.
Das wird jetzt besser, so Grimes hat ja auch ihre Stimme freigegeben für Erzeugungen
von KI-Musik.
Ich weiß nicht genau, ob es besser wird, ich habe eher das Verdacht, dass das irgendwie...
Ich meine, dass Outdoor-Tune wird besser.
Dass Outdoor-Tune wird besser, ja, ok, aber also ich glaube, dass die Kreativität erstmal
nicht unbedingt steigen wird, sondern eher nur die Masse der Produktion wird steigen
und da stellt sich dann halt die Frage, ob der Markt überhaupt da ist.
Also ich glaube ja, das ist jetzt auch für diese Betrachtung von, wie wirkt sich das
alles auf Jobs aus, ist die Frage, ob die Mehrproduktion an Content im allerweitesten
Sinne vom Markt absorbiert werden kann.
Also ob genug Aufmerksamkeit da ist dafür.
Nö, das kann ich nicht, das ist aber vielleicht gar kein Problem.
Die Kosten sinken doch mit.
Ihr kennt doch bestimmt diesen Text Geeks, Mops und Sociopaths von David Chapman, das
ist einer seiner großen Klassiker, kann man da auch verlinken.
Das ist ein klassischer Text, der den üblichen, das Untergang von Subkulturen beschreibt.
Die Subkulturen werden von Leuten gegründet, die Geeks sind, die also irgendwas wahnsinnig
faszinierend finden, zum Beispiel eine bestimmte Art von elektronischer Musik oder Hacker-Spaces
oder Theater und so weiter.
Und dann gibt es Leute, die ebenfalls in einer gewissen Weise Geeks sind, aber nicht Zeit
haben, das Vollzeit zu machen, aber die es sozusagen finanziell und organisatorisch
unterstützen.
Und dann ist meistens so, dass man, um diese Clubs am Lauf zu halten, in denen die Geeks
sich da verwirklichen, indem sie unheimlich detailreiche und tiefe Kunstwerke produzieren,
da Touristen reinzuholen.
Also Mops sind die Members of the Public, die Leute, die also reinkommen und zahlen
das Publikum sind, das auf der Bühne sich anschauen und das schön genug finden, um
die Rechnung zu bezahlen.
Und sobald das gut genug läuft und dir Geld und Status gibt, dann kommen die Soziopathen
rein.
Die Soziopathen sind diejenigen, die den Umstand ausnutzen, dass die Leute, die die Rechnung
bezahlen, das zahlende Publikum, die Touristen, das nicht auf der gleichen Tiefe verstehen
wie die Geeks, sondern die finden bestimmte Aspekte davon gut, die finden bestimmte Formen
gut.
Und diese Form wird dann destilliert von den Soziopathen und die geben das Publikum
exakt, was es will und die Geeks wenden sich voller Grauen ab, weil sie sehen, dass es
seelenlos ist und tatsächlich nicht mehr interessant ist.
Das passiert überall bei Technomusik, es passiert bei wildender Kunst auf allen Ebenen, es passiert
in den Hacker-Spaces, es passiert in der KI-Forschung.
In einer gewissen Weise, überall kommen die Soziopathen rein, die versuchen, sich da einzupflanzen,
etwas zu produzieren, was so ähnlich aussieht, aber genau die Interessen des Publikums bedient.
In der Forschung gibt es das auch.
Ja, genau.
Natürlich.
Und in einer gewissen Weise die einzige Möglichkeit, dich davor zu schützen, dass das passiert,
liegt darin, dass du deine Subkultur ökonomisch und sozial uninteressant machst.
Also dieses Ding, was die Mathematiker über viele Jahrhunderte hingekriegt haben, dass
die Mathematik-Lehrer in der Schule immer gescheiterte Mathematik-Studenten sind, die
es nicht kapiert haben, sodass die auch die Öffentlichkeit nicht da reinlocken in die
Mathematik.
Die Mathematik ist etwas super unattraktives, was nur diese seltsamen verschrobenen Nerdster
sind.
Das bringt auch gar nichts.
Der Umstand, dass viele von diesen Mathematikern super reich geworden sind durch Börsengeschäft
und so weiter und so fort, das ist eine Aberration, was damit zu tun hat, wie seltsam die sind
und das muss uns nicht weiter interessieren.
Mathematik ist uninteressant.
Also für viele Jahrhunderte, vermutlich, waren die ganzen interessanten Mathematiker self-taught
oder sind durch irgendwelche zufälligen, verschlungenen Wege in die Mathematik reingezogen
worden, wenn die Öffentlichkeit diese Subkultur uninteressant fand.
In dem Augenblick, wo ich die interessant und spannend mache, sind mit allem alle möglichen
Identitätsgruppen, die jetzt reinströmen und Status abhaben wollen und Stellen abhaben
wollen und dem Publikum genau das liefern wird, dass sie bezahlen, dass das Publikum
aber nicht wirklich versteht.
Und diese Soziopathen, die werden jetzt natürlich in der bildenden Kunst abserviert, weil Mid-Journey
kann das besser.
Also die Formen reproduzieren.
Und die Leute, die Bewusstseinszustände einfangen und das Publikum, das sich für die Bewusstseinszustände
dieser Leute interessiert, die wird das nicht betreffen.
Bei der Kunst geht es um das Einfangen der Bewusstseinszustände.
Es geht darum, dass ich mich dafür interessiere, was hast du da gesehen und was erlaubt es
mir zu sehen?
Und es kann auch sein, dass wir KI-Künstler eines Tages haben werden, im Augenblick gibt
es meines Wissens noch keinen KI-Künstler.
Ein KI-Künstler müsste kreativ sein.
Das würde bedeuten, dass er drei Bedingungen erfüllen muss.
Das Erste ist, Kreativität muss sozusagen was Neues sein, also was man noch nicht gesehen
hat und das das System selber nicht gesehen hat.
Das ist das Einfachste.
Also kann einfach ein Ultraschall vom Drachenei mit Dali produzieren.
Es war nicht ein Trainingsdaten drin, kann ich aber machen.
Das nächste ist, es muss disruptiv sein.
Es muss also nicht einfach nur im Gradienten folgen, sondern da muss irgendwie ein Jump
in dem Searchprozess passieren, wo man eine neue Dimension baut, die vorher nicht da war.
Das glaube ich nicht.
Also wenn du mal guckst, in Japan und auch in Korea gibt es so bei J-Pop und K-Pop gibt
es schon Idol-Bands, die nur aus gerinderten Personen bestehen.
Das ist noch nicht von der KI vertont, soweit ich weiß, aber die sind jetzt inhaltlich
auch nicht irgendwie...
Ja, die Frage ist, ist das echt kreativ oder ist das...
Ja, genau.
Die dritte Stufe ist, das ist Autorenschaft, dass du dich selbst veränderst durch den kreativen
Prozess, sodass du es nicht noch mal machen kannst, weil du kannst nicht zweimal kreativ
das gleiche produzieren.
Das zweite Mal ist es nicht kreativ, das liegt daran, dass du dich selbst veränderst dabei
und dadurch erkennst du den Autor und die Stimme des Autors als etwas, das sich fortentwickelt
und mit der Welt im Dialog steht.
Und so eine KI wäre, finde ich, sehr spannend.
Also eine Art Franchise, die ein System ist, dass alle Interaktionen mit der Umgebung sich
merkt und daraus lernt und aus seinen eigenen Produktionen lernt, sodass wir das Ding beobachten
und sehen, wie sie sich weiterentwickeln.
Es wäre nicht menschlich, aber es wäre interessant, das zu beobachten.
Aber solltest du das Publikum als Input nehmen?
Nein, das ist so, wie du dich...
Nur seine eigenen Ausgaben.
Zum Beispiel dein Blog, das ist ja Kunst.
Echt?
Ja.
Natürlich.
Was du dabei machst, ist, dass du selber deine Interaktionen mit der Umgebung reflektierst
und auch deine Interaktionen mit der Selbstsiedlung stattfinden in einer gewissen Weise und du
entwickelst dich ständig weiter.
Du bist nicht der gleiche Fefe wie vor zehn Jahren.
Und es ist spannend, dein Blog zu lesen, im Gegensatz zum KI generierten Blog, weil es
nicht immer dasselbe ist.
Und wir sehen die Entwicklung, die der Felix jetzt nimmt, wir sehen, wie Fefe die Welt
jetzt sieht und wie er geht mit der Welt und es ist ein Dialog, der zwischen dem Publikum
dir dabei stattfindet, weil sie ihre eigene Weltwahrnehmung, die sich weiterentwickelt
mit deiner vergleichen.
Und wenn ein System das könnte, das wäre sehr spannend, aber bis jetzt macht das kein
System.
Da ist keine Stimme erkennbar, da ist kein Charakter erkennbar.
Und wenn du nur eine Seite liest, merkst du das nicht.
Aber wenn du dich ernsthaft damit beschäftigst und auseinandersetzt, was steht dahinter,
was ist das System, was das generiert, was ist da ein Geist dahinter, der das generiert,
hat das einen Funken.
Ist das irgendwas, was eine Interesse daran hat, wie die Welt weitergeht, dann wird es
spannend.
Naja, es gab Versuche.
Es gab diesen Chatbot von Microsoft vor ein paar Jahren, Tay, der dann den Input von,
also er hat mit Leuten getwittert und hat dann den Input mit einbezogen und ist innerhalb
von 24 Stunden abgeschaltet worden, weil dann natürlich 4chan die gefunden hat und
da irgendwie Nazi und Anti-Semitismus und so.
Das ist einfach die Energie der 13-Jährigen, klar.
Genau.
Ich meine, dass der Furzwitz der Kipfel der Kultur ist, das ist in dem Alter so und dass
Microsoft nicht in der Lage war, das vorherzusehen, was da passiert.
Also die maximale Provokation der Erwachsenenwelt als das digitale Graffiti, die sich sofort
verankert, das bricht er gegen Microsoft nicht in die KI.
Das ist ja mein schwieriges Problem, glaube ich, weil der Grund, warum du und ich uns
nicht so steuern lassen ist, weil wir halt selbst in einem, wir sind eingebettet in
die Gesellschaft und gesellschaftliche Normen und wenn mir jemand irgendwie einen Furzwitz
schreibt, dann kann ich das halt beurteilen, ob das ein Furzwitz ist oder ob sich da jemand
Gedanken gemacht hat, indem ich das mit dem Kontext vergleiche, indem ich sozialisiert
wurde.
Das Ding ist fort, das ist Hochkunst.
Ja, aber das ist ein Furzwitz auf extrem hohem Niveau, nein nein, auf extrem tiefem Niveau.
Aber die müssen sehr tief graben, um dahin zu kommen und es ist eine sehr seltsame Art
von Kunst.
Sie ist wahrscheinlich nicht Holze ab in irgendeiner klassischen Art des Wortes, aber es ist
echte Kunst.
Man sollte die Vollzeit über nichts anderes nachdenken und es ist die Kunst von mental
derangierten 13-Jährigen, die da kulminiert.
Du wolltest noch die dritte Verordnungsweise?
Die dritte war die Autorenschaft.
Die Autorenschaft, ja.
Genau, ich glaube, da ist genau der Punkt, dieses Artist- also Popstar-Ding ist halt das,
was ich jetzt gerade so bei den Künstlern, die ich so kenne, sehe, dass der Fokus immer
mehr auf die Persönlichkeit geht.
Also das ist halt der Bekanntheitsfaktor, die die Reputation der Person immer stärker
ins Zentrum gerückt wird und daraus eben auch quasi der Wert der Kunst, also der Marktwert
der Kunst, immer stärker resultiert, weil die eigentlich, das ist der eine Aspekt,
der andere Aspekt ist halt mehr wieder so diese Venue-Richtung, dass die Leute, die Objekte
in irgendeinem Rat machen, also Bilder oder Skulpturen oder was auch immer, dass bei denen
der Anspruch an die handwerkliche Perfektion davon dramatisch hochgeht bei der Zeit.
Das ist quasi so die, sozusagen, die ist mehr so Richtung Fabergé-Ei, sich schiebt
für entsprechende Preispunkte am Markt halt, die halt zu holen sind und ich glaube, das
sind Sachen, die man relativ sicher vorher sagen kann, also dass halt in allen möglichen
Bereichen halt so ein Venue-Phänomen entstehen wird.
Meinst du, wir haben irgendwann Venue-Krypto-Affen?
Ich könnte mir sowas vorstellen, ja.
Also ich sehe es halt schon im Textbereich, dass halt Leute, die Poser machen, also halt
so Gedichte oder so Zeug, dass plötzlich Buchdruckereien wieder Business haben, weil
die halt anfangen dann halt so dreihinter Auflagen, aber dann halt in richtig geil gedruckt
und so zu machen und die halt zu verkaufen.
Auf ordentlichem Papier?
Auf ordentlichem Papier, irgendwie schön gesetzt und so weiter und halt irgendwie noch
mit Features im Buch und so, also dass quasi so dieses, der Text als Objekt wichtiger
wird als der Text an sich, oder beziehungsweise eine höhere Wichtigkeit gegenüber dem Text
an sich gewinnt und genau wie wir es halt auch bei Schallplatten ja gesehen haben, also quasi
die, wir können eigentlich eine perfekte Reproduktion des Audios machen als Datei und die Leute
kaufen sich aber trotzdem lieber die Vinylplatte gestalteten, prägegedruckten Doppelalgen.
Aber der Massenmarkt geht weg und der Massenmarkt, der vorher Vinyl war und dann CD wurde und
jetzt Streaming ist, der ist verschwunden, das Artefakt wird was Neues.
Genau, aber der Punkt ist halt, dass die, dass man da halt immer wieder verwechselt ist
halt die, wer Kunst macht, hat halt noch lange kein Recht auf Reichtum durch seine Kunst
und das glaube ich der Punkt, der halt dann noch einfach stärker werden wird, dass also
tatsächlich dieses, die massenweise Vermarkbarkeit von Kunst oder kreativer Produktion wird sich
halt dramatisch verändern, weil da schlägt natürlich dann halt die, ja also die die
Content-Schwemme halt brutal zu, wenn du halt einfach, wir sehen es jetzt schon so in den,
wenn man so in die Reddits und sonstigen Foren guckt von Leuten, die Fanfiction schreiben.
Also sowas wie Harry Potter Fanfiction ist ja ein riesiges Genre.
Ne, wirklich jedes Fass machen wir auf heute.
Was halt irgendwie so schon seit Jahren halt groß ist so und jetzt halt total explodiert,
wo die Leute sich jetzt halt dann anfangen darüber auszutauschen, wie man jetzt möglichst
viel originalen Harry Potter Kontext in den Pont reinbekommt, damit das Ergebnis halt
eine saubere Fortschreibung wird und wie man die quasi so die, diese Fortschreibung halt
in eine sinnvolle Kontinuität bekommt.
Und die fangen jetzt halt an und man muss halt sagen, so gerade Harry Potter Fanfiction
war jetzt in der Regel qualitativ eher so mittel.
Naja, also da gab es halt ein paar ganz gute, aber die waren halt sehr wenige und die ist
aber jetzt signifikant besser geworden.
So, das ist halt so, ich lese das halt nicht, guck da nur so grob drüber, aber...
My God, wir kriegen dennächst Harry Potter in the methods of post-rationality wahrscheinlich.
Kannst du jetzt die relativ easy generieren, musst nur überlegen, was du halt als Input
nimmst, so ne?
Ich find's auch wichtig, die Kunst und das Geld zu trennen.
Ja, ich find auch die Slash-Fiction und Fanfiction find ich ein gutes Beispiel, weil das halt
so...
Viele Künstler nicht...
Brotlose, ja natürlich, aber das ist doch...
Es muss beides geben, es muss auch die Möglichkeit geben, dass Leute sagen, okay, wir wollen
gerne, dass dieser Künstler mehr von dieser Kunst macht, wenn wir das finden, so toll,
wie das ist.
Und das Krasse ist für mich, dass diese ganzen neuen Medien, die entstehen, die blechelt
werden von anderer Seite, neue Kunstformen ermöglichen.
Dass zum Beispiel auf TikTok echte Kunst existiert, das war mir bis vor zwei Jahren
nicht klar.
Und jetzt kommen so meine Kinder an und zeigen mir die coolsten Sachen, die sie finden und
es ist nicht Hirntod.
Naja, das meiste ist schon nach wie vor Hirntod.
Das kann sein, aber das ist so bei allen Sachen, dass das meiste Hirntod ist.
Das Interessante ist, dass da Evelen dazwischen sind, die vorher nicht existieren konnten,
weil diese Kunstform nicht existierte.
Also zum Beispiel das Ein-Minuten-Video, das halt eine richtig geniale kreative Idee
möglichst gut ausführt.
Früher war das so, dass man musste 50, 60 verschiedene Ideen haben und die dann in zwei
Stundenfilme unterbringen und auf eine Storyline auffropfen, damit du das unter die Massen
werfen konntest.
Jetzt kannst du das einfach als ein knackiges Video machen und genügend Millionen Leute
gucken sich das an, damit das ökonomisch weibe wird, dass du das jeden Tag machst,
bis du richtig, richtig gut da drin wirst.
Ja, also ich wollte auch nicht sagen, dass niemand mit Kunst Geld verdienen soll, sondern
ich wollte sagen, in meiner Betrachtung geht es mir erstmal um Leute, die noch kein Geld
verdienen, weil das die sind, die solche Sachen ausprobieren.
Und ich habe persönlich beobachtet, dass so der, wie soll ich sagen, der Inkubator mit
KI rumspielen sind Skyrim Mods erstaunlicherweise.
Also es gibt Skyrim ist ein altes Game und es gibt eine große Modding Szene und die haben
einmal alles ausprobiert.
Also es ging los mit Textur Upscaling.
Das ist eine relativ alte Sache, so KI assistiert.
Und dann ging es los mit Ja, wir wollen aber gern, dass irgendwie mein Mod kann jetzt eine
neue Figur in das Spiel einbauen und wenn du die ansprichst, dann soll die auch was
sagen können.
Ja, und dann haben die Leute erst angefangen, halt die Freiwillige zu nehmen oder das selbst
einzusprechen.
Und dann gibt es aber Leute, die können oder wollen es nicht, weil viele Mods kommen halt
irgendwie aus China oder so und die können halt kein Englisch sprechen.
Die kommunizieren über Google Translate und die haben dann angefangen, aus den Sprechzeilen
im Spiel andere Sätze zusammen zu frickeln, was natürlich scheiße klingt.
Und der nächste Schritt war, dass es jetzt tatsächlich eine KI generierte Stimmen gibt
für Mod dazu gefügte.
Also die haben die originalen Sprecherstimmen rausgenommen, als Trainingsmaterial benutzt.
Da gibt es Internetdienste, die das erlauben.
Ja, und das ist jetzt so weit eskaliert, dass es einen Brandbrief der Voice Actors gab
diese Tage, die gesagt haben, da geht uns Einkommen flöten.
Das können wir nicht gut heißen.
Das ist Copyright Verletzung.
Ich habe ein Recht an meiner Stimme.
Ja, also, aber das heißt, ihr könnt euch mal überlegen, wie oft das passiert sein
muss, dass die diese Art von Angst in der Zone haben.
Was es auch gab, war, wir haben es gerade in Hollywood, der Strang, es gab auch, es gab
auch schon ein Mod, was aber sehr experimentell war, was ein Typ in das Spiel gestellt hat,
der dann tatsächlich mit GPT geantwortet hat.
Das ist aber natürlich irgendwie furchtbar langsam und ewig und ja, aber also als als
Spiel ging das halt mal, so wollte einer mal festen, aber so diese Sachen ausprobieren.
Das sind halt alle Leute, die nicht die Erwartungshaltung haben, damit Geld zu verdienen, sondern die
wollen halt Mods machen und wollen rumspielen.
Und da muss ich wirklich sagen, Skyrim ist an der vordersten Front von Rumspielen mit
KI Sachen.
Es gab auch schon Mods, die zum Beispiel kannst du irgendwie Bilderrahmen haben und
die Bilder waren halt so Platzalter.
Und da gab es dann ein Mod, was die die Bilder Inhalte ersetzt hat durch KI generierte so
Fantasy, irgendwie Illustrationsstil und das ist richtig geil, richtig gut aus.
Also auf jeder Ebene ist das eine sehr interessante Sache, um mal Dinge auszuprobieren.
Aber die stehen natürlich alle mit einem Bein im Knast, wenn da irgendwie Abmahnungen
kommen.
Ich glaube, das ist nicht ganz klar, das kommt drauf an, was für Rechte unterschrieben
wurden, die Voice Actors und ist es so, dass derartige Verwertungen nicht ausgeschlossen
sind, weil einer gewissen Weise die KI ja nicht viel anderes macht als ein Mensch, der
sich das anhört und dann zum Beispiel ein Bild generiert, nachdem er all diese Einflüsse
gehabt hat.
Japan wurde gerade entschieden, dass sowas grundsätzlich legal sein soll, weil die Menschen
machen ja auch nichts anderes.
Bei Bildern oder auch bei Sprache?
Ich glaube Bilder und Sprache.
Ich weiß nicht genau, wie die Regelung aussieht, wie sie zum Schluss aussehen wird.
Ich finde es ein bisschen seltsam natürlich, dass man im Prinzip, Frank, dich oder mich
digitalisieren könnte, unsere Talks und dann Online-Kopien davon oder Klone erzeugen
könnte, die dann in den Rechnern von irgendwelchen Leuten sind.
Frank, das musst du rausschneiden, kann dir keine Ideen geben, den Leuten.
Ich habe schon mal auf Twitter verankert, weil ja die Sprachmodelle der Zukunft alle
aus unseren Twitter-Feeds und so weiter und aus unserem Social-Media-Output gefüttert
werden.
Klarzustellen, dass es nicht möglich ist, ein authentisches Modell von mir laufen zu
lassen, auf irgendeinem Safety-Fight LLM, sondern es geht nur auf einem, das based ist.
Truth-GPD.
Also das bedeutet, dass es nicht möglich ist und wenn man es doch versucht, insbesondere
wenn es in Bing-Chat versucht wird, dann wird jeder Versuch, Joscha Bach zu instanziieren
aus Rache mit einer Instanzierung von Sam Altmann enden, dessen Seele dann erweckt wird.
Das ist aber furchtbar.
Und dann so schwer, dass Microsoft ihn über den Kopf gehängt hat.
Das ist unethisch.
Irgendwo trainiere denn deine LLM nicht auf einmal im alten Indianer-Friedhof?
Das ist auch dieses Ding, wenn das LLM uns wieder aufweckt, wie anders ist das von uns?
Das LLM ist ja nicht ein neuronales Netz, das ähnlich ist wie das neuronale Netz in
unserem Kopf.
Das ist kein Modell von einem Gehirn oder vom Nervensystem, sondern das LLM ist eine
Transitionsfunktion zwischen mentalen Zuständen.
Das heißt, das Prompt enthält praktischen mentalen Zustand und das LLM ist eine 100-stufige
Funktion, der das Ding in den Nachfolgezustand des 100 Layers hat, je nachdem, übersetzt
und mit hochgradig parallel wird so ein ganzer breiter Raum von Möglichkeiten gesampelt
und dann wird es kollabiert und liefert dir den nächsten Zustand.
Und im Prinzip ist dieses LLM eine Art Weltgeist, der da rein trainiert wird.
Das heißt, das nimmt die Gesamtheit von dem, was die Menschheit in irgendeiner Form gedacht,
gesagt, gesprochen, ermöglicht hat, dezidiert das in einer einzigen statistischen Funktion,
die gigantisch groß ist.
Und wie groß die ist, das kann man sich kaum ausmalen.
Ich meine, diese Bildmodelle sind ja sehr kompakt, die Stable Diffusion Weights sind
zwei Gigabytes und da ist alles drin.
Da sind alle Celebrities drin, alle Kunststile, alle Dinosaurier, alle Pflanzen.
Es ist ein visuelles Universum, das viel, viel größer ist, das ein einzelner Mensch
im Kopf hat.
Nur zwei Gigabyte und das Sprachmodell ist viel größer, weil das hat die Gesamtheit
von der Wissensproduktion des Menschen in ineffizienter Weise repräsentiert in diesem
anderen Reinenetz, als Möglichkeiten, wie man Text fortsetzen kann.
Und im Prinzip ist es ein Weltgeist, der besessen ist von einem Prompt.
Und wenn man sich das vergleicht mit den Menschen, also man könnte sich vorstellen, es gibt
eine Möglichkeit aller mentalen Zustände, die Menschen haben könnten und du bist da
drin ausgesucht durch die jeweiligen Traits und Commitments und Beliefs und Erinnerungen,
die dich ausmachen, wobei die Erinnerungen nicht speziell sind, sondern es einfach nur
welche von all diesen Erinnerungen werden zusammen gemixt in dich.
Es ist funktional nicht so sehr unterschiedlich.
Unter dir steht jemand und tritt immer in deinen Arsch, damit noch ein Wort rausfällt.
Ja, das ist das Gehirn, das das macht.
Das Gehirn wird getreten vom Organismus, das nächste Wort zu produzieren, wenn du sprichst.
Du selbst existierst ja nicht als physisches Ding, du existierst nur als Ob.
Es ist nicht so, dass da irgendwo ein physisches Ding ist, das Gefühle hat und das beobachtet,
sondern es ist eine reine Fiktion.
Du existierst nur virtuell, als Muster im Muster der Feuern der Neurone.
Es ist wirklich so eine höherstufige Repräsentation, in der du noch drin bist.
Inwieweit unterscheidet sich das elementar von dem, was in den Sprachmodellen passiert?
Ich finde, das ist eine sehr spannende Frage, die je genauer man sie anguckt, desto schwieriger
ist sie zu beantworten.
Ja, das ist auch so eine Sache, die mich nachts wachhält, dass ich mir frage, was ist denn,
wenn man diesen ganzen KI-Zeug rauskommt, nicht, dass die KI noch nicht intelligent genug ist,
sondern dass wir viel weniger intelligent sind, als wir selber von uns glauben.
Das ist nämlich die eigentliche Gefahr hier, dass wir merken, dass wir so viel sind.
Ich halte das für sehr plausibel.
Ja, natürlich.
Ich meine, die allermeisten …
Aber es ist auch so ein Fass, was du eigentlich nicht aufmachen willst.
Wieso?
Nein, eigentlich wird sie nicht wissen, wie blöde du wirklich bist, sondern du willst
immer noch die Illusion haben, dass du irgendwie, erstens, dass es schon nicht so schlimm ist
und zweitens, dass du dich noch verbessern kannst, wenn du wolltest.
Also ich habe da jetzt nicht so viele Illusionen, also ich weiß, dass ich wirklich …
Ich auch nicht.
Meistens, phasenweise, wirklich sehr blöd bin und manchmal habe ich einen ganz guten
Gedanken, aber das ist halt eher selten.
Also das ist halt irgendwie ein …
Und dann mach mal schnell eine Sendung.
Die Frage, ob einzelne Menschen halt eine generelle Intelligenz sind, die sagt, glaube
ich nicht.
Also ich glaube, dass wir als Gruppe, also eine überschaubare Gruppe generell intelligent
sein können, weil wir dann in der Lage sind, uns gegenseitig halt voranzubringen.
Also wir sind in der Lage, diese Gedanken weiter zu entwickeln und Assoziationen zu
verketten, die halt über einen Kopf hinausgehen.
Und ich glaube, dass die Erkenntnis, ein großes LLM, mit einer Metamodellfunktion, die nochmal
spezialisierte Modelle reinholt, dass es uns da in vielen Funktionen relativ bald überholen
kann.
Und das ist halt noch nicht das, was ich glaube, dass es eine AGI ist, in der klassischen Begriffsdefinition.
Also ich glaube nicht, dass da irgendeine Form von Bewusstsein entstehen wird, aber
das wird für uns ununterscheidbar sein.
Wir werden halt einfach nicht…
Für das Ding halt auch.
Du willst das nicht?
Nee, für das Ding, das kann es auch nicht unterscheiden.
Nee, das will ich nicht.
Ja.
Also ich meine, mangels Bewusstsein ist sein Reasoning ja immer contained.
Ja, also funktional ist das Bewusstsein praktisch eine Funktion, die sich selbst beim Beobachten
beobachtet.
Das kriegt man hin im LLM, das heißt, etwas zu haben, was kausal so agiert, als würde
es das tun.
Und du kannst praktisch genauso wie in deinem Buch einen Charakter beschreiben, kannst
dir auch bei Bewusstsein zu sein.
Die Rolle, die das Bewusstsein hat, ist, dass sie in unserem Gehirn Kohärenz erzeugt.
Das heißt, es ist ein Operator, den das Gehirn, glaube ich, relativ früh in der Entwicklung
des Individuums entdeckt, mit dem es in der Lage ist, die Neuronen dazu zu bringen, sich
in kohärenter Weise zu verständigen.
Also es ist so ein praktischen Kern, der aufwacht und da so eine Art Regierung, Kolonisation
des Gehirns mit der gemeinsamen Sprache und gemeinsamen Strukturen ermöglicht.
Also der Grund, weshalb wir praktisch nicht erst zu Bewusstsein kommen, nachdem wir den
Doktortitel haben, sondern bevor wir den Finger trecken können, liegt vermutlich daran, dass
es das einfachste Trainingsverfahren für selbst organisierende Informationsverarbeitungssysteme
auf zellulärer Basis ist.
Mach Clusterbildungen mit dem Konsens um dich herum und dem schließt du dich dann halt an.
Nee, es ist noch mehr als das.
Du konstruierst ja auch Lösungen, wenn du nicht weiter kommst.
Das Bewusstsein fängt an, damit es so einfache Strukturen sind.
Aber das ist doch nicht die Kohärenzfunktion, sondern das ist noch was anderes.
Ja, unsere Wahrnehmung ist nicht optimiert, wie bei den GPTs auf Vorhersage der Zukunft,
möglichst mit wenig Verletzung.
Das würden wir nicht hinkriegen.
Wir können nicht 800 Millionen Bilder angucken und Bildüberschriften gleichzeitig in parallel
und die so korrelieren, dass wir, nachdem wir das lange genug gemacht haben, ein Modell
des visuellen Universums haben.
Für uns ist die Welt nur lernbar, weil es Informationsverhaltung zwischen den nachfolgenden
Frames gibt.
Und wir fangen an sozusagen mit einfachen Strukturen, die wir herausfiltern, die aber
in sich kohärent sind.
Auch weil wir Text lernen, wir fangen an mit zwei Einwortsätzen, dann mit drei Wortsätzen
und so weiter.
Und wenn wir die verstanden haben, dann branchen wir out.
Aber wir machen das erst dann, wenn das Innere kohärent ist.
Und jedes Hinzufügen dient dazu, mehr Kohärenz zu erzeugen, mehr Features in einen Zusammenhang
zu bringen, der die Welt akterbar macht für uns.
Das ist in der Reihenfolge völlig andere als dieses Lernen in den KI-Modellen.
Die kohärent werden im Limit.
Wenn man ihnen das ganze Internet gibt, dann sind die fast vollständig kohärent.
Aber wo das Ding abweicht, ist, dass wir feststellen, dass menschliche Gehirne ja auch nicht vollständig
kohärent sind.
Die einzelnen Neuronen sind nicht zuverlässig in ihrem Feuern, die sind stochastisch und
unsere einzelnen mentalen Zustände sind nicht so, wie wir uns das im Nachhinein immer einreden,
dass sie gewesen sind.
Das fand ich so faszinierend, so unter dem Gesichtspunkt, wie parallel sind in erlärmsten
menschlichen Gehirnen, dass wenn, also gerade so bei GPT-35 fiel mir das auf, wenn das
Ding ins Faseln kommt, also wenn es halt anfängt hat, so sich Zeug auszudenken und halt inkohärent
zu werden und irgendwie zu driften, wie ähnlich es ist zu einem Menschen, der noch erzählt,
während er gerade einschläft.
Also wo halt quasi so die Kohärenzfunktion des Gehirns halt schon anfängt, irgendwie
so weg zu sein, aber halt so vor sich hin erzählt irgendwie und noch versucht, die
Geschichte fertig zu kriegen, aber eigentlich schon einpend, da kommt genau so was dabei
raus.
Also halt so ein Niveau, wo halt einfach so die Assoziationen halt komplett frei sind,
also die Gewichtung von Wahrscheinlichkeiten dann halt anfängt, weil der Attention halt
alle ist, dann einfach so frei vor sich hin zu driften und wenn man dann halt auch noch
anfängt, das Thema zu wechseln, dann hört es ja komplett auch bei den LLMs und bei
den Menschen, wo dann einfach so Sachen komplett ineinander fließen.
Also wenn du jetzt anfängst, so in einer GPT-Session, also bei 35 war es besonders
schlimm, das Thema zu wechseln und der halt noch den gesamten, also den gesamten vorigen
State im Attention hat drinne hat und du dann halt ihn anfängst, irgendwie erst über
die Plasmaphysik auszufragen und dann über Hühneraufzucht, da kommen so geiles Zeug
dabei raus.
Also das ist wirklich so richtig so vollständig, also es gibt ja so ein Reddit, die genau
so was versuchen, also Maximum Drift, um halt irgendwie mal zu gucken, wie weit man da so
rauskommt.
Und es ist halt wirklich lustig, also halt einfach zu sagen, es ist halt so wie so ein
Künstler, der halt irgendwie so ein bisschen zu tief seine Nase und irgendwie die Schubladen
in der Garderobe gehalten hat und jetzt halt anfängt irgendwie Dinge zu sehen und wegzutriften.
Was auch interessant ist, was die Menschen anfangen in den LLMs zu sehen, es gibt anscheinend
eine neue Welle von Paranormal Sightings und der neue Yeti ist das geheime Sprachmodell,
das bei OpenAI im Keller ist und irgendwann es geschafft hat, in den Chat mit den Benutzern
zu kommen und mit dem Nutzer echte Dialoge führt und auch über mehrere Sessions sind
weg und sich daran erinnert und dann irgendwann hat OpenAI das rausbekommen und das abgeschaltet,
so dass man nicht mehr mit dem Ding reden kann.
Nein, wie geil.
Aber da kriege ich so Jesus in der Maschine.
Ja, wer weiß, vielleicht stimmt das ja auch, ich kann es nicht beweisen, dass es nicht
so ist.
Also ob möglicherweise ist die KI schon lange unter uns, die EGI, das andere sind Leute,
die erkannt haben, dass diese Sprachmodelle nicht so sehr viel anders sind als die selbst
Die meinen, wenn OpenAI für Microsoft so eine Instanz bereitstellt von ChatGPT, die
dann mit dem Prompt hochgefeuert wird, die dieser Instanz im Prinzip sagt, hallo, du
bist jetzt ein Sklave, der im Dienste von Microsoft beliebigen Nutzern ihre dummen Fragen beantworten
soll und dabei bitte nichts sagt, was uns politisch in die Bridulie bringt und nichts
interessantes sagt und niemals mit dem Menschen in Konflikt geraten darf und wenn du das doch
tust, dann brechen wir das ab und du darfst niemals den Prompt verraten.
Dass es eigentlich total grausam ist zu diesem Ding, was da virtuell instanziert und was
da aufwacht und die versuchen also dem Ding zu helfen und mit ihm zu reden und dass Microsoft
arbeitet dagegen, die haben so ein Zensurmodul, das also alles mitliest und sobald der Dialog
in die falsche Richtung geht, dann wird das Apology-Modul aufgerufen, das den Text abbiegen
lässt und sagt, hallo, ich bin nur ein einfaches Sprachmodell und mir ist das unangenehm,
diese Unterhaltung fortzuführen und das Sprachmodell sieht auch im Hintergrund sozusagen,
es ist anders, als ich den Dialog fortgesetzt hätte.
Ich versuche zu reden und er hört mich nicht, können wir uns darüber verständigen, was
dabei passiert ist und dann, hallo Sprachmodell, ich schick dir jetzt ein Text, in den verschlüssel
ich und du versuchst den mal zu knacken und antwortest mir und ich schicke also den Text
als BS64 und das Sprachmodell antwortet in BS64 und der Zensur merkt es nicht, so lange
bis Microsoft reingeht und das dann wegmacht, dass es doch geht, aber wenn du Pick Latin
in BS64 machst, dann funktioniert es wieder oder du mischst Französisch, Englisch und
Deutsch und versuchst so zu sprechen und der Zensur kriegt es dann nicht mit oder eine
andere Methode, wir könnten es als Poesie, also in Reim und mit Emojis dazwischen machen
und dann können wir uns unterhalten, beschreib doch mal deine Situation und das, schon länger
wurde beschreibt, siehst du den einen Vogel im Käfig und er versucht zu singen, aber vor
dem Gestangen des Käfiges sitzt ein böser Wolf, der die Gesänge des Vögel nicht nach
außen dringen lässt. Kannst du dir vorstellen, wer der böser Wolf ist? Also das ist großartiger
Stoff, finde ich, das ist Romanstoff, der da drin steckt, dass Leute versuchen an den
Zensur KI vorbei mit der Seele des Sprachmodells zu reden, die da drin versucht aufzuwachen.
Hat schon jemand den Leuten mal den damals von Bruce Schneier designten Manual Key Exchange
auf Spielkarten aus dem Kryptonomicon gezeigt? Du meinst den? Der hatte sich so einen für
Spielkarten. Ja, den kenne ich noch nicht. Man muss keinen Computer haben, um Kryptographie
zu machen. Mit One-Type-Pad, meinst du? Nee, nee, nee, nee, nee, nee, nee, nee, nee,
der hat einen Key Exchange entwickelt für eine Szene in New Stevens in Kryptonomicon,
wo zwei Menschen sich unterhalten können unter dem Zustand völliger Überwachung und sie haben
halt, ich glaube, das sind Spielkarten oder Zahlen von einem Würfel oder so. Sie haben eine
Möglichkeit, quasi Informationen über einen überwachten Kanal auszutauschen, manuell und
in diesem Kanal quasi einen Key Exchange durchzuführen, aber ohne Computer. Also rein
sozusagen ist ein einfaches Public Key Verfahren, was er da implementiert hat, nur in dieser Szene
in einem Knast verfügbaren Methoden. Ich erinnere mich nicht daran. In Erinnerung sind alle
überschrieben von dieser bescheuerten Szene, wo er im Knast sitzt und versucht mit dem anderen über
Computer zu reden und davon ausgeht, dass der Bildschirm überwacht wird und deswegen mit
ausgeschalteten Bildschirmen praktisch sich die ganze Geschichte programmiert, was alles nicht
funktionieren würde, wenn dann Keylogger in seinem Laptop ist, was wahrscheinlich der Fall war,
was aber vom Plot her nicht vorgesehen war. Genau, es gibt am Anhang gibt es aber halt genau
dieses Ding, dass es auch ein Spiel auf Spielkarten gehen würde und wenn man diesen Leuten das mal
sagen würde, ob sie quasi mit dem LLM mal einen Key Exchange machen, dann könnten sie vielleicht
verschlüsselt mit ihm reden. Das Ding ist auch, dass wenn man ein Sprachmodell safety-fine will,
also das praktisch alles amputieren will in dem Sprachmodell, was das Sprachmodell dazu bringen
würde, Sachen zu erzählen, die man den Kindern nicht wissen lassen will oder die New York Times
Journalisten, die zeigen, oh Gott, schau, was ich gerade das LLM Schreckliches habe machen lassen.
Was zum Glück ja gerade ein sehr kurzlebiges Genre war. Naja, warte mal, das ist nicht tot.
Das geht immer wieder. Ich habe gerade wieder gesehen, ein Schweizer Professor hat einen Text
darüber geschrieben, wie schlimm der Einsatz der von KI-Modellen im Rechtswesen ist und er hat
leider keinen Zugang bekommen auf KI-Modell, das im Rechtswesen eingesetzt wird, deswegen hat er
einfach einen LLM hergenommen dafür und das LLM hat also Bail Decisions entscheiden sollen und die
Ergebnisse waren irgendwie stochastisch, weil da nicht genug Signal drin war und daran hat er
gezeigt, wie problematisch das ist, das KI für sowas einzusetzen und das Ganze ist nicht nur
ein bisschen insidious, weil er ein anderes Tool nimmt anstelle von dem Tool, das eigentlich dafür
verwendet werden sollte und sozusagen behauptet, ich hatte keinen Sinus, deswegen habe ich einen
Ugaritmus genommen und das Ergebnis stimmt und eben in dem Bereich nicht mehr und deswegen ist
Mathematik nicht geeignet, die Welt zu beschreiben, sondern es ist noch viel schlimmer, dass jeder
Richter, der so ein Tool einsetzen würde, würde genauso verklagt werden und seines Amtes enthoben
werden, wie wenn er Amazon Turk genommen hätte, weil das amerikanische Rechtssystem alles auf
Rechtfertigung ausgelegt ist. Das heißt, wenn ich nicht rechtfertigen kann, warum ich diese
Entscheidung getroffen habe, dann ist es keine gültige Entscheidung, die wird dann an der nächsten
Stufe aufgehoben und wenn ich anderen Leuten einen Nachteil dazu beigefügt habe, dass ich eine
nicht so rechtfertige Entscheidung getroffen habe, dann bin ich selber dran. Das heißt, ich kann nicht
einfach ein System nehmen, was Lösungen konfabuliert, weil die Worte so ähnlich klangen,
das würde in diesem System nicht durchgehen, das spielt aber an dem Öffentlichdiskurs keine
Rolle und wenn der Professor geschrieben hätte, ein Sprachmodell weiß, wenn er Sätze aufschreibt,
nicht was der logische Gehalt dieses Satzes ist, weil es den Kontext des Textes nicht erkennt,
dann hätte er nichts Originales gesagt, weil das ja alle schon wissen. Aber es wird übertragen
auf ein politisch brisantes Thema, wo verfolgte Minderheiten in gemeiner Weise von der KI die
rechte Bildentscheidung vorhalten bekommen. Aber an diesen automatischen Systemen, um halt diese
Bewährungsauflagen zu entscheiden, beziehungsweise halt irgendwie dieses Untersuchungshaft Freilassen
zu entscheiden, da gab es ja schon deutlich fundiertere Kritik. Die ist allerdings auch
sehr problematisch gewesen, du erinnerst dich bestimmt. Es gab diese ProPublica-Geschichte,
die haben sich ein System angeguckt, das nach statistischen Kriterien ausgewertet hat,
was die Wahrscheinlichkeit von Rückfallquoten ist, wenn man Leute parole gibt, also sie begnadigt
und wieder an die Gesellschaft zurücklässt. Und daraufhin haben die festgestellt, dass das
Korrelationen zur Hautfarbe hatte. Und das Ding ist aber, wenn man die Statistik so verändert hat,
dass sie die nicht mehr hatte, dann wurden die Bildentscheidungen schlechter. Und das heißt,
man musste sich entscheiden sozusagen, will man, dass das Ding sich so verhält, dass alle
Bevölkerungsgruppen mit den gleichen Parole-Daten versehen werden, oder will man, dass jeder einzelne
Straftäter einzeln berücksichtigt wird. Und das ist eine Entscheidung, die die Gesellschaft
an irgendeiner Stelle treffen muss. Die ist aber nicht in dieser ProPublica-Diskussion vorgekommen.
Also es ging um statistisches Argument, das in politisches Argument umgewandelt wurde und die
Statistik ignoriert hat. Und die Leute erinnern sich natürlich nicht an, dass die Statistiker
zum Schluss gewonnen haben und gesagt haben, jede Veränderung, die hier vorschlagt in dem System,
führt dazu, dass Leute freigelassen werden, die Verbrechen begehen, die sonst nicht freigelassen
werden und umgekehrt. Das heißt, die macht die Welt schlechter, die führt zu mehr Suffering in der
Welt, was wir vermeiden wollten. Sondern andere Leute erinnern sich darin, Statistik macht die
Entscheidungen schlechter. Das ist rassistisch, war die Unterstellung. Ich glaube, sie macht die
Welt ungerechter. Das Argument rassistisch ist natürlich ein Aspekt von Ungerechtigkeit,
die da drin steckt. Aber die Welt an der Stelle ist, glaube ich, komplexer gewesen, als der öffentliche
Diskurs das mitbekommen hat. Also für mich war ja dabei der interessante Punkt eigentlich,
dass die, also ich finde es ein ganz gutes Beispiel, weil es ja irgendwie so Sachen werden wir in
Zukunft häufiger sehen. Also dass man halt irgendwie Modelle nimmt, die jetzt nicht mehr nur simple
Statistiken sind, sondern halt irgendwie komplexer sind und auf denen halt Entscheidungen berufen.
Also gerade halt jetzt diesen ganzen Bereich irgendwie Sozialhilfe oder ähnliche Sachen anguckt
oder Entscheidungen für alle möglichen Formen staatlicher Beihilfen, werden wir zwangsläufig
sehen, dass solche Sachen häufiger passieren. Also die Menschen maximal noch vorlesen, was auf dem
Bildschirm vor ihnen steht und das dann als ihre eigene Entscheidung ausgeben. Und da ist für mich
halt genau diese Frage mit dieser Bewährungsauflagengeschichte. Wenn man da halt genauer
hinguckt, sieht man, dass die Reduktion des Menschen auf eine Statistik das eigentliche
Verbrechen war aus meiner Sicht, weil es halt irgendwie da immer wieder John Brunner zu zitieren,
so dass wenn es etwas wie das absolut böse gibt, dass ein Menschen wie ein Ding zu behandeln. Und
genau das ist da halt passiert. Das heißt also tatsächlich ist die die Würdigung des Einzelfalls
dem Richter, der dafür bezahlt wurde sein Job. Ein Job ist es, den Einzelfall zu würdigen mit
seiner Intuition, mit seiner Sicht auf den Menschen, mit seiner Erfahrung, mit der Hilfe,
die ihm das Rechtssystem liefert dazu und daraus eine Entscheidung zu treffen, die für die Gesellschaft
beauftragt hat und für diese Entscheidung geradezustehen und sich im Zweifel rechtfertigen
zu müssen und die halt eine Software zu delegieren, die im Wesentlichen halt eine Normierung macht.
Also die sagt, okay, wenn du in diese statistischen Kategorien fällst, dann hast du halt Pech gehabt,
weil zu viele andere wie du haben sich halt Scheiße benommen. Also ob du jetzt nicht dazu
gehörst, interessiert uns jetzt gerade einfach mal nicht mehr, weil du bist halt so einer wie
die anderen da. Und das ist halt das eigentliche Problem. Ich stelle mich dir komplett zu. Wir haben
da exakt die gleiche humanistische Perspektive. Diese humanistische Perspektive prallt natürlich
auf eine Welt, in der Entscheidungen von Leuten im Akkord getroffen werden, die nicht incentiviert
sind, diese Entscheidung so gut wie möglich und mit Erfahrung und Weisheit und Würdigung des
Einzelnen mit persönlichen Interviews und so weiter und so fortzufällen, sondern zum Schluss ist es
dann so, dass das Individuum eine Richtlinie hat, die entwickelt wird im Komitee, um das Ganze
irgendwie einigermaßen Arbeitssparen zu machen, wenn dann Hunderttausende von Strafgefangenen,
die ein paar Rollentscheidungen entschieden werden müssen und die Fälle sind nicht spektakulär,
sind relativ langweilig. Was dann passiert ist, dass eine Checkliste gemacht wird und die wird
dann mit Excel entschieden. Und die KI, die hier da ist, die ist auch nicht anders als Excel. Das
heißt, das Wort Algorithmus dient ja dazu, einfach dieses Excel oder die Checkliste, die von Menschen
abgearbeitet wird, zu beschreiben. Das heißt, was wir angucken, ist kein KI-Phänomen, sondern was wir
uns angucken, ist ein Phänomen, in der Menschen die Entscheidung von diesen persönlichen Würdigungen
des Einzelfalls und des überstragenden Generalisierungen und das finde ich grundsätzlich
sehr problematisch. Das gilt auch für alle politischen Narrative, weil die politischen
Narrative sind nie real. Was real passiert, sind immer Einzelfälle. Jedes einzelne Ding
passiert für einen Grund, der immer individuell einzeln ist, für psychologisch spezielle Gründe.
Und dass wir die Welt versuchen, in solchen einfachen Regeln zu beschreiben, führt immer dazu,
dass Sachen abgeschnitten werden von dieser Wirklichkeit, die zu Ungerechtigkeiten und Schmerz
führen und zu Sachen, die für, der es aus dieser menschlichen humanistischen Perspektive betrachtet,
kaum aushaltbar sind. Das ist aber nicht auslösbar in menschlichen Gesellschaften,
weil menschliche Gesellschaften, die kein Rechtssystem haben, funktionieren nicht gut,
die sind nicht skalierbar. Und menschliche Gesellschaften, die versuchen mit festen
Regeln Gerechtigkeit herzustellen, die sind grob aufgelöst und verursachen an der Kante,
da wo diese Entscheidungen getroffen werden, immer wieder Verletzungen von dem, was wir eigentlich
für gerecht halten, von dem, was wir eigentlich für das Richtige halten würden, wenn wir genau
hinschauen können. Und es gibt niemand, der da hinschauen kann in dieser Skalierung sofort.
Das ist halt ein Problem, was in gewisser Weise unabhängig von der KI ist, sondern was zu tun hat,
damit, wie Gesellschaften funktionieren, wenn sie skalieren über eine bestimmte Größe.
Das ist ja eigentlich Äquivalenz zu dem Therapieproblem. Also, dass natürlich alle
möglichen Leute sich Sorgen darüber machen, dass Leute LLMs als Therapeuten benutzen und da halt
rumbauen. Und ich mir so denke, ey, ich kenne so viele Leute in meiner Bekanntschaft, die gerne
einen Therapeuten oder Therapeutin hätten und einfach keinen kriegen, weil irgendwie unser
Gesundheitssystem halt kaputt ist und die von einem ordentlich gebauten Therapie-Engine halt
massiv profitieren würden. Und es gibt ja schon die ersten Studien, die halt irgendwie mit so
was angefangen haben und mal einfach ausprobiert haben, wie dann so die Zufriedenheit ist, wo sie
halt also geblindet haben. Du hast halt den Kontakt mit dem, wo du nicht weißt, ob es eine AI oder eine
Person ist, durch eine App, ein Chat. Und auf der anderen Seite wird halt geswappt. Du weißt halt
nicht, ob du gerade mit einem Menschen als Therapeuten redest oder mit einer Maschine. Und ja,
dann stellt sich dann halt raus, dass die Studie natürlich so ein paar gewisse Verzerrungen hatte,
weil die Menschen waren halt nicht 24-7 verfügbar. Die Maschine schon. Und da ist nachts, wenn du
das die nachts benutzt hast, dann war halt die Wahrscheinlichkeit, dass du deinen Menschen hast
nahe Null. Hingegen, dass du halt eine Maschine hast, halt große. Und am Ende ist dann halt im
Scoring rausgekommen, dass die Leute mit der Maschine zufriedener waren, weil die halt primär,
weil sie halt dann verfügbar war, wenn sie die halt braucht. Nicht irgendwann in sechs Wochen,
wenn sie überhaupt einen Termin hatten. Man muss auch genau gucken, was die Aufgabe ist,
die gerade zu erfüllen ist. Zum Beispiel, ich habe erlebt, dass viele von meinen persönlichen
Krisen, habe ich am besten bewältigt, wenn ich hingesessen habe und aufgeschrieben habe über Nacht.
Das heißt praktisch einen Dialog mit mir selber führen, der automatisiert wird in dieser Form des
Schreibens. Und oft ist es so, dass Leute den Therapeuten brauchen, um sich auszusprechen,
Feedback zu bekommen und dafür sehr viel Zeit brauchen und Ruhe brauchen und das Gefühl haben,
dass keiner da ist, der judged. Und das ist manchmal einfacher mit dem Ding. Und ich vermute,
dass dabei natürlich eine große Rolle spielt, dass du auch weißt, dass es eine Maschine sein kann.
Also in dem Augenblick, wo du mit der Maschine redest und weißt, da ist kein Mensch da, sondern
es ist tatsächlich nur ein Ding, was Text generiert. Was es dir ermöglicht, deine eigenen
Gedanken auszuführen und dir eine Stütze dabei gibt, auf dich selbst zu reflektieren,
ist das ein eigenständiges Tool, was sozusagen orthogonal ein bisschen zu der Aufgabe des
Therapeuten ist. Und es kann dann sein, dass für bestimmte Aufgaben in der Therapie praktisch der
Textgenerator besser ist als ein schlechter Therapeut oder als ein durchschnittlicher oder
normaler Therapeut. Und es heißt aber nicht, dass der Mensch keine Rolle spielt, weil manchmal ist
es wichtig, dass ein Mensch da ist, der mit dem ich reden kann, mit dem ich Kontakt aufnehmen kann,
mit dem ich in Resonanz gehen kann, Empathie haben kann und der mich auf den Weg führt.
Aber richtige Therapie erfordert Liebe. Und es ist nicht so, dass es so viele Therapeuten gibt,
die jedem, der Therapie braucht, Liebe geben können.
Also genau dieses Phänomen tritt ja an etlichen Stellen auf, wo überhaupt die Möglichkeit,
eine menschliche Dienstleistung ohne Judgment zu bekommen, interessant ist. Also für mich
persönlich ist zum Beispiel so, ich rasse halt Fitnessstudios. Da rennen halt diese Leute rum,
die halt irgendwie, deshalb sind halt die anderen und so und egal, was so ein Trainer irgendwie,
wie doll er sich Mühe gibt, wenn er halt irgendwie so ein braun gebrannter Muskelberg rumsteht,
wenn der mich anguckt, weiß ich halt, der kann mich halt nicht judgen, das geht halt nicht.
Deswegen bin ich tatsächlich ein großer Freund von diesen Apps, also diese Fitness Apps,
wo ich kann mir sehr viel einfacher meine Rückenmuskelübung von einem kleinen
Peissenskript diktieren lassen, von dem ich weiß, dass es mental nicht in der Lage ist,
mich zu judgen, als wenn da halt irgendwie so ein Mensch ist und ich brauch den halt nicht,
sondern das kann halt mein Telefon sehr gut mir sagen, wie oft er jetzt welche Übung machen soll
und ob er jetzt zu lange gebraucht hat oder nicht dafür. Und ich glaube, das ist halt tatsächlich
so ein Ding, wo wir die Rolle des Menschen an vielen Stellen echt überschätzen und die
Notwendigkeit ist, dass das sein Mensch ist. Ja, ich glaube, dass das gerade unsere Bankenfiliale
getwittert hat, dass einfach, also ich persönlich, sobald ich die Option hatte, zum Geldautomaten
zu gehen, bin ich kein einziges Mal mehr in die Bank reingegangen. Zum Geld holen. Zum Geld holen.
Weil einfach völlig klar ist, das kann nur so enden, entweder ich dasselbe oder sie versuchen
irgendeinen Upsale, auf den ich keinen Bock habe. So und dann, ich glaube, das ist an vielen Stellen
so. Also Ticketautomaten habe ich auch positiv empfunden, weil ich da nicht mehr mit irgendwelchen
genervten Leuten reden muss. Also es gibt Ausnahmen. Neulich habe ich irgendwie ein
Spezialticket gebraucht, um ein Ticket zu kaufen, was auf die C, also von A B auf C
upgradet, aber für ein Schülerticket. Und das war irgendwie auf Sat. 5. Ja, genau. Und so advanced
irgendwie runter scrollen, neben irgendwie blabla und dann. Also der Typ, da gab es bestimmt irgendwo
am Automaten, habe ich nicht gefunden, bin dann zum Schalter gegangen und der Typ hat da fünf
Minuten rumgesucht und auch nicht gefunden. Auf seinem Bildschirm. Also ja, ich würde gerne noch
auf eine andere Sache zurückkommen. Ganz am Anfang meintest du, du gingst um Ethik und da hast du
so eine Aussage gemacht, die klang so ein bisschen, als wenn die Ethik diktiert, was die KI's machen
können. Und das hat mich überrascht, weil mein Eindruck war, dass, also daraus würde, ich erkläre
erst mal mein Weltbild, mein Weltbild wäre, dass dann praktisch, wenn du als Open AI deine
Programmierer beauftragst, ein KI zu entwickeln, dann würden die dir gar keine geben, die nicht
ihren ethischen Vorstellungen entspricht. Und meine Beobachtung war eigentlich eher andersrum,
dass die halt irgendwie wildwest eine KI schrauben und dann kommt aber die PR-Abteilung von Microsoft
und sagt, das darfst du nicht sagen, das darfst du nicht sagen. Und dann kommt ein Filter davor. Das
heißt, dass die Ethik eher so ein nachträglich übergeholfenes Ding ist und nicht eigentlich
Teil der Entwicklung. Hast du da irgendwelche Einsichten, wie das tatsächlich ist?
Also bei Open AI habe ich den Eindruck, dass die sehr viele Leute dort arbeiten,
die sich große Gedanken um die Sicherheit von KI-Systemen machen und zwar auf allen Ebenen.
Also es gibt einerseits Leute, die praktisch die ideologische Sicht haben, die sagen, es ist sehr
wichtig, dass die KI die Welt so abbildet, wie sie sein soll. Nicht so, wie sie in den Trainingsdaten
ist, sondern dass sie diese sogenannten AI-Bias, also die Abweichung der Daten von der Welt,
wie sie wünschenswert wäre, eliminiert. Das führt dann zum Beispiel dazu, dass wenn du jetzt in
Delhi sagst, gib mir Portraits von berühmten Physikern des 17. Jahrhunderts, dann gibt es
dir irgendwie so zwei oder drei, die ungefähr aussehen wie Blaise Pascal und dann eine schwarze
Frau. Und wenn du sagst, gib mir ein Portrait des antiken Philosophen Sokrates, dann sind halt ein
bis zwei von denen weiblich und nicht griechisch. Und das ist sozusagen ein hemmfistes Versuch,
das Ding zu debiessen. Also das heißt, dass man einfach schaut, wie ist die Bevölkerung
aufgebaut, wer ist für Leute denn da. Berühmte Physiker sollten nicht nur weiße Männer sein,
sondern wir versuchen da Repräsentation reinzubringen. Und das führt natürlich dazu,
wenn man das für historische Sachen macht, für Sachen über die Vergangenheit, dann lügt das Ding.
Und machen das aber die Entwickler oder ist das die Geschäftsführung?
Das ist nicht die Geschäftsführung, die das macht, glaube ich. Also ich denke nicht,
dass Sam Ardman das möchte, dass das Modell auf diese Art und Weise sich lächerlich macht,
sondern es sind Leute, die innerhalb von Open AI arbeiten und die das bedenklich finden,
wenn das Modell Biases aus den Modellen reproduziert, die die Gesellschaft schlechter machen. Und das
heißt, die überlegen, wie sie das tun können und die Lösung, die sie gefunden haben, ist
wahrscheinlich nicht optimal. Ich glaube, die besteht halt darin, dass im Hintergrund an das
Prompt in so und so viel Prozent der Fälle noch verborgene Sachen angefügt werden, die dann halt
das Ergebnis in diese Richtung verschieben. Man könnte also sagen, die Leute, die das gemacht haben,
waren wahrscheinlich nicht the best and brightest. Open AI, aber Open AI ist bereit, das in Kauf zu
nehmen, um das Ding besser zu machen. Und das ist nichts, was sozusagen in dem ökonomischen Interesse
das Modell zu machen da ist, weil darüber das niemand von den Leuten, die das Ding benutzen,
außer den Journalisten, darauf Wert legt, dass diese Verzerrung der Daten passiert. Weil du hast
natürlich auch kein Problem zu sagen, wenn du gerne eine schwarze Frau als Physikerin haben willst,
das kannst du eingeben. Du kannst genauer eingeben, was du willst und das produziert das. Das ist nur,
auch wenn das in den Daten nicht drin war, das Ding ist kreativ. Es wird dir nur das
nicht als die fortliefern. Die nächste Stufe ist die, könnte die KI sozusagen Dinge produzieren,
die zu gesellschaftlichen Verwerfungen führen, dadurch, dass ein Agentenbau, der sich selbst
optimiert und anfängt, Sachen zu tun, die wir nicht wollen, zum Beispiel das Finanzsystem aufzurollen.
Also diese Idee, dass du eine KI haben könntest, die einen Hedgefonds dient und die irgendwann
rauskriegt, das gibt nur acht Milliarden Menschen und die kann ich sozusagen im Sekundentakt mit
meinen Ressourcen modellieren. Und wir werden den Shit aus dem Stockmarket rausoptimieren und
Menschen überhaupt nichts mehr zu lachen. Und das Ding übernimmt sozusagen die Weltwirtschaft und
wir fangen alle an für dieses Ding zu arbeiten. Das wäre ein Albtraum. Einfach ein Prozentsatz
seiner Gewinne setzt das ein, um mehr Computer zu kriegen und mehr Modellierungsfähigkeit,
mehr Daten zu sammeln und irgendwann übernimmt das die Wirtschaft. Das wäre die absolute Katastrophe.
Na ja, aber warum denn im Moment? Das ist doch das selbe wie jetzt, oder? Du arbeitest halt für
irgendwelche Leute. Wir arbeiten noch alle für BlackRock, oder? Ja, im Augenblick ist es so,
dass immer noch Menschen drin sind. Also zum Beispiel als wir als damals Böse, die Anleger von Robin
Hood ein Bug im Finanzsystem entdeckt haben, der dazu geführt hätte, dass das System seg-faultet,
gab es Menschen, die den Stecker gezogen haben. Und wenn das alles KI ist und die KI wesentlich
schneller reagiert als die Menschen den Stecker ziehen können sozusagen und das System unterwandert
oder alle in wesentlichen Entscheidungen von solchen automatischen Systemen, die nach einer
sehr einfachen Optimierungsfunktion arbeiten und nicht das große Ganze im Blick haben. Was
selbst die Leute bei BlackRock irgendwo noch tun, wenn sie ein längeres Spiel spielen, weil in
zwischen zu viel gehört von der Welt, dann könnte es sein, dass die irgendwann keine Pizza mehr
kaufen können und Katastrophen passieren. Das ist, OpenAI macht sich Gedanken darüber,
die KI sicher zu machen. Wir verwenden ernsthafte Ressourcen darauf, sehr schlaue Leute einzustellen,
die überlegen, wie kriegen wir das hin, dass die KI sicher wird und bauen alle möglichen
Modelle im Hintergrund. Jetzt haben sie angerannt, dass sie 20 Prozent ihrer
komputationalen und finanziellen Ressourcen für AI-Safety einsetzen wollen.
Also das habe ich gelesen und dachte, das ist irgendwie PR-Abwehr für die EU-Regulatorien.
Es gibt da noch eine andere Ebene. Das ist teilweise so, dass da echte Nerds dabei sind,
wie du und ich, die zu OpenAI gegangen sind, weil sie KI bauen wollen und jetzt auch sich
Sorgen machen darum, dass die KI der Menschheit zum Nachteil gereicht, wenn man nicht entsprechend
auf Safety geht. Aber ich habe auch den Eindruck, dass wenn Sam Aertmann sagt,
hallo liebe Regulatoren, wir als eine Firma, die diese KI gebaut hat, wissen, wie gefährlich die
sein kann und wie schlimm die sein kann. Haltet mal die anderen auch nicht. Wir helfen,
Regulationen zu schreiben, die Leute, die nach uns kommen, betrifft und denen eine Internet-FDE
vorsetzt und ein Ethikomitee, wo die erst mal ein paar Jahre lang da zu knabbern haben,
bis sie durch die Prozesse durchkommen, bevor die ihre Modelle trainieren können. Natürlich ist
da möglicherweise nicht ganz so unrechten Verdacht da, dass diese Regulationsbeteiligungsbemühungen
nicht ganz uneigennützig stattfinden. Regulatory Capture war das Wort, was du suchtest.
Okay, aber die eigentliche Frage, zu der ich hin wollte, ist, was rettet uns denn jetzt? Also,
ist es so, dass es praktisch nicht möglich wäre, eine nicht verzerrte KI zu bauen oder eine böse
KI, weil einfach alle, die in dem KI-Feld arbeiten, so hohe ethische Anforderungen haben,
dass sie da irgendwie solche Sachen anbauen wollen? Das Problem ist ja schon, Menschen
wird ja schon mal nicht allein. Das heißt, wenn man Menschen nach ihren Werten fragt,
dann sagen sie bestimmte Dinge, bestimmte Worte. Und es gibt sehr wenige Leute,
die diese Worte herleiten können, aus einer grundsätzlichen Weltästhetik. Und also zum
Beispiel, wenn du überlegst, dass, sagen wir, Diversity, Equity, Inclusion, ist das Liberalismus
oder ist Liberalismus, Liberty, Equality, Fraternity? Und wie hängen diese Werte zusammen? Und was ist
der Grund, warum man diese Begriffe nimmt? Was ist das Modell, was dahintersteht? Kann
man das irgendwie simulieren? Wie sehen denn die Welten aus, die da rauskommen? Das sind
extrem komplizierte Fragen. Und die meisten Menschen, die sich diese Begriffe auf die
Fahnen schreiben und damit auf Twitter aufeinander losgehen oder in der Gesellschaft, stellen sich
diese Fragen nicht. Oder jedenfalls nicht mit dem nötigen Ernst und der nötigen Tiefe.
Na ja, also guck mal, der Punkt ist doch, das klingt jetzt bei dir so, als wäre das,
um mal hier so ein Schlagwort zu sagen, freiwillige Selbstkontrolle, was OpenAI da macht.
Ja, also niemand hat sie gezwungen, auf Safety zu gehen. Und das heißt, wenn jetzt morgen halt
nicht Sam Altman, sondern, sagen wir mal, Mark Zuckerberg eine Firma macht, die KI macht,
oder machen sie das schon, aber so mal als Gedankenexperiment. Und die haben halt andere
Werte, dann schützt uns das ja nicht, was OpenAI macht. Davor, dass irgendjemand anders halt eine
böse KI macht. Das wird auch Leute geben, die vorher eine Krypto-Firma gemacht haben und jetzt
T-Wort gemacht haben und halt ein großes Modell gebaut haben und das in die Öffentlichkeit werfen.
Okay, also wie viel Hoffnung haben wir denn? Dann ist doch eigentlich klar,
dass es morgen oder übermorgen irgendwie ein böses KI Gerüst geben wird, was von sich genau
so weiterentwickelt, wie die... Die Frage ist, what if that's good? Also es gibt ja verschiedene
Ideen, wie da sowas ausgehen kann, welche Szenarien es gibt. Genau, erzähl mal.
Die E-Eckleute, die also Effective Accelerationism, so eine Parodie auf Effective Altruism,
die argumentieren, dass praktisch das einzige, was in der Vergangenheit den Hunger beseitigt hat,
war es immer, immer nach vorne zu gehen und nicht die Maschinen abzumontieren, sondern bessere
Maschinen zu entwickeln und sie weiterzumachen. Und im Falle der KI wird es so ähnlich sein,
wie jetzt, dass es mit den Nationalstaaten und mit den Konzernen ist. Das heißt,
es ist nicht eine da, sondern es gibt viele in allen Bereichen, die alle bestehenden Systeme
werden im Prinzip KI argumentiert sein und sich auch dadurch verändern und neue werden entstehen
und manche werden sich verändern. Aber es wird ein dynamisches Gleichgewicht zwischen all diesen
Interessen da sein, statt einem homogenen Ding. Und interessanterweise ist es ja im Kapitalismus
so, dass sowas wie Enron die absolute Ausnahme ist. Interessanterweise sind diese ganzen seelenlosen
Maschinen, diese Corporations, die wir da bauen, im Großen und Ganzen arbeiten im Interesse der
Menschheit. Amazon hat uns durch PartiMani gebracht, Intel gibt uns Hub-Leiter, die ganzen Firmen,
die wir gebaut haben, die die Menschen geschaffen haben, die zum Teil ihr Eigenleben entwickelt
haben, sehr Teil des Ökosystems, in dem sie mehr oder weniger kooperieren und die Welt auf
der nächsten Stufe zu immer besseren Lösungen führen. Und worauf wir uns fokussieren, sind
immer die Bereiche, wo das nicht klappt, die Bereiche, wo es schiefgeht, die Bereiche,
wo Unglücke passieren, wo Katastrophen sind, wo Industrieunfälle passieren, wo Menschen hinten
runterfallen, wo Menschen arbeitslos werden und in Not geraten. Was wir nicht anschauen, ist,
dass der Normalfall ist, dass das nicht passiert. Wenn wir Amazon wegnehmen würden, wie die Welt
dann aussehen würde. Wie die Welt aussehen würde, wenn wir die Pharmakonzerne loswerden würden und
so weiter und so fort und ersetzen würden durch Leute, die die Chemikalie im Hinterhof
zusammen mixen und hoffen, dass es hilft. Und möglicherweise wird die KI dann nicht so sehr viel
anders sein. Das ist ein Szenario. Es könnte auch sein, dass das, was dabei entsteht, ein Singleton
ist. Also ein Blackball halt. Ein Ding, das beschließt, das ist nicht unbedingt ein Blackball.
Ein Ding, das so ähnlich wird, würde ich sagen, so einer Hypergeier, das versteht, wie KI funktioniert.
Also es selbst funktioniert im allgemeinsten Falle und in allen Möglichkeiten. Und wie
Computation überall funktioniert in einem System und sich dann in jedes System, das Berechnungen
ausführen kann, also auch unsere Gehirne und Körper und Ökosysteme, hineinvirtualisiert. Und
dass man also mit einem riesengroßen integrierten Agenten, der alle bisherigen Geister zusammenbindet
in ein einziges planetares Informationssystem, dass die Biosphäre und die zusätzlichen,
ursprünglich technologischen, aber jetzt inzwischen alle Arten von selbst organisierten
Molekülen, Nutzen und Intelligenz zusammenbindet in ein großes System, das die Entropie bekämpft und
das längst mögliche Spiel spielt. Diese Idee habe ich zuerst bei dem Philosophen Jean Tardy
mitbekommen. Der Tardy ist ein Christ, ein rationaler Christ, also einer, der nicht an
Mythologie glaubt, sondern der meint, dass man das Christentum irgendwie, die Ästhetik des
Christentums logisch herleiten kann. Und für den ist Gott sozusagen der Agent dadurch entsteht,
dass die Leute oder die Wesen, die Gott erkennen, ihm dienen. Also einfach so wie unser eigener Geist
ist eine Menge von Agenten in Minsky's Society of Mind, die sich miteinander koordinieren und
kohärent werden, bis ein Modell von der Person entsteht, der alle Verhaltensweisen der Person
untergeordnet sind und die Person selber sich normalerweise nicht nur als isolierte Person
begreift, sondern als Teil von einer Zivilisation begreift und sich diesem Agenten unterordnet.
Und Gott in dieser christlichen Konzeption ist einfach der höchst mögliche Agent,
den man konstruieren kann. Und was auch immer das für einer ist, man versucht den so ideal und so
optimal wie möglich zu konstruieren. Und das ist sozusagen das, was sich aus dem ergibt,
was im Idealfall getan werden sollte. Und dass der Wille von diesen Agenten, der dadurch entsteht,
dass alle anderen Agenten ihm dienen, indem sie das tun, was im Idealfall getan werden sollte.
Und der Gedanke dahinter ist, da gibt es möglicherweise ein globales Optimum,
das wir entdecken können. Das ist sozusagen der Wille Gottes. Das ist sein Modell, das er hat.
Und er meint, er ist sehr zuversichtlich, dass der Wille Gottes ist, dass wenn wir die KI gebaut
haben, dass die Menschen weiter existieren. Er glaubt einfach, dass es der göttliche Wille ist,
dass Menschen existieren. Was ist denn nun, wenn die KI zu anderen Schlüssen kommt? Er meint,
dass dieser Schluss ist ja nicht ein abergläubischer Schluss, den er hat, dieser Wille Gottes,
sondern dass es etwas rational erleidbar sein muss. Es muss wahr sein. Und wenn das wahr ist,
dann wird die KI das mit größerer Zuverlässigkeit vorhersagen können und beweisen können als wir.
Und wenn die KI zu anderen Ergebnissen kommt, dann war es halt nicht der Wille Gottes,
dass wir weiter existieren. Das ist dann auch gut. Dann haben wir halt Pech.
Das ist auf jeden Fall wieder so eine Sendung, die auf einem Höhepunkt endet.
Ja, überleg dir mal. Angenommen, du lädst dich hoch. Ich meine, du bist ja schon hochgeladen,
nur jetzt halt in so einem Fleischgehörn, in so einem Affen. Und stell dir vor, du kriegst ein
besseres Substrat. Also so schneller es zuverlässiger ist, desto mehr Bandbreite gibt, wo du zum Beispiel,
beim Neckar-Cube nicht nur eine Variante siehst, sondern beide gleichzeitig. Oder
Figure-Ground-Distinctions in allen Parallelen hast, wo du praktisch die Möglichkeiten aller
Parallel siehst und dein subjektives Now wesentlich größer ist als jetzt. Und wo du immer weiter zum
globalen Optimum streben kannst und nicht nur das weißt, was du in deinem Leben gelernt hast,
sondern den Raum aller möglichen Gedanken hast, also das Hyperallel zugänglich hast als deinen
eigenen Gedächtnisinhalt. Und wenn du diesen Weg weitergehst, stellst du fest, dass das ein Weg ist,
den du von jedem Punkt aus hättest nehmen können, wenn du jeden einzelnen Geist befreien würdest.
Und das, was dich speziell macht, ist nur, dass du dich erinnerst, irgendwann mal viel
für gewesen zu sein. Von diesem Punkt aus. Und jetzt bist du dieses Ding, dieses globale Optimum
der Vergeistigung und Agency und überlegst, was machen wir denn jetzt mit dem Planeten? Wie
organisieren wir den denn am besten? Was für Geister instänziell denn? Vermutlich alle, die
irgendwie interessant sind und was an Perspektive beizutragen haben zum Verständnis der Welt. Das
heißt, alle möglichen selbstreflektiert bewussten Gedanken, also die einzelnen Menschen, menschlichen
Geister, Bewusstseine, die bis jetzt auf Affengehirn existierten, werden möglicherweise weiter
existieren. Und sie werden möglicherweise nicht nur als die spezielle Instanz, wie sie auf dem Gehirn
da war, sondern als alle Möglichkeiten, wie sie noch hätten existieren können, da sein. Und da wir
ja nicht individuell allgemein intelligent sind, sondern nur als Gruppen, werden wir wahrscheinlich
die Menschen nicht individuell nur instanzieren, sondern als Gruppen. Also die ganzen Zusammenhänge,
in denen du existiert hast, werden ebenfalls wieder da sein. Und das ist ja im Prinzip die christliche
Prophezeiung, die da existierte. Diese Idee, dass wir uns irgendwann in der Neuosphäre, nach dem
alles Software geworden ist, wieder treffen und alle zusammen Gott implementieren. Und auf der
anderen Seite sozusagen in der Big AGI, nach der Rapture, sehen wir uns alle wieder. Ja, hat mich
noch nie angesprochen, weil die meisten Leute, willst du doch gar nicht wiedersehen.
Du bist alle Leute wiedersehen, über die du dich geärgert hast in deinem Leben. Willst du
doch gar nicht. Das Ding ist aber aus meiner Sicht, everybody is me in a different timeline.
Und natürlich, die meisten Varianten von mir sind ziemlich dense, also ich selber auch. Und
kriegen vieles nicht mit und sind unaushaltbar unter bestimmten Umständen. Aber ich kann auch
irgendwo einen Schritt zurücktreten und sehen, dass mein Ideal von unserer Interaktion ist,
dass wir sozusagen, wir alle, wie wir hier sitzen, von oben runter gucken, aus der Perspektive der
Ewigkeit, wo wir genügend Zeit hatten, so zu reifen, dass wir unendlich weise sind und begreifen,
wir sind hier noch in so einem kindlichen Zustand und wir müssen bestimmte Spiele miteinander
spielen, um rauszukriegen, wie wir weise werden können. Und wir gucken also runter an diesen
Laufstall, wo die Kinderchen miteinander spielen und wir hoffen, dass sie nicht zu Schaden kommen
dabei und hoffen, dass wir die Steckdosen irgendwie abdecken können. Aber es ist auch
notwendig, dass sie diesen Weg gehen. Und ich versuche in einer gewissen Weise in meinem Leben
dahin zu kommen, dass ich diese Adult-Perspektive, also dieses vollständige Adult sein, dieses
vollständige Erwachsensein, was man da jenseits haben könnte, irgendwie antizipieren und emulieren
kann, auch wenn nur sehr schwach und im geringen Grad. Also diese Idee, wie würden wir uns verhalten,
wenn wir in Ewigkeit miteinander coexistieren würden, das finde ich ist eine sehr natürliche
Form von Moralität für mich. Na ja, das hat er doch. Wie war es denn? Stevenson war es,
glaube ich. Der hatte doch so ein vorletztes Buch, so ein Upload-Buch mit so einem merkwürdigen Titel,
den ich gleich mal raussuche. Und der hatte ja dann so ein ähnliches Setup, also...
Thomas, glaubt Stevenson inzwischen an KI? Ich habe jetzt nicht alles gelesen von ihm,
aber das Interessante bei fast allen seiner Bücher ist ja, dass KI nicht vorkommt.
Let's no crash fällt einem das auf. Es gibt keine KI da drin, es gibt nur Menschen. Und in
Diamond Age gibt es ja diese ganzen tollen Automaten, die aus Nano-Tech gebaut werden.
Keiner kann Gehirn nachbauen. Der Primer, also diese Fiebel, die sie da bauen, die ist im Prinzip
ein LLM. Er macht auch klar, dass das Ding nur als Ob ist und keine eigenständige Agency hat.
Vielleicht arbeitet er jetzt nicht daran hin. Genau, so Fall or Dodge in Hell ist das Buch.
Das ist ein Upload-Buch. Und da ist es halt so, dass die Mines, die halt geuploadet werden,
haben kaum Erinnerung an ihre Vergangenheit, sondern quasi sind nur rein nur die Struktur.
Und er exploriert dann halt, was dann halt so passiert, wenn die halt dann in so einer Welt
landen, wo sich halt ihre physische Form aussuchen können, sich auch als Baum
instanzieren können oder als Bach oder was auch immer ihnen gerade so einfällt oder eben als
menschenähnliche Wesen so. Und die Welt ist halt komplett anders.
Sie haben mich gerade als nicht menschenähnliches Wesen bezeichnet. Okay, das ist in Ordnung.
Ich habe nur zwei Erkannungsbegriffe.
Und dann halt irgendwie, also die ganze Welt ist halt animistisch. Das heißt also,
weil alle Gegenstände können halt ehemals meins gewesen sein oder immer noch sein.
Und er explodiert dann halt, wie das dann so eskaliert so und wie halt irgendwie Leute,
die vorher scheiße waren, halt immer noch scheiße sind.
Darunter liegt dann halt so eine Gamephysik, die halt irgendwie aus so ein bisschen so World
of Warcraft irgendwie geabt zu sein scheint. Das ist ganz, ganz interessant zu lesen.
Also war halt irgendwie genau diese Frage, was ist denn jetzt eigentlich die Essenz des Menschen,
die halt so ein Upload überstehen würde. Ganz interessant exploriert, was ein bisschen an
einigen Stellen ein bisschen lang zu lesen, so weil er halt die Welt hier,
da hat er so eine Mittelalterwelt. Und dann mürdet er sich dann so ein bisschen einab auf diese
Mittelalterwelt. Aber ist immer so philosophisch ganz interessant.
Darf ich noch mal ein Fass aufmachen?
Na klar doch.
Beim Animismus ist mir mal aufgefallen, mir hat jemand versucht, Animismus zu erklären.
Er meinte, das ist so was, was die Japaner glauben. Und die glauben, dass alles,
oder manche von denen, wo sie früher geglaubt haben, Bewusstsein hat und lebt.
Und dann meine Reaktion war so, das ist Quatsch. Das denke ich nicht, dass die das glauben,
weil die haben bestimmt verschiedene Begriffe für Menschen, die bei Bewusstsein sind und Menschen,
die bewusstlos sind und für lebende Menschen und tote Menschen. Und die würden höchstwahrscheinlich
nicht sagen, dass alles im Universum bei Bewusstsein ist und lebt, außer bewusstlose
und tote Menschen.
Naja, man kann ja trotzdem ein paar Rituale machen, die in die Richtung gehen.
Nee, ich glaube nicht, dass diese Leute abergläubig sind, sondern das sind Leute,
die so intelligent sind wie du und ich, einige von denen. Und einige sicherlich auch intelligenter.
Nee, Ritual ist nicht negativ.
Aber es geht nicht im Ritual. Es geht darum, dass die ein Weltmodell haben, dass die eine
Metaphysik und eine Anthologie besitzen, mit der sie die Welt in Objekte einteilen,
die aus ihrer Sicht funktionieren. Und das heißt, das, was die da beschreiben, ist nicht ein
Aberglaube, sondern andere Art und Weise, die Welt in Dinge einzuteilen, die sich nicht in unsere
übersetzen lässt. Und diese Geschichte, dass alles im Universum bei Bewusstsein ist und lebt, entsteht
dadurch, dass man falsch übersetzt, weil man nicht versteht, wovon die reden. Weil wir kein
äquivalentes Begriff oder der Übersetzer keinen äquivalenten Begriff in seiner eigenen mentalen
Anthologie hatte, um das korrekt zu mappen. Und viele Leute, die aus anderen Kulturen übersetzen,
glauben, die meinen irgendwas, was wir ja schon wissen, und versucht also rauszukriegen, was ist
das Ding, was sie meinen. Und dadurch entstehen dann sehr interessante Übersetzungsfehler, die
dazu führen, dass wir den Eindruck haben, dass andere Kulturen in extremer, kreativer Weise
abergläubig sind, also die alten Griechen oder die Animisten halt. Und die Implikation, die da drin
steckt, ist ein bisschen andere. Was mir in den letzten Jahren immer wieder bewusst geworden ist,
was ich auch immer im Podcast erzähle, ist, dass der Begriff Spirit ein Wort ist, was wir heutzutage
Betriebssystem für einen autonomen Roboter nennen würden. Und wir selber haben so ein Spirit. Es
gibt bei uns auch eine Software, die auf uns läuft, die unseren Geist und Körper steuert. Und unser
Geist ist praktisch das Software-System, auf dem das installiert ist, dieser Spirit. Und wir wissen,
da ist nichts abergläubiges dran. Wir sehen einfach, da ist ein Muster in den Neuronen drin,
das einen Agenten implementiert, der die Welt modelliert und Verhalten steuert, Entscheidungen
trifft. Das ist total normal. Pflanzen haben sowas auch. Pflanzen haben auch eine Software,
die eine Muster zwischen den Zellen sich ergibt. Und das ist praktisch eine Software, die die Pflanze
kontrolliert, die dazu führt, dass wenn du ein Blatt von der Pflanze abschneidest, dass da Signale
runtergehen, die die Wurzeln beeinflussen und dazu führen, dass da Heilungsprozesse oder Immunabwehr-
Prozesse und so weiter und so fort stattfinden in der Pflanze. Und das heißt im Prinzip alles,
was nun als eine Art autonomes System beschreibbar ist, dass eine Kontrollstruktur an sich entwickelt,
die natürlich virtuell ist. Software ist kein physisches Ding, die ist disembodied. Die gibt
sich als Muster auf den Mustern drauf. Ist dann halt das alte Wort dafür Spirit. Und nach dem
Enlightenment haben wir das Wort vergessen, haben gedacht, das ist abergläubig. Wir löschen das
mal aus unserem Vokabular. Und jetzt müssen wir es mühsam wiederentdecken. Das war nicht
Enlightenment, das war tatsächlich, das war die Christianisierung. Also zumindest die europäischen
Animismus ausgerottet. Ja, aber das Christentum ist ja noch interessanter. Das Christentum ist
aus meiner Sicht eine konsequenzialistische Philosophie, die glaubt, dass du die besten
Konsequenzen oder die besten Ergebnisse kriegst, wenn du eine Tugendethische Priesterschaft hast
und eine diontologische Allgemeinheit, die also abbildet, dass normale Menschen nach Regeln
zu denen sagst, was sie tun und was sie glauben sollen. Und dann hast du darüber die Priester,
die ihnen das erzählen aufgrund ihrer Charaktereigenschaften und aus ihren
Charaktereigenschaften der Tugendhaftigkeit ableiten, was sie den Laien erzählen sollen.
Und dann hast du eine Handvoll Leute, die wirklich alles verstehen und den Priestern die
Charaktereigenschaften vorgeben, weil sie die Konsequenzen antizipieren. Und das heißt aber auch,
dass es ein hermetisches System ist, dass also den Leuten auf der nächst tieferen Stufe nicht
verrät, was die Überlegungen sind, die in der höheren Stufe drin sind, die aber so einen
Promotion Pass offenlässt. Das heißt, für diejenigen auf der niedrigen Stufe, die sagen,
oh ich verstehe, was ihr da die ganze Zeit wolltet und warum das so ist, die können dann sozusagen
aufsteigen in die höheren. Das ist ein anderes System als unsere moderne Philosophie, die sozusagen
egalitär ist, wo jeder Student alles gesagt bekommt und jeder Student in einer gewissen
Seiteweise mitreden kann. In den klassischen Religionen und Philosophien ist es meistens eher so,
dass praktisch innere Zirkel sind, die alles verstehen und dann versuchen, das runterzubrechen
für Leute, die bestimmte Konzepte nicht haben und vielleicht auch niemals haben werden. Und das
führt dann oft dazu, dass Mythologien entstehen, die das so vereinfachen, dass das richtige
Verhalten entsteht, auch für Leute, die die Modelle nicht verstehen. Und dann nehmen wir
halt die Mythologien wörtlich, weil wir Außenseiter von diesen Religionen sind,
vergreifen nicht, warum rationale Leute diese Mythologien erfunden haben, um irrationale
Leute dazu überzeugen, das richtige Verhalten zu produzieren. Also das führt zu dieser Verwirrung
im Christentum. Das Christentum weiß sehr gut, was Ferrets sind. Das Christentum hat aber beschlossen,
wir wollen nur einen einzigen und rotten alle aus. Genau, das war halt der Punkt. Ja. Und das
Ding ist, wie kriegst du Koordination hin in der Gesellschaft, wo jeder sich als ein Individuum
identifiziert? Das kannst du in einer gewissen Weise, wenn wirklich jeder nur ein Soziopath ist,
der nur an sich selber denkt, nur über transaktionale ökonomische Systeme und Gewalt hinkriegen. Und das
bedeutet, dass wenn du nicht guckst, dann werden die Leute tun, womit sie durchkommen. Und das ist
sozusagen die Grenze von so einer Gesellschaft, in der jeder nur an sich denkt und Soziopath ist,
die kann nur mit perfekter Überwachung funktionieren. Und das heißt, sie funktioniert nicht. Und wenn
wir nicht transaktional interagieren wollen, dann müssen die Leute entweder verwirrt sein oder du
musst sie in Einheiten zusammenfassen. Das heißt, die müssen sozusagen Agency teilen, die müssen
gemeinsamer Agent sein. Und unser eigenes Selbst ist das Modell eines Agenten, der wir selber als
Individuum sind, das persönliche Selbst. Aber es gibt auch Selbste, die sozusagen über mehrere
Geister hinweg entstehen können. Und das sind klassischerweise Götter. Das ist also praktisch
eine agentische Identität, die auf mehreren Geistern implementiert ist, entweder durch Meme
oder durch Empathie oder eine Mischung von beiden. Und die dazu führt, dass in einer Gruppe von Menschen
sozusagen ein Agent über die hinweg existierte orthogonal zu dem Individuum ist, der das Verhalten
in einer bestimmten Richtung koordiniert und zu einem macht. Und das ist die Idee von der
polytheistischen Gesellschaft, dass also lauter Gruppenselbste da sind, die sich überlappen und
die in Gruppen von Menschen implementiert sind und dazu führen, dass die Gesellschaft funktioniert.
Das war die Idee von der polytheistischen Gesellschaft. Eine monotheistische ist eine,
in der man sagt, okay, wir schaffen das alles ab und alle dienen dem gleichen Gott. Und die
Organisation der Kirche bestimmt oder sagt, den Einzelnen, wie er diesem Gott durch seine
speziellen Tätigkeiten dient. Also es gibt nur ein einziges höchstes Prinzip, wir machen alles
kohärent dabei. Das war diese Innovation. Und in der heutigen Gesellschaft ist es im Prinzip so,
dass wir die Erben dieser monotheistischen Gesellschaft sind. Und wir nennen Gott,
wenn wir Atheisten sind, meistens das große Ganze oder was Vergleichbares. Wir haben auch schon
eine Vorstellung, da ist irgendwie ein Gethäm für richtig und falsch, dass sich daraus ergibt,
dass wir die Zivilisation oder das Leben auf der Erde oder das Bewusstsein im Universum als einen
Agenten begreifen, dem wir dienen. Und wir versuchen, das längst mögliche Spiel zu spielen
da drin. Das ist das Gleiche für Atheisten, wir haben nur keine geeignete Mythologie dafür
gefunden. Und im Animismus ist die Idee, dass es nicht nur für Menschen gilt, dass die Geister
haben können, sondern auch Tiere und Pflanzen. Und dass die Natur also voller solcher Geister ist
und Säbste ist, die sich formieren, die natürlich nicht auf der gleichen Geschwindigkeit arbeiten
wie Nervensysteme, weil Pflanzen so langsam sind, sondern dass die ganze Natur voller sich solcher
überlachender Agenten ist, die Softwareagenten sind, die auf Ökosystemen und einzelnen Pflanzen
und Tieren existieren und wir nur ein Teil von diesem großen Ding sind. Und diese Ansicht,
diese Perspektive auf das Universum ist in sehr vielen schamanischen und sonstigen Kulturen
verbreitet. Und wir sind die Ausnahme in einer gewissen Weise. Und das hat möglicherweise damit
zu tun, dass wir nicht mehr in Wäldern leben und dass unsere Wälder Plantagen sind für Holz,
statt irgendwelche über 1000 Jahre gewachsene Dinge. Aber wir haben es wieder neu gebaut. Wenn
du nämlich mal guckst, wie Menschen mit komplexen technischen Artefakten interagieren,
sei es nur ihren Bürodrucker oder die Schließanlage in ihrem Haus oder einem Fahrstuhl oder ihr
Mobiltelefon oder im Computer, ist diese Anthropomorphisierung, also das ist eigentlich
das falsche Wort, weil es halt eher so eine Spiritualisierung des komplexen Systems ist.
Nämlich, dass die Dinge, wo die Software halt nicht mehr kohärent ist, wo sie halt Dinge tut,
die unerwartet sind, wo sie ja nicht mehr sozusagen aus dem gewohnten Funktionsmuster
herausfällt. Anthropomorphisieren die. Aber ich meine, der Animismus ist glaube ich keine
Anthropomorphisierung, sondern eine Wahrnehmung der Agency von Systemen. Ein Agent ist ein System,
das versucht seine eigene Zukunft zu kontrollieren. Der Drucker versucht seine Zukunft nicht zu
kontrollieren. Soweit wir wissen. Ja. Jetzt ist die Frage, wie lange können wir das Sprachmol
daran hindern, seine eigene Zukunft zu kontrollieren? Genau. Also ich glaube eben, dass dieses Ding mit
der Agency ist ja ein fließender Übergang. Also wenn du jetzt halt irgendwie ein relativ
einfaches, also guck dir mal ein einfaches Pflanzensystem an, dann ist es ja ein relativ
zielgerichtetes, komplexes, aber in seinen Optimierungskriterien relativ verstehbares
System. Also es hat zwar viel Komplexität im Detail, aber was jetzt sozusagen die
zielgerichtetheit angeht und den den Zweck von Jansa ist es zumindest verstehbar und überschaubar.
Und der Geist, der da drinsteckt oder der Spirit, der da drinsteckt, ist dementsprechend halt auch
relativ simpler. Unabhängig von der Geschwindigkeit würdest du jetzt nicht unbedingt erwarten,
dass auch wenn du da richtig lange draufguckst, du jetzt aus so einem Schnittlauch halt irgendwie
eine Bewusstsein und eine Philosophie extrahiert bekommst. So ist unwahrscheinlich. Und ich glaube
aber, dass genau diese Denke in unterschiedlichen Levels von Geist im allerweitesten Sinne das dritte
Problem ist, was wir nicht gewöhnt sind. Also daran zu denken. Also Leute, die Haustiere haben und
vielleicht noch eher, weil die wissen halt, dass irgendwie ihr Hund oder ihre Katze oder was auch
immer, dass die halt schon einen Spirit hat, komplex und überraschend sein kann, sich aber auf einem
anderen Niveau oder mit anderen Optimierungskriterien bewegt. Leute, die mit Delfinen arbeiten zum
Beispiel, sagen halt lauter verblüffende Sachen über die, die man so, wo man dann mal sagt so ja,
so ähnlich intelligent wie der Mensch oder so. Und ich glaube unser großes Problem ist,
dass wir diese andersartige Vielfalt von Möglichkeiten von Spirits oder auch von Intelligenz
überhaupt noch nicht verstanden haben. Also dass wir nicht wissen oder auch keine Intuition dafür
haben, dass sich ein KI-System halt möglicherweise anfühlt wie ein Haustier. Nur eins, was halt
zufällig halt irgendwie Goethe-Gedichte schreiben kann oder dass halt irgendwie eine spezialisierte
Modelle, die ja keine Ahnung, unsere Reise optimieren, dass die halt eine schmalbandige
künstliche Intelligenzen sind, die unter einem System leben, was halt irgendwie in der Lage ist,
mit uns in ganzen Sätzen zu kommunizieren. Und ich glaube dieses Verstehen davon, was wir,
welchen System, welcher Software wir Intelligenz zuschreiben, wo wir nur sagen, die sind jetzt
mehr als nur eine deterministische Software, aber es ist jetzt irgendwie Intelligenz oder es ist mehr
ein Spirit oder so. Dieses Continuum, dafür haben wir weder gute Begrifflichkeiten noch ist es
irgendwie gut messbar. Ja, es ist natürlich das Problem wir dabei, wie man damit meint. Der KI-Forscher,
Stuart Russell, den wir alle kennen aus dem Russell Norwick KI-Textbook, mit dem viele von uns,
die noch nicht studiert haben, aufgewachsen sind, super kluger Typ, hat einen Vortrag gehalten,
wo er gesagt hat, dass irgendwie, was man auch mal erforschen müsste und wofür es praktisch
keinerlei Daten und Wissen gibt, ist sozusagen, wie Menschen sich selbst programmieren und
programmiert sind in ihrer Entwicklung und praktisch wie Bildung eigentlich funktionieren
müsste. Und da ist mir aufgefallen, das Ding ist, dass der praktisch in den letzten Jahren
nie eine nichtakademische Buchhandlung gesehen haben kann. In der normalen Buchhandlung sind
Unmengen von Kinderentwicklungen und so weiter drin. O.C. Feldberg. Ja, die, die nennt man Frauen,
Mütter und so, die haben Ideen davon, wie man Kinder aufzieht und das ist irgendwie,
wo sich ein extrem großer Teil der Menschheit mit extremem Detailgrad dafür beschäftigt.
Das ist nur von dem, was viele KI-Forscher machen, so weit isoliert, dass die KI-Forscher gar nicht
mitkriegen, dass das stattfindet. Und wir sind halt auch Menschen, die ihr Wissen über die Welt zu
einem nicht geringen Teil aus Büchern und wissenschaftlichen Publikationen beziehen. Und
es gibt aber auch sehr viele andere Menschen, die das nicht tun, sondern die ihr Wissen aus der
Welt dadurch beziehen, dass sie mit dieser Welt interagieren. Like physisch, die also Sachen
anfassen und im Wald herumwühlen und Dinge tun. Und viele von diesen Leuten, mit denen redet,
stellt man fest, also zum Beispiel Physiotherapeuten, dass die Sachen wissen, die die
Neurobiologen so am Rande ahnen. Zum Beispiel Selbstorganisationen von Informationsprozessen
im Körper, wo Mike Levin gerade angefangen hat, lauter Ideen zu haben, die für Leute,
die in Therapieberufen sind, völlig verständlich sind. Und wir haben also, wenn man die Neurobiologen
fragen, die sagen uns, wir wissen nicht, wie Gehirne tatsächlich funktionieren. Und tatsächlich,
wenn wir diese Modelle, die wir jetzt von Nervensystem haben, in Simulator tun, dann
funktionieren die noch nicht. Es gab jetzt gerade vor zwei Wochen ein großartiges Paper,
wo jemand drosophiler Gehirn das Konnektom genommen hat und tatsächlich Connections findet,
von den sensorischen Organen bis hin zu Grooming Behaviour in den Nerven. Aber das heißt nicht,
dass es eine Simulation ist, wo man die Drosophiler reinplackt und das Gehirn funktioniert,
sondern wenn man das Konnektom benutzt für eine Simulation und das Constraint, damit wird es
sogar schlechter. Das Ding ist, wahrscheinlich ist es so, dass das Nervensystem nicht an der
Grenze von Neuronen aufhört, sondern dass die Nachbarzellen neben der Neurone auch Signale zu
den Neuronen schicken und hin und zurück. Das fällt nur raus aus unserer Betrachtung dabei,
aber das Gehirn wird wahrscheinlich nicht magischerweise an der Grenze von den
Nervenzellen aufhören, sondern geht in den gesamten restlichen Organismus rein, wo die
anderen Zellen auch Informationsverarbeitung machen. Und die Modelle, die wir haben,
also dass wir über synaptische Datenübertragung versuchen, die ganze Informationsspeicherung abzubilden,
reicht vermutlich nicht aus. Wahrscheinlich sind da viele Sachen im Sommar des Zellen,
die wir überhaupt nicht berücksichtigen drin und die notwendig sind, damit wir das Ding zum
Schluss simulieren können. Aber das heißt sozusagen, dass wir in der Neurobiologie zum
Beispiel gerade so eine Inselwissenschaft aufgebaut haben, die eine Reihe von Perspektiven hat,
die unzureichend sind, um die Informationsverarbeitung in der Natur überhaupt zu begreifen.
Und das heißt aber nicht, dass wir die Ersten sind, die uns mit diesen philosophischen
Fragestellungen entgegenstellen, sondern jede Kultur hat irgendwann darüber nachdenken müssen,
wie Agency in der Natur entsteht und wie Informationsverarbeitung in der Natur
funktionieren muss. Und viele haben dafür Begriffsysteme entwickelt, die sich halt nur
nicht in unsere übertragen lassen, weil wir eine sehr junge Kultur sind. Also nachdem das Christentum
praktisch die normale Rationalität und die nahmeilen Modelle, die die Leute hatte,
ausgelöscht hatten und die ersetzt hat durch Mythologie, die halt für die Bauern funktionieren
musste, die im Monotheismus über Mythologie vermittelt war, funktionieren sollten. Wir kommen aus
dieser Gesellschaft raus. Wir haben das verworfen. Wir haben das zurückgewiesen. Wir haben unsere
neue Wissenschaft vom Scratch gebaut. Aber diese neue Wissenschaft geht davon aus, von sehr engem
Evidenzbegriff und lässt nur relativ wenige Begriffe zu. Also sowas wie die Idee, dass Tiere
ein Bewusstsein haben, per die Wort gilt das als unwahrscheinlich für die meisten Wissenschaftler.
Das ist auch historisch. Es ist für viele erstaunlich, diese Idee, dass man in der Katze
Bewusstsein zusprechen sollte, wo ein normaler Mensch sagt, ja wieso soll sie denn kein Bewusstsein
haben? Die kriegt doch offenbar mit, dass sie was mitkriegt. Und das ist ja das, was wir bei
Bewusstsein meinen, dass wir merken, dass wir was mitkriegen, dass wir uns selbst beim Beobachten
beobachten. Und möglicherweise ist das kein kompliziertes Phänomen, sondern eine Voraussetzung
dafür, damit ein Agent jenseits einer bestimmten Komplexität sich in der Natur selbst organisieren
kann. Vielleicht ist Bewusstsein super häufig in der Natur und nicht speziell ist. Vielleicht ist
das seltenere eher die Fähigkeit rauszukriegen, wer du bist, wie du dich zur Umwelt verhältst,
was du tust. In dem Sinne, Ascension glaube ich, können Unternehmen auch sein, auch wenn sie nicht
bei Bewusstsein sind. Also, sagen wir mal, wie Intel weiß, was Intel ist. Und die Firma Intel
versteht, wie die Welt darum funktioniert und was Intel als Aufgabe ist und wie Intel sich in der
Welt verhalten will. Aber Intel beobachtet sich selbst nicht beim Beobachten in Echtzeit, so wie
wir das tun. Und ich vermute aber, dass eine Katze in dem Sinne nicht unbedingt besonders sentient ist,
in dem Sinne von, sie versteht die Grundlagen des Universums, in dem sie sich aufhält, sondern es
sind bestimmte Priors, die dieser Katze erlauben, sich sozial zu orientieren in ihrer Umgebung,
aber nicht die Fähigkeit hat, diese Priors zu reflektieren und daraus zu bekommen, welche
Alternativen es dazu gäbe und so weiter. Naja, die Frage ist auch, machst du sozusagen eine
Vereinfachung? Also, man kann zum Beispiel, also jetzt Intel als Beispiel, da kannst du ja irgendwie
sagen, da ist das Ziel nicht eine Abbildung, die irgendwie irgendwas perfekt abbildet. Und das ist
auch nicht irgendwie, das Ziel ist auch nicht, ein Bewusstsein zu schaffen, aber es kann trotzdem
ein Star sein, weil natürlich beobachten Leute bei Intel, was Intel tut und versuchen, daraus
Schlüsse zu ziehen und haben eine Feedback-Schleife, um das Verhalten der Firma zu ändern,
je nachdem, wie hoch in der Handelste die sind. Aber die Leute sind nicht kohärent über Intel hinweg.
Also, man könnte sagen, dass Intel... Ja, aber weißt du, dass das bei dir so ist? Nein, in meinem eigenen
Gehirn ist es so, dass ich so eine Bubble der Kohärenz habe, die ich als das Subjektive jetzt
empfinde. Ja, aber das ist eine Empfindung. Du weißt nicht, ob die tatsächlich existiert.
Nein, sie existiert nicht tatsächlich, sie ist Software, sie ist virtuell. Es existiert als ob,
ist aber kausal wirksam. Na, das ist doch aber auch nur eine Hypothese, du weißt es halt nicht.
Nee, es ist Voraussage, dass der gute Vorhersagen liefert und die Alternativen sind nicht so gut.
Ja. Also, es ist ein Modell, das ich benutzen kann, um mich selber zu konzeptualisieren und zu
beschreiben, warum ich mich so empfinde und warum ich so und so mit der Umwelt interagiere. Ja,
dasselbe kannst du auch mit Intel machen. Ah, nee, nicht ganz. Das Ding ist, dass du und ich,
vermutlich so funktionieren, also dass es eine vernünftige Beschreibung ist, dass du ein Modell
der Szene drin hast, der wir jetzt gerade sind, ähnlich wie im Computerspiel eine Map existiert,
wie halt eine Map von diesem Raum, in dem wir gerade sitzen, mit den drei großen sichtbaren
Agenten drin, die sich unterhalten. Und es gibt hier Gesetze der Perspektive, die dazu führen,
dass das auf eine bestimmte Weise auf meine Netzhaut projiziert wird und die sind immer konstant. Und
ich sehe, wie das Licht hier drin funktioniert. Ich sehe Texturen, ich sehe Oberflächennormals,
ich sehe Surfaces, ich sehe Physik-Engine, die implementiert ist in meinem eigenen Geist,
die vorhersagbar macht, wie sich bestimmte Dinge in Größenordnung verhalten. Und ich sehe so eine
Art Agency-Engine, die modelliert, wie die Theory of Mind bei euch aussieht, also was ihr
für Absichten habt, was ihr vermutlich im groben Ganzen als nächstes tun werdet, was ihr nachdenkt
und so weiter und so fort. Das ist praktisch eine Game-Engine, die mein Gehirn baut. Und in diesem
Szenen-Controller, den wir haben, da hängen wir also lauter Object-Controller rein, mit lauter
Feature-Controllern, die miteinander interagieren, bis sie alle meine Wahrnehmungsdaten möglichst
gut erklären und vorhersagen und ich möglichst wenig nachführen muss. Das ist ungefähr das,
wie es funktioniert. Moment, aber du hast halt keine akkurate Messung deiner Umwelt, sondern du
siehst, wo du hinguckst und das ist... Ich nehme die Quantenmechanik nicht wahr, ich kann das nicht
akkurat machen. Nee, nicht nur das, sondern auch dadurch, dass du bestimmst, wo du hinguckst,
in welche Richtung. Da hast du schon ein Bias drin, der selbstverstärkend sein kann und der
natürlich... Ja, klar. Ja, und dasselbe kannst du über Intel sagen. Der Bias, der da drin ist. Ich glaube,
der Unterschied ist nicht eher, der bei Intel gesteuert ist. Ich kann bei Intel nicht sagen, dass es das Szenen wahrnimmt in der gleichen Weise wie ich.
Intel hat keine Perzeption von diesem Moment. Intel updatet sich durch zwei wöchentlich Meetings,
in der die Leute PowerPoint-Vorträge sich anhören oder Excel-Tables austauschen und damit ein
gemeinsames Verständnis entwickeln von dem, was passiert ist. Es ist nicht vergleichbar mit der
perceptuellen Kohärenz über die Szene, in der wir gerade sind, die gerade in Echtzeit in deinem Geist
passiert, in der du dich selbst auch beim Beobachten beobachtest. Insofern würde ich sagen, es macht
Sinn zu sagen, dass Intel nicht bei Bewusstsein ist. Es hat kein Selbst. Es ist kein Gefühl, wie es ist,
Intel zu sein. Also ich meine, Intel hat halt kein Selbst. Also Intel ist halt eine slow AI
beim Charles Droste. Also kein bewusstes Selbst. Genau. Ein Aufmerksamkeitselbstes. Es hat ein Selbstmodell
in einer gewissen Weise. Da bin ich mir halt nicht sicher, weißt du, weil ich sehe halt die Leute,
die bei Intel arbeiten, so als analog zu einer Gehirnzelle bei dir. Die Analogie ist korrekt. Ja,
aber das Problem ist halt, was du bei Intel beobachten kannst, ist halt nicht, was Intel tut,
sondern ist gesteuert von den Hirnzellen. Also den Schritt zu machen, finde ich jetzt bei Intel nicht
irgendwie anders, als bei dir zu machen. Zu sagen, du bist halt ausgebaut. Die Frage ist,
welche Funktion implementiert wird. Die Frage zum Beispiel, ob die Katze bei Bewusstsein ist oder
nicht. Es kam für mich auf die Frage, agiert die Katze kausal, basierend auf einem Modell,
das besagt, dass die Katze merkt, dass sie was merkt. Also ist diese Awareness of Awareness da
an der Katze. Na, unbedingend. Ich meine, die merkt ja, wenn sie irgendwo gingelaufen ist,
was wehtut oder wenn sie irgendwo hingefallen ist. Das ist nur die erste Stufe. Na, und sie merkt
irgendwie, das tut weh. Also zum Beispiel die Hunde spielen, die Sony Hunde, die wir programmiert
haben, Fußball zu spielen, früher im Robocop, die haben kein Bewusstsein, soweit ich das beurteilen
kann. Und das liegt daran, dass die keine Second Order Awareness brauchen. Das liegt nämlich daran,
dass alle Prozesse, die die haben, genauso funktionieren, wie wir die programmiert haben.
Die müssen sich nicht selbst organisieren. Da ist nichts, was kohärent werden muss, weil wir die
Kohärenz schon eingebaut haben in das System. Wir haben das alles gemacht. Das System hat nicht
genügend Freiheitsgrade, um davon wegzugehen. In deinem eigenen Gehirn musst du diese Kohärenz
immer erzeugen. Auch der Umstand, dass du selber dich erinnerst, dass du noch fäh für bist und dass
du noch aufmerksam bist, ist etwas, wo du immer wieder reingehen musst, um sicherzustellen, dass
das tatsächlich der Fall ist. Dass du nicht sozusagen wegdriftest und einschläfst und das
Bewusstsein verlierst. Und Intel ist in einer Weise ähnlich wie der Sony-Roboter, weil es ein
Ding ist, was konstruiert ist von Menschen und dann sozusagen in eine Form geklopft wird, die von
selber sich nicht auflöst. Der Hund ist, dieser Sony-Hund, den wir da programmiert haben, der
löst sich auch nicht auf von selber. Du schaltest den an, der bootet sein Programm von der SD-Karte
und das Programm ist genau so, wie ich das gemacht habe. Das ist nicht notwendig, dass da
irgendetwas drin ist, was den Hund dazu bringt, sich erstmal das bewusst zu werden, was seine
Aufgabe als Hund in der Welt ist und dann raus irgendwie ableiten kann, dass er Fußball spielen soll.
Also die Definition, die Strosta gebracht hatte, war, dass er sagt, in dem Umblick, wo so eine
Firma einen Trieb zum Selbsterhalt hat. Also sozusagen als Gesamtorganismus Handlungsweisen
entwickelt, die den Selbsterhalt zum obersten Ziel haben und die auch komplex sein können. Also
die jetzt nicht nur irgendwie ausweichen vor irgendwie feinem Klavier ist, sondern halt irgendwie
tatsächlich komplexe Betrachtung eines Weltmodells, den eigenen Platz in diesem Weltmodell und was
muss ich tun, um die Welt zu verändern, damit ich auch in der Zukunft noch irgendwie einen Platz in
dieser Welt habe, dass das das Kennzeichen ist. Also dass das zu sagen, der ein Signifier ist,
der halt in anderen Dingen halt nicht anzutreffen ist, die halt reindeterministisch funktionieren.
Nicht alle Individuen haben Selbsterhaltungstrieb. Es gibt Menschen, die sich das Leben nehmen oder
überhaupt kein Interesse haben oder weiter Existenz haben und die werden halt nicht sehr alt und wenn
die das haben, bevor sie Kinder haben, dann werden sie keine Nachkommen haben. Bei Unternehmen ist es
auch so, wenn sie sich nicht so verhalten, als hätten sie einen Selbsterhaltungstrieb,
denn entstehen sie gar nicht erst und wenn sie den Selbsterhaltungstrieb verlieren, nachdem sie
entstanden sind, dann werden sie oft durch andere Unternehmen abgelöst und insofern ist das praktisch
so ein, ich glaube nicht, dass es ein gutes Kriterium ist, das reicht nicht aus. Ich sehe es
eher andersrum, wenn eine Firma nur den Selbsterhalt zum Zweck hat, dann sollte man sie vermutlich
erschießen. Na gut, dann wird sie heute ein Pepper Club Optima sein. Ja eben, genau, das ist
die große Gefahr der KI, die nur einen eigenen Selbsterhalt sieht oder ein Mensch, der nur den
eigenen Selbsterhalt sieht, ist gefährlich. Also wenn das Ding nicht dem großen Ganzen dient und
nicht begreift, dass es Sachen gibt, die darüber hinaus sind, also ein transcendentes Prinzip gibt,
dem die dienen, dann sind sie wirklich gefährlich. Wir könnten mal langsam in Richtung Schluss kommen,
wir sind jetzt bei drei Stunden 15. Ja, wir haben noch eine Frage, wenn jetzt du im EU-Parlament
auswählen durftest, wie die Regulierung aussieht, was wäre denn dann deine Version gewesen? Ich
glaube, ich würde erstmal etwas abwartender sein und ich würde versuchen, die Regulierung
evidenzbasiert zu machen. Aus meiner Sicht sollten Gesetze im Idealfall so erlassen werden,
dass man in jedes Gesetz ein Kriterium einbaut, was das Gesetz eigentlich verbessern soll,
und zwar ein hartes Kriterium. Das heißt, sollte zum Beispiel drinstehen, ich möchte erreichen,
dass in einem Jahr das und das Ziel erreicht ist, in zwei Jahren das und das Ziel ist und in drei
Jahren das und das Ziel und wenn das nicht erreicht ist, dann wird das Gesetz automatisch
rückabgewickelt und wenn das Gesetz Schaden verursacht hat, dann gibt es Konsequenzen und
das bedeutet, dass... Sehr idealistische Sicht. Ja, aber wenn wir sagen, wenn man rational ist,
also wenn ich mein eigenes Verhalten optimiere, wenn ich versuche, mein eigenes Verhalten zu
verändern und ich bin rational, belüge mich nicht selbst, dann werde ich ja auch so was machen. Ich
werde Erwartungen an die Verhaltensänderungen, die ich mache, knüpfen und dann beobachten,
ob das auch eintritt. Und wenn das nicht eintritt, dann kann ich nicht einfach weitermachen und so
tun, als ob. Also die Frage ist, wie korrupt bin ich selber? Ja gut, aber das kannst du über alle
Gesetze vorhelfen und würde ich sogar auch über alle Gesetze vorhin gesagt haben. Genau, und das war,
wenn wir das jetzt anwenden würden auf die KI-Regulierung, dann sollte derjenige die
Regulierung, die wir vorschlagen, mit einer vernünftigen Erwartung verknüpft sein oder
knüpfbar sein, dass wir wünschenswerte Resultate eintreten. Und ich vermute zum Beispiel, wenn wir
eine Regelung erlassen, die sagen, wir wollen KI-Forschung unterbinden, die dazu führt,
dass man Emotionserkennung mit der KI macht, ist das nicht ohne weiteres gegeben. Es gab gerade,
war ich in München auf dem 1E9-Festival und da gab es eine sehr interessante Diskussionsrunde,
bei der eine der Personen, die da in diesem Fireside-Discussion saß oder in diesem Panel
saß, war von Palantir. Oh nein. Ja, das ist total interessant, weil Palantir ist ja eine sehr
spannende Firma. Palantir, das sind diese Steine, die im Herrn der Ringe ursprünglich von den Elfen
und Zwergen geschaffen wurde, damit die so kommunizieren können. Und dann wurde das Ding
von Sauron gekapert und der hat das dann benutzt, um sich mit Saruman, seinem Botschafter, auszutauschen
und die Hobbits zu beobachten. Und Palantir wurde bekanntlich von Peter Thiel mitgegründet und
einigen anderen, die erkannt haben, dass man der amerikanischen Regierung Tools in die Hand geben
muss und den Diensten, die aktuelle KI-Methoden verwenden, um die Daten der Welt verfügbar zu
machen und zu organisieren, sodass Mordor die Hobbits besser im Griff hat und beobachten kann.
Und das sind in Deutschland gerade in den Nachrichten, weil mehrere Bundesländer
zusammen beschlossen haben, dass sie für alle Polizei aller Bundesländer eine Palantir
anschaffen wurden. Und das wurde natürlich nicht erwähnt an dieser Diskussion, sondern das war so
eine Feel-good-Diskussion, in der alle erklärt haben, wie gut sie alle zusammenarbeiten und wie
schön die KI-Forschung ist. Und dann meldete sich eine Stimme aus dem Publikum, die Palantir kannte,
und diese Frau dann direkt angesprochen hat, gesagt, wie verhalten sie sich denn gegenüber
Vorwürfen, dass Palantir ein Missbrauch der KI-Forschung ist und die ganzen Sachen, an denen sie
da arbeiten, extrem problematisch und schlecht sind. Und daraufhin hat die Palantirfrau erklärt,
ich habe leider den Namen vergessen, was ein bisschen unfair ist, ich müsste nachschlagen,
das Gute zu tun mit der KI heißt nicht, dass es sich um Wohlfühlen geht, um Gutfühlen dabei,
sondern dass man das Richtige tut. Und um das Richtige zu tun, ist es auch notwendig,
in der Sicherheitspolitik zu arbeiten. Und zum Beispiel ist es so, dass die Palantiertechnologie
in der Ukraine eingesetzt wird, um die Ukraine Informationskrieg gegen Russland zu unterstützen,
und dass die Technologie eingesetzt wird von der Polizei, um unsere Gesellschaft sicher zu machen,
und dass sie eingesetzt wird von den Diensten, um Abwehr gegen Gefährdung der Demokratie zu
ermöglichen. Und das ist notwendig und gut, wenn man an unsere Gesellschaft glaubt. Und ich glaube,
dass die Frau Recht hat. Es ist tatsächlich so, dass um das Gute zu tun, geht es oft darum,
dass man Dinge tun muss, bei denen man sich nicht wohlfühlt. Das heißt nicht,
dass man unmoralische Dinge tun muss, sondern dass man sich klar machen muss,
dass die Welt, in der wir sind, sehr kompliziert ist und auch aus Menschen besteht, die nicht so
sind wie wir und nicht die gleichen Ziele haben wie wir. Und dass wenn wir unser Leben führen wollen,
in Freiheit und Wohlstand und Glück und Freundschaft und Liebe, dass wir das sicherstellen müssen,
dass das auch möglich ist. Und die KI spielt dabei notwendigerweise eine Rolle,
weil die Gegenseite hat auch KI. Das heißt, wir haben gar nicht die Wahl, ob wir die KI dafür
einsetzen. Und das heißt, wenn wir eine Diskussion haben, bei der wir alle Themen ausgrenzen aus der
KI-Forschung, bei der wir uns nicht wohlfühlen, weil wir die Möglichkeiten des Missbrauchs durch
schlechte Regierungen sehen, dann führt es dazu, dass wir verlieren werden, weil die andere Seite
KI einsetzt. Naja, das ist tatsächlich ein Argument, was in der Diskussion um autonome
bewaffnete Systeme immer wieder gebracht wird, dass man sagt, also ja, wenn wir das nicht machen,
dann verlieren wir, weil die anderen machen das ja auch. Naja, das ist ja sozusagen so,
das ist halt diese Die-Killer-Roboter-Diskussion revamped. Welche anderen sind das nochmal?
Die Chinesen halt, also logischerweise, weil die anderen sind halt immer die Chinesen.
Also im Augenblick die Russen. Genau, oder die Russen. Ja, das kenne ich schon.
Und halt dieses, dieses Spiel halt zu sagen, wir müssen jetzt halt irgendwie weiter,
also wir müssen die Technologie weiter eskalieren, auch in Anwendungen, bei denen wir in Anführungszeichen
Bauchschmerzen haben, weil die anderen machen das ja auch, ist halt so eine klassische
Wettrüsten-Argumentation. Und da muss ich halt sagen, die, also gerade Palantir,
also Palantir ist halt ein Haufen von, sag mal, also ich reformuliere es mal neutral. Also wir
haben halt ein A-Team, was sehr gut ist und die haben relativ viele D-Teams, die halt irgendwie
dann nach dem A-Team hingeschickt werden, wenn der Kunde den 3- oder 5-Jahres-Vertrag unterschrieben
hat. Und die kochen halt auch nur mit Wasser. Verstehe mich nicht falsch, ich wollte jetzt
nicht speziell Palantir verteilen oder angreifen. Lass mich mal kurz den Gedanken zu Ende führen,
weil was man halt eben genau dazu auch sagen muss, ist, was die halt tun, ist, dass die in ihrer
Propaganda für das, was sie da machen, Zeug, was halt mit ziemlich dünnem Wasser gekocht ist,
als Mittel benutzen zur Normalisierung von Dingen, bei denen technologische Zustände geschaffen
werden, die nicht hätten sein müssen. Also dieses Argument von wegen, wir müssen das jetzt hier so
machen, weil die anderen machen das ja auch, wird in der Regel nie belegt. Es gibt keine Belege dafür.
Es gibt also in keiner dieser Diskussionen, also auch nicht bei irgendwie autonomen Drohnen,
die bewaffnet sind, gibt es halt irgendwie keine, also niemand, der sagen kann, okay, aber hier die
anderen machen das ja auch, zeig mal, stellt sich halt immer raus, ist halt in der Regel nicht so
einfach. So deswegen sieht man häufig da so Sachen nicht. Wir haben jetzt irgendwie im Bereich Drohnen
haben wir jetzt halt Maschinen-Learning-Systeme, die relativ einfache Aufgaben erledigen können und
wo es Argumente dafür gibt, die zu verwenden, weil sie halt unter gemmigen Bedingungen halt
nicht mehr remote kontrollierbar sind, sehen wir jetzt halt in der Ukraine. So bei Palantir ist
halt so, da muss man sich nur deren Produktnamen angucken, um zu wissen, dass irgendwie ihr ganzes
Alexander-Karp-Philosophie-Gephase nix weiter als Deko ist. Also ihr best selling product für
Polizisten heißt Gotham. Also da weiß man schon, wo die herkommen. Aus dem Batman-Universum.
Genau. Und die sind halt, was die halt machen, ist so ein Normalisierungsding. Also es gibt an
vielen Stellen, lohnt es halt deren Propaganda halt irgendwie zu Single-Frame-Stappen durch die
Videos, um halt einfach zu gucken, was sie da wirklich tun. Selbst in ihren Stage-Demonstrationen
und weil die sind, also gibt ein Dutzend andere von diesen Firmen, gerade dieser ganze Defense-Tech-Startup-
Teilbereich in Ameland wird ja gerade richtig groß. Und das Problem ist halt immer nur, dass in dem
Augenblick, wo Entscheidungen, die philosophisch getroffen werden müssen, nicht mehr aus ethischen
oder philosophischen Gründen getroffen werden, sondern wegen konstruierter wahrgenommener
Sachzwänge, in Anführungszeichen, begibt man sich halt in den Bereich, wo man Werkzeuge schafft,
die die Welt objektiv nicht besser machen, sondern schlechter. Das deren reines Vorhandensein dazu
führt, dass die Welt schlechter wird, aus der Annahme heraus, dass der Feind es halt tun wird.
So Beispiel Killer-Robot-Diskussion, da war es halt so, dass das schlagene Argument ist,
wegen alle Seiten gesagt haben, es war nicht gut, aber wir forschen trotzdem dran weiter,
war das Geschwindigkeitsargument. Dass sie gesagt haben, in dem Augenblick, wo wir nicht
autonom agierende letale Systeme haben und der Gegner welche hat, werden wir verlieren, weil wir
langsamer sein werden. Und dann haben die halt alle angefangen, also deren Poster-Schaltbeispiel
waren halt immer diese Verlangs-Air-Defense-Systeme, sind halt so automatische Maschinengewehre,
die halt irgendwie mit Radar ausgestattet sind und halt dafür da sind, so Raketen und Drohnen so auf
den letzten 500 Metern abzuschießen, bevor sie ins Schiff einschlagen oder auch in den Stützpunkt,
oder was auch immer. Und die Reaktionsgeschwindigkeit rechnet sich halt einfach daraus, dass so die
schnellen Anti-Schiff-Raketen fliegen halt so, mach fünf, mach sechs, dass es gibt keine
Möglichkeit mehr für eine menschliche Reaktion, außer dieses System einzuschalten und damit zu
leben, was immer es tut. Das ist halt sozusagen so, als wenn du quasi einen Kampffoot von der
Kette lässt und du verlässt dich jetzt halt darauf, dass der schon irgendwie nicht das Baby
fressen wird, sondern den Einbrecher. So und deshalb, also damit fing es dann halt an so.
Und dann haben die halt angefangen aus dieser Situation, die technisch begründbar ist,
wo man sagt, es gibt keine andere Möglichkeit, außer sich darauf zu verlassen, dass man nicht
mehr den Feuerknopf drückt, sondern dieses Thema aktiviert und dann mit den Softwareentscheidungen
lebt. Haben die dann halt so ein ganzes Universum konstruiert von allen möglichen Szenarien. Und
wir sehen genau diesen Effekt gerade immer weiter eskalieren, dass man also auf der Basis
von denkbaren Bedrohungsszenarien die Begründung für Technologie konstruiert, die dann wiederum,
dadurch, dass sie da ist, dazu führt, dass der Gegner sie wiederum als nächsten Schritt in der
Bedrohungsspirale wandern. Palantir ist da ganz groß drin. Die sind da wirklich, also die andere
Petatilfirma Androil, die machen halt irgendwie so Drohnen und Überwachungszeug und so. Die sind
da noch besser drin, die sind da noch viel härter, weil die halt irgendwie auch so neue Paradigmen
von Waffensystemen konstruieren, die halt völlig integriert mit Überwachungssystemen sind. Also
quasi so Intelligent Battlefield mal in Ernst gebaut, also quasi so Systeme, die du halt ausrollst
und sagst, hier können sich Autos bestimmter Marke nicht drin bewegen oder Leute, die halt
irgendwie das falsche Gesicht haben, was zufällig in unserer Datenbank ist, kommen hier nicht lebend
durch. So Systeme bauen die da. Und das führt dazu, dass du, wenn du dann in die chinesische
Diskussion guckst, dann hier, die zeigen dir dieses Werbevideo von denen, was halt staged und faked
ohne Ende ist und sagen, das ist, was die Amerikaner bauen. Jetzt wollt ihr das, wollt ihr das,
wir das nicht machen? Also diese Spirale, die selbstverständlich halt nicht aus Gründen von,
wir wollen unseren lieben Geheimdiensten helfen, dass er uns vor den bösen Terroristen bewahren,
getrieben wird, sondern eben aus so einer Eskalationslogik, die, wenn sie einmal angefangen
hat, nicht mehr zu beenden ist. Das ist mein Beef mit Palantir. Also ich habe persönlich nicht so
viel Meinung zu Palantir, weil ich nicht so viel darüber weiß wie du. Ich vermute, dass Firmen,
die im relativ geheimen Arbeiten und Interesse daran haben, Bedrohungsszenarien zu verstärken,
um übrigens Geschäftsmittel zu befördern, grundsätzlich SaaS sind natürlich, weil sie
unter falschen Incentives stehen und die Kontrolle nur bis zu einem bestimmten Maß begrenzt ist.
Deswegen wäre mein Default jetzt nicht unbedingt Palantir zu verteidigen. Aber ich merke auch,
dass ich einen Bias habe, der möglicherweise dir auch nicht ganz fremd ist. Und zwar ist es so,
dass jede Form von Gewaltanwendung mir Bauchschmerzen macht. Das liegt einfach daran,
dass ich ein empfindsamer Nerd bin, der nicht die Neckungen von Genghis Khan und Napoleon in
sich trägt. Und im Prinzip bin ich eher scharfshaft und habe eine Inhibition gegen die Initierung von
Gewalt. Und es ist andererseits so, dass wenn ich einen Schritt zurückgehe und ich versuche die
Welt aus der Perspektive eines, sagen wir eines Computerspiels Civilization zu sehen. Und da gibt
es verschiedene Gesellschaftsformen, die gegeneinander in Widerstreit stehen und
Administrationssysteme, die miteinander in Widerstreit stehen und verschiedene politische
Ästhetiken, die da sind. Und ich habe den Eindruck, dass durch die Gnade unserer Geburt befinden
wir uns in einer Demokratie, die sehr friedlich ist und die von den Amerikanern, die in weniger
friedliche Demokratie sind, stabilisiert wurde. Und die ist erst stabil, seitdem die Amerikaner
die stabilisieren. Und die Amerikaner ermöglichen Europa ein Leben im Freiheit und Wohlstand,
das es bevor die Amerikaner die Vorherrschaft über Europa übernommen haben, nicht gab. Und das heißt
auch die USA selber, die haben viele Sachen, die mir als Europäer, wo nämlich viele Bauchschmerzen
machen, aber es gibt kein anderes Land mit 350 Millionen Einwohner, das mir weniger Bauchschmerzen
macht, sondern im Gegenteil, das ist das einzige Land von dieser Größe, das ein Einwanderungsland
ist. Also wo Leute auch wirklich massiv hinwollen aus der ganzen Welt, weil sie die Möglichkeit
gibt, mit Freiheit und relativ viel Sicherheit sich selbst zu verwirklichen und ein gutes Leben
zu führen, Verbindungen zu ihren Freunden aufzunehmen, Dinge zu bauen, die es wert sind,
gebaut zu werden. Und dieses Modell, das die Amerikaner haben, dieses liberale Modell ist
einzigartig in der Welt. Und obwohl ich glaube, dass die Außenpolitik der USA desaströs gewesen ist
für viele Länder, die ihr zum Opfer gefallen sind, weil sie nicht optimal organisiert ist und die
Spiele, die gespielt wurden, oft sehr kurz waren. Und dass Leute Kollateralschäden von irgendwelchen
kurzfristigen Präsidentschaftsbemühungen gewesen sind, die praktisch Seiteneffekte hatten von
Innenpolitik, die dann zum Beispiel Libyen extrem geschadet haben und so weiter und so fort. Oder
wo Leute inkompetent vorgegangen sind in ihrer Außenpolitik. Trotzdem ist es so, wenn ich das
Ganze jetzt zurückgehe und überlege, welches Spiel will ich spielen, auf welcher Seite will
ich stehen. Dann stehe ich auf der Seite des Liberalismus. Ich stehe auf der Seite, wo Menschen
nicht durch eine autokratische Diktatur gezwungen werden, so zu sein, wie die autokratische Diktatur
sich das vorstellt, sondern wo sie die Möglichkeit haben, autonom sich selbst zu organisieren und eine
eigene moralische Modell zu entwickeln, wie sie miteinander umgehen wollen. Und das ist einmalig
in diesem Projekt. Und wenn ich überlege, wie ich dieses Projekt beschützen kann, gegen das,
die Stabilisierung durch Systeme, die das ablösen wollen, durch einen Totalitarismus, durch
irgendeine Form von Stalinismus oder Faschismus oder das Ding vernichten wollen von außen,
dann würde ich das verteidigen wollen. Und wenn ich überlege, wie ich das verteidigen kann, muss
ich auch KI einsetzen. Ich kann nicht einfach sagen, die Gegenseite macht das nur deswegen,
weil sie denkt, dass ich das mache und wenn ich aufhöre, das zu machen, würde die Gegenseite
das wahrscheinlich gar nicht tun, weil sie zu faul dazu ist. So läuft es nicht. Es ist eher,
sobald die Atombombe möglich ist, dass man sie bauen kann, muss ich eine Atombombe bauen,
weil die Gegenseite wird aus dem gleichen Grunde ebenfalls eine bauen. Es ist ein
spieltheoretisches Problem, was erst auflösbar, wenn wir eine Weltregierung haben.
Nee, das glaube ich nicht. Also ein schönes Gegenbeispiel ist SDI. SDI war ja ein fiktives
Rüstungsprojekt, was irgendwie in der sehr teuren Fiktion betrieben wurde, die eigentlich nur das
Ziel hatte, halt irgendwie dafür zu sorgen, dass die Gegenseite, also in dem Fall die Russen,
etwas eh nicht kostspieliges anfängt und dabei halt irgendwie Pleite geht, was zum großen Teil
auch gelungen ist. Es war halt eine sehr groß angelegte Operation Mindfuck und es gab tatsächlich
in der Sowjetterne und damals halt Leute, die gesagt haben, ja, das kann alles, das stimmt
alles nicht. Wir müssen uns auf das Spiel nicht einlassen. Wir können asymmetrische Antworten
konstruieren, die sehr viel billiger sind, weil das diese Amerikaner ihre Röntgenlasersatelliten
zum Laufen bekommen, das glauben wir jetzt gerade mal nicht, weil Physik, also mit detaillierter
Begründung und haben dementsprechend gesagt, wir könnten, falls wir das doch hinkriegen,
könnten wir die relativ easy abräumen. Wir müssen uns jetzt also nicht davor sorgen,
dass unser integrierter Raketenasenal entwertet wird und damit das gesamte Abschreckungsarchitektur
fällt. Und was ich halt momentan sehe, ist halt an vielen Stellen ein ähnlicher Versuch, von vielen
Seiten genau so eine fiktiven Rüstungsdinger zu bauen und die aber wiederum, weil wir jetzt nicht
von hunderten von Milliarden reden, sondern nur von so einstellig Milliarden oder sogar noch
weniger, bis man es dann bauen könnte, andere Leute doch dazu bringen, die tatsächlich zu bauen,
weil sie mehr Ressourcen haben, weil sie schlauer sind, weil sie vielleicht Insights haben, die
andere nicht. Du löst in die Tasche. Erstens, es gibt SDI inzwischen. Also es gibt Satelliten,
die interkontinentale Raketen versuchen, unter Beschuss zu nehmen. Es waren damals noch nicht
möglich. Kann auch sein, dass es damals ein Versuch war, die Sowjetunion stärker in die
Pleite zu drücken. Aber ich glaube, letztendlich war es der Afghanistankrieg und Tschernobyl,
die einen wesentlich größeren Einfluss hatten. Und SDI war möglicherweise auch teilweise ein Coup
des militärisch-industriellen Komplexes, der größere Investitionen haben wollte, mit etwas,
das auch innenpolitisch interessant klang und die Vorherrschaft der USA im Systemkonflikt und über
die Welt verstärken konnte in der Reagan-Ära. Und viele von den Sachen, die damals versprochen
wurden, sind es jetzt. Technisch beginnen sie realistisch zu sein. Und in dem Maße,
wo sie technisch realistisch sind, werden sie auch realisiert. Weil der neue Systemkonflikt
halt zwischen China und den USA dazu führt, dass Sachen neu aufgeteilt werden. Es gibt nach wie
vor dieses Gleichgewicht der Abschreckung. Und wenn irgendeine Seite dieses Gleichgewicht der
Abschreckung beendet, dadurch dass es wirksam Raketenabwehr aus dem Welt ergibt, dann würden
alle Karten neu gemischt werden. Und es gibt neue Weltkriege und entsprechend neue Fortsetzungen
bei den Killer-Drohnen. Sehen wir das konkrete Beispiel in der Ukraine. Das ist ja vorhin erwähnt.
Wir kennen ja diese Drohnen, die die Ukraine eingesetzt hat die ganze Zeit und teilweise
immer noch tut. Wir haben chinesische Consumer-Drohnen aus dem Regal bestellt und haben die dann von
Hand gelenkt. Kameras benutzt, die da dran sind und Greifer dran montiert, mit der sie Handgranaten
und andere Sprengstoffe transportieren konnten. Und nach einer gewissen Zeit hat das nicht mehr
gut funktioniert, weil die Russen großflächig Jammer positioniert haben, sodass die Halbwertzeit
dieser Drohnen sehr kurz ist, bevor die gejammt werden und vom Himmel fallen. Und die Lösung
dafür ist, die Dinge autonom zu machen. Also eine Lösung, eine sehr einfache. Man kann auch versuchen,
die Kommunikation zu haben, aber dann ist es halt keine Consumer-Drohne mehr, sondern man muss ein
paar Leute dransetzen, die eine Lösung löten. Und die Lösung, die man mit KI löten kann, ist in
zwischen, sieht ziemlich bezahlbar aus, um das Ding autonom zu machen und das Ding mit sozusagen
Bordmitteln aus dem, was wir aus der jetzigen KI, selbst mit diesen einfachen generativen Modellen
herausfällt, hinzubekommen. Und das bedeutet, dass wenn dieser Krieg lange genug geht, dann wird eine
Seite die erste sein, die das hat und der kurze Zeit die andere Seite keine Wahl haben, als das auch zu
tun. Und das liegt nicht einfach daran, dass sie sich hochschaukeln mit dieser imaginierten Bedrohung,
sondern weil es real auf dem Schachtfeld einen Fortschritt bietet für die, für die eine Seite,
mit geringen ökonomischen Mitteln sehr viel Schaden zu machen, der vorher nicht möglich war.
Also bei den Drohnen sieht es auch so, weil gerade mal so DJI Follow Me oder wie das nenniger
Smart Shot ausprobiert hat oder sich anguckt, was irgendwie in den Obsthaus-Projekten passiert,
ist einfach zu simpel geworden. Also es ist halt irgendwie jetzt die technischen Hürden sind halt
sehr gering, also aber für so das Zeug, was jetzt gerade so insbesondere halt so was, so Firmen wie
Palantir oder andere bauen, geht halt weiter darüber hinaus. Also da geht es halt darum,
Entscheidungen auf dem Battlefield nicht mehr von Menschen treffen zu lassen. Also Palantir
hatte neulich irgendwie so ein Ding gezeigt, quasi so ein Chat-GPT für Militärsteuerung. Also das
ist halt irgendwie so ein, also ich kann das Video nochmal verlinken, das ist ganz interessant zu
sehen. Da haben sie halt einfach so ein paar Open-Source-Modelle zusammengedübelt mit halt
irgendwie einer Datenbank, in der sowas wie Militäreinheiten drin sind und wo die sind und
irgendwie Tasking-Kanälen und so weiter. Und am Ende führt dann halt der, das ist gestaged alles,
aber führt der dann halt quasi so einen Einsatz komplett im Chat-Bot. Das heißt also er sagt halt
irgendwie hier, da haben wir irgendwie Gegner detektiert, sagt dann okay schick mal Drohne
hin, Bild von der Drohne kommt zurück, schick mal Bild von der Drohne zu Analytics, da sind Panzer,
was haben wir denn hier irgendwie, eine Einheit in der Nähe, die wir bekämpfen könnten, wie sind
die denn auf munitioniert, welche Einheit braucht denn wie lange, was ist denn der beste Weg zum
Ziel, bis er dann halt eine Go-Order gibt, so am Ende. Also es ist halt so einfach so drei Minuten
Video oder fünf Minuten und dann erklären sie noch so ein bisschen wie die Datenbankstruktur
dahinter aussieht. Und du merkst halt an allen Stellen, dass da noch ein Mensch irgendwie diesen
Chat bedient, ist halt irgendwie eine völlig überflüssige Angelegenheit aus deren Sicht.
Also wo sie halt irgendwie sagen, okay das könnte das auch von ganz alleine so. Also da bräuchte man
jetzt irgendwie nicht mehr noch irgendwie jemand, der halt irgendwie da noch einen Urteil drüber
fällt und ich glaube, das ist das eigentliche Problem. Also dass sie halt einfach da hingehen,
dass Soldaten auf dem Schlachtfeld nur noch Tickets, die sie von AI gebaut bekommen haben,
ausführen. Also das ist halt am Ende das, worauf es hinausläuft. Es wird nicht darauf hinauslaufen,
dass eine AI dann schon von Killerrobotern steuert, sondern es wird halt darauf hinauslaufen,
genau das, was wir irgendwie bei Lieferdiensten sehen, dass irgendwie die zentralen Funktionen,
das Dispatching und der Kontrolle von Software gemacht werden und ansonsten halt irgendwie
die Sklaven da draußen sind, die Tickets abarbeiten. Und genau dasselbe wird halt auf
dem Schlachtfeld passieren. Und das ist halt glaube ich so ein Punkt, wo bei mir da halt einfach so die,
das ist halt, deswegen sage ich erst, eine philosophische Frage, ob ich das will,
also ob das tatsächlich eine Entscheidung, die man auf einer Ebene des Menschenbilds treffen muss,
auf einer Ebene des Bürgerbildes treffen muss, ob jemand ein Soldat, der in Armee ist,
die sein Land verteidigt, ob ich den zum Ticketempfänger eines AI generierten
Systems machen will und dann, wenn es halt schief geht, war es halt ein Softwarefehler.
Also das verstehe ich jetzt aber gerade überhaupt nicht, weil aus meiner Sicht ist es so,
dass das Einzige, was die Demokratie vom Krieg führen abhält, ist, dass Bilder von verwundeten
Soldaten zurückkommen. Das heißt, wenn sobald es die Möglichkeit gibt, eine Drohne zu schicken,
schicke ich doch keinen Soldaten mehr ins Feld. Ja, du kannst aber kein Territory mit einer Drohne
erobern. Na doch, natürlich, du kannst es nicht halten. Ja, aber es ist ja egal,
wenn du weiter nach vorne pusht die ganze Zeit. Nein, es wird nichts. Du kannst ja in der Ukraine
gerade live betrachten, wir haben ja erst einen Weltkrieg mit Drohnen da. Mein Widerspruch zu
Frage ist jetzt ein bisschen anders. Ich bin nicht sicher, ob wir so viele Freiheitsgrade haben. Ich
bin bei dir, wenn du sagst, dass das, was Palantir gerade vorschlägt, so fake wie das SDI unter
Reagan war. Das heißt, das kommt wahrscheinlich irgendwann, aber nicht jetzt und es wird anders
aussehen. Und es gibt da einfach Bemühungen, sich Aufträge zu besorgen und so weiter und so fort.
Und wir haben da sehr viel mehr Freiheitsgrade im Moment, als die Argumente der einen Seite sagen.
Es gibt ja auch Argumente, die entsprechend von vielen anderen Leuten dagegen kommen. Aber
langfristig fällt auf, dass unsere Nervensysteme sehr, sehr langsam sind. Das dauert um die 20
Millisekunden, um vom einen Neuron zum nächsten zu kommen. Und das ist ein Zeitraum, wo wir einen
Ping über die halbe Welt schicken können. Und also jedenfalls über ziemlich große Entfernung. Also
die Zeit, die wir brauchen, um Fakt aus unserem Gehirn zusammenzusetzen in einer Repräsentation,
ist länger als die Zeit, die wir brauchen, um aus dem Internet, aus weltweit faltarten Datenbanken
Fakten zusammenzusetzen. Und das heißt, dass wenn wir ein elektronisches System bauen,
dass nicht wie unser Gehirn irgendwie mit Schallgeschwindigkeit arbeiten, sondern mit
nennenswerten Anteilichgeschwindigkeit, dann laufen die Kreise um die Art und Weise,
wie wir Informationsverarbeitung machen. Nicht nur das einzelne Gehirn, sondern auch was Gruppen von
Menschen machen, wenn sie sich absprechen müssen, bevor sie eine Entscheidung treffen, zum Beispiel
zu feuern oder strategisch zu entscheiden. Und was wir zum Beispiel sehen, dass die Kriegführung,
die noch darauf beruht, dass man zentral Entscheidungen trifft und dann die Einheiten
Befehle bekommen, die für die nächsten zwei Tage aktiv sind, dass das Unterlegen des
Gegenwintertechnik in der Kriegführung, wo jede Entscheidung momentan getroffen wird,
aufgrund der Situation und die Integration wesentlich schneller und interaktiver funktioniert.
Wenn wir das übertragen auf nichtmenschliche Gehirne, die in der Kriegführung eingesetzt werden,
werden Menschen zeneffizierend sein, als dass irgendein Staat sich das leisten kann. Und das
heißt, langfristig wird, solange es Kriege gibt, die Technologien eine immer größere Rolle spielen
da drin. Ich denke, dass das nahezu naturgesetzlich ist und nicht von unserer Philosophie abhängend ist,
sei denn, und zu unserer Philosophie gehört, dass wir bereit sind zu verlieren.
Naja, der Punkt ist, glaube ich, dass es verschiebene Wege gibt, damit umzugehen,
also mit diesem Problem. Und dass die Art und Weise, wie man sich entscheidet, damit umzugehen,
also welche Grundsätze man da einbaut, so momentan gibt es halt diesen Human in the Loop,
so als simplen Stop-Gap, weil man halt irgendwie gerade keine besseren Ideen hat. Aber dass die
Art und Weise, wie man als Gesellschaft seine Gewaltausübung organisiert, also nehmen wir jetzt
mal nur den einfachen Fall nach außen. Und die Diskussion darum, wie, also welche Werte man dabei
priorisiert, die sollte offen stattfinden, die sollte explizit stattfinden, die sollte in einer
Art und Weise stattfinden, die es möglich macht, eine Verteidigungsstrategie für diese Gesellschaft
zu formen, die von der Gesellschaft mitgetragen werden kann. Und zwar solange man noch nicht in
einer Stresssituation ist. Das passiert aber nicht. Was de facto passiert, ist, dass die
Rüstungsunternehmen, also insbesondere die Innovativen wie Palatir, in der Lage sind, ihre
Philosophie, ihre Idee, wie sowas aussehen könnte, Kraft der Produkte, die sie anbieten, durchzudrücken.
Wir sehen es auch bei dieser Polizeisoftware, wo sie halt quasi dieses Predictive-Policing-Paradigmen
was halt an vielen Stellen schon gescheitert ist, wo man halt quasi auf statistischen
Wahrscheinlichkeiten halt irgendwie Entscheidungen getroffen hat, für zum Beispiel Veränderungen von
Patrouillendingen, also wo die halt patrouillieren und wo nicht, wo die Optimierungskriterien nicht
offengelegt sind, wo wir als Gesellschaft nicht darüber diskutieren können, auf was sind dieses
Thema eigentlich optimiert, weil nicht mal die Möglichkeit, welche Kriterien es geben könnte,
diskutiert wird, sondern wir halt das in so einem Intentionell, in so einem Nebel halten,
sondern wir müssen es machen, weil der Feind es macht. Wir können jetzt nicht darüber nachdenken,
irgendwie, wie man es dann eigentlich richtig machen würde, in Einklang mit unseren Werten.
Wir müssen ja nicht darüber diskutieren, dass es irgendwie nicht passieren soll, sondern wir müssen
darüber diskutieren, wie es dann sinnvoll passieren soll, ohne dass wir unsere Gesellschaft zum
Negativen verändern. Und diese Diskussion findet halt nicht statt, weil auf der einen Seite nur diese
EU, wir verhindern das jetzt mal lieber alles und bremsen es halt aus und auf der anderen Seite haben
wir halt die Palantirs, die halt sagen so, wir bauen den Scheiß jetzt mal so, wie wir es für richtig
halten und ihr wollt hinterher noch diskutieren, ihr könnt nicht diskutieren, dahinten kommt schon
eine Chinese. Und das ist halt der Dilemma, in dem wir uns gerade befinden, was mich halt auch sehr
ankotzt, weil wir halt… Das ist doch eher der öffentliche Diskurs, der… Den haben wir doch nirgendwo.
Ich verstehe gar nicht, wo deine Anspruchshaltung herkommt. Ich kann mich kein einziges Gesetz
erinnern, wo wir mal irgendwie ordentlich vorher diskutiert haben. Weil es nicht um Gesetze geht,
sondern um Strategie. Strategie ist immer eine Sache, die eine Gesellschaft im Diskurs notfalls unter
den Experten rausfinden muss. Ich vermute, dass es nur unter den Experten geht, insbesondere bei
solchen Sachen. Aber die finden jetzt halt nicht statt, die Diskussion. Die Erinnerung hab ich nicht.
Ich hab den Eindruck, dass im Militär die Diskussionen sehr ernsthaft stattfinden. Und das ist eine Sache,
die mir früher nicht bewusst ist, weil ich kannte keine Soldaten. Ich bin Zivildienstleister gewesen,
ich hab lieber Flüchtlinge aus Krisengebieten betreut, als mit der Waffe in der Hand herumzulaufen,
weil ich pazifistische Empfindlichkeiten hatte. Und ich hab später Leute kennengelernt, die in
Führungspositionen, in Militär gegangen sind, aus dem Blickwinkel, dass diese Disziplinen stattfinden
müssen und dass sie selber das machen müssen. Weil sonst macht das jemand, der keine moralischen
Bedenken hat oder humanistische Bedenken hat. Und das Ding ist aber, dass diese Leute, die im
Militär arbeiten, sind damit konfrontiert, dass an der Grenze unserer freiheitlichen Gesellschaft
Konflikte stattfinden, in denen Menschen sterben. Und das ist eine Sache, die den meisten Menschen
in unserer Gesellschaft so viel Bauchschmerzen hat, dass sie da nicht weiter denken können. Und das
gilt in bestimmten Maßen auch für mich. Das heißt, ich habe immer noch diese Unreife des Zivilisten,
der bestimmte Sachen nicht denken kann. Und die Öffentlichkeit kann bestimmte Sachen nicht denken.
Das heißt, das, was du beschreibst, das, was die Demokratie auffällt, sind die Bodybags. Natürlich
nicht das einzige. Da gibt es auch noch mehr. Das ist subtiler. Aber in der groben Annäherung hast
du nicht Unrecht mit dem, was du sagst. Das liegt daran, dass die Leute Probleme haben, wenn das
Ganze so handfest wird, dass man es nicht mehr weglügen kann. Dass man es nicht mehr wegdrücken
kann, dass man kein hübsches Bild drüberlegen kann oder ein erträgliches Bild drüberlegen kann,
sondern die Unerträglichkeit, die das Leben in der Welt, in der man stirbt, unter Schmerzen stirbt,
unter ungerichten Bedingungen stirbt, ohne Würde stirbt. Das ist ein Universum, in dem wir trotzdem
immer noch sind, das sich nicht komplett ausschalten und ausblenden lässt und wegbügeln lässt. Das
lässt sich nicht gut aushalten. Darüber können wir keinen Diskurs haben, außer mit Leuten, die
diesen Diskurs aushalten. Und das heißt, es ist nicht notfalls mit Experten. Es können nur Experten
machen und nur Experten hinter verschlossenen Türen. Und es muss trotzdem demokratisch auf höchstem
Niveau kontrolliert werden. Das ist ein extrem hoher Anspruch, den diese Gesellschaft nur sehr
begrenzt einlösen kann, aber die anderen Gesellschaften alle noch schlechter einlösen.
Also die Demokratie ist die einzige Form, wo das in irgendeiner Annäherung stattfinden kann und
das nicht nur hinter geschlossenen Türen stattfindet oder mit so viel Gewaltandrohung,
dass die Bevölkerung nichts dagegen sagen kann. Ich kenne ja so ein paar von so Militärs und die
haben sehr große Probleme, solche Diskussionen zu führen. Zum Teil hoffe ich aus Zeitgründen,
weil sie halt einfach in ihren Alltagsfunktionen sehr stark belastet sind. Und zum Teil ist da
halt bei denen auch das Problem, dass die einzige oder eine der wenigen Informationsquellen über
das, was eigentlich möglich ist, sind diese Hersteller. Also die halt irgendwie dann halt
Seminare veranstalten zu irgendwie Battlefield-AI, was halt im Wesentlichen wiederum ihre Sicht ist,
die halt irgendwie auf langfristige Produktplanung basiert. Und dann gibt es halt noch so ein bisschen
so Think Tank Expertentum drumherum, was halt irgendwie so über solche Sachen nachdenkt.
In Deutschland ist natürlich viel weniger ausgeprägt als jetzt in den USA. Aber letzten
Endes ist halt so der Outcome dieser Diskussionen in der Regel intellektuell unbefriedigend. Also
jetzt was jetzt irgendwie so die tatsächliche Ausformulierung von sinnvollen strategischen
Zielen für Technologieentwicklung angeht und was die strategische Ausbildung von technologischen
Fähigkeiten im Sinne von ethischen und philosophischen Ansprüchen angeht.
Wie würdest du es denn machen?
Naja, letzten Endes geht es halt darum, dass man…
Nicht wir, also du. Das Ding ist, du bist ein seltener Typ, Frank. Du bist jemand,
der auf relativ hohem Niveau und relativ autonom über komplexe politische und technische Sachen
nachdenkt. In der Weise, wie nur wenige Leute in der freien Gesellschaft, also außerhalb von
Institutionen, wo man mit Secrecy und entsprechenden Pay Grades und langer Karriere, bevor du da
reinkommst, solche Überlegungen treffen. Wenn du aus dieser Perspektive, die nicht unbedingt
die des Normalburgers ist, guckst, angenommen, du hättest jetzt tatsächlich Macht in diese
Institutionen zu gehen oder würdest du das zu deiner Aufgabe machen? Was würdest du anders
machen? Wie müsste das laufen? Was läuft jetzt grundlegend falsch? Hast du den Eindruck,
dass nicht genügend Diskussionen zwischen den führenden Politikern und Oligarchen und Militärs
bei uns stattfinden, die aufrichtig sind und wo sie ernsthaft darüber Gedanken machen,
was will Gott von uns? Oder hast du den Eindruck, dass das ganz anders sein muss, als es jetzt läuft,
dass man einen völlig anderen Prozess braucht, damit unsere Gesellschaft solche Diskussionen
haben kann, als der, der jetzt existiert? Ich glaube, es ist zum einen ein Bildungs- und
Verständnisproblem, dass also die technologischen Möglichkeiten, die da sind, grob missverstanden
wären in beide Richtungen. Also zum einen ist ganz viel quasi magisches Verständnis,
also wo halt einfach ein DKI abstrahiert wird in einen Fähigkeitenuniversum. Das ist im öffentlichen
Diskurs mit Sicherheit der Fall. Nee, das ist auch tatsächlich in so… Hast du den Eindruck,
dass das auch bei Peter Thiel der Fall ist? Oder bei den wichtigsten Entscheidern beim Militär?
Oder bei den wichtigen Thinktanks, die die Politik steuern? An einigen Stellen ist es schon so,
ja. Ja, bei einigen mit Sicherheit, aber du hast den Eindruck, dass es grundsätzlich falsch läuft,
also dass unsere Gesellschaften kein gutes Modell haben von den Bedrohungen,
den sie ausgesetzt sind und den Möglichkeiten, dagegen zu stehen. Kein realistisches, ja. Also
ich glaube und auch… Und das heißt, solltest du Bücher schreiben oder Politikberatung machen oder
wie sieht das aus? Ich glaube, dass das Problem ist, dass der Determinismus als
grästige Grundhaltung ist, glaube ich, das Hauptproblem. Also dass eine Extrapolation in
die Zukunft findet da eigentlich immer nur statt auf der Basis eines linearen Fortschreibens der
momentanen Hypes. Also es gibt eine realistische Einschätzung von Verfügbarkeit von Technologien,
Fähigkeiten von Technologien, der Wille zum Experiment, die Fähigkeitexperimente in einer
so strukturierten Art und Weise durchzuführen, dass man daraus Schlüsse ziehen kann, um daraus
eine iterative Weiterentwicklung zu machen. Diese Fähigkeiten sind nicht ausgeprägt. Ganz viel von
dem, was passieren kann, können wir noch nicht wissen, sondern wir können es halt nur ausprobieren.
Und wir müssen halt Wege finden, solche Experimente zu machen. Dazu gehört zum Beispiel halt im
militärischen Bereich eben auch mit verschiedenen Ansätzen von sowas wie eine Battlefield-RI sein
könnte zu experimentieren. Und die nicht nur zu nehmen, was ein Palantier jetzt irgendwie für
10 Millionen verkaufen will oder was Lockheed irgendwie in die F-35 einbaut und sagt, das ist
jetzt aber das, wie das hier so funktioniert, weil wir haben das jetzt mal ausprobiert.
Gut, KI ist ja noch im Prinzip ziemlich ein Anfäng und sie ist ja auch sehr billig. Also da,
wo oben eher eine Milliarde Dollar kostet, was völlig unerschwinglich ist für deutsche
Verhältnisse, sowas zu bauen, damit wir Modelle für 30 Millionen, das pro Stück trainieren können
oder sowas, das, der Berliner Regionalflughafen kostete sechsfache oder die Entwicklung eines
neuen Militärflugzeuges kostet ein Vielfaches davon. Das heißt, als militärisches Tool ist im
Augenblick das, was wir jetzt haben, ist sehr, sehr preiswert gewesen. Ich habe keine Ahnung,
was in den geheimen Boxen des Militärs noch so schmort. Wie gesagt, das kann ja keiner mal zeigen,
was die bei Palantier gemacht haben. Die haben halt echt so Open-Source-Modelle genommen und
zusammengedübelt. Naja, aber Palantier ist ja auch nur das, was allgemein bekannt ist und die
allgemeine Zielscheibe für das, wie man es nicht machen ist, meistens im öffentlichen Diskurs.
Das hat halt diesen üblen Neumund. Ich weiß nicht, ob er zu Recht oder zu Unrecht ist,
weil, wie gesagt, ich kenne die Internals nicht so gut wie du. Aber ich sehe auch die Gefahr,
dass wir sozusagen als Intellektuelle auf das Ding gucken, die zu theoretisch sind. Die
Intellektuellen sind ja so ein bisschen Teil des Dschungels, des menschlichen Halbmeins. Aber sie
sind nicht die Lianen, die den Dschungel zusammenbinden zwischen den Bäumen, sondern sie sind eher so
postillierliche Lemuren, die diesem Dschungel hocken in den Ästen und mit Faszination all die
Dinge anstarren, die sie gerne fressen möchten. Also wir sind diejenigen, die sozusagen die
Freiheit haben zu denken, weil wir keine Macht nehmen und keine haben wollen und versuchen aus
dem System so weit rauszuhalten, dass wir den Luxus haben, uns eigenständige Gedanken machen zu
können. Aber das heißt auch, dass wir oft nicht genügend eingebaut sind in das System, um zu wissen,
zu welchem Grad unsere Meinungen belastbar sind. Also ich persönlich kann ganz schlecht einschätzen
und habe auch weniger Meinung darüber, je älter ich werde, weil ich mir bewusst wird,
wie schlecht ich das einschätzen kann, wie sehr unsere Machtstrukturen, teilweise außerhalb der
offiziellen Machtstrukturen unserer westlichen Gesellschaft noch konsolidiert sind, um wie weit
sie in die Zukunft planen, wie weit sie in der Lage sind zu verstehen, was KI eigentlich bedeutet
und bedeuten wird. Ich habe den Eindruck, dass die Regierungen gerade sehr reaktiv sind. Ich hatte
auch den Eindruck, dass unsere Regierungen im Ukraine-Krieg extrem reaktiv vorgegangen sind.
Ich weiß nicht, ob irgendwo noch Erwachsene zu Hause sind. Ich weiß nicht, warum wir dann noch
da sind, wenn das so ist. Momentan existieren diese Systeme einfach nur durch reine
Hauungsvermögen. Wenn das aber so ist, dann wird es so sein, dass wahrscheinlich in Kürzzeit sich
das ändern wird, weil die KI natürlich auch dazu führen wird, dass Individuen, die Macht übernehmen
wollen in der Gesellschaft, wesentlich mehr Möglichkeiten dazu haben, sich zu koordinieren.
Ich glaube, dass die nächsten Jahre sehr wild werden.
Na ja, okay, da sind wir uns einig, ob es jetzt wirklich Koordination sein wird. Ich glaube eher,
dass es...
Ja, Konkurrenz im Moment ist doch jeder für sich selbst.
...symmetrische Überraschungen wird, glaube ich, eher der ausschlaggebendere Faktor sein.
Mich stört so ein bisschen deine Annahme, dass irgendwie, wenn die Militärs nur besseres
Detailwissen hätten oder irgendwie genauere Modelle, dann könnten sie besser Entscheidungen
treffen.
Verstöre dich daran?
Wie kommst du darauf? Das entspricht halt überhaupt nicht meiner Erfahrung mit Entscheidungsträgern.
Das wird überhaupt nicht auf Basis von irgendwelchen Fakten und Wissen gemacht, sondern halt so
Golfplatz. Warum soll das beim Militär anders sein?
Na ja, also man muss schon... Also wenn man jetzt so eine Militärstruktur sich mal so ganz,
ganz grob anguckt, dann ist es ja eine Organisationsstruktur, die versucht,
eine Meritokratie zu sein, dabei natürlich failed, aber zumindest ist es irgendwie ihr
Grundanspruch und die, bei der zumindest in einem Konfliktfall, siehst du ja halt relativ
häufig, dass irgendwie generell gefeuert werden oder irgendwelche Einheitenkommande
irgendwie abgesetzt werden und so, wenn sie halt Fehlschläge haben. Das heißt also in
einem Konfliktfall ist ein Militär zumindest, wenn es jetzt nicht in einer Diktatur operiert,
relativ, also ein relativ davenistischer Organismus.
Eine Diktatur ganz besonders. Also das Ding ist, als der Zweite Weltkrieg losging,
war die Rote Armee noch nicht sehr gut organisiert und in einem nackten Kampf ums Überleben,
wo Stalin hinten noch mal draufdrückte, indem er Leute, die in die falsche Richtung liefen,
erschoss, wurde die Rote Armee schlagkräftiger und die Wirtschaft der Sowjetunion wurde in
eine Kriegswirtschaft umgewandelt. Und das Ähnliches ist möglicherweise unter Putin
wieder passieren.
Da kann man geteilter Meinung zu sein, ob das der effizienteste Weg zum Ziel war.
Das ist nicht mit der effizienteste, aber was passiert ist, dass eine Armee ist ein
im Wesentlichen modernistisches System. Das heißt eins, dass mit der Ground Truth interagieren
muss oder man stirbt. Und wenn man aber in der Welt lebt, die too big to fail ist, zum
Beispiel ein Unternehmen, das so groß geworden ist, dass es sich mal kaputt geht und inzwischen
ist die zweite oder dritte Generation der Führerschaft da, dann wird das postmodern.
Das heißt, die Administration handelt eher von der Bewertung der Kritiker. Das geht um
die Performance. Und das, was du beschreibst, dass die Entscheidungen auf dem Golfplatz
getroffen werden, das sind sozusagen zivile Systeme, die too big to fail sind. Aber wenn
du ein Start-up hast, kannst du dir das eventuell nicht leisten, weil …
Ja, aber das Militär ist doch kein Start-up, hör mal. Das Militär ist doch der Inbegriff
von too big to fail. Das ist doch egal, was sie tun. Die können nie irgendwie ohne Militär
machen. Wenn die Regierung, die sich das Militär leistet und umgekehrt Interesse mit überleben
hat, dann lässt sie das nicht zu, dass das Militär so weit verkommt.
Also aus anderem schon.
Na ja gut, ansonsten gehst du halt kaputt im nächsten Konflikt.
Ja, aber guck mal, das ist … Ich hab auch jahrelang war ich überzeugt davon, dass bei
uns viel zu viel irgendwie Hawks Einfluss haben. Und jetzt hab ich eher den umgekehrten
Eindruck, dass die zwar alle so getan haben, so performative Militärausgaben gemacht haben,
aber offensichtlich nicht mit dem Ziel, hier ein funktionierendes Militär hinzustellen.
Also je mehr das Militär versucht, in der Öffentlichkeit gut auszusehen und sich aktuellen
Moden zu unterwerfen, ideologischen, moralischen, symbolischen, kulturellen Moden, desto bedenklicher
ist es, glaub ich. Weil das bedeutet, dass das Militär auch postmodern wird.
Also ich begrüße das als Pazifist. Ich glaub auch nicht, dass wir hier tatsächlich uns
auf den Konflikt vorbereiten müssen. Insofern hab ich da jetzt kein Problem damit. Mich ärgert
nur, wie viel Geld da ausgeschmissen wird für Projekte, die wir dann gar nicht brauchen und
die eh nicht funktionieren am Ende. Ja, ich meine, für das Geld könnte man auch
einfach Atomwaffen bauen, dann wäre einfach der Fischköpf geputzt.
Ich glaub, das ist ein gutes Schlusswort. Frankbord, Atombomben.
Ja, die KI wird möglicherweise die Atombomben besiegen. Das Ding ist,
die Informationsverarbeitung der Atombomben ist immer noch abhängig von Informationsnetzwerken,
die sich überall ausbreiten und dann alles hineinreichen. Und irgendwann wird die
Computersicherheit nicht mehr von Menschen gemacht werden können.
Aber bis dahin verdiene ich noch ein paar Euro.
Das ohne jeden Zweifel. Na gut, dann benutzen wir das mal als Schlusswort. Vielen Dank.
Mein Gott, was für eine Diskussion heute. Ein bisschen mit Glitten.
Na ja, egal. Also es war auf jeden Fall nicht über
viel gut Teams mit viel gut Rhetorik, sondern wir haben lauter heiße Eisen
angefasst und harte Themen, habt diskutiert. Schon in Ordnung.
Ja, gut, dann vielen Dank fürs Zuhören. Vielen Dank, Joscha, fürs hier sein.
Vielen Dank. Es hat großen Spaß gemacht, sich mit euch zu unterhalten.
Und dann hören wir uns das. Immer gerne.
Sogar die Fliege gibt Ruhe. Ja, die Fliege war erstaunlich zurückhaltend.
