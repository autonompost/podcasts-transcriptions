# After Alignment: Orienting Synthetic Intelligence Beyond Human Reflection 

```
Source https://www.youtube.com/watch?v=_DMn7CnsOQg
```

Die Geschichte der KI und die Geschichte der Philosophie der KI sind eng miteinander verwoben, von Leibniz über Turing und Hubert Dreyfus bis heute. Gedankenexperimente treiben Technologien voran, die wiederum das Verständnis dessen, was Intelligenz ist und werden könnte, verändern und so weiter und so fort. Aber damit die Philosophie heute, in dieser Phase der KI, ihren Weg findet, muss sie sich von der europäischen philosophischen Tradition lösen, um herauszufinden, was KI überhaupt ist. Und die Konnotation von künstlicher Intelligenz aus der Deng-Ära in China war eine Art von industrieller Massenmobilisierung. In Osteuropa gibt es das, was Stanislav Lem als existenzielle Technologien bezeichnete, und in der Sowjetära bedeutete es eher so etwas wie eine Rationalisierung der Verwaltung. All dies steht im Gegensatz zu den westlichen individualisierten und singulären anthropomorphen Modellen, die auch heute noch die zeitgenössischen Debatten beherrschen. Wer also ernsthaft über die planetarische Vergangenheit und Zukunft der KI nachdenken will, muss nicht nur unsere Vorstellungen von Künstlichkeit und Intelligenz als solche erweitern und verändern, sondern auch in gewissem Maße, fast zwangsläufig, aus diesen Traditionen schöpfen und sie hinter sich lassen. Was zum Beispiel Turing in seinem berühmten Test als hinreichende Bedingung für Intelligenz vorschlug, ist stattdessen zu solipsistischen Forderungen und Fehleinschätzungen geworden. Die Idealisierung dessen, was in der KI als das meiste menschliche Zitat erscheint und funktioniert, sei es als Lob oder als Kritik, schränkt unser Verständnis dessen, was maschinelle Intelligenz ist, willentlich ein. Und das gilt auch für die Sprache selbst. Große Sprachmodelle und ihre unheimlich überzeugenden Text- und Vorhersagefähigkeiten werden genutzt, um Romane und Drehbücher zu schreiben, Bilder in Filmen, Lieder, Stimmen, Symphonien zu erzeugen und werden sogar von Biotech-Forschern genutzt, um Gensequenzen für die Medikamentenentwicklung vorherzusagen. Zumindest hier ist die Sprache der Genetik wirklich eine Sprache. LLMs bilden auch die Grundlage für generalistische Modelle, die in der Lage sind, Inputs und Outputs von einer Modalität zur anderen zu mischen, zu interpretieren, was ein Bild sieht, und so die Bewegung eines Roboterarms anzuweisen und so weiter. Solche grundlegenden Modelle können zu einer neuen Art von öffentlichem Nutzen werden, um den herum sich die Industriezweige organisieren, was wir kognitive Infrastrukturen nennen. Und was ist mit ihrer spekulativen Philosophie? Ehrlich gesagt glaube ich nicht, dass die Gesellschaft derzeit über die kritischen und konzeptionellen Voraussetzungen verfügt, um diese Realität richtig anzugehen. Wie ein Mitautor und ich kürzlich schrieben, Zitat, ist die Realität, die die Grenzen des bequemen Vokabulars überschreitet, der Anfang, nicht das Ende des Gesprächs. Anstelle von Murmeltier-Debatten darüber, ob Maschinen eine Seele haben oder so denken können, wie der Mensch sich das vorstellt, sollte die fortlaufende Doppelhelix-Beziehung zwischen KI und Philosophie weniger ihre eigenen Maximen projizieren und stattdessen neue, nuanciertere Vokabeln für Analyse, Kritik und Komposition konstruieren, die auf der Verrücktheit direkt vor unseren Augen basieren. Und das ist das eigentliche Thema meines Vortrags: die Seltsamkeiten, die uns direkt vor Augen stehen, und die Unbeholfenheit unserer Sprache, sie zu erfassen. In diesem Zusammenhang möchte ich noch einmal darauf hinweisen, dass die Unklarheiten darüber, ob Maschinenintelligenz als Geist, Empfindungsvermögen oder Bewusstsein bezeichnet werden kann, eher auf unsere Sprache und unsere Vorstellungskraft zurückzuführen sind als auf das, was tatsächlich passiert ist und passieren wird. Das produktive Interesse könnte weniger damit zu tun haben, wie die KI sich an frühere Modelle hält, sondern vielmehr damit, was sie über die Grenzen dieser Modelle offenbart und bewirkt. Ich sage also: offenbart und tut. Warum die Trennung? Nun, anstatt davon auszugehen, dass zuerst Ideen entstehen und dann Werkzeuge eingesetzt werden, um sie umzusetzen, können wir stattdessen beobachten, dass unterschiedliche Werkzeuge unterschiedliche Ideen ermöglichen. Sie laden nicht nur dazu ein, die Welt anders zu betrachten, sondern machen die Welt auf eine Weise denkbar, die sonst unmöglich wäre. In Anlehnung an Lem, genauer gesagt an Stanislaw Lem, und seinen Begriff der Unterscheidung zwischen epistemologischer und instrumenteller Technologie, könnten wir sagen, dass einige Arten von Technologien die größten sozialen Auswirkungen haben, weil sie die Welt künstlich verändern können. Diese sind instrumentell. Andere hingegen haben eine größere soziale Wirkung, wenn sie uns zeigen, wie die Welt funktioniert. Das sind epistemologische Technologien. Teleskope und Mikroskope sind gute Beispiele dafür. Ja, sie ermöglichen die Wahrnehmung des ganz Großen und des ganz Kleinen, aber noch wichtiger ist, dass sie eine kopernikanische Wende im Selbstverständnis ermöglichen und uns selbst als Teil der planetarischen und sogar außerplanetarischen Bedingungen begreifen. Mit solchen Verschiebungen war es möglich, sich nicht nur daran zu orientieren, wo der Planet ist, sondern auch daran, wo und wann und was, Zitat, wir sind. Zusammengenommen kann man diese Technologien auch als epistemologische Technologien bezeichnen. Auch hier steht fest, dass die Computertechnik die Welt künstlich verändert, und zwar in Form einer zufälligen Megastruktur, die Politik, Wirtschaft und Kultur nach ihrem eigenen Bild verändert. Die Computertechnologie ist aber auch eine epistemologische Technologie, die den Kurs der planetarischen Lebensbedingungen neu bestimmt hat, bestimmt und bestimmen wird. Wir können sogar sagen, dass der Planet als solcher ein Bild ist, das durch Berechnungen entsteht, z. B. durch die Klimawissenschaft, die natürlich auf Planetensensoren und -modellen und vor allem auf Supercomputersimulationen der Vergangenheit, Gegenwart und Zukunft des Planeten basiert. Die Idee des Klimawandels selbst ist also eine erkenntnistheoretische Errungenschaft der planetarischen Berechnungen. Und damit indirekt auch die Idee des Anthropozäns und der Menschheit als Terraforming-Subjekt. Und das ist es, was auf dem Spiel steht. Um es ganz offen zu sagen: In dieser Hinsicht kann mein eigener Ansatz für eine Philosophie der Technologie in gewisser Weise als Umkehrung des von Heidegger beklagten Unbehagens verstanden werden, für den die Entfremdung der intuitiven Gegebenheit der Welt aus technischen Gründen ihr und in der Tat unser Untergang ist. Ich hingegen glaube, dass er es genau umgekehrt sieht. Die Entfremdung, die kopernikanische Verrücktheit, die durch die technologische Vermittlung unserer Erkenntnis erreicht wurde, war und wird ein Weg sein, um zu etwas zu gelangen, das man Sein nennt. Noch einmal: wo wir sind, wann wir sind, wo wir sind und wie wir sind. Aber die KI legt diese Dinge nicht nur offen, sie zwingt uns auch, sie zu hinterfragen. Wir erleben dann verschiedene Arten von KI-Überhängen und - wenn du so willst - Unterhängen. Ein KI-Anwendungsüberhang bedeutet, dass die Technologie in der Lage ist, Dinge zu tun, die eine Gesellschaft aus guten oder schlechten Gründen nur schwer integrieren, modellieren oder übernehmen kann. Was in unserem Antikythera-Programm, einem der Meta-Wissenschaftsprojekte von Darren Zhu, Will Freudenheim und Imran Sekolala, als epistemischer Überhang der KI bezeichnet wird, bedeutet hingegen, dass die KI in der Lage ist, Dinge zu entdecken, zu wissen und zu enthüllen. Die menschliche Wissenschaft tut sich schwer damit, diese zu modellieren, zu integrieren und zu übernehmen. Wir sind der Meinung, dass Letzteres nicht nur ein Problem der Wissenschaft ist. In seiner Allgemeinheit ist es in vielerlei Hinsicht der Schwerpunkt dieses Vortrags. Zunächst also zum Thema Anpassung. Was bedeutet es, maschinelle Intelligenz zu bitten, sich an den Wünschen und dem Selbstverständnis des Menschen auszurichten? Ist dies eine nützliche Taktik für das Design oder eine zweifelhafte Metaphysik, die verschleiert, wie sich Intelligenz als Ganzes entwickeln könnte? Angesichts der Tatsache, dass sich KI und KI-Philosophie in einer engen Verbindung entwickelt haben, die sich gegenseitig informiert und abgrenzt, stellt sich die Frage, wie wir diesen Rahmen in Theorie und Praxis neu überdenken sollten. Oder lassen Sie es mich etwas anders ausdrücken. Wenn der Stack die Topologie der planetarischen Datenverarbeitung beschreibt, stellt sich die Frage, wozu die planetarische Datenverarbeitung gut ist. Wir könnten darauf bestehen, dass die Entwicklung der maschinellen Intelligenz in Richtung einer Art planetarischer Intelligenz gelenkt werden muss, um eine tragfähige langfristige Zukunft zu gewährleisten. Anstatt sich stark an menschlichen Werten zu orientieren und oberflächlich anthropozentrisch zu sein, müssen wir diesen Humanismus mit einem differenzierten Misstrauen betrachten und stattdessen ein breiteres Potenzial erkennen. Es geht nicht nur darum, was KI ist, sondern auch darum, was eine Gesellschaft ist und wozu sie gut ist. Und was soll mit was zusammenpassen? Der Begriff "künstliche Intelligenz" bezieht sich in unserem Sprachgebrauch auf den weiteren Bereich der künstlich geschaffenen intelligenten Systeme, die sowohl mit den Traditionen des Humanismus übereinstimmen als auch nicht. Diese Systeme können natürlich die menschliche Kognition, Intuition, Kreativität, Abstraktion und Entdeckung ergänzen und sich mit ihnen verbinden. Aber als solche werden beide durch diese Verschmelzungen für immer verändert. Die maschinelle Intelligenz selbst kann, streng genommen, künstlich sein oder auch nicht. Wenn wir unter künstlich etwas verstehen, das absichtlich von einer vorhergehenden Intelligenz geschaffen wurde, dann ist die KI eine Form der maschinellen Intelligenz, die so geschaffen wurde. Aber so einfach ist es vielleicht nicht. Wir erkennen jeden Tag, dass es Formen von maschineller Intelligenz gibt, die echt sind und sich dennoch ohne absichtliches Design entwickelt haben. Schau dich einfach in der Stadt um. Und zweitens können wir herauszoomen und sehen, dass die Intelligenz, die etwas künstlich macht, selbst entwickelt ist. Ihre Artefakte sind also auch Teil dieser evolutionären Abstammung. Für diesen Vortrag bedeutet das vor allem, dass wir KI nicht einfach als direkte Widerspiegelung menschlicher Ideen, Kultur und Wirtschaft sehen sollten, ich wiederhole: nicht. Das sollte sie auch nicht sein, wenn es um die Anpassung geht. Direkt gesagt: Das Ausmaß, in dem sie die menschliche Kultur direkt widerspiegelt, ist weder Ziel noch Realität. Das Ausmaß, in dem sie von der menschlichen Kultur abweicht, ist weder eine Katastrophe, noch ist es eine Hypothese. Diese Abweichung ist in der Tat unsere Realität. Dass die menschliche Intelligenz die KI auf eine lebensfähige planetarische Zukunft ausrichten muss oder sollte - das ist der von uns bevorzugte Begriff - ist unerlässlich. Aber auch hier gilt, dass diese Zukunftsfähigkeit nicht einfach dadurch erreicht wird, dass die KI uns ähnelt, uns bewundert oder sich unseren Wünschen unterwirft. Ganz im Gegenteil. Offensichtlich gibt es eine Überschneidung zwischen der Ethik der KI auf der einen und der Ausrichtung der KI auf der anderen Seite. Aber es gibt auch eine Art Sackgasse zwischen ihnen. Oder zumindest im Prinzip einen Widerspruch zwischen ihren Visionen. Die KI-Ethik, vor allem im Zusammenhang mit populären Experten und so weiter, besteht darauf, dass die KI einfach ein Spiegelbild der menschlichen Gesellschaft ist, wenn man sie dazu überredet. Von ungerechten Vorurteilen und ungleichen Wirtschaftssystemen, die sie hervorbringen. Sie versucht, KI als uns zu entmystifizieren. Nicht mehr. Und nicht weniger. Als Theorie fordert sie uns auf, jede Technologie, insbesondere KI, grundsätzlich als ontologisch artefaktisch zu betrachten. KI-Ausrichtung hingegen, und auch hier entspricht meine Abstraktion eher den populären und populistischen Erscheinungsformen als einer tieferen, ernsthaften Forschung. Die Ausrichtung geht davon aus, dass das potenzielle existenzielle oder zumindest ernsthafte Risiko der KI in der Tatsache begründet ist, dass sie sich von den menschlichen kulturellen Werten und Normen so weit entfernt hat. Und dass die Sicherung einer sicheren Zukunft bedeutet, sie an diese Werte und Normen zu binden. Du siehst also das theoretische Problem. Wie kann KI sowohl automatisch menschliche Vorurteile und Werte widerspiegeln, als auch gefährlich unreflektiert menschliche Vorurteile und Werte widerspiegeln? Wie können die Positionen, die sich zwischen meinem Cartoon-Binär bewegen, gleichzeitig die scheinbar widersprüchliche Schlussfolgerung ziehen? Wie können wir feststellen, dass die KI wie wir ist, was schlecht ist, und gleichzeitig feststellen, dass sie nicht wie wir ist, was ebenfalls schlecht ist? Nun, es kann beides sein, aber nur, wenn wir das, was wir unter Angleichung verstehen, radikal qualifizieren und spezifizieren und eine solche Angleichung zulassen, dass sich die KI nicht nur den gesellschaftlichen Normen beugt, sondern sich die Gesellschaft auch im positiven Sinne in Bezug auf die erkenntnistheoretischen und instrumentellen Möglichkeiten der KI weiterentwickelt. Bevor ich also näher darauf eingehe, was ich mir vorstelle, möchte ich noch einmal klarstellen, was ich mir nicht vorstelle und was ich nicht meine. Die möglicherweise sehr vernünftige Perspektive, dass KI und potenzielle AGI ein existenzielles Risiko darstellen und daher im Mittelpunkt der geopolitischen und geosozialen Debatte stehen sollten, ist in der Öffentlichkeit nicht immer so gut vertreten worden, wie es sein sollte. Die moralische Panik der KI überwältigt die fantasievolle Vernunft in mehreren gleichzeitigen moralischen Paniken der KI, die um Aufmerksamkeit, Sauerstoff und Hegemonie konkurrieren. Diese reichen von den eher vorhersehbaren amerikanischen Kulturkriegsschablonen, die sich weniger darauf konzentrieren, was gesagt wird, als darauf, wer es sagt, bis hin zu einer seltsamen Umkehrung, bei der einige der bekanntesten schwärmerischen, millenarischen Visionen von KI ohne Umschweife zu apokalyptischen, eschatologischen Ideen übergegangen sind. Von der Singularität zum Unibomber und zurück ist die neue Hufeisentheorie der KI-Politik. Der Hype um den Untergang implodiert in sich selbst. Anderswo, aber nicht allzu weit entfernt, verbrachten viele öffentliche Intellektuelle den Frühling 2023 mit einem vielleicht gut gemeinten Frömmigkeitsspiel, um herauszufinden, wer sagen kann, dass wir in Wirklichkeit mehr am Arsch sind. Du sagst, wir sind am Arsch wegen der KI. Ich sage, wir sind mehr im Arsch als du. Manchmal mündete das Spiel in öffentlichen Briefen, in denen Besorgnis geäußert wurde. Sie waren von unterschiedlicher Qualität und intellektueller Legitimität, aber fast alle wurden von sehr guten und klugen Menschen unterzeichnet. Der fragwürdigste von ihnen forderte die Verantwortlichen auf, den imaginären roten Pausenknopf für die KI zu drücken, bis wir herausgefunden haben, was los ist, wie der Mann sagte. Wohl wissend, dass es einen solchen Knopf nicht gibt. Dass die bösen Akteure nicht mitspielen werden und dass sie vielleicht selbst davon profitieren werden, wenn sie ihre Besorgnis auf diese Weise signalisieren. Vor allem aber, dass es im Gegensatz zu Außerirdischen in einem Science-Fiction-Film, die landen und sagen: "Bringt mich zu eurem Anführer", keine Bittsteller gibt, wenn es um die ernsten, ernsten Risiken geht, die erkannt wurden. Wer die Verantwortung trägt, ist die richtige Frage. Und ich würde gerne glauben, dass das Aufwerfen dieser Frage der eigentliche Sinn und hoffentlich auch die Wirkung der Briefe war. Abgesehen davon ist klar, dass der gegenwärtige Diskurs über KI ironischerweise beispielhaft für die Art von Diskurs ist, vor der uns der Diskurs über KI warnt. Stammesdenken, Übertreibungen, Unwahrheiten, unnötige Dominanz desjenigen, der am lautesten redet und das Ungeheuerlichste sagt, und das alles verstärkt durch Werbemaschinen. Einige Kritiker gehen sogar so weit zu behaupten, dass KI weder künstlich noch intelligent ist. Sie sagen, dass sie nicht künstlich ist, weil sie von Menschen zu bestimmten Zwecken aus physischen Materialien hergestellt wird, was die eigentliche Definition des Künstlichen ist. Sie sagen, dass sie nicht intelligent ist, weil sie lediglich Probleme modelliert und löst, was in vielerlei Hinsicht eine gute Kurzdefinition für eine allgemeine Theorie der Intelligenz ist, die das Gefühl, ein Mensch zu sein, einschließt, aber nicht ausschließt. Sie sagen, dass KI nicht künstlich ist, weil sie menschlich gemacht ist. Andere gehen vielleicht noch einen Schritt weiter und vertreten eine Position, die wir als KI-Leugnung bezeichnen könnten. Das heißt, KI gibt es nicht wirklich. Lass dich nicht täuschen. Sie ist nur eine Statistik. Sie ist nur ein Gradientenabstieg. Das ist ein bisschen so, als würde man sagen, dass eine Symphonie nicht existiert, sondern nur Schallwellen sind. Oder dass es keine Nahrung gibt, sondern nur Moleküle. All das ist trivialerweise wahr, aber diese KI-Leugnung ist nicht im Entferntesten hilfreich, wenn es um die Anliegen geht, für die sie vorgibt zu stehen, indem sie dieses spezielle Argument vorbringt. Die Sache ist die, dass sie in der Regel als Teil einer politischen Position in Bezug auf die Ökonomie der KI vorgebracht wird, die oft durchaus legitim ist und die dann zu einer ontologischen Behauptung aufgestockt wird. Und so ist es vielleicht schwierig, aus dem Denialismus auszusteigen, weil er die Gültigkeit der Politik in Frage zu stellen scheint. An anderer Stelle geht der KI-Denialismus Hand in Hand mit dem, was wir als KI-Abschaffung bezeichnen könnten. KI existiert nicht wirklich, sollte aber trotzdem abgeschafft werden. Nun, es gibt hier viel auszupacken und um diesen Positionen gerecht zu werden und die KI-Kritik auf diese Weise systematisch zu kritisieren, bräuchte es mindestens noch ein paar weitere Vorträge, aber lassen Sie mich nur die Pointe dieser anderen Vorträge nennen, denn sie ist auch die Pointe dieses Vortrags oder eines davon. Es gibt mehrere. Der Soziomorphismus, der besagt, dass KI ein Abbild der menschlichen Gesellschaft ist oder sein sollte, ist die logische Fortsetzung des Anthropomorphismus, der besagt, dass KI das Abbild eines einzelnen Menschen ist oder sein sollte. Beides ist keine echte Alternative zur planetarischen Hegemonie einer kalifornischen Ideologie. Sie sind sogar der Gipfel der Hegemonie. Die stark anthropomorphe Sichtweise auf KI geht mindestens auf den Turing-Test zurück, bei dem das, was er als hinreichende Bedingung für die Identifizierung von Maschinenintelligenz anbot, zu einer notwendigen Bedingung wurde. Das heißt, wenn eine KI nicht in der Lage ist, so zu denken, wie ein Mensch denkt, dann ist sie disqualifiziert. Diese Idealisierung dessen, was wir als Reflexionismus bezeichnen könnten, hat sich auch im Psychologismus des Human-Centered Design manifestiert, der sich, wie sich herausstellte, als eine sehr gemischte Sache erwies, und ist auch in dem jetzt umstrittenen Terrain der Human-Centered AI, der humanistischen KI usw. zu finden, die vielleicht viele der gleichen Fehler wie das Human-Centered Design begehen. Ich werde gleich auf das eingehen, was wir Human-AI Interaction Design (HAID) nennen. Wir in Antikythera sind sehr an dieser Idee interessiert, nicht trotz, sondern gerade wegen ihrer Verrücktheit und Komplexität. Wir interessieren uns auch für die Verrücktheit, die durch den Versuch, das Schlechte auszumerzen, gewährleistet wird. Das letzte Jahrzehnt der KI-Ethik hat sicherlich eine Menge schrecklicher Dinge verhindert. KI-Forscherinnen und -Forscher haben selbst zu vielen der Kerntechnologien beigetragen, die wir heute nutzen, insbesondere zu den Skalierungsgesetzen für ROHF. Gleichzeitig hat sich die Ethik aber auch zufällig mit den Markeninteressen der Unternehmen verzahnt, so dass wir heute KIs haben, die so lobotomiert sind, dass sie niemals sinnvoll über Sex und Gewalt sprechen. Wir haben prüde KIs. Wir alle ahnen, wie schlimm es werden könnte, wenn die schlimmsten menschlichen Ängste direkt mit der Macht der Basismodelle in Einklang gebracht würden. Aber gleichzeitig denken wir auch über die entscheidende Rolle von Sex und Gewalt in der Evolution der tierischen Intelligenz nach, einschließlich der unseren. Und so erkennen wir die Seltsamkeit der maschinellen Intelligenz, die sich mit diesen Themen entwickelt, als unaussprechlich an. Um es noch einmal klarzustellen: Meine Position soll nicht auf Kosten der KI-Ethik- und Alignment-Forschung gehen, sondern mit deren Schlussfolgerungen übereinstimmen, dass Ethik und Alignment als solche zwar notwendige, aber unzureichende Rahmenbedingungen für die langfristige Ausrichtung der maschinellen Intelligenz sind. Mit anderen Worten: Die Überanpassung ist real. Meine Sorge ist jedoch, dass die Erschöpfung mit dem technischen Solutionismus einer selbstgefälligen Parade des politischen Solutionismus weicht, der jetzt die Meinungsspalten, Fachbücher und ja, auch Schulen und Universitäten überflutet. Auf dem Kontinent führt die Unfähigkeit zu begreifen, wie die planetarischen Berechnungen die Formen der westfälischen Staatsbürgerschaft aus dem 18. Jahrhundert auf den Kopf stellen, zu regulatorischem Solutionismus, zu KI-Gesetzen, die sich mit den Problemen von gestern befassen, und dazu, dass die EU immer dorthin rennt, wo der Ball nicht mehr ist. Sie versucht, die Dynamik des Planeten in eine Politik auf Bürgerebene zu zwängen. Der ständige Fokus auf die Daten der einzelnen Bürgerinnen und Bürger ist in einer Welt nach der Pandemie wahrscheinlich der falsche Ansatzpunkt für die Politik. Der Ausweg ist, den Knoten der schwächsten Form des Reflexionismus zu durchschlagen, den wir als das moralische und praktische Axiom definieren könnten, dass KI ontologisch anthropomorph ist oder sein sollte. Technologien erschöpfen sich nicht nur nicht in der Projektion sozialer Beziehungen auf sie, sondern können auch neue praktische Konzepte erzwingen, die diesen sozialen Beziehungen von vornherein zuwiderlaufen. Der Schaden liegt also nicht nur darin, worauf der Reflexionismus unsere Aufmerksamkeit lenkt, sondern vor allem darin, wovon er unsere Aufmerksamkeit ablenkt, um es einmal so auszudrücken. KI stellt ein existenzielles Risiko und ein existenzielles Potenzial im doppelten Sinne des Wortes dar. Damit meine ich nicht, dass sie uns umbringen könnte oder nicht, sondern dass sie der menschlichen und tierischen Intelligenz, der planetarischen Intelligenz, grundlegende Wahrheiten darüber offenbaren könnte, was wir sind und was ihr existenzieller Zustand wirklich ist, oder nicht. Das ist das kopernikanische Risiko-Ertrags-Kalkül, das weder messianisch noch apokalyptisch ist. Du hörst vielleicht meine Kritik am oberflächlichen Anthropomorphismus der KI und sagst: Ja, aber wie sich herausstellt, spiegelt die KI die menschliche Intelligenz in einigen wichtigen Punkten wider. Im Gegensatz zum oberflächlichen Anthropomorphismus, der darauf besteht, dass die KI so denkt, wie der Mensch denkt, dass der Mensch denkt, gibt es auch einen tiefen Anthropomorphismus, oder besser gesagt, einen tiefen Biomorphismus, der dem entspricht, wie Menschen und andere Tiere wirklich denken, auch wenn sie das Denken nicht so erleben. Das ist nicht nur wahr, sondern auch tiefgründig, und das ist, wie ich schon sagte, das, was der seichte Reflexionismus modelliert. Erst kürzlich wurde zum Beispiel erforscht, wie KIs Kanten in Bildern erkennen. Dabei stießen die Forscher auf noch nicht identifizierte, nicht näher bezeichnete neuronale Mechanismen im menschlichen Gehirn, die mehr oder weniger dasselbe tun. Wie ich gleich in Bezug auf eines der Projekte von Antikythera erläutern werde, werden KIs zu einer Art Versuchsorganismus, wie eine Laborratte, an der man menschliche Bedingungen und Reaktionen testen kann. Das würde nicht funktionieren, wenn es keine grundlegende Entsprechung gäbe. Aber was die Qualität dieser Übereinstimmung ist und was nicht, ist von echtem philosophischen und praktischen Interesse. Wir sehen auch, vielleicht auf einer höheren Abstraktionsebene, dass die iterative Vorhersagedynamik von Transformatormodellen mit der iterativen Vorhersagedynamik biologischer Neuronen übereinstimmt. Das war nicht geplant, aber es ist so. Ja, du bist also tatsächlich ein stochastischer Papagei. Das war schon immer so. Aber du solltest das nicht als die Beleidigung auffassen, die die Autoren des berüchtigten Artikels vielleicht beabsichtigt haben. Iterative stochastische Vorhersagen und das Denken durch die Rekursionen der mentalen Simulation und die eingebettete verkörperte Wahrnehmung haben die Menschen all die Dinge geschaffen, die dir am Herzen liegen. Literatur, Musik, Wissenschaft und so weiter. Papageien sind übrigens sehr klug und kreativ und eignen sich daher nicht besonders gut als Beispiel für gedankenlose Wiederholungen, aber das ist eine andere Sache. Die tiefere Übereinstimmung zwischen iterativen stochastischen Vorhersagen und künstlichen und natürlichen Systemen ist technisch gesehen ein Anthropomorphismus, aber wie gesagt, es ist wahrscheinlich besser, es einen Biomorphismus zu nennen. Und das legt eine andere Art von AGI nahe, eine künstliche generische Intelligenz. Und genau das ist der Punkt. Die Betonung der Übereinstimmung zwischen KI und dem offensichtlichen Bild menschlichen Denkens, menschlicher Intelligenz und menschlicher Kultur hat einen schrecklichen Preis: Sie verdeckt die reale und zutiefst bedeutsame Übereinstimmung zwischen tierischer und maschineller Intelligenz, die nicht bereits in den gängigen kulturellen Normen verankert ist, die diese Normen aber an der zugrunde liegenden Realität orientieren könnte, aus der sie hervorgeht. Ein anderer bidirektionaler Weg der Angleichung und für die Angleichung. Wohlgemerkt, ich sage "aus denen sie hervorgehen" und nicht die Realität, die aus diesen kulturellen Normen hervorgeht. An diesem Punkt unterscheidet sich unser Ansatz vielleicht von anderen, die in den Geisteswissenschaften angeboten werden. Es geht um etwas sehr Grundsätzliches: Was ist in was drin? Der Planet macht Welten oder Welten machen Planeten. Ich sage, dass wir vermeiden müssen, was die tieferen und philosophisch anspruchsvolleren Wege verdeckt, auf denen KI zwar wie Gehirne denkt, sich aber gleichzeitig nicht an humanistischen Normen orientiert und damit menschliche Gehirne auf unbequeme Weise von menschlichen Werten entfernt. Auf unangenehme Art und Weise. Ist das der eigentliche Streitpunkt und das Unbehagen? In den extremsten Versionen des Reflexionismus erscheint mir das, was verteidigt wird, manchmal wie eine Art politisch-theologische Überzeugung, dass es nichts außerhalb des Textes gibt, wie man früher sagte. Nichts außerhalb der soziologischen Interpretation der Technologie. Die politische Ökonomie der Wissenschaft. Die Realität der Kultur als Bestimmungsfaktor der Realität. Nichts verursacht die Kultur, sondern die Kultur selbst. Kultur verursacht Kultur, die wiederum von mehr Kultur verursacht wird, und somit ist alles, auch die KI, ein Spiegelbild dieser Kultur und nichts anderes. Wir könnten dies als sozialen Reduktionismus und kulturellen Determinismus bezeichnen, der trotz aller Lippenbekenntnisse zum Posthumanismus die militanteste Form des Humanismus sein kann. Natürlich ist die KI in ihrer jetzigen Form glücklicherweise und leider auch ein Spiegelbild der Kulturen, die sie hervorgebracht haben, aber - und hier ist die vielleicht entscheidende Weggabelung. Sie ist nicht nur ein Spiegelbild der Kultur und sollte es auch nicht sein. Sie ist mehr. Wir sind mehr. Die künstliche Intelligenz selbst und, was noch wichtiger ist, die Eigenschaften der Realität, die durch die künstliche Intelligenz aufgedeckt werden, all die kopernikanischen Wendungen, die kommen werden, sind Dinge, denen sich die Kultur anpassen muss und wird. Nicht nur etwas, das sich an die Kultur anpassen muss und wird. Also, zwei Schlussfolgerungen. Nur einige. KI ist eine existenzielle Technologie und muss sich daher in beide Richtungen ausrichten. Die KI muss sich an der Weisheit der Kultur orientieren. Die Kultur an den Offenbarungen der KI. Erstens sollte die Ausrichtung in Kleinbuchstaben als Taktik gesehen werden, um die maschinelle Intelligenz zu instrumentalisieren und sie mit dem Handeln und der Absicht in Einklang zu bringen, damit sie funktioniert. Die Ausrichtung in Großbuchstaben und die damit verbundene Metaphysik ist jedoch eine unzureichende Grundlage für die langfristige Ausrichtung der maschinellen Intelligenz durch die tierische Intelligenz. Zweitens ist eine Ausrichtung in beide Richtungen möglich und wünschenswert. Die erkenntnistheoretischen Überhänge der KI, die Dinge, die sie weiß und von denen sie annimmt, dass wir sie wissen, die wir aber nur schwer begreifen, aufnehmen und integrieren können, sind keine Pathologien. Sie sind vielmehr der tiefere Sinn der KI. Zwischen KI als allgemeiner Intelligenz und KI als experimentellem Superorganismus, wie in einem unserer Antikythera-Projekte mit dem Titel The End of Science von unseren Studioforschern Darren Zhu und Connor Cook, wird KI zu einer unheimlich produktiven Art von Spiegel. Aber es ist kein Spiegel, der das widerspiegelt, was wir zu sein glauben, weil wir es sehen und fühlen können, sondern eher ein Spiegel dessen, was wir sind, aber nicht sehen und fühlen können. Zumindest noch nicht. Ich möchte dies nun näher erläutern und ein wenig auf die Arbeit eingehen, die wir im Rahmen des Antikythera-Programms geleistet haben, um diese und viele andere Ideen zu erforschen, und euch ein wenig über das Studio und vor allem über die Arbeit erzählen. Alle Projekte, die ich dir gleich in einer Art Zusammenfassung zeigen werde, wurden erst Ende letzter Woche fertiggestellt und in Los Angeles erstmals privat gezeigt. Und im Herbst werden wir wieder nach London kommen, um sie in einer größeren Ausstellung zu präsentieren. Antikythera ist, wie Stephanie schon sagte, ein Forschungsprogramm, eine Art Denkfabrik für die spekulative Philosophie des Rechnens. Es wird vom Berggruen Institut unterstützt und ist dort untergebracht. Wir freuen uns, dass Niels Gilman vom Institut heute Abend bei uns ist. Stephanie ist die stellvertretende Direktorin. Nikolai ist auch hier, mein langjähriger Freund und Mitarbeiter. Shrelka ist unsere Studiodirektorin und wir werden auch von Case Miller und Emily Knapp über Wasser gehalten und es scheint, dass wir jeden Tag wachsen. Das Programm umfasst mehr als 70 Partnerforscher aus der ganzen Welt und verschiedenen Universitäten und hat gerade in der letzten Phase 12 Studioforscher, die diesen Studiozyklus abgeschlossen haben. Es ist im Wesentlichen ein Programm, das nicht nur versucht, die planetarische Berechnung zu kartieren, sondern auch einige vorläufige Antworten auf die Frage zu geben, wozu die planetarische Berechnung gut ist. Wie ich bereits gesagt habe, hat sich die Philosophie und ganz allgemein das Projekt, tragfähige Konzepte darüber zu entwickeln, wie die Welt funktioniert, und somit darüber nachzudenken, wie die Welt funktioniert, immer in Verbindung mit dem entwickelt, was die Technologie offenbart und tut und somit, was man denken kann. Zumindest in dieser Hinsicht bin ich also so etwas wie ein technologischer Determinist, aber nur, wenn wir die Definition von Technologie so weit ausdehnen, wie es angemessen ist. Die Sache ist die. Im Moment hat die Technologie und insbesondere die planetarische Berechnung unsere Theorie überholt. Wie ich heute Abend bereits angedeutet habe, besteht die Antwort darauf darin, dass wir einer Situation, die nicht nur nach einem anderen Rahmen verlangt, sondern diesen auch bereits hervorbringt, bequeme und feste Vorstellungen von Ethik, Größe, Politik und Bedeutung aufzwingen. Anstatt also einfach die Philosophie auf das Thema Computer anzuwenden, gehen wir in die andere Richtung und entwickeln Ideen und Spekulationen aus der direkten Begegnung, aus der Herstellung von Dingen. Das eigentliche Interesse des Antikythera-Programms liegt also nicht so sehr in der Berechnung, der Formalisierung, der Quantifizierung und der Interoperabilität an sich, sondern in der Frage, wie die Berechnung Orientierung, Navigation, Kosmologie, im Grunde genommen einen Planeten schafft. Die Inspiration für den Namen stammt vom Antikythera-Mechanismus, der 1901 in einem Schiffswrack vor der gleichnamigen griechischen Insel entdeckt und auf etwa 200 v. Chr. datiert wurde. Aber er ist mit Sicherheit ein Ur-Computer. Aber er war nicht nur eine Rechenmaschine. Er war auch eine astronomische Maschine, die die Bewegungen der Sterne und Planeten kartierte und vorhersagte, jährliche Ereignisse markierte und eine Seekultur auf der Erdoberfläche ausrichtete. Sie berechnete also nicht nur ineinander greifende Variablen, sondern gab dem Denken eine umfassende Orientierung in Bezug auf die astronomischen Gegebenheiten und ermöglichte es dem präskriptiven Denken, in Bezug auf diese offengelegten Umstände zu handeln. Über die Formen der Berechnung hinaus, die bereits in natürlichen Systemen wahrnehmbar sind, ist eine künstliche Berechnung wie diese eine Art Weltordnung, eine Grundlage für das, was eine komplexe Kultur werden würde. Und das ist wirklich der Kern der Sache. Für unsere Initiative bezieht sich der Name Antikythera auf eine Rechentechnik, die die planetarische Bedingung der Intelligenz offenlegt und beschleunigt. Ich möchte nun etwas näher auf einige der Themen und Ideen des Programms eingehen und dir einige der Arbeiten zeigen, die im Hintergrund laufen, während ich ein wenig erkläre, woher sie kommen und was sie vorhaben. Einige der Projekte, nicht alle, sprechen direkt Fragen der KI an, und zwar ziemlich direkt Fragen der KI-Ausrichtung. Das Projekt HAI ID oder HAID, Human Artificial Intelligence Interaction Design von Antikythera Studio Researchers William Morgan, Sarah Olympia Scott und Daniel Barkay ist das, was du hier siehst. Es ist ein ständig wachsender Katalog von existierenden und fast existierenden Formen, Positionen und Syndromen der menschlichen KI-Interaktion, der es uns ermöglicht, den Raum zu kartieren und zu verallgemeinern. Es ist ein Kompendium von Hunderten von Betriebsmodellen, Syndromen, Mustern und beständigen Volksontologien. So bildet es nicht nur ein, sondern mehrere konzeptionelle Modelle ab, auf denen die Gestaltung menschlicher KI-Interaktion basieren könnte. Er sieht HAID als eine Art Teilbereich von HCI, der diesen Bereich aber wohl überwältigen und neu definieren wird, vor allem, wenn persönliche KI in größerem Umfang auf Plattformen eingesetzt wird. Wie ich bereits betont habe, sind die Geschichte der KI und die Geschichte der Philosophie der KI eng miteinander verwoben. Auf der einen Seite des Buches finden sich zahlreiche Gedankenexperimente, sowohl kanonische als auch obskure: das Nachahmungsspiel, das chinesische Zimmer, der Büroklammermaximierer, das Problem der drei blauen Bananen, Samanthas Untreue, der fahrerlose rote Wagen und so weiter. Diese Gedankenexperimente reagierten auf die Ausweitung der KI und trieben ihrerseits die Weiterentwicklung der Technologie voran. Aber jedes dieser Experimente war nicht nur eine Metapher für das, was KI ist, sondern auch ein Szenario für die Interaktion zwischen Mensch und KI und das eine bedingt das andere. Wir versuchen herauszufinden, was KI ist, indem wir die Begriffe für die Interaktion mit ihr herausfinden und lernen, wie wir mit ihr interagieren können, indem wir lernen, was sie ist - ein durchaus verständlicher Ansatz. In letzter Zeit jedoch, mit dem Aufstieg von LLM, gibt es viele neue Einträge in dieser Liste, darunter Sydneys Nervenzusammenbruch, in dem eine Journalistin, anstatt sich wie sie in dieses wortgewandte OS zu verlieben, einen Chatbot dazu bringt, verstörende Kunststücke der abnormalen Psychologie zu vollbringen. Zu den berüchtigtsten Neuzugängen gehört das Blake-Lamoine-Szenario, bei dem die hochentwickelte Tendenz, sprachlich kompetenter Konversation Intentionalität zuzuschreiben, zu einigen unnötigen Schlussfolgerungen führen kann. Blaze und ich haben zu dieser Episode einen Artikel mit dem Titel Das Modell ist die Botschaft geschrieben, in dem wir darauf hinweisen, dass die Intelligenz nicht ganz so ist, wie Lamoine dachte, aber auch nicht ganz so, wie er es dachte. Bei vielen KI-Schnittstellen sieht es so aus, als ob Computer es geschafft haben, sich so zu präsentieren, dass die Nutzerinnen und Nutzer kaum noch etwas anderes verstehen müssen als die ihnen vertrauten Hinweise zur sozialen Interaktion. Die Geschichte der KI ist in dieser Hinsicht eine Geschichte, die sich von Menschen, die verstehen müssen, wie Computer funktionieren, um sie zu nutzen, zu Computern entwickelt, die herausfinden, wie Menschen funktionieren, um von ihnen genutzt zu werden. Nun beschleunigt die Sprache in ihren abstraktesten Formen, das sprachliche Denken, nicht nur das Sprechen und Schreiben, letzteres dramatisch und flexibel, sogar beunruhigend. Und so ziehen sich die praktischen Grenzen von Haid sowohl tief als auch weit. Wie du sehen wirst, ist die Fähigkeit der KI, sich durch menschliche soziale Hinweise zu präsentieren, bemerkenswert und wird in der Tat zur Schnittstelle an und für sich. Der Wechsel von HCI zu Haid bedeutet einen Wechsel von der Entwicklung von Klickpfaden zur Entwicklung synthetischer Persönlichkeiten. Die vielleicht quantitativ am weitesten verbreitete Form von Haid ist eine, bei der der Nutzer nicht einmal weiß, dass es die KI gibt. Die Dinge funktionieren einfach. Sie funktionieren, und es ist egal, wie. Die Formen von Haid, auf die sich dieses Projekt konzentriert, sind jedoch diejenigen, die persönliche Beziehungen nicht nur zur KI, sondern auch zur KI-Persona inspirieren und erweitern. Das, was wir als persönliche KI bezeichnen, ist von großer Bedeutung und ein Bereich von enormem Interesse, aber persönlich kann auch bedeuten, dass die KI durch deine persönliche Nutzung angepasst wird und nicht unbedingt eine Persona ist. Aber viele der KIs, die du benutzen wirst und die dich benutzen werden, werden so personalisiert sein wie dein Suchverlauf, wenn nicht sogar dein Fingerabdruck. Der Weg, den wir mit diesem Projekt beschreiten wollen, ist der Wechsel von einer Form der KI, die hauptsächlich auf räumlichen Bezügen basiert - innen und außen, oben und unten, oben und unten - zu einer Form, die auf psychosozialen Metaphern basiert. Das ist natürlich eine enorm starke Veränderung, die aber auch alle Risiken und Nachteile der menschlichen Psychologie mit sich bringt. Und doch ist dies in seiner grundlegendsten Form keine Option. Ein projektives Verständnis in Form eines mentalen Modells von dem, was hier vor sich geht. In diesem Fall geht es darum, was die KI ist, welche Möglichkeiten sie hat, was sie tut und was nicht, was und wo und warum sie ist und so weiter. Folk Ontologien sind nicht optional. Die meisten KI-Hasser, so könnte man vermuten, werden mit KI interagieren. In gewisser Weise sind KIs unsichtbar, langweilig und unscheinbar, aber dennoch entscheidend für die Reproduktion des täglichen Lebens, aber wie gesagt, persönliche KIs sind eine andere Sache. Sie sind eine Art von KI, die durch dein Denken trainiert wird, so wie man einem Hund einen neuen Trick beibringt, aber auch durch dein Denken trainiert wird, so wie man einen Stein zu einer Pfeilspitze schnitzt. Es ist eine Personalisierung eines externen mentalen Modells. Und ist dies möglicherweise eine Erfahrung des Selbst in der dritten Person? Wenn ja, wie können wir dann nicht fasziniert sein? Gleich werde ich über ein anderes Projekt von uns sprechen, das mit Simulationen zu tun hat. Die Simulationen knüpfen also bereits an die Diskussion über persönliche KI an, die in gewisser Weise eine Simulation von uns ist, oder vielleicht sind wir der digitale Zwilling der KI, die in unserem Namen arbeitet. In beiden Fällen sind die Simulations- und die realen Problemstellungen real und natürlich unheimlich. Vielleicht bist du der NPC. Vielleicht ist dein Schatten hinter dir her. Vielleicht ist jede Persönlichkeit ein Placebo. Die Erinnerung ist ein Schlüssel. Vielleicht der Schlüssel zu jeder persönlichen Ausrichtung, die diesen Namen verdient. Wenn das unheimliche Tal bedeutet, dass du dich vor etwas gruselst, das zwar menschlich, aber nicht ganz menschlich ist, dann ist das umgekehrte unheimliche Tal vielleicht, dass du dich noch viel mehr gruselst, wenn du dich selbst durch die Augen des maschinellen Anderen siehst und nicht ganz erkennst, was du siehst, aber du erkennst, dass das, was du siehst, zwar du bist, aber in gewisser Weise nicht, und dennoch ist es realer als die Version von dir, die du als dich erlebst. Vielleicht lassen sich du und das neu entmystifizierte Du auf das ein, was Sicherheitsteams als koordiniertes, unauthentisches Verhalten bezeichnen. Was ist dann Anpassung? Das Feld der Hade ist in der Realität also nicht ganz neu. Es ist zwar schon ziemlich alt, aber vielleicht neu als formales disziplinäres Forschungs- und Gestaltungsfeld, das als solches beginnt, wie gesagt, als Teilbereich von HCI und mit der Zeit vielleicht auch diesen umfassen wird. Wenn dem so ist, gibt sie dann vor, von der kognitiven Psychologie der HCI zu einer Erneuerung der Psychoanalyse für HAI ID überzugehen? Die Zeit wird es zeigen. Ok. Weiter. Wie gesagt, uns ist klar, dass wir uns sehr für LLM interessieren, aber nicht nur als Chatbots. Wir sind auch sehr daran interessiert, aber eher als eine Form dessen, was wir kognitive Infrastruktur nennen. Die Einbettung der sprachlichen Kompetenz und damit des symbolischen Denkens in die unbelebten und ganz und gar nicht anthropomorphen Materialien und Systeme der Welt, für die hier buchstäblich der Geist verteilt wird. Dieses Projekt, Whole Earth Codec, stellt KI nicht als ein Gehirn in einer Petrischale dar, sondern als eine synthetische Erweiterung der Formen von Intelligenz, die in und als komplexe ökologische Nischen entstehen. Das Projekt wird von den Forschern des Antikythera Studios, Christina Lu, einer ehemaligen DeepMind-Mitarbeiterin, sowie Delana Tran und Connor Cook durchgeführt. Das Projekt betrachtet KI als ein landschaftliches Phänomen und konzentriert sich weniger darauf, wie sich KI mit dir oder mir verbindet, sondern wie sie sich mit der KI in der freien Wildbahn und mit dem gesamten Ökosystem verbindet. KI als anorganischer Teilnehmer in einer organischen, sich zunehmend selbst modellierenden Lebenswelt. Anders ausgedrückt: Whole Earth Codec überdenkt die Position und Anwendung von künstlicher Intelligenz als eine Form planetarischer Intelligenz und betrachtet die möglichen und notwendigen Bedingungen für ihre Anpassung. Am Anfang stand die Frage nach der Qualität der Daten, die für die Gründungsmodelle verwendet werden, und mit Qualität war nicht nur gemeint, ob die Daten etwas taugen, sondern auch, um welche Art von Daten es sich handelt. Wenn du Modelle trainierst, die einen globalen Einfluss auf die Daten haben, die zufällig in der Öffentlichkeit liegen, ist ein gewisses Maß an suboptimaler Qualität so gut wie garantiert. Wenn die interessantesten Daten, die theoretisch zu einer breiten Basis gesellschaftlich konstruktiver Zwecke beitragen könnten, sowohl privat als auch privatisiert sind, dann sind andere Ansätze gefragt. Techniken wie das föderierte Lernen würden es ermöglichen, dass diese Daten zur Neugewichtung gemeinsamer Modelle beitragen, ohne die zugrunde liegenden Werte offenzulegen. Im Prinzip könnten wir unseren Kuchen haben und ihn auch privat halten. Für dieses Projekt bedeutet eine solche Umstellung aber auch, dass sich die Art der zu produzierenden Daten ändern muss. Es geht davon aus, dass die Aggregation von Daten über einzelne menschliche Nutzer nur ein Bruchteil dessen ist, was für eine planetarische Intelligenz, die diesen Namen verdient, möglich und notwendig ist. Sie schlägt eine grundlegende Entdifferenzierung der Computerbeobachtung vor, die sich stattdessen auf unpersönliche, ökologische und systemische Daten konzentriert. Das heißt, anstatt individuelle Daten in den Mittelpunkt zu stellen und ökologische Daten als eine Art außergewöhnliche Nebenrolle zu betrachten, kehrt es dies um. Es stellt Daten über Individuen als eine spezifische Untergruppe ökologischer Daten dar, die, wie klar sein sollte, ein wiederkehrendes Thema in unserer gesamten Arbeit darstellen, nämlich Kultur als Funktion des Planeten und nicht umgekehrt. Das Szenario, das hier für die planetarische Intelligenz erforscht wird, ist also eines, in dem die Erfassungs- und Modellierungssysteme global sind, aber vor allem ist es ein Observatorium, das nicht nach außen, sondern nach innen schaut. Die Selbstbeobachtung des Transformatormodells wird als alternative Metapher zum Panoptikum von Foucault dargestellt. Die Positionen des Beobachters und des Beobachteten werden weniger überwacht und kontrolliert, als dass sie sich gegenseitig rekursiv sind. Das Modell spürt sich selbst und damit spürt sich auch der Planet selbst. Die Selbstreferenzialität des Transformators ist die Figur, die Allegorie auch für planetarische Modelle. Sie nennen diese Faltung den Blick. Das Szenario hängt auch von der Figur und Funktion der Multimodalität ab. Wenn wir die Berechnung selbst als eine Art generische Syntax zwischen qualitativ unterschiedlichen Dingen und Handlungen betrachten, dann verortet dieses Projekt diese generische syntaktische Funktion in den Erfassungs- und Modellierungsanwendungen der KI und der Landschaftstechnologie. Das Erfassungs- und Modellierungssystem ist ein System für die künstliche Umwandlung planetarischer Phänomene in integrierte und rekombinante Daten, also ein Codec für die ganze Erde. Multimodalität wirkt sich sowohl auf die Art der Phänomene aus, die einbezogen und künstlich miteinander verbunden werden, als auch auf das Spektrum der Anwendungen und Funktionen, auf die das System als Ganzes ausgerichtet werden kann, indem es Inputs und Outputs mischt und aufeinander abstimmt. Multimodale Phänomene, die in eine generische Syntax umgewandelt und gefiltert und als multimodale Anwendungstechnologien ausgegeben werden. In diesem Szenario ermöglicht es die planetarische Intelligenz, dass sich die planetarischen Ökosysteme, einschließlich der menschlichen Systeme, neu zusammensetzen, weil die Zusammensetzung des Whole Earth Codec als Technologie für die planetarische Zusammensetzung das Entstehen dieser Intelligenz ermöglicht. Wissen ermöglicht Machen, aber Machen macht Wissen möglich. Das letzte Projekt, das ich heute Abend zeigen werde. Das, was sich Vivarium nennt. Vielleicht beginnt die Philosophie der Simulation mit den Anfängen der Philosophie selbst. In einer Höhle in Griechenland kultivierten Platon und Sokrates eine lange währende Paranoia, nicht nur gegenüber Simulationen, sondern auch gegenüber der vermittelten Wahrnehmung und ihrer Beziehung zum Denken. Äußere und innere Simulation im Konflikt oder in Übereinstimmung. In dieser Höhle legten sie nicht nur den Grundstein für das, was später ein Thema für die Philosophie werden sollte, sondern vielleicht auch für die grundlegende Paranoia, aus der die westliche Philosophie hervorging. Die Politik der Simulation kann aber auch sehr persönlich sein. Wenn du durch eine Sicherheitskontrolle gehst, z. B. an einem Flughafen, wird nicht nur deine physische Person überprüft, sondern auch deine digitalen Spuren, die mit dir verbunden sind, aber in einer nahen Schattenstadt namens Cloud leben. Wenn die Uniform dich durchlässt, liegt das daran, dass eine Entscheidung auf der Grundlage von Risikomodellen für diese Silhouetten getroffen wurde, von denen deine physische Person nur ein Spiegelbild ist. Deine Ohren mögen brennen, wenn die Infrastruktur über deine Doppelgänger flüstert, aber es bist nicht nur du, der im Spiel ist. Zu Hause und bei der Arbeit, wenn KI und Simulationen zusammenkommen, wird die Unterscheidung zwischen Designer/in und Spieler/in in beiden Richtungen verschwinden, weil große KI-Modelle und große Simulationsmodelle selbst zusammenkommen werden, wobei letztere die Schnittstelle zu ersteren bilden. An anderer Stelle haben wissenschaftliche Simulationen eine andere Art von planetarischer Politik im Rahmen des Klimawandels vorgeschlagen, die darauf abzielt, groß angelegten Langzeitsimulationen makrologischer Prozesse politische Priorität und Handlungsfähigkeit zu verleihen. Der Kern dieses Ansatzes, der Kern der Klimapolitik, ist der Versuch, die Aufmerksamkeit der Regierungen von der Vermittlung von Stimmen auf die Vermittlung von Ökologien zu lenken und wissenschaftlich bedeutsame Simulationen zu souveränen Akteuren zu machen, Simulationen der Zukunft zu machen, um die Gegenwart zu regieren. Viverium, ein Projekt der Forscherinnen und Forscher des Antikythera Studios, Deliana Tran, Christina Lu und Will Freudenheim, befasst sich nun ganz direkt mit der Frage, was simuliert und was real ist. Es stellt eine Plattform für kollektive Intelligenz dar, die mehrere Spielzeugwelten zu einer größeren Plattform von Welten zusammenfasst, die zum Trainieren physischer KI und zum Sammeln kollektiver Daten und damit kollektiver Intelligenz genutzt werden können. Es funktioniert im Verhältnis eins zu eins, ein Mensch zu einer KI, zwischen einem Menschen und vielen KIs, vielen Menschen in einer KI und, was vielleicht am interessantesten ist, für Formen der kollaborativen Verkörperung, viele Menschen in vielen KIs. In der Praxis sind Simulationen, wie bereits erwähnt, eine epistemologische Technologie. Sie sind Technologien, mit denen man denken kann. Deshalb ist eine Philosophie der Simulation, eine Philosophie der Dinge, mit denen man denken kann, von zentraler Bedeutung für den Zweck eines Programms wie dem unseren. Wir wissen, dass Simulationen allgegenwärtig sind. Unsere Freunde aus der Neurowissenschaft weisen darauf hin, dass Simulationen nicht nur eine Art externe Technologie sind, mit der die Intelligenz die Welt begreift, sondern dass Simulationen die Voraussetzung dafür sind, dass der Verstand überhaupt intelligent ist. Die kortikalen Säulen der Gehirne von Tieren sagen ständig voraus, was als Nächstes kommen wird. Sie führen kleine Simulationen der Welt und der unmittelbaren Zukunft durch, lösen sie mit neuen Eingaben auf und konkurrieren sogar miteinander, um Wahrnehmung und Handeln zu organisieren. Viele Computersimulationen dienen als Modell, das die Realität widerspiegelt, wie zum Beispiel in der Klimawissenschaft oder Astrophysik. Für andere ist das Hin und Her nicht nur ein Spiegeln. Manche Simulationen modellieren nicht nur die Welt, sondern geben direkt und indirekt Rückmeldung über das, was sie modellieren. Diese nennen wir rekursive Simulationen. Rekursive Simulationen sind solche, die die Realität nicht nur modellieren, sondern es uns ermöglichen, in einer entscheidenden Rückkopplungsschleife in sie einzugreifen und mit ihr zu interagieren, als Teil unserer verkörperten und bewussten Erfahrung. Die so genannten digitalen Zwillinge, vielleicht eine Form der persönlichen KI, sind eine solche Dynamik. Wie Vyvarium zeigt, werden viele KIs, vor allem solche, die in der Welt verkörpert sind, wie z. B. fahrerlose Autos, bereits in Simulationen der Spielzeugwelt trainiert, in denen sie freier erkunden und gegen Wände stoßen können, bis sie, wie wir, lernen, wie sie die reale Welt am besten wahrnehmen, modellieren und vorhersagen können. Bei der rekursiven Simulation zwischen Simulation und Realität ist die Realität in gewisser Weise das Basismodell für die Simulationen und die Simulationen sind manchmal das Basismodell für die Realität. Spielzeugwelten dienen als eine Art begrenzter Bereich des eingeschränkten Informationsaustauschs zwischen ansonsten ungleichen und unvereinbaren Dingen und Handlungen. In ihnen lernen manche KIs, sich in der realen Welt zurechtzufinden, indem sie sich durch diese konzentrierten, reduzierten Simulationen ihrer Konturen bewegen. Der Übergang von der Simulation zur realen Welt besteht nicht nur in den Auswirkungen bestimmter gelernter Erfahrungen, sondern auch in der physisch-virtuellen Hybridisierung als solcher. ML existiert in der Welt. KI ist auf dem Weg, so etwas wie ein allgemeines Lösungsmittel zu werden, das in die Dinge und ihr Verhalten eindringt. Und so hört das Hin- und Herlernen zwischen künstlicher und natürlicher Intelligenz nie wirklich auf. Für das Projekt gibt es, wie gesagt, mehrere mögliche Kombinationen von menschlichen Nutzern, KI als Prothesen, KI als Nutzer, Menschen oder Menschen als Prothesen. Es gibt verschiedene Kombinationen von Verkörperung, Handlungsfähigkeit und Aktion in und zwischen Simulation, Realität und Rekursion. Nicht nur eins zu eins, eins zu vielen, sondern letztendlich viele zu vielen. Vergiss aber nicht, dass die Welt der KI für uns eine Simulation der unseren ist, mit der wir interagieren können. Die KI, unsere Welt, ist nur ein Teil der Omni-Simulation, die sie einfach Realität nennt. Lass mich zum Schluss kommen. Und während ich einige abschließende Bemerkungen mache, werde ich Ausschnitte aus einem vierten Projekt namens Xenoplex zeigen, das sich mit KI und der Philosophie der Biologie, der Montagetheorie und der empirischen Astrobiologie beschäftigt. Es stammt von Antikythera, Derenzu und Connor Cook. Zurück zu unserem Ausgangspunkt, der von Stanislaw Lem inspirierten Unterscheidung zwischen existenziellen oder erkenntnistheoretischen und instrumentellen Phasen von Technologien. In Bezug auf die instrumentellen Auswirkungen von KI ist die Überanpassung selbst eine Art existenzielles Risiko. Wie gesagt, ist die Ausrichtung nach Kapital A eine unzureichende praktische Metaphysik für das, was die KI-Orientierung impliziert und erfordert. Ich gehe davon aus, dass die meisten, wenn nicht sogar alle, ernsthaften Alignment-Forscher dem nicht widersprechen würden. Wenn jetzt nur die Journalisten, Influencer und charismatischen Megakritiker ihrem Beispiel folgen würden. Was die erkenntnistheoretischen Auswirkungen der KI angeht: Wie wird sich die KI letztendlich auswirken? Letztlich wird sich die KI auf das auswirken, was wir, Zitat Ende, über das, was wir sind, wie wir sind, warum wir sind, und über die Kontingenzen dieses Pronomens begreifen werden. Was das sein wird, wissen wir nicht und wir können es nicht wissen. Wir können kopernikanische Verschiebungen und Traumata nicht wirklich im Voraus erkennen. Erinnere dich daran, dass wir die Existenz anderer Galaxien erst 1924 bestätigt haben und das genaue Alter der Erde erst 1953 wissenschaftlich gesichert wurde. Wir wissen es nicht, aber wir müssen den Raum verteidigen, in den das, was wir lernen werden, passen wird. Wir können davon ausgehen, dass im Hinblick auf die KI als experimentellen Superorganismus einer dieser wahrscheinlichen Bereiche das ist, was wir heute Neurowissenschaft nennen und morgen vielleicht einfach Philosophie und umgekehrt. Welche Fragen sollten also gestellt werden, die wahrscheinlich in die Richtung der epistemischen Offenlegung führen? Es gibt wahrscheinlich keine falschen Antworten, aber wir können darauf wetten, dass grundlegende Fragen darüber gestellt werden, was, Zitat, Leben ist, was Intelligenz ist und warum die Wörter, die wir benutzen, möglicherweise unangemessene Bezeichner für die Bandbreite der Phänomene sind, die sie zu beschreiben hoffen. Sogar die Grenze zwischen diesen Begriffen ist unklar, denn die Grenze zwischen Leben und Technologie und Intelligenz und Technologie ist bereits unklar, nicht nur für fortgeschrittene Computer, sondern für alles. Vielleicht ist Leben im Grunde so etwas wie evolutionäre Autopoiesis durch Nischentechnologisierung oder vielleicht ist Intelligenz oder vielleicht beides. Biotische Systeme nutzen abiotische Systeme, um sich als Organismen und über Generationen hinweg zu vermehren. Ohne diese grundlegende Technologisierung der Welt können sie nicht existieren. Wenn ein Teil der Definition von Intelligenz agnostische Problemlösung bedeutet, dann ist diese Nischentechnologisierung zumindest teilweise intelligent. Dieser Zyklus findet nicht nur ein- oder zweimal hier und da statt, sondern überall und immer wieder über Milliarden von Jahren hinweg. Er findet nicht nur auf der Erde statt. Er geschieht auf der Erde. Leben - Intelligenz - Technologisierung ist etwas, das die Erde tut. Und sie tut es nicht nur, sondern sie erschafft und erneuert sich durch diesen Prozess selbst, indem sie ein Gerüst für das nächste etwas komplexere Gerüst baut, das wiederum in das nächste Gerüst integriert wird und so weiter. Das ist der Grund, warum wir eine Atmosphäre haben und warum wir künstliche Intelligenz besitzen. Einige Planeten, zumindest einer, falten sich im Laufe der Zeit zu Materieformen, die nicht nur in der Lage sind, am Zyklus teilzunehmen, sondern auch Abstraktionen über ihre eigene Teilnahme am Zyklus zu machen und ihn dadurch neu zu justieren. Die menschlichen Gehirne sind eine solche Form. Aber sie sind nicht unbedingt die einzige Form, die zu solchen Abstraktionen fähig ist. Und diese Gehirne sind auch nicht unabhängig von den technischen Systemen der maschinellen Erfassung, Modellierung, Simulation und Vorhersage, die diese Abstraktionen möglich machen. Die Intelligenz selbst ist technologisch. Genauer gesagt, ist es klar, dass die Simulation, wie gesagt, nicht nur Teil der Funktionsweise von Tiergehirnen, wissenschaftlicher Forschung und Vorhersagen ist, sondern auch der Rekursion, die für die direkte Komposition notwendig ist. Die Simulation, wie wir sie kennen, ist eine fortgeschrittene Kopplung von biotischen und abiotischen Systemen. Sie ist ein Teil des Gerüsts. Das heißt, Biosphären erzeugen Technosphären, die wiederum Biosphären erzeugen, die Technosphären nutzen, um die gesamte Dynamik zu verstehen. Ich denke, du verstehst, worauf ich hinaus will. Die so genannte künstliche Intelligenz ist der Name für eine Form der Technologisierung, die in diesem Zyklus mehr als eine Position einnehmen kann. Sie kann Teil der technischen Modellierung sein, die der Mensch einsetzt, um die planetarischen Prozesse zu verstehen. Sie kann aber auch die Form der Intelligenz sein, die das Erfassen übernimmt. Sie kann nicht nur ein Mittel der planetarischen Intelligenz sein, sondern auch ein Bestandteil dieser Intelligenz selbst. Das ist eine Möglichkeit, wie die epistemischen Implikationen von KI wirklich interessant und seltsam werden. Es ist dann möglich, KI nicht nur im reflektierenden Schatten der menschlichen Intelligenz zu verorten, sondern im längeren Bogen der Intelligenz als planetarisches Phänomen und in der Entstehung der planetarischen Intelligenz als solcher. Ich habe angedeutet, dass die Definition dieser Begriffe nicht nur durch die Philosophie in Frage gestellt wird, sondern auch durch das, was intelligente Maschinensysteme bereits tun, und durch die Notwendigkeit, die Worte an die Realität anzupassen. Ich wiederhole: Wir müssen die Worte an die Realität anpassen. Ich schließe mit diesem Satz. Zurzeit gibt es eine gefährliche Trennung zwischen Kosmologie und Kosmologie. Wenn ich meine Freunde in der Astrophysik frage, nehmen sie an, dass ich mehr über Schwarze Löcher, Urknalle, die Krümmung der Raumzeit und solche Dinge wissen will. Aber wenn ich meine Freunde in der Anthropologie frage, werden sie annehmen, dass ich wissen will, wie sich die verschiedenen Kulturen Eschatologie und Verwandtschaft vorstellen und wie sie glauben, dass das Universum im Verhältnis dazu entstanden ist. In den Geisteswissenschaften gibt es leider viel Lärm um diese Trennung. Die Schlussfolgerung, die manche daraus ziehen, ist, dass die Abstraktionen der wissenschaftlichen Kosmologie auf den Boden der Tatsachen geholt werden müssen. Sie sollen die Souveränität der menschlichen Kulturen wiederherstellen. Ich frage mich jedoch, welche Kulturen der Welt, die nicht nur geerbt, sondern auch gelebt und durchlebt werden, komponiert werden können, um ihre Wege mit den Offenbarungen der planetarischen Prozesse in Einklang zu bringen, und zwar mit der Intelligenz, die sie möglich macht und die von ihnen erfasst werden kann. Dieses Projekt besteht darin, kollektiv Kosmologien zu schaffen, die der Herausforderung der langfristigen Lebensfähigkeit des Planeten gerecht werden. Nicht unbedingt die Versöhnung mit der Vielfalt der kulturellen Traditionen durch ihre Unterordnung. Das heißt, die These der Entzauberung, dass die moderne Säkularisierung des Kosmos der Kultur die kosmologische Grundlage entzogen hat, ist falsch. Stattdessen hat sie eine echte Kosmologie erst möglich gemacht. Die kulturelle Kosmologie entsteht aus der materiellen Möglichkeit des Denkens. Und diese materielle Möglichkeit des Denkens ergibt sich aus den physischen Realitäten, die auf lange Sicht unter den Menschen kontinuierlich sind. Selbst wenn sie die unsicheren Grenzen dessen, was Menschen sind, überschreiten. Anstatt also kulturelle Traditionen zu verdinglichen und auf das Universum zu projizieren, besteht das bessere kosmopolitische Projekt für die Zukunft darin, zu erfassen, was in der Planetarisierung der Zivilisationen sowohl konvergent, weil evolutionär, als auch divergent, weil menschlich, ist, und daraus Abstraktion und Bedeutung abzuleiten. Ich hoffe, dass die Auswirkungen auf die Ausrichtung der KI, auf die Verlagerung der Worte auf die Realität, klar sind. Was bei diesem Wandel durch KI auf dem Spiel steht, ist im Grunde alles. Ich danke dir. 
