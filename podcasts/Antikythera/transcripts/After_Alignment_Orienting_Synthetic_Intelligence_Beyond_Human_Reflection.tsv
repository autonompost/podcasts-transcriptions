start	end	text
30000	58440	The
58440	64120	history of AI and the history of the philosophy of AI are deeply intertwined, from Leibniz
64120	67600	to Turing to Hubert Dreyfus to today.
67600	72960	Thought experiments drive technologies, which in turn drive a shift in the understanding
72960	79040	of what intelligence itself is and might become and back and forth.
79040	87440	But for that philosophy to find its way today, for this phase of AI, which it needs to, that
87760	93200	finding its way needs to include expanding from the European philosophical tradition
93200	98120	of what AI even is.
98120	102800	And the connotation of this, from the connotation of artificial intelligence drawn from the
102800	109000	Deng era in China was as a kind of, in relation to a kind of industrial mass mobilization.
109000	114320	The Eastern European includes what Stanislav Lem called existential technologies, just
114320	119760	as the Soviet era, it meant something more like governance rationalization.
119760	126600	All of these contrast with the Western individualized and singular anthropomorphic models that dominate
126600	130020	contemporary debates still today.
130020	137360	So to ponder seriously the planetary pasts and futures of AI, must not only, it must
137360	143960	extend and alter our notions of artificiality as such, intelligence as such, and must not
143960	150760	only draw from this range of traditions, but also to a certain extent, almost inevitably,
150760	153960	also leave them behind.
153960	158400	What Turing proposed in his famous test as a sufficient condition for intelligence, for
158400	164520	example, has become instead, solipsistic demands and misrecognitions.
164520	171920	To idealize what appears and performs as most quote human in AI, either as praise or as
171960	178960	criticism, is to willfully constrain our understanding of what machine intelligence is as it is.
182880	186360	And this includes language itself.
186360	191320	Large language models and their eerily convincing text and prediction capabilities has been
191320	196840	used to write novels and screenplays, to make images in movies, songs, voices, symphonies,
197600	202480	and are even being used by biotech researchers to predict gene sequences for drug discovery.
202480	207520	Here at least, the language of genetics really is a language.
207520	213000	LLMs also form the basis of generalist models capable of mixing inputs and outputs from
213000	218120	one modality to another, interpreting what an image sees, so instruct the movement of
218120	221320	a robot arm and so forth.
221320	226840	Such foundational models may become a new kind of public utility around which industrial
226840	232800	sectors organized, what we call cognitive infrastructures.
232800	236400	So with their speculative philosophy then?
236400	242440	Well, I honestly don't think that society at present has the critical and conceptual
242440	246720	terms to properly approach this reality head on.
246720	252120	As a co-author and I wrote recently, quote, reality overstepping the boundaries of comfortable
252120	257560	vocabulary is the start, not the end of the conversation.
257560	262960	Instead of groundhog day debates about whether machines have souls or can think like people
262960	268760	imagine themselves to think, the ongoing double helix relationship between AI and the philosophy
269440	275440	to do less projection of its own maxims and instead construct newer, more nuanced vocabularies
278320	286320	for analysis, critique and composition based on the weirdness right in front of us.
286320	292320	And that is really the topic of my talk, the weirdness right in front of us, and the clumsiness
292320	295440	of our language to engage it.
295520	301760	Toward that, let me say that, again, that the impasses over whether machine intelligence
301760	307280	as mind or sentience or consciousness are, in fact, impasses in our language and our
307280	314160	imagination more than they are in what is actually happening has happened and will happen.
314160	321280	The productive interest instead may have less to do with how AI adheres to precedent models
321360	327760	than what it reveals and does about the limitations of those models.
327760	334240	So I say reveals and does. Why the split? Well, instead of presuming that ideas are
334240	340280	first formed and then tools are wielded to act upon them, we may observe instead that
340280	346960	different tools, or as well, that different tools make different ideas possible. It's
346960	352000	not just that they invite different dispositions towards the world, they literally make the
352000	359000	world conceivable in ways otherwise impossible. Per Lem, Stanislaw Lem that is, and his notion
361900	368900	of an epistemological and instrumental technology distinction, we might say that some kinds
370000	376120	of technologies have the greatest social impact in what they do and enable in artificially
376120	382720	transforming the world. These are instrumental. Others, however, have greater social impact
382720	389720	in what they reveal about how the world works. These are epistemological technologies. Telescopes
390160	397160	and microscopes are good examples. Yes, they allow perception of the very large and the
397280	404280	very small, but more importantly, they enable Copernican shifts in self-comprehension,
404960	411960	grasping of our very selves as part of planetary and indeed extraplanetary conditions. With
413120	419040	such shifts, it was possible to orient not only where the planet is, but thereby where
419040	426240	and when and what, quote, we are, and of course, also thereby putting into question that collective
426240	433240	pronoun itself. Taken together, again, these may be called epistemological technologies.
434280	441280	Again it is certain that computation is artificially transforming the world in the form of a accidental
441640	448640	megastructure that shifts politics and economics and cultures in its own image. However, computation
449440	456400	is also an epistemological technology that has and does and will reorient the course
456400	463400	of what a viable planetary condition may be. In fact, we may say that the planetary as
463880	470880	such is an image that emerges via computation, via, for example, climate science, which is
471480	476800	based of course on planetary sensors and models and most of all super computing simulations
476800	483800	of the planetary past, present and future. The very idea of climate change is, in other
483880	490880	words, an epistemological accomplishment of planetary computation. And thus, so indirectly,
491040	498040	is the notion of the Anthropocene and of humanity as a terraforming subject. And that is what
498960	505960	is at stake. So, full disclosure then, in this regard, my own approach to philosophy
507720	512440	for a philosophy of technology then can then be understood as, in a sense, an inversion
512440	519440	of the malaise carefully lamented by Heidegger for whom technical reasons alienation of
519440	526360	the intuitive givenness of the world is its and indeed our downfall. Whereas for me, I
526360	533360	think he has it backwards. That alienation, that Copernican weirdness achieved through
534240	541240	technological mediation of our cognition has been and will be a path to access anything
541240	548240	called being. Once again, where we are, when we are, where we are and how we are. But clearly,
553800	560800	AI is not only disclosing these, it is also forcing us to question them. We then experience
561360	568360	different kinds of, if you like, AI overhangs and arguably underhangs. An AI application
568680	575100	overhang means that the technology is capable of doing things, that a society has a hard
575100	582100	time integrating, modeling, adopting for any number of good or bad reasons. What one of
582840	588800	our, in Antikythera program, one of the meta-science projects by Darren Zhu, Will Freudenheim and
588800	595800	Imran Sekolala calls an AI epistemic overhang, on the other hand, means that AI is capable
596440	603440	of discovering things, knowing things, disclosing things. That human science has a hard time
605200	611840	modeling and integrating and adopting. The latter, we would argue, is not just an issue
611840	618840	for science. In its generality, it is many ways the focus of this talk. So first, about
618840	625840	alignment. What does it mean to ask machine intelligence to align to human wishes and
638920	645840	self-image? Is this a useful tactic for design or a dubious metaphysics that obfuscates how
645840	652360	intelligence as a whole might evolve? Given that AI and philosophy of AI have evolved
652360	658120	in a tight coupling, informing and delimiting one another, how should we rethink this framework
658120	664520	in both theory and practice? Or let me put it somewhat differently. If the stack describes
664520	671520	the topology of planetary scale computation, the question that it implies is what is planetary
672040	678920	scale computation for? We might insist that the emergence of machine intelligence must
678920	686080	be steered toward a kind of planetary sapience in the service of viable long-term futures.
686080	693080	And for that, instead of strong alignment with human values and superficial anthropocentrism,
693240	700240	this steerage of AI means treating these humanisms with some nuanced suspicion and recognizing
701240	708240	instead a broader potential. At stake is not only what AI is, but what a society is and
710880	717880	indeed what either one is for. And what should align with what? The term synthetic intelligence
720080	725600	in our parlance refers to the wider field of artificially composed intelligent systems
725600	732600	that both do and do not correspond with humanism's traditions. These systems, however, can of
735520	742520	course complement and combine with human cognition and intuition and creativity and abstraction
742640	749640	and discovery. But as such, both are forever altered by these amalgamations.
750640	757640	Now, machine intelligence itself may or may not be, strictly speaking, artificial. Now,
760160	765920	if we mean artificial as something that is composed deliberately by some kind of precedent
765920	772920	intelligence, then AI is a form of machine intelligence that is so composed. But it is
773600	780200	perhaps not so simple. We recognize every day that there are forms of machine intelligence
780200	787200	that are genuine and yet evolved without deliberate design. Just look around the city. And second,
790480	797040	we can zoom out and see that the intelligence that does any artificializing is itself evolved.
797040	804040	And so, its artifacts are then also part of this evolutionary phylogeny. Now, the primary
804560	811200	significance of this for the present talk is that we should not, repeat not, see AI
811200	818200	simply as a direct reflection of human ideas, culture, and economics. Nor, vis-a-vis alignment
818480	825480	should it be. Put directly, the extent that it directly reflects human culture is not
825520	832960	a goal, nor is it a reality. The extent to which it departs from human culture is not
832960	839960	what we might name a disaster, and nor is it a hypothetical. That departure is, in fact,
840080	847080	our reality. That human intelligence must or should orient, which is our preferred term,
847080	854080	AI toward viable planetary futures, is essential. But again, that viability does not arrive
858440	865000	simply from making AI resemble us or admire us or be subservient to our wishes. To the
865000	872000	contrary. Now, there is obviously a Venn diagram overlap between AI ethics on the one hand,
877480	884040	and AI alignment on the other. But there is also, between them, a kind of impasse. Or
884040	891040	at least in principle, a contradiction between their visions. AI ethics, particularly in
891040	898040	guises associated with popular pundits and so forth, insists, when coaxed, that AI is
898500	905400	simply the reflection of human societies. From unjust biases and unequal economic systems
905400	911400	that produce it. It seeks to demystify AI as just us. Nothing more. Nothing less. As a
915360	921360	theory, it asks us to identify in principle any technology, especially AI, as ontologically
923760	929760	artifactual. AI alignment, on the other hand, and again, my abstraction of these correlates more to
929760	935760	the popular and populist guises than any deeper serious research. Alignment may hold that the
940800	948160	potential existential, or at least serious, risk of AI is based in the fact that it is now so
948160	955160	deeply divergent from human cultural values and norms. And that securing a safe future means
955160	961160	actually gluing it to those values and norms. So you see the theoretical problem. How can AI be
964320	969840	both automatically reflective of human biases and values and dangerously unreflective of human
969840	975840	biases and values? How can the positions that straddle my cartoon binary hold the apparently
975840	981840	contradictory conclusion at once? How can we observe that, again, that AI is us, and this is
985420	991420	bad, and simultaneously that it is not us, and this is also bad? Well, it can be both, but only
993920	1000800	if we would radically qualify and specify what we mean by alignment and allow for alignment such
1000840	1008840	that AI not only bends to social norms, but also for which society evolves in the positive sense
1008840	1014840	in relation to the epistemological and instrumental affordances of AI. So before I go into a little
1017920	1023960	bit more detail about what I envision, let me further contrast and clarify what I don't
1024000	1030000	envision, what I don't mean. The possibly very sensible perspective that AI and potential AGI
1033200	1040320	pose an existential risk and so therefore should be the focus of planetary concern for
1040320	1047720	geopolitical and geosocial debate has not always been well represented in the public sphere as it
1047720	1053720	should be. AI moral panics overwhelm imaginative reason in what amounts to several simultaneous AI
1058600	1064600	moral panics competing for attention, oxygen and hegemony. These range from rather predictable
1065880	1071880	American culture war templates that focus less on what is said than who is saying it to a strange
1072040	1078040	inversion where some of the most well-known for rapturous, millenarian visions of AI have rotated
1081080	1088040	to apocalyptic, eschatological ideas without missing a beat. From the singularity to the
1088040	1094040	Unibomber and back is the new horseshoe theory of AI politics. The hype doom binary imploding into
1095000	1101000	itself. Elsewhere, but not too far away, many public intellectuals spent the spring of 2023 in a
1104440	1112280	perhaps well-meaning piety game to see who could say that we are in fact more fucked. You say we
1112280	1121320	are fucked because of AI. Well, I say we are more fucked than thou. Sometimes the game
1121320	1127960	eventuated in public letters of concern of varying quality and intellectual legitimacy,
1127960	1132840	I think, but almost all with signatories that included very good and smart people.
1134920	1142840	The most dubious of these, however, called for those in charge to push the imaginary red pause
1142840	1150520	button on AI, quote, until we can figure out what's going on, as the man said. Knowing full
1150520	1157240	well that no such button exists. That bad actors will not play along and that they themselves
1157240	1161160	perhaps stand to benefit down the line for having signaled their concern thusly.
1163240	1169400	Most importantly, that unlike aliens in a sci-fi movie who land and say take me to your leader,
1170600	1178040	that when it comes to the serious, serious risks identified, there is no them to petition.
1178040	1184360	Who is in charge is the right question. And I would like to think that the posing of that
1184360	1194040	question was the real point and hopefully impact of the letters. That said, it is clear that the
1194040	1201000	present discourse around AI is ironically enough exemplary of the kind of discourse that the
1201000	1208440	discourse around AI is warning us about. Tribal, hyperbolic, truthy, unnecessarily dominated by
1208440	1215000	whoever talks loudest and says the most outrageous thing, all amplified by advertising machines.
1217000	1226600	Some critics may even go so far as to insist that AI is neither artificial nor intelligent.
1226760	1232840	They say that it is not artificial because it is made of physical materials by people for specific
1232840	1238840	purposes, which is the very definition of the artificial. They say it is not intelligent
1238840	1244120	because it is merely modeling and solving problems, which in many significant ways is a good
1244120	1249640	shorthand definition for a general theory of intelligence that is inclusive of but not
1249640	1256520	exclusive to what it feels like to be human. They say that AI is not artificial because it is made
1256520	1266840	human. Others may go a step further and advance a position that we might call AI denialism. That is,
1266840	1273480	AI doesn't really exist. Don't be fooled. It is just statistics. It is just gradient descent.
1275480	1280360	This is a bit like saying a symphony doesn't exist, it is just sound waves. Or that food
1280360	1284920	doesn't exist, it is just molecules. All of these are trivially true,
1286600	1293240	but this AI denialism is not remotely helpful in addressing the concerns it purports to stand for
1293240	1301720	by making this particular case. The thing is it is usually advanced as part of a political position
1301720	1309160	in relation to the economics of AI, often a quite legitimate one, that then raises the stakes
1309160	1315560	to an ontological claim. And so it is perhaps difficult to climb down from denialism
1316520	1319320	because it seems to put the validity of the politics in question.
1321560	1329080	Elsewhere, AI denialism dovetails with what we might call AI abolitionism. AI does not really
1329080	1337160	exist but should nevertheless be abolished. Now, there is a lot to unpack here and to do
1337160	1342200	these positions justice and to systematically critique the critique of AI in this way and would
1342200	1348200	take at least a few other lectures, but let me then just offer the punch line of what those other
1348200	1355240	lectures might be because it is also the punch line of this lecture or one of them. There are
1355240	1365480	several. Sociomorphism, that AI is or should be the reflection of human society, is the logical
1365480	1371000	extrapolation of anthropomorphism, that AI is or should be the reflection of a single human.
1372360	1380600	Both of these, neither of these, is a real alternative to a California ideology's planetary
1380600	1387800	hegemony. They are in fact the pinnacle of it. The strong anthropomorphic view of AI
1388440	1395160	goes back at least to the Turing test where what he offered as a sufficient condition for
1395240	1403000	identifying machine intelligence became a necessary condition. That is, unless AI could perform
1403000	1411960	thinking the way that humans think that humans think, then it's disqualified. This idealization
1411960	1418840	of what we could call reflectionism, it manifested as well in the psychologism of human-centered
1418840	1426040	design, which proved a very mixed bag as it turned out, and is present in the now contested
1426040	1434280	terrain for human-centered AI, humanistic AI and so on, which are perhaps posed to make many of
1434280	1443080	the same errors as human-centered design. I will talk about what we call human-AI interaction
1443160	1449080	design, or HAID, in a moment. We are, in antikythera, very invested in this idea,
1449960	1453800	not despite of its weirdness and complexity, but because of it.
1455480	1463560	We are interested in the weirdness as well that is ensured by attempts to eradicate the badness.
1464200	1472200	The last decade of AI ethics surely prevented a lot of horrible things. Alignment researchers
1476520	1482040	themselves contributed to many of the core technologies that we now make use of, scaling
1482040	1490040	laws to ROHF in particular. And yet, also, at the same time, ethics ended up dovetailing
1490200	1497640	accidentally with corporate brand concerns to give us LLMs that are lobotomized to never speak
1497640	1505640	about sex and violence in any meaningful way. We have prudish AIs. We all foresee how bad it
1505640	1511560	could get if the worst human preoccupations were directly aligned with the power of foundation
1511560	1518600	models. But we also, at the same time, think about the critical role of sex and violence in
1518600	1526040	the evolution of animal intelligence, including ours. And so recognize the weirdness of machine
1526040	1533240	intelligence evolving with these topics as unspeakables. Now, again, to be clear, my
1533240	1539880	positions on this are not intended to be posed at the expense of the research in AI ethics and
1539880	1546840	alignment, but rather actually in concert with their conclusions that ethics and alignment as
1546840	1555720	such are together necessary but insufficient frameworks for the long-term orientation of
1555720	1563000	machine intelligence. That, in other words, alignment overfitting is real. My concern,
1563000	1573000	however, is that exhaustion with tech solutionism gives way to self-congratulatory parades of
1573000	1580280	political solutionism that is now overflowing op-ed columns, trade books, and yes, schools and
1580280	1588520	universities. On the continent, the inability to grasp how planetary computation upends 18th
1588520	1597080	century forms of Westphalian citizenship leads as well to regulatory solutionism, AI laws that
1597080	1602360	address yesterday's problems, the EU forever running to where the ball no longer is.
1603640	1610680	Trying to shoehorn planetary dynamics into citizen-scale policies. For example,
1610680	1616440	its permanent focus on individual citizen data as the core locus of concern and governance
1617160	1627800	is, in a post-pandemic world, probably the wrong lens. The way out of this is to cut the knot
1628440	1634520	of the weakest forms of reflectionism, which we might define as the moral and practical
1634520	1643640	axiom that AI does or should be ontologically anthropomorphic. Not only are technologies not
1643640	1650200	exhausted by the projection of social relations upon them, they are capable of forcing new
1650200	1655960	practical concepts that contravene those social relations in the first place.
1658520	1665880	As such, the harm, to use the parlance of the day, is not only in what reflectionism directs
1665880	1673160	our attention to, but equally, perhaps more so, what it directs our attention from.
1675160	1682040	AI represents an existential risk and existential potential in both senses of that term.
1682520	1689400	By this, I don't mean that it may or may not kill us, but that it may or may not disclose to humans
1689400	1695000	and to animal intelligence, to planetary intelligence, fundamental truths about what we
1695000	1703320	are, what their existential condition really is. This is the Copernican risk-reward calculus,
1704120	1710120	one that is neither messianic nor apocalyptic. Now, you may hear my criticism, such as it is,
1716440	1723320	of shallow AI anthropomorphism and say, yes, but as it turns out, AI actually does reflect
1723320	1729960	human intelligence in some important ways. So, against a shallow anthropomorphism that
1729960	1737400	insists that AI present itself as thinking how humans think that humans think, there is also
1738200	1745400	a deep anthropomorphism, or better, a deep biomorphism, that may correspond to how humans
1745400	1752200	and other animals do really think, even if they don't experience thinking in that way.
1753000	1760520	This is not only true, it's profound, and this is, as I say, what shallow reflectionism
1760520	1770440	models. For example, very recently, research in how AIs discern edges in images was, for example,
1770440	1776280	directed researchers to unidentified, as yet identified, unspecified neuronal mechanisms in
1776280	1782360	human brains that perform more or less the same thing. As I'll discuss in a moment in relation to
1782360	1789960	one of Antikythera's projects, AIs are becoming a kind of experimental organism, like a lab rat,
1791000	1794680	in which it's possible to test for human conditions and responses.
1795960	1804360	This would not work if there was no fundamental correspondence. But what is and isn't the quality
1804360	1810520	of that correspondence is of genuine philosophical and practical interest.
1812520	1818360	We also see, at perhaps a higher level of abstraction, that iterative predictive dynamics
1818360	1823800	of transformer models does correspond with the iterative predictive dynamics of biological
1823800	1832760	neurons. This was not the plan, but there it is. So yes, actually, you are a stochastic parrot,
1832760	1838520	after all. Always has been. But you should not take that as the insult
1839320	1842760	that the authors of that infamous paper perhaps intended it to be.
1845000	1851560	Iterative stochastic prediction and thinking through the recursions of mental simulation
1851560	1857800	and embedded embodied perception is how humans made all the things that you hold most dear.
1858600	1865800	Literature, music, science, and so on. Parrots, by the way, are actually very smart and creative,
1865800	1872040	so they're kind of a lousy token species for mindless repetition, but that's another thing.
1873720	1880760	The deeper correspondence between iterative stochastic prediction and artificial and
1880760	1886280	natural systems is technically an anthropomorphism, but as said, probably better to call it a
1886280	1894680	biomorphism. And it suggests then a different kind of AGI, an artificial generic intelligence.
1897480	1904760	And this is really the point. Emphasis on the correspondence between AI and the manifest image
1904760	1913000	of human thought and intelligence and culture comes at this terrible price, obscuring the real
1913000	1920440	and profoundly significant correspondence between animal machine intelligence that do not already
1920440	1928280	register in common cultural norms, but which could orient those norms to the underlying reality
1929000	1936200	from which they emerge. A different bidirectional path of and for alignment.
1936200	1943640	And notice I say from which they emerge, as opposed to the reality that emerges from those
1943640	1949240	cultural norms. This is where perhaps there are some points of difference in our approach
1949960	1957640	and some others on offer in the humanities. It comes down to something rather fundamental
1957640	1963480	of what is inside of what. The planet makes worlds or worlds make planets.
1963480	1970280	I say that we must avoid what obscures the deeper and more philosophically challenging ways
1970280	1978680	that AI does think like brains, but simultaneously does not orient itself around humanist norms,
1979400	1986440	which thus distances human brains from human values in uncomfortable ways.
1986920	1993640	In uncomfortable ways. Is this the real point of contention and unease?
1996040	2002680	In the most extreme versions of reflectionism, what is being defended, I sometimes wonder,
2003720	2010600	seems like a kind of political theological conviction that there is nothing outside the
2010680	2017240	text as they used to say. Nothing outside the sociological interpretation of technology.
2017240	2022920	The political economy of science. The reality of culture as determinant of reality.
2023720	2030680	Nothing causing culture, but culture itself. Culture causing culture, which is caused by more
2030680	2038520	culture and thus anything, including AI, is intrinsically a reflection of that culture
2039240	2046520	and nothing more. We might call this social reductionism and cultural determinism,
2047080	2055960	which for all its lip service to post-humanism can be the most militant guise of humanism.
2057480	2066120	Now, obviously AI as it exists is fortunately and unfortunately a reflection of the cultures
2066120	2072440	that produced it, but and here is the perhaps critical fork in the road. It is not nor should
2072440	2082680	it be only a reflection of culture. It is more. We are more. AI itself and more importantly,
2082680	2089800	the qualities of reality that are certain to be revealed by AI, all the Copernican twists to come
2090760	2099560	are things to which culture must and will align. Not only something that must and will align to
2099560	2105240	culture. So, two conclusions.
2105240	2123800	Just some. AI is an existential technology and as such must align in both directions.
2124440	2132440	AI aligning to culture's wisdom. Culture to AI's disclosures. So, specifically,
2133320	2140840	first, lowercase alignment should be seen as a tactic for making machine intelligence's
2140840	2149000	instrumentality, making it cohere to agency and intention to make it work. But uppercase alignment
2149720	2155880	and the attendant metaphysics is an inadequate grounding for the long-term orientation of machine
2155880	2165720	intelligence by animal intelligence. Second, a two-way alignment is both possible and desirable.
2166360	2172440	AI's epistemic overhangs, things that it knows and implies for us to know that we have a difficult
2172440	2180200	time grasping and accommodating and incorporating are not pathologies. They are in fact the deeper
2180200	2189720	point of AI. And so, between AI as generic intelligence, AI as an experimental super
2189720	2195240	organism per one of our Antikythera projects called the End of Science by our studio researchers
2195240	2204360	Darren Zhu and Connor Cook, AI becomes an uncannily productive sort of mirror. But it's not a mirror
2204360	2210680	reflecting what we think we are because we can see it and feel it, but rather a mirror of what
2210680	2232840	we are but cannot see and cannot feel. At least not yet. Now, I would like to then
2233720	2238360	specify this, ground this a bit in some of the work that we've done to try to explore
2239240	2245720	these ideas and many others in the Antikythera program and to tell you a little bit about the
2245720	2253240	studio but more importantly about the work. All the projects that I'll show you in a kind of
2253240	2258760	summary coming up were all really just completed at the end of last week where they were first
2258760	2263720	privately shown in Los Angeles. And again, we'll be back in London in the fall to do a
2263720	2271880	bigger showcase around these. Antikythera, as Stephanie signaled to you, is a research
2271880	2277720	program, a think tank of sorts for the speculative philosophy of computation. It is supported and
2277720	2284520	housed at the Berggruen Institute. We're pleased to be joined by Niels Gilman from the Institute
2284520	2292200	here tonight. Stephanie is the associate director. Nikolai is also here, my longtime friend and
2292200	2298760	collaborator. Shrelka is our studio director and we are also held afloat by Case Miller and Emily
2298760	2305320	Knapp and growing quite, growing every day it seems. The program includes 70 plus affiliate
2305320	2311000	researchers from around the world, various universities, and has just completed in our
2311000	2317400	last phase 12 studio researchers who completed this studio cycle. It is, in essence, a program
2317400	2323480	that not only seeks to map planetary computation but to ask and provide some provisional answers
2323480	2329480	to what planetary scale computation is for. Now, as I've already said, philosophy and more
2332680	2338680	generally, the project of developing viable concepts about how the world works and thus
2338680	2344440	thinking about and thus thinking about how the world works has always developed in conjunction
2344440	2349880	with what technology reveals and does and thus what it's possible to think. And so at least in
2349880	2354920	that regard, I am something of a technological determinist but only if we expand the definition
2354920	2363960	of technology to its properly expansive scope. Here's the thing. At this moment, technology
2364040	2372120	and particularly planetary computation has outpaced our theory. The response, as I've hinted
2372120	2377560	tonight, is to some extent to force comfortable and settled ideas about ethics and scale and
2377560	2383640	polity and meaning onto a situation that not only calls for a different framework but is already
2383640	2388200	generating that different framework. So instead of simply applying philosophy to the topic of
2388200	2394200	computation, we start from the other direction and produce ideas and the speculative from the
2398040	2404040	direct encounter, from making things. So that being said, the program, the Antikythera program's
2406500	2412200	real interest is not so much in calculation, in formalization, quantification, interoperability
2412200	2418200	as such, than it is about how computation provides orientation, navigation, cosmology, in
2421740	2427740	essence, planetary. The inspiration for the name comes from the Antikythera mechanism first
2430780	2438780	discovered in 1901 in a shipwreck off the Greek island of said name and dated to about 200 B.C.
2438860	2446160	It is perhaps apocryphally the first computer. But it is certainly a primordial computer. But it
2446160	2452160	was not simply a calculator. It was also an astronomical machine mapping and predicting the
2452160	2458080	movements of stars and planets, marking annual events and orienting a naval culture upon the
2458080	2464080	surface of the globe. So it not only calculated interlocking variables, it gave a comprehensive
2464080	2470080	orientation of thought in relation to its astronomic predicament, enabling prescriptive
2474340	2480340	thought to act in relation to this revealed circumstance. So beyond forms of computation that
2482340	2489080	are already perceivable in natural systems, artificial computation such as this is a kind of
2489080	2495080	world ordering, a foundation for what would become complex culture. And that is really the
2498500	2506500	core of it. For our initiative, the name Antikythera refers to computational technology
2506500	2512500	that discloses and accelerates the planetary condition of intelligence. So let me go a bit
2512580	2520580	deeper into some of the themes and ideas of the program and to show you some of the work,
2520580	2526500	which will be playing in the background as I explain a little bit where it came from and what
2526500	2532000	it's up to. Several of the projects, not all of them, several of the projects speak directly
2532000	2537880	to questions of AI and indeed to questions of AI alignment rather directly. The project
2537880	2543880	HAI ID or HAID, Human Artificial Intelligence Interaction Design by Antikythera Studio
2546040	2553040	Researchers William Morgan, Sarah Olympia Scott and Daniel Barkay is what you see here. It is
2553040	2559040	an ever growing catalog of existing and almost existing modes, positions and syndromes of human
2560840	2567840	AI interaction that allows us to map and generalize the space. It is a compendium of
2567880	2573880	hundreds of operant models, syndromes, patterns and persistent folk ontologies. As such, it maps
2576420	2581540	not one but several conceptual models for what human AI interaction design may be and might be
2581540	2587540	based upon. It sees HAID as present as a kind of subset of HCI but one that will arguably
2589640	2596180	overwhelm and redefine that field, especially as personal AIs are more generally deployed at
2596180	2601600	platform scale. As I've already insisted, the history of AI and the history of philosophy of
2601600	2607020	AI are deeply intertwined. One side of that ledger is populated by numerous thought
2607020	2613640	experiments, both canonical and obscure, the imitation game, the Chinese room, the paper clip
2613640	2620140	maximizer, the three blue banana problem, Samantha's infidelity, the driverless red
2620140	2626140	trolley and so on. These thought experiments responded to extend AI and in turn framed and drove
2628720	2635560	further development of the technology. But each was not only a metaphor for what AI is but also a
2635560	2641560	scenario for human AI interaction and indeed one because the other. We try to figure out what AI
2641560	2646260	is by figuring out the terms for interacting with it and to learn how to interact with it by
2646260	2652260	learning what it is, a perfectly understandable approach. Lately, however, with the rise of LLM,
2654340	2660020	there are many new entries to this list, including Sydney's nervous breakdown in which instead of
2660020	2665760	falling in love with this articulate OS, as in her, a journalist coaxes a chat bot to perform
2665760	2673260	disturbing feats of abnormal psychology. Among the most notorious new entries may simply be
2673260	2679260	called the Blake-Lamoine scenario where the highly evolved tendency to ascribe intentionality to
2681020	2687020	linguistically competent conversance can lead to some unnecessary conclusions. Blaze and I wrote a
2689600	2694980	piece addressing this episode called the model is the message, suggesting that the intelligence
2694980	2700980	there is not quite what Lamoine thought it was, but not quite not what he thought it was either.
2700980	2708100	With many AI interfaces, it would seem that computers have mastered presenting themselves in
2708100	2713900	ways that require almost no additional comprehension for users beyond ingrained social
2713900	2720860	interaction cues. The history of HCI is in this way a story that shifts from humans having to
2720860	2726360	understand how computers work in order to use them to computers figuring out how humans work in
2726360	2733280	order to be used by them. Now, language in its most abstract forms, linguistic reasoning, not only
2733280	2741280	talking and writing, accelerates the latter dramatically and flexibly, even disturbingly. And so
2741280	2749280	draws the practical boundaries of Haid both deep and wide. As you will see, the capacity for AI to
2750120	2757120	present itself through human social cues is remarkable and in fact becomes the interface in and of
2757120	2763120	itself. The shift from HCI to Haid means a shift from designing click paths to designing synthetic
2765120	2773120	personalities. Now, perhaps the most quantitatively pervasive form of Haid is one in which the user
2773200	2780000	doesn't even know the AI is there. Things just work. They work and who cares how. However, the forms
2780000	2785580	of Haid that this project focuses on are those that inspire and extend personal relationships with
2785580	2793580	not only AI but AI persona. Now, what we call personal AIs are essential to this and represent a
2793580	2799840	field of tremendous interest, but personal can simply mean AIs that are customized by your
2799840	2806800	personal use of it that are not necessarily persona. But many of the AIs that you will use and
2806800	2812800	which will use you will be as personalized as your search history, if not your fingerprint. The
2815300	2820680	avenue of exploration for this project is then the shift from a form of HCI that is based largely
2820680	2827840	in spatial references, inside versus outside, up and down, over, under, to one that is based on
2827840	2835340	psychosocial metaphors. Now, this is obviously a tremendously powerful shift, but one that comes
2835340	2841340	with all the risks and downsides of human psychology itself. And yet, in the most basic form,
2843680	2849760	this isn't optional. Some projective comprehension in the form of a mental model of what's
2849760	2855760	going on here. In this case, what the AI is, what its affordances are, what it is and isn't doing,
2855800	2863800	what and where and why it is, is so on. Folk ontologies are not optional. Most AI hate, we
2863800	2868800	might suppose, will be interaction with, again, in some ways, AIs are invisible and boring and
2868800	2874260	unmemorable and yet critical to the reproduction of everyday life, but as said, personal AIs are
2874260	2882020	another matter. They are, they mean a kind of AI that is being trained in how you think, like
2882020	2888360	teaching a dog a new trick, but also being trained by your thinking, like carving a rock into
2888360	2894360	an arrowhead. It is a personalization of an external mental model. And is this potentially an
2897600	2905600	experience of the self in the third person? If so, how can we not be fascinated? Now, in a moment,
2906180	2911480	I will talk about another project of ours that is with simulations. Simulations, then, but
2911480	2917180	however, clearly already tie back to the discussion of personal AIs, which are, in a sense,
2917180	2924680	simulations of us or perhaps we are the digital twin of the AI that is working on our behalf. For
2924680	2930680	both, the sim to real problematics are real and, of course, weird. Perhaps you are the NPC.
2933760	2939760	Perhaps your shadow is chasing you. Perhaps all personality is a placebo. Memory is a
2941940	2948940	key. Maybe the key to any personal alignment worth the name. Perhaps, then, if the uncanny valley
2948940	2955980	is when you are weirded out by something that is but is not quite human, the inverse uncanny valley
2955980	2960860	is when you are much more deeply weirded out by seeing yourself through the eyes of the
2960860	2967660	machinic other and don't quite recognize what you see, but you do recognize that what you see is
2967820	2973660	you, but in a way not, and yet it is more real than the version of you that you experience as
2973660	2980780	you. Perhaps you and that newly demystified you will engage in what security teams call
2980780	2986780	coordinated inauthentic behavior. What is alignment then? The field of Hade, then, is obviously
2991040	2997280	not brand new in reality. It's quite old, but it is new perhaps as a formal disciplinary field of
2997280	3003860	research and design, one that begins as such as said as a subset of HCI and may in time come to
3003860	3010580	encompass it. Then, if so, does it pretend to shift from cognitive psychology of HCI to a
3010580	3016580	renewal of psychoanalysis for HAI ID? Time will tell. Okay. Next. As said, we are as clear, we
3016580	3022580	are quite interested in LLM, but not just as chatbots. We are also deeply interested, but
3030160	3035920	rather also as a form of what we call cognitive infrastructure. The embedding of linguistic
3035920	3042040	competence and hence symbolic reasoning in the inanimate and utterly non-anthropomorphic
3042040	3048580	materials and systems of the world for which here, mind is literally distributed. This
3048580	3054540	project, Whole Earth Codec, posits AI not as a brain in a petri dish, but as a synthetic
3054540	3060540	augmentation of the forms of intelligence that emerge in and as complex ecological niches.
3060540	3068540	It's by, this project is by Antikythera Studio researchers, Christina Lu, a DeepMind alum,
3068660	3076660	and Delana Tran and Connor Cook. The project takes AI as a landscape scale phenomenon, focusing
3076660	3084660	less on how AI may align with you or me than how it may align with AI in the wild, may align
3084660	3094660	with the wider ecosystem. AI as an inorganic participant in an organic increasingly self-modeling
3094820	3102080	living world. Put differently, Whole Earth Codec rethinks the position and application of
3102080	3108000	artificial intelligence as a form of planetary intelligence and considers potential and
3108000	3115200	necessary conditions for their alignment. It started by responding to a brief about the
3115200	3120620	quality of data used for foundation models and by quality, it was meant whether the data is
3120620	3127620	any good, but also what kind of data it is. Training models that would have global influence
3127620	3135620	on just whatever data happens to be left out in the open, all but guarantees some degree of
3135620	3142740	suboptimal quality. If the most interesting data that could, in theory, contribute to broad
3142740	3149620	base socially constructive purposes is both private and or privatized, then other approaches
3149620	3156240	are needed. Techniques like federated learning would allow that data to contribute to the
3156240	3162240	reweighting of common models without disclosing underlying values. We could, in principle,
3162240	3169960	have our cake and keep it private too. But for this project, such a rotation also implies a
3169960	3177500	shift in what kind of data should be produced. It ventures that aggregating data about
3177500	3184080	individual human users is only a fraction of what is possible and necessary for planetary
3184080	3191580	intelligence worth the name. It proposes a fundamental deindividuation of computational
3191580	3200000	observation in a focus instead on impersonal, ecological and systemic data. That is, instead of
3200000	3205620	centering on individual data, instead of centering on individual data with ecological data as a kind
3205620	3211900	of exceptional subsidiary, it inverts this. It posits data about individuals as a specific
3211900	3219000	subset of ecological data, which, as should be clear, traces a recurring theme in all of our
3219000	3227280	work, culture framed as a function of the planetary rather than the inverse. So, the scenario
3227280	3233960	it explores for planetary intelligence is one in which systems of sensing and modeling are
3233960	3243700	global, but importantly, it is an observatory looking not outward but inward. The self-attention
3243700	3250540	of the transformer model is posed as an alternative metaphor to the panopticon of Foucault. The
3250540	3256020	positions of the observer and the observed are less supervisor and supervised than they are
3256020	3265520	mutually recursive. The model is sensing itself and thereby the planet is sensing itself. The
3265520	3272760	transformer's self-referentiality is the figure, the allegory for planetary models as well. They
3272760	3281120	call this folding the gaze. The scenario also hinges on the figure and function of multimodality.
3281120	3288160	If we see computation itself as a kind of generic syntax between qualitatively unlike things and
3288160	3293960	actions, then this project locates this generic syntactical function in the sensing and modeling
3293960	3301380	applications of, as I say, AIs and landscape scale technology. The sensing and modeling system
3301380	3307880	is a system for the artificial transduction of planetary phenomena into integrated and
3307880	3315680	recombinant data, hence whole earth codec. Multimodality operates both at the level of the
3315680	3321560	kinds of phenomena that are incorporated and artificially mutualized and in the range of
3321560	3328120	applications and functions to which the system as a whole might be directed, mixing and matching
3328120	3336000	inputs and outputs. Multimodal phenomenon, transduced and filtered into a generic syntax,
3336040	3343680	outputted as multimodal application technologies. In this scenario, planetary intelligence enables
3343680	3351880	planetary ecologies, again inclusive of human systems, to recompose themselves because the
3351880	3359040	composition of whole earth codec as a technology for planetary composition enables the emergence
3359520	3371520	of that intelligence. Knowing enables making, but making makes knowing possible. Last project that
3371520	3384520	I'll show tonight. The, which is called vivarium. Perhaps the philosophy of simulation begins with
3384560	3391000	the beginnings of philosophy itself. In a cave in Greece where Plato and Socrates cultivated a
3391000	3398560	long-standing paranoia, not just of simulations, but of mediated perception and its relation to
3398560	3406920	thought. External and internal simulation in conflict or alignment. There in that cave, they
3406920	3412640	set the foundation not only as what would become a topic for philosophy, but perhaps, as I say,
3412720	3419760	the foundational paranoia from which Western philosophy was born. Now, the politics of
3419760	3425960	simulation can also be very personal. As you pass through a security gateway, perhaps at an
3425960	3432600	airport, what is under inspection is not only your physical person, but also trace digital
3432600	3439760	personas linked to you, but which live in a near-distance shadow city called the cloud. If the
3440200	3446160	uniform lets you pass, it's because a decision was made according to risk models on those silhouettes
3446160	3453640	of which your physical person is a reflection. Your ears may burn as the infrastructure whispers
3453640	3462080	about your doubles, but it's not just you that's in play. At home and at work, as AI and simulations
3462080	3467880	convene, the designer versus player distinction will collapse from both directions because large
3467880	3473120	AI models and large simulation models will themselves converge, the latter as the interface
3473120	3480720	to the former. Elsewhere, scientific simulations have proposed a different kind of planetary
3480720	3486640	politics around the frame of climate change that seeks to give political priority and agency to
3486640	3493880	large-scale long-duration simulations of macrological processes. It doesn't articulate itself as such,
3493920	3500440	but the core of this approach, the core of climate politics, I say, is an attempt to refocus
3500440	3506440	governmental attention from the mediation of voice to the mediation of ecologies and to make
3506440	3513840	scientifically significant simulations sovereign actors, to make simulations of the future in
3513840	3521160	order to govern the present. Now, Viverium, a project by Antikythera Studio researchers
3521160	3527000	Deliana Tran, Christina Lu, and Will Freudenheim deals with the question of sim to real rather
3527000	3533760	directly. It poses a platform for collective intelligence that aggregates multiple toy worlds
3533760	3540600	into a larger platform of worlds that can be used to train physicalized AI and to aggregate
3540600	3546600	collective data and thus collective intelligence. It works for one-to-one, one human, one AI,
3546720	3553920	between one human and many AIs, many humans in one AI, and perhaps most interestingly, for forms
3553920	3561440	of collaborative embodiment, many humans in many AIs. In practice, as already posed, simulations
3561440	3566560	are an epistemological technology. They are technologies to think with, which in principle
3566560	3573160	makes a philosophy of simulation, a philosophy of things to think with, central to the purpose of
3573160	3580480	any program such as ours. We recognize that simulations are pervasive. Our friends from
3580480	3586480	neuroscience raise the point that simulations are not only a kind of external technology with
3586480	3591520	which intelligence figures out the world, but simulations is how minds have intelligence at
3591520	3597560	all. The cortical columns of animal brains are constantly predicting what will be next,
3597560	3602360	running through little simulations of the world and the immediate future, resolving them with
3602360	3609160	new inputs and even competing with each other to organize perception and action. For many
3609160	3614680	computational simulations, their purpose is as a model that reflects reality such as one hopes
3614680	3621220	for climate science or astrophysics. For others, the back and forth is not just mirroring. Some
3621220	3626820	simulations not only model the world, but feed back upon what they model both directly and
3626820	3633340	indirectly. These we call recursive simulations. Recursive simulations are those which not only
3633340	3639700	model that reality, but allow us to intervene and interact with it as part of our embodied and
3639700	3647140	intentional experience in a decisive feedback loop. So what are called digital twins, perhaps a
3647140	3655460	form of personal AI, are one such dynamic. So as Vyvarium shows, many AIs, especially those
3655460	3660780	embodied in the world, such as driverless cars, are already trained in toy world simulations where
3660780	3667500	they can explore more freely, bumping into walls until they, like us, learn the best ways to
3667500	3674740	perceive and model and predict the real world. For the recursive simulation between simulation and
3674740	3681820	the real, in some ways the real is the baseline model for the simulations and simulations are
3681820	3689420	sometimes the baseline model for the real. Toy worlds serve as a kind of bounded domain of
3689420	3694660	constrained information exchange interaction between otherwise unlike and incompatible things
3694660	3699900	and actions. They are where some AIs learn to navigate the real world by navigating these
3699900	3708220	focused reduction simulations of their contours. The sim to real passage is not just in terms of
3708220	3714140	the implications of specific learned experiences, but also the physical virtual hybridization as
3714140	3723380	such. ML exists in the world. AI is on its way to become something like a generic solvent soaked
3723380	3729660	into things and into how they behave. And so the back and forth learning between artificial
3729660	3737020	intelligence and natural intelligence never really stops. For the project, there are, as said,
3737020	3743660	multiple possible combinations of human users, AI as prostheses, AI as users, human or humans as
3743660	3750620	prostheses. There are multiple combinations of embodiment, of agency, of action in and across
3750620	3757700	the simulation, the real and the recursion. Not just one to one, one to many, but ultimately many
3757700	3765300	to many. Keep in mind, however, for us the AI's world is a simulation of ours and one we can
3765300	3773940	interact with. The AI, our world, is just one part of the omni-simulation that it simply calls
3773940	3790780	reality. Let me conclude. And while I make some concluding remarks, I will show clips from a
3790780	3799540	fourth project called Xenoplex, which is on AI and the philosophy of biology, assembly theory and
3799540	3811340	empirical astrobiology. It's by Antikythera, Derenzu and Connor Cook. Back to where we began, back
3811340	3816780	to the Stanislaw Lem inspired distinction between existential or epistemological and
3816780	3827100	instrumental phases of technologies. So for AI, in terms of its instrumental impact, alignment
3827100	3834420	overfitting is itself a kind of existential risk. As said, capital A alignment is an inadequate
3834420	3842420	practical metaphysics for what AI orientation implies and demands. Now, I assume that most, if
3842420	3848460	not all, serious alignment researchers would not disagree. Now, if only the journalists,
3848460	3855740	influencers and charismatic mega critics would follow their lead. As for the AI epistemological
3855740	3861260	impact, what will be the ultimate impact of AI? The ultimate impact of AI will be on what we,
3861260	3866460	quote unquote, come to grasp about what we are, how we are, why we are and the contingencies of
3866460	3875060	that pronoun. What that will be, we don't know and we can't know. We can't really anticipate
3875060	3881500	Copernican shifts and traumas in advance. Just recall that we didn't confirm the existence of
3881500	3889420	other galaxies until 1924 or scientifically confident precise age of the earth until 1953.
3889420	3900740	We don't know, but we have to defend the space in which what we will learn will go. We may presume
3900740	3908700	that with regards to AI as an experimental super organism, one of those likely areas is what we
3908700	3915340	today call neuroscience and tomorrow may simply call philosophy and vice versa. So what are the
3915340	3922020	kinds of questions to be asked that are likely to lead in the direction of epistemic disclosure?
3922020	3927300	There's likely no wrong answers, but safe bets are that posing fundamental questions about what,
3927300	3934100	quote, life is and what intelligence is and why the words that we use may be inadequate
3934100	3942220	signifiers for the range of phenomenon that they hope to describe. Even the boundary position
3942220	3947620	between these is unclear as the boundary between life as is the boundary between life and technology
3947620	3953820	and intelligence and technology are already, not just for advanced computers but for anything.
3953820	3962300	Perhaps life is fundamentally something like evolutionary autopoiesis through niche
3962300	3971820	technologization or perhaps intelligence is or perhaps both. Biotic systems make use of
3971820	3978540	abiotic systems to replicate themselves as organisms and across generations. They can't
3978540	3985220	exist without this fundamental technologization of the world. If part of the definition of
3985220	3993100	intelligence is means agnostic problem solving, then this niche technologization is at least
3993100	4000300	partially intelligent. This cycle happens not just once or twice here and there, but
4000300	4007900	everywhere and constantly over and over for billions of years. It doesn't just happen on
4008260	4016260	the earth. It happens by the earth. Life slash intelligence slash technologization is something
4016260	4022860	that the earth does. And it not only does it, the earth makes and remakes itself through this
4022860	4029780	process, building scaffolds for the next slightly more complex scaffold which are incorporated
4029780	4036260	into the next scaffold and so on. It's why we have an atmosphere and why we have artificial
4036260	4044900	intelligence. Some planets, at least one, fold themselves over time into forms of matter capable
4044900	4050180	of not only participating in the cycle but of making abstractions about their own participation
4050180	4057980	in them and thereby recalibrate them. Human brains are one such form. But they're not
4057980	4063780	necessarily the only form capable of such abstractions. And nor are those brains
4063940	4068500	independent of the technical systems of machine sensing and modeling and simulation and
4068500	4074500	prediction that make those abstractions possible. Sapience itself is technological. More
4078260	4082900	specifically, it's clear that simulation is, as said, not only part of how animal brains
4082900	4087860	work, scientific inquiry works, how prediction works, it's ultimately how the recursion
4087860	4095100	necessary for direct composition works. Simulation, as we know it, is an advanced coupling of
4095100	4101100	biotic and abiotic systems. It is part of the scaffolding. That is, biospheres make
4103700	4111700	technospheres that create biospheres that use technospheres to comprehend the whole dynamic. I
4111700	4117340	think you see where I'm heading with this. What's called artificial intelligence is the
4117340	4123420	name for a form of technologization that can occupy more than one position in this cycle.
4123420	4129460	It can be part of the means of technical modeling that humans use to grasp planetary process.
4129460	4136500	But it can also be the form of intelligence that's doing the grasping. It can be not only a
4136500	4142500	means of planetary sapience but also co-constitutive of that sapience as such. That's one way in
4142660	4148660	which the epistemic implications of AI get really interesting and really weird. It's then
4152240	4157740	possible to locate AI not just in the reflective shadow of human intelligence but in the longer
4157740	4163720	arc of intelligence as a planetary phenomenon and in the emergence of planetary intelligence as
4163720	4170720	such. I suggested the very definition of these terms is, of course, put up for grabs not just by
4171240	4177240	philosophy but by what clearly intelligent machine systems are already doing and by the need to
4179080	4185080	shift the words to the reality. I repeat, to shift the words to the reality. I will end with
4187260	4193260	this. There is at present a dangerous disconnect between cosmology and cosmology. By this I mean
4194260	4201260	that if I go ask my friends in the astrophysics department, they will presume I want to know
4201260	4208260	more about black holes and big bangs and curvature of space time and that kind of stuff. But if I
4208260	4212220	go ask my friends in anthropology, they will presume I want to know about how different
4212220	4219100	cultures imagine eschatology, kinship, how they think the universe began accordingly in
4219100	4225100	relationship to those. Now, in the humanities there is, I am sorry to report, significant noise
4227400	4234060	generated around this disconnect. The conclusion drawn adamantly by some is that the
4234060	4241560	abstractions of scientific cosmology must be brought, quote, down to earth. Made to heal to the
4241560	4247560	sovereignty of human cultures. I, however, wonder what are the cultures, plural, of the
4249180	4255180	world that can be composed, not just inherited and lived and lived through that align their
4256640	4262640	ways with the disclosures of planetary processes with that sapience that make them possible and
4263980	4269980	which are graspable by them. That project is to collectively compose cosmologies adequate to the
4270860	4276860	challenge of long-term planetary viability. Not necessarily the reconciliation of that with the
4280060	4286060	diversity of cultural traditions by its subordination. That is, the disenchantment thesis
4288180	4294180	that modern secularization of the cosmos removed cosmological grounding from culture is wrong.
4295180	4301180	Instead, it made a real cosmology finally possible. Cultural cosmology emerges from the material
4303720	4309140	possibility of thought. And that material possibility of thought emerges from the physical
4309140	4315140	realities that are, in the long run, continuous among humans. Even if they exceed the
4315760	4323760	uncertain boundaries of whatever humans are. So, instead of reifying cultural traditions and
4323760	4330100	projecting them onto the universe, the better cosmopolitical project for the future is to
4330100	4336100	grasp what is both convergent, because evolutionary, and what is divergent, because human, in the
4337760	4343760	planetarization of civilizations and to derive abstraction and meaning accordingly. I hope
4347060	4353060	that the implications for AI alignment, for shifting the words to the reality, are clear.
4353760	4360180	What's at stake for that shift via AI is basically everything. Thank you.
